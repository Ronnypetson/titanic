{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j6dxGxcHAx5P"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ],
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx\n",
        "\n",
        "def _cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = (row + offset)\n",
        "        idx[row, col, ch, 1] = (col + offset)\n",
        "        idx[row, col, ch, 2] = (ch  + offset)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "def poly1norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  idxu = (0.5 ** 0.5) * torch.cat([idxu, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "def poly2norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  _idxu = idxu.reshape((-1, d_idx, 1))\n",
        "  middle = (\n",
        "      torch.bmm(_idxu, _idxu.permute(0, 2, 1))\n",
        "      .reshape((*idxu.shape[:-1], d_idx ** 2))\n",
        "  )\n",
        "  idxu = 0.5 * torch.cat([(2.0 ** 0.5) * idxu, middle, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _knndot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"k-NN Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  num_neigh = 1\n",
        "  dots = []\n",
        "  q_idxu = idxu.cpu().detach().numpy().reshape(-1, d_idx)\n",
        "  for _pos in range(n):\n",
        "    neigh = NearestNeighbors(n_neighbors=num_neigh)\n",
        "    neigh.fit(idxv[_pos].cpu().detach().numpy().reshape(-1, d_idx))\n",
        "    n_idxu = neigh.kneighbors(\n",
        "        q_idxu, return_distance=False\n",
        "    ).reshape(-1)\n",
        "    n_idxu = torch.from_numpy(n_idxu).long()\n",
        "    _v = v[_pos].reshape(-1, d_val)[n_idxu].reshape(m, d_u, d_val)\n",
        "    # _dot: M x d_val x d_val\n",
        "    _dot = torch.bmm(_v.permute(0, 2, 1), _v)\n",
        "    # _dot: M x 1 x d_val\n",
        "    _dot = torch.diagonal(_dot, dim1=1, dim2=2).unsqueeze(1)\n",
        "    dots.append(_dot)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.cat(dots, dim=1)\n",
        "  return dot\n",
        "\n",
        "def _fbmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Fast Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # uidxu: M x d_val x d_idx\n",
        "  # idxvv: N x d_idx x d_val\n",
        "  uidxu = torch.bmm(u.permute(0, 2, 1), idxu) # / d_u\n",
        "  idxvv = torch.bmm(idxv.permute(0, 2, 1), v) # / d_v\n",
        "  # dot: M x N x d_val\n",
        "  dot = (\n",
        "    (\n",
        "        uidxu.reshape(m * d_val, d_idx)\n",
        "        @ (\n",
        "            idxvv\n",
        "            .permute(0, 2, 1)\n",
        "            .reshape(n * d_val, d_idx)\n",
        "            .T\n",
        "          )\n",
        "    ).reshape(m, d_val, n, d_val)\n",
        "    .permute(0, 2, 1, 3)\n",
        "  )\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = 2 * int(np.log((d_u + d_v) // 2)) + 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "# def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, idx_part)\n",
        "#   kidxv = k(idxv, idx_part)\n",
        "#   d_idx_k = kidxu.shape[-1]\n",
        "#   assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "#   assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "#   sidx = (\n",
        "#       (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "#       + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "#   )\n",
        "#   sidx = sidx / norm\n",
        "#   sidx = sidx.repeat(batch_m, 1, 1)\n",
        "#   return sidx\n",
        "\n",
        "# def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "#   # iTki_kjTj: M x N x d_idx x d_idx\n",
        "#   iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "#   diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "#   ###\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   diag = diag / norm\n",
        "#   ###\n",
        "#   diag = diag.repeat(batch_m, 1, 1)\n",
        "#   return diag\n",
        "\n",
        "# def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # ski: (M * N) x d_idx\n",
        "#   # skj: (M * N) x d_idx\n",
        "#   # norm: M x N x 1\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "#   skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "#   # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "#   # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "#   idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "#   idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "#   kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "#   kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "#   # sikiT: M x d_idx x d_idx\n",
        "#   # sjkjT: N x d_idx x d_idx\n",
        "#   sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "#   sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "#   sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "#   sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "#   del kidxu\n",
        "#   del kidxv\n",
        "#   del idxu\n",
        "#   del idxv\n",
        "#   # sikiT: (M * N) x d_idx x d_idx\n",
        "#   # sjkjT: (M * N) x d_idx x d_idx\n",
        "#   sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "#   # skjjT = sjkjT.permute(0, 2, 1)\n",
        "#   # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "#   # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "#   xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "#   # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "#   # xor_idx = diag_sikiT_skjjT\n",
        "#   xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "#   xor_idx = xor_idx / norm\n",
        "#   return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    ###\n",
        "    # mdot = _nsbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = _fbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ### _knndot\n",
        "    # mdot = _knndot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, onesb, aidx, bidx)\n",
        "    #     + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    midx = (\n",
        "        _fbmd(aidx, onesb, aidx, bidx)\n",
        "        + _fbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _rdot(aidx, onesb, aidx, bidx)\n",
        "    #     + _rdot(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    # midx = _nsbmd(aidx, bidx, aidx, bidx)\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _knndot(aidx, onesb, aidx, bidx)\n",
        "    #     + _knndot(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # xidx = xidx / np.linalg.norm(xidx, axis=-1)[:, None]\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    # self._ones_idx = _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # self.activation = nn.ELU()\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.LeakyReLU()\n",
        "    self._probe = nn.Linear(self._feat_samples[-1], 10).to(device)\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    # _mag = 1.0\n",
        "    # _W = nn.Parameter(\n",
        "    #     _mag * torch.rand(shape, device=device) - (_mag / 2.0)\n",
        "    # )\n",
        "    # _mag = 10.0\n",
        "    # _W_idx = _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    # _mag = 0.001\n",
        "    # _template = _mag * torch.rand((1, idxdim), device=device) - (_mag / 2.0)\n",
        "    # _num_idx = np.prod(shape)\n",
        "    # _pos = torch.tensor([[pos + 1.0] for pos in range(_num_idx)]).to(device)\n",
        "    # _W_idx = nn.Parameter(_pos @ _template)\n",
        "    _mag = 1000.0\n",
        "    _W_idx = nn.Parameter(\n",
        "      _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    )\n",
        "    _std = 0.01\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((*shape, idxdim), device=device)\n",
        "    # )\n",
        "    # _W_idx = _std * torch.randn((*shape, idxdim), device=device)\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      ###\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      if (step < n_layers - 1):\n",
        "        pool = (\n",
        "            MTensor.reshape(\n",
        "                pool, (n * feat_sets[step], -1)\n",
        "            )\n",
        "            @ mw\n",
        "        )\n",
        "      else:\n",
        "        pool = self._probe(pool.data.reshape(n, -1))\n",
        "        pool = MTensor(\n",
        "            pool,\n",
        "            torch.zeros((*pool.shape, self._idx_dim)).to(pool.device)\n",
        "        )\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 100 # 3 # 10\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim, mag=1000.0)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rows, cols, d = 28, 28, 1000\n",
        "# template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=d, mag=1000.0)\n",
        "# tidx = template_x_idx.detach().numpy()\n",
        "# # plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# # fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "\n",
        "# ntidx = tidx / (np.linalg.norm(tidx, axis=-1)[:, None] + 1e-6)\n",
        "# # plot_df = pd.DataFrame({\"x\": ntidx[:, 0], \"y\": ntidx[:, 1], \"z\": ntidx[:, 2]})\n",
        "# # fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "\n",
        "# dots = ntidx @ ntidx.T\n",
        "# exp = 1.0\n",
        "# # dots = ((dots + 1.0) / 2.0) ** exp\n",
        "# ref = 1 / (rows * cols)\n",
        "# print((dots.mean(axis=-1) / ref).mean())\n",
        "# print()\n",
        "# _idx = 0 # (rows*cols) // 2\n",
        "# import seaborn as sns\n",
        "# sns.heatmap(dots[_idx].reshape(rows, cols))"
      ],
      "metadata": {
        "id": "x0gnLj8YEQno"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizações"
      ],
      "metadata": {
        "id": "8_m1YvjxBdj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ],
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b4d5a62e-b9fb-4c95-acdd-e5399c42499d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784, 1,],\n",
        "        \"samples\": [9, 784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [1, num_classes,],\n",
        "        \"samples\": [9, 784,],\n",
        "        \"is conv\": [False, False,]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.MW.idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 10 # 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.MW.idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    ###\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    _loss = loss.item()\n",
        "    # loss += 1e-1 * torch.cat(model._penalties, dim=0).sum()\n",
        "    ###\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(_loss)\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 1\n",
        "    _batchidx = 0\n",
        "    pool = model.all_pools[_layer]\n",
        "    pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "    display.clear_output(wait=True)\n",
        "    plot_features(pool)\n",
        "    from time import sleep\n",
        "    sleep(3)\n",
        "    #\n",
        "    # pool = model.all_samples[_layer - 1]\n",
        "    # _shape = (\n",
        "    #     config[\"features\"][\"sets\"][_layer - 1],\n",
        "    #     config[\"features\"][\"samples\"][_layer - 1],\n",
        "    # )\n",
        "    # _set = (config[\"features\"][\"sets\"][_layer - 1]) // 2\n",
        "    # pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "    # display.clear_output(wait=True)\n",
        "    # plot_features(pool)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "##\n",
        "# phi = idxu[0] @ idxv[0].T"
      ],
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "1SknOTQ7O9BS",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "Lyzd22RQX-Yg",
        "8_m1YvjxBdj9",
        "Y-K_7fUh2anJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNXl0yIdJS5InJ4/VVbQmkI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}