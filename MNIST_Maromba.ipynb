{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6/pXXCxCo4WCkaTnL8NQU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "RGCfrrmCXap_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "img_dim = 7\n",
        "\n",
        "def _transform(x):\n",
        "  x = x.resize((img_dim, img_dim))\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "\n",
        "bsize = 32\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "j6dxGxcHAx5P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _sin_arr(d, idx, rows):\n",
        "  _x = (np.arange(0, d) / d) * (4 * np.pi * (1 + idx / rows))\n",
        "  return np.sin(_x)\n",
        "\n",
        "def _cos_arr(d, idx, cols):\n",
        "  _x = (np.arange(0, d) / d) * (4 * np.pi * (1 + idx / cols))\n",
        "  return np.cos(_x)\n",
        "\n",
        "def _ind_arr(d, idx, bins):\n",
        "  _x = np.zeros(d)\n",
        "  idx = (d * idx) // bins\n",
        "  _x[idx] = 1.0\n",
        "  return _x\n",
        "\n",
        "def _2ind_arr(d, idx, bins):\n",
        "  return 2 * _ind_arr(d, idx, bins)\n",
        "\n",
        "def _bincat2d(rows, cols, d=32):\n",
        "  bitsr = len(format(rows, \"0b\"))\n",
        "  bitsc = len(format(cols, \"0b\"))\n",
        "  assert 2 * (bitsr + bitsc) <= d\n",
        "  idx = np.zeros((rows, cols, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      binr = format(row, f\"0{bitsr}b\")\n",
        "      binc = format(col, f\"0{bitsc}b\")\n",
        "      for pos, bit in enumerate(binr):\n",
        "        idxidx = 2 * pos + int(bit)\n",
        "        idx[row, col, idxidx] = 1.0\n",
        "      for pos, bit in enumerate(binc):\n",
        "        idxidx = 2 * bitsr + 2 * pos + int(bit)\n",
        "        idx[row, col, idxidx] = 1.0\n",
        "  return idx\n",
        "\n",
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def _posenc(shape, f_row, f_col, d=32, nonlin=None):\n",
        "  \"\"\"\n",
        "  3D Positional encodings (f_row(row) + f_col(col))\n",
        "  \"\"\"\n",
        "  assert len(shape) == 2\n",
        "  rows, cols = shape\n",
        "  idx_sin = np.zeros((rows, d))\n",
        "  idx_cos = np.zeros((cols, d))\n",
        "  for idx in range(rows):\n",
        "    idx_sin[idx] = f_row(d, idx, rows)\n",
        "  for idx in range(cols):\n",
        "    idx_cos[idx] = f_col(d, idx, cols)\n",
        "  idx_sin = torch.from_numpy(idx_sin)\n",
        "  idx_cos = torch.from_numpy(idx_cos)\n",
        "  idx = (\n",
        "      idx_sin.reshape((rows, 1, d)).repeat(1, cols, 1)\n",
        "      + idx_cos.reshape((1, cols, d)).repeat(rows, 1, 1)\n",
        "  )\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  if nonlin:\n",
        "    idx = nonlin(idx)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# binidx = _cat2d(5, 2, d=10)\n",
        "# binidx @ binidx.T\n",
        "# np.exp(binidx[0]) / np.exp(binidx[0]).sum()"
      ],
      "metadata": {
        "id": "taSPF5ITc5vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rows, cols, d = 5, 5, 32\n",
        "# pos = _posenc(\n",
        "#     (rows, cols),\n",
        "#     _ind_arr, # _sin_arr,\n",
        "#     _2ind_arr, # _cos_arr,\n",
        "#     d=d,\n",
        "#     nonlin=lambda x: x / 3.0, # torch.sigmoid\n",
        "# ).reshape(rows, cols, d)\n",
        "# fig, axs = plt.subplots(nrows=rows, ncols=cols, layout=None)\n",
        "# for row in range(rows):\n",
        "#   for col in range(cols):\n",
        "#     axs[row][col].plot(range(d), pos[row, col].numpy())\n",
        "# plt.show()\n",
        "# print(pos[0] @ pos[1].T)"
      ],
      "metadata": {
        "id": "fyWPtI28l-pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x, y = MNIST_train_data[5]\n",
        "# plt.imshow(np.array(x.reshape(7, 7))), y"
      ],
      "metadata": {
        "id": "KS12YlllA3xE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classe Tensor Maromba"
      ],
      "metadata": {
        "id": "kTfYY3SQXNJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def _gbmd(self, u, v, idxu, idxv, kernel=None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    'General Batch Maromba Dot'\n",
        "    Shorter implementation for the 'batch maromba dot' operation.\n",
        "    u: M x d_u\n",
        "    v: N x d_v\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u = u.shape\n",
        "    n, d_v = v.shape\n",
        "    d_idx = idxu.shape[-1]\n",
        "    assert (m, d_u, d_idx) == idxu.shape\n",
        "    assert (n, d_v, d_idx) == idxv.shape\n",
        "    if kernel:\n",
        "      idxu = kernel(idxu, self._idx_part)\n",
        "      idxv = kernel(idxv, self._idx_part)\n",
        "    # uidxu: M x d_idx\n",
        "    # vidxv: N x d_idx\n",
        "    uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "    vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "    dot = uidxu @ vidxv.T\n",
        "    ### Under experimentation\n",
        "    normalizer = idxu.sum(dim=1) @ idxv.sum(dim=1).T\n",
        "    dot = dot / normalizer\n",
        "    ###\n",
        "    return dot\n",
        "\n",
        "  @staticmethod\n",
        "  def _soft_kernel(idxu, part_dim):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    assert d_idx % part_dim == 0\n",
        "    norm_idxu = torch.softmax(idxu.reshape(m, d_u, -1, part_dim), dim=-1)\n",
        "    norm_idxu = norm_idxu.reshape(m, d_u, d_idx)\n",
        "    return norm_idxu\n",
        "\n",
        "  def _kernel_idx(self, idxu, idxv, k):\n",
        "    \"\"\"\n",
        "    k: callable: A x B x C -> A x B x C\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    # kidxu: M x d_u x d_idx\n",
        "    # kidxv: N x d_v x d_idx\n",
        "    kidxu = k(idxu, self._idx_part)\n",
        "    kidxv = k(idxv, self._idx_part)\n",
        "    assert kidxu.shape == idxu.shape\n",
        "    assert kidxv.shape == idxv.shape\n",
        "    # ski: (M * N) x d_idx\n",
        "    # skj: (M * N) x d_idx\n",
        "    # norm: M x N x 1\n",
        "    ski = kidxu.sum(dim=1)\n",
        "    skj = kidxv.sum(dim=1)\n",
        "    norm = (ski @ skj.T).unsqueeze(-1)\n",
        "    ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "    skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "    # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "    # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "    idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "    idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "    kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "    kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "    # sikiT: M x d_idx x d_idx\n",
        "    # sjkjT: N x d_idx x d_idx\n",
        "    sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "    sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "    sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "    sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "    # sikiT: (M * N) x d_idx x d_idx\n",
        "    # sjkjT: (M * N) x d_idx x d_idx\n",
        "    sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "    skjjT = sjkjT.permute(0, 2, 1)\n",
        "    diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "    diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "    xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "    xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "    xor_idx = xor_idx / norm\n",
        "    return xor_idx\n",
        "\n",
        "  def _xor_idx(self, idxu, idxv):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    ### Under experimentation\n",
        "    # idxu = nn.functional.relu(idxu)\n",
        "    # idxv = nn.functional.relu(idxv)\n",
        "    # norm_idxu = torch.softmax(idxu.reshape(m, d_u, -1, self._idx_part), dim=-1)\n",
        "    # norm_idxu = norm_idxu.reshape(m, d_u, d_idx)\n",
        "    # norm_idxv = torch.softmax(idxv.reshape(n, d_v, -1, self._idx_part), dim=-1)\n",
        "    # norm_idxv = norm_idxv.reshape(n, d_v, d_idx)\n",
        "    normalizer = idxu.sum(dim=1) @ idxv.sum(dim=1).T\n",
        "    normalizer = normalizer.unsqueeze(-1)\n",
        "    ###\n",
        "    # idxu: (M * d_u) x d_idx x 1\n",
        "    # idxv: (N * d_v) x d_idx x 1\n",
        "    idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "    idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "    # siiT: M x d_idx x d_idx\n",
        "    # sjjT: N x d_idx x d_idx\n",
        "    siiT = torch.bmm(idxu, idxu.permute(0, 2, 1))\n",
        "    siiT = siiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "    sjjT = torch.bmm(idxv, idxv.permute(0, 2, 1))\n",
        "    sjjT = sjjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1) ###\n",
        "    # siiT: (M * N) x d_idx x d_idx\n",
        "    # sjjT: (M * N) x d_idx x d_idx\n",
        "    siiT = siiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    sjjT = sjjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    # si: (M * N) x d_idx x 1\n",
        "    # sj: (M * N) x d_idx x 1\n",
        "    idxu = idxu.reshape(m, d_u, d_idx)\n",
        "    idxv = idxv.reshape(n, d_v, d_idx)\n",
        "    si = idxu.sum(dim=1).unsqueeze(1)\n",
        "    si = si.repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "    sj = idxv.sum(dim=1).unsqueeze(0)\n",
        "    sj = sj.repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "    diag_siiT_sjjT = torch.diagonal(torch.bmm(siiT, sjjT), dim1=1, dim2=2)\n",
        "    diag_siiT_sjjT = diag_siiT_sjjT.unsqueeze(-1)\n",
        "    # xor_idx = torch.bmm(siiT, sj) + torch.bmm(sjjT, si) - 2 * diag_siiT_sjjT\n",
        "    xor_idx = torch.bmm(siiT, sj) + torch.bmm(sjjT, si) - diag_siiT_sjjT\n",
        "    # xor_idx = xor_idx.reshape(m, n, d_idx) / d_u ### TODO: check this\n",
        "    xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "    # xor_idx = torch.sigmoid(xor_idx)\n",
        "    ### Under experimentation\n",
        "    xor_idx = xor_idx / normalizer\n",
        "    ###\n",
        "    return xor_idx\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns 'mdot'\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    mdot = self._gbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1]),\n",
        "        b.data.reshape(-1, b.data.shape[-1]),\n",
        "        aidx,\n",
        "        bidx,\n",
        "        kernel=MTensor._soft_kernel\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # midx = self._xor_idx(aidx, bidx)\n",
        "    midx = self._kernel_idx(aidx, bidx, MTensor._soft_kernel)\n",
        "    midx = midx.reshape(apre + bpre + (d_idx,))\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    # adata = self.data.reshape(n * out_a, in_a).unsqueeze(1)\n",
        "    # aidx = self.idx.reshape(n * out_a, in_a, d_idx)\n",
        "    # bdata = b.data.reshape(n * out_b, in_b).unsqueeze(1)\n",
        "    # bidx = b.idx.reshape(n * out_b, in_b, d_idx)\n",
        "    # # aidxa: N x out_a x d_idx\n",
        "    # # bidxb: N x out_b x d_idx\n",
        "    # aidxa = torch.bmm(adata, aidx).squeeze(1).reshape(n, out_a, d_idx)\n",
        "    # bidxb = torch.bmm(bdata, bidx).squeeze(1).reshape(n, out_b, d_idx)\n",
        "    # # dot: N x out_a x out_b\n",
        "    # dot = torch.bmm(aidxa, bidxb.permute(0, 2, 1))\n",
        "    # # idx = self._xor_idx(aidx, bidx)\n",
        "    # return dot\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ],
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classe do Módulo Treinável"
      ],
      "metadata": {
        "id": "yGg59zEqYGe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MModule(nn.Module):\n",
        "  def __init__(self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    _W_idx = torch.rand((1, n_params, idx_dim), device=device)\n",
        "    # _W_idx = nn.functional.relu(_W_idx)\n",
        "    # _W_idx = _W_idx / _W_idx.max()\n",
        "    self.W_idx = nn.Parameter(_W_idx)\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    self.activation = nn.ReLU()\n",
        "    # self.activation = nn.Tanh() # nn.Sigmoid()\n",
        "\n",
        "  def _msample(self, x: MTensor, n_sets, n_samples):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "\n",
        "    Returns\n",
        "    x_sets: N x n_sets x n_samples\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    x_sets = []\n",
        "    for _ in range(n_sets):\n",
        "      idx = np.random.choice(in_dim, n_samples, replace=False)\n",
        "      idx = torch.tensor(idx).long()\n",
        "      # x_sampled.data: N x 1 x n_samples\n",
        "      x_sampled = MTensor.unsqueeze(x[:, idx], dim=1)\n",
        "      x_sets.append(x_sampled)\n",
        "    # x_sets.data: N x n_sets x n_samples\n",
        "    x_sets = MTensor.cat(x_sets, dim=1)\n",
        "    return x_sets\n",
        "\n",
        "  def _W_step(\n",
        "      self,\n",
        "      x: MTensor,\n",
        "      W: MTensor,\n",
        "      sets,\n",
        "      samples,\n",
        "      random=True,\n",
        "      activation=True):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    # Put 1 into x\n",
        "    one = MTensor(\n",
        "        torch.ones(n, 1).to(self.device),\n",
        "        torch.ones(n, 1, idx_dim).to(self.device),\n",
        "    )\n",
        "    x = MTensor.cat([x, one], dim=1)\n",
        "    # Sample W\n",
        "    # W_sets = []\n",
        "    # for _ in range(self.sets):\n",
        "    #   idx = np.random.choice(self.n_params, self.samples, replace=False)\n",
        "    #   idx = torch.tensor(idx).long()\n",
        "    #   W_sets.append(self.MW[:, idx])\n",
        "    # W_sets = MTensor.cat(W_sets, dim=0)\n",
        "    # W_sets = self._msample(self.MW, self.sets, self.samples)\n",
        "    if random:\n",
        "      W_sets = self._msample(W, sets, samples)\n",
        "      W_sets = MTensor.squeeze(W_sets, 0)\n",
        "    else:\n",
        "      W_sets = MTensor.reshape(W, (sets, samples))\n",
        "    # mdot: N x sets\n",
        "    mdot = x @ W_sets\n",
        "    if activation:\n",
        "      mdot.data = self.activation(mdot.data)\n",
        "    return mdot\n",
        "\n",
        "  def _pool_step(self, x: MTensor, sets, samples, activation=True):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    # x0: N x 1 x samples\n",
        "    # x1: N x sets x samples\n",
        "    x0 = self._msample(x, 1, samples)\n",
        "    x1 = self._msample(x, sets, samples)\n",
        "    # mdot.data: N x sets\n",
        "    mdot = x0 * x1\n",
        "    mdot = MTensor.squeeze(mdot, 1)\n",
        "    if activation:\n",
        "      mdot.data = self.activation(mdot.data)\n",
        "    return mdot\n",
        "\n",
        "  def _forward(self, x: MTensor, n_steps=2):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    assert n_steps > 0\n",
        "    # pool: N x sets\n",
        "    activate = (n_steps > 1)\n",
        "    pool = self._W_step(x, activation=activate)\n",
        "    for step in range(1, n_steps):\n",
        "      # pool: N x (in_dim + step * sets)\n",
        "      activate = (step < n_steps - 1)\n",
        "      if step % 2 == 0:\n",
        "        pool_new = self._pool_step(pool, activation=activate)\n",
        "      else:\n",
        "        pool_new = self._W_step(pool, activation=activate)\n",
        "      pool = MTensor.cat([pool, pool_new], dim=1)\n",
        "    return pool_new\n",
        "  \n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    pool = x\n",
        "    # Pdb().set_trace()\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      pool = self._W_step(\n",
        "          pool,\n",
        "          self.MW[:, wl: wr],\n",
        "          self.sets[step],\n",
        "          self.samples[step],\n",
        "          random=False,\n",
        "          activation=activate\n",
        "      )\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ],
      "metadata": {
        "id": "Oipx_P9qYUUb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Custo"
      ],
      "metadata": {
        "id": "QQRFtDATXUmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, 7)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  # y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)"
      ],
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treino"
      ],
      "metadata": {
        "id": "039kGqbPXp4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "idx_dim = rows + cols + (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "\n",
        "# template_x_idx = _posenc(\n",
        "#     (rows, cols),\n",
        "#     _ind_arr,\n",
        "#     _2ind_arr,\n",
        "#     d=idx_dim,\n",
        "#     nonlin=lambda x: x / 3.0,\n",
        "# )\n",
        "template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MModule(\n",
        "    n_params=rows * cols * 100 + 100 * num_classes,\n",
        "    idx_dim=idx_dim,\n",
        "    samples=[rows * cols, 100],\n",
        "    sets=[100, num_classes],\n",
        "    device=device\n",
        ")\n",
        "optimizer = Adam(model.parameters(), lr=1e-1)\n",
        "\n",
        "num_epochs = 180\n",
        "batch_size = 32\n",
        "epoch_len = 60 # len(MNIST_train_data) // batch_size\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  # for x, y in iter(train_data_loader):\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    # Pdb().set_trace()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  model.eval()\n",
        "  for x, y in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    acc = maromba_accuracy(y, y_pred)\n",
        "    train_log[\"eval loss\"].append(loss.item())\n",
        "    train_log[\"train loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(acc.item())\n",
        "    train_log[\"set\"].append(\"eval\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  df_train[group_cols].groupby(\"epoch\").agg(lambda x: x.median(skipna=True)).plot(figsize=(24, 4))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "HNheVxvNNK30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "92915821-d8ee-45c4-bbd8-624129895cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(train_log)"
      ],
      "metadata": {
        "id": "jPdqOyP9Sdx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred.idx = nn.functional.softmax(y_pred.idx, dim=-1)\n",
        "y_pred.idx = MTensor._soft_kernel(y_pred.idx, img_dim)\n",
        "\n",
        "index_match = torch.bmm(y_pred.idx, y.idx.permute(0, 2, 1))\n",
        "# index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "# y_true_match: N x 1 x d_out(pred)\n",
        "# y_pred_match: N x 1 x d_out(true)\n",
        "y_pred_match = torch.bmm(y_pred.data.unsqueeze(1), index_match)"
      ],
      "metadata": {
        "id": "mGSWz0GB9api"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_match[0].sum(dim=-1)\n",
        "# y_pred_match\n",
        "# torch.argmax(y.data, dim=-1)"
      ],
      "metadata": {
        "id": "cR6CRFgWCpFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "loss = ce(y_pred_match.squeeze(1), torch.argmax(y.data, dim=-1))\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "lAQUfdi_9wUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred_match[0]\n",
        "# index_match[0]\n",
        "y_pred.idx[0]\n",
        "# y.idx[0]\n",
        "# y_pred.data[0: 5]\n",
        "# [param.grad.max() for param in model.parameters()]"
      ],
      "metadata": {
        "id": "teVFiPYE_KrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.MW.idx[0, 0]"
      ],
      "metadata": {
        "id": "2DWnC3k4LO6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GwvDxtrN_fEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}