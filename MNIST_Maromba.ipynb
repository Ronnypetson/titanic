{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa6e900-83c5-42a8-ecca-1d090822adf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_root/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 382918059.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 35081289.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_root/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 164128708.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6947676.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 348935889.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 80757129.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 126918048.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7769383.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  x = x.resize((img_dim, img_dim))\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "\n",
        "bsize = 32 ###\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, d=2):\n",
        "  idx = np.zeros((rows, cols, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      # idx[row, col, 0] = (1 + row) / rows\n",
        "      # idx[row, col, 1] = (1 + col) / cols\n",
        "      idx[row, col, 0] = 2.0 * ((row) / rows) - 1.0 ### (row + 1)\n",
        "      idx[row, col, 1] = 2.0 * ((col) / cols) - 1.0 ### (col + 1)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _sgbmd(u, v, idxu, idxv, sim=None, f=None, normalize=True) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Slow General Batch Maromba Dot\"\n",
        "  Slower, more general, implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  sim: index similarity function\n",
        "  f: value function\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  sim = Pairwise(sim)\n",
        "  f = Pairwise(f)\n",
        "  ###\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  ###\n",
        "  # sims: (M * N) x 1 x (d_u * d_v)\n",
        "  # vals: (M * N) x (d_u * d_v) x d_val\n",
        "  sims = sim(idxu, idxv).reshape(m * n, 1, d_u * d_v) ###\n",
        "  norm = 1.0\n",
        "  if normalize:\n",
        "    # norm: (M * N) x 1\n",
        "    norm = sims.sum(dim=-1)\n",
        "  vals = f(u, v)\n",
        "  vals = vals.reshape(m * n, d_u * d_v, d_val)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.bmm(sims, vals).squeeze(1)\n",
        "  eps = 1e-8\n",
        "  dot = (dot / (norm + eps)).reshape(m, n, d_val)\n",
        "  return dot\n",
        "\n",
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1\n",
        "  idxuv = idxu[bsidx].reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  # dot = dot / (normalizer + 1e-6)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    # kernel = _cosine_kernel\n",
        "    # mdot = _gbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1]),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1]),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel=kernel,\n",
        "    #     idx_part=self._idx_part,\n",
        "    # )\n",
        "    # mdot = _sgbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     f=vecprod,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = _nsbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # _kernel_idx # _fast_kernel_idx # _fast_kernel_idx_sum\n",
        "    # midx = _fast_kernel_idx_sum(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel,\n",
        "    #     self._idx_part,\n",
        "    # )\n",
        "    # midx = _sgbmd(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     # f=vecsum,\n",
        "    #     f=vecmean,\n",
        "    # )\n",
        "    ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # midx = norm_normalize(\n",
        "    #     norm_normalize(_nsbmd(aidx, onesb, aidx, bidx))\n",
        "    #     + norm_normalize(_nsbmd(onesa, bidx, aidx, bidx))\n",
        "    # )\n",
        "    # midx = norm_normalize(_nsbmd(aidx, bidx, aidx, bidx))\n",
        "    ###\n",
        "    midx = (\n",
        "        _nsbmd(aidx, onesb, aidx, bidx)\n",
        "        + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _rdot(aidx, onesb, aidx, bidx)\n",
        "    #     + _rdot(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "def idx2d(\n",
        "    channels: int,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    stride: int=2,\n",
        "    dilation: int=1,\n",
        "    device=\"cpu\"\n",
        "  ):\n",
        "  idx = []\n",
        "  dilh = 1 + dilation * (h - 1)\n",
        "  dilw = 1 + dilation * (w - 1)\n",
        "  for row in range(0, rows - (dilh - 1), stride):\n",
        "    for col in range(0, cols - (dilw - 1), stride):\n",
        "      for ch in range(channels):\n",
        "        for drow in range(0, dilh, dilation):\n",
        "          for dcol in range(0, dilw, dilation):\n",
        "            idx.append(\n",
        "                cols * rows * ch\n",
        "                + cols * (row + drow)\n",
        "                + (col + dcol)\n",
        "            )\n",
        "  idx = torch.tensor(idx).long().to(device)\n",
        "  return idx\n",
        "\n",
        "def unsort(idxs):\n",
        "  ridxs = [0 for _ in idxs]\n",
        "  for i, idx in enumerate(idxs):\n",
        "    ridxs[idx] = i\n",
        "  ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "  return ridxs\n",
        "\n",
        "def get_perms(tmp_idx):\n",
        "  idxs, _idxs = [], []\n",
        "  for dim in range(tmp_idx.shape[-1]):\n",
        "    ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "    idxs.append(ordering.cpu().detach())\n",
        "    _idxs.append(unsort(ordering).cpu().detach())\n",
        "  return idxs, _idxs\n",
        "\n",
        "def resort(k, src, tgt):\n",
        "  assert src == 0 or tgt == 0\n",
        "  global idxs, _idxs\n",
        "  if tgt == 0:\n",
        "    return idxs[src][k]\n",
        "  return _idxs[tgt][k]\n",
        "\n",
        "def hoods(dims, k0, w, _min=0, _max=None):\n",
        "  assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "  if len(dims) == 0:\n",
        "    return [k0] # [k0.item()]\n",
        "  _hoods = []\n",
        "  global idxs, _idxs\n",
        "  _k0d = resort(k0, 0, dims[-1]) #, idxs, _idxs)\n",
        "  for _w in range(-(w[-1] // 2), (w[-1] // 2) + (w[-1] % 2)):\n",
        "    # k0d = min(_max, max(_min, _k0d + _w))\n",
        "    k0d = torch.clip(_k0d + _w, min=_min, max=_max)\n",
        "    _hoods += hoods(\n",
        "        dims[:-1],\n",
        "        resort(\n",
        "            k0d,\n",
        "            dims[-1], 0,\n",
        "            # idxs, _idxs\n",
        "        ),\n",
        "        w[:-1],\n",
        "        # idxs, _idxs,\n",
        "        _min, _max\n",
        "    )\n",
        "  return _hoods\n",
        "\n",
        "idxs, _idxs = None, None\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods\n",
        "\n",
        "def _idxhood(xidx, ws, stride):\n",
        "  \"\"\"\n",
        "  xidx: in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  dims = tuple(range(xidx.shape[-1]))\n",
        "  global idxs, _idxs\n",
        "  idxs, _idxs = get_perms(xidx)\n",
        "  pivots = torch.tensor([piv for piv in range(0, len(xidx), stride)]).long()\n",
        "  all_hoods = hoods(dims, pivots, ws, 0, len(xidx) - 1)\n",
        "  # all_hoods = torch.tensor(all_hoods).long().T.reshape(-1)\n",
        "  all_hoods = torch.cat(all_hoods, dim=0).reshape(len(all_hoods), -1).T\n",
        "  all_hoods = all_hoods.reshape(-1)\n",
        "  # Pdb().set_trace()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdZ8zHIcPQPS"
      },
      "source": [
        "#### MModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tQoFxrDIPScK"
      },
      "outputs": [],
      "source": [
        "class MModule(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _W_step(\n",
        "      self,\n",
        "      x: MTensor,\n",
        "      W: MTensor,\n",
        "      sets,\n",
        "      samples,\n",
        "      random=True,\n",
        "      conv=False,\n",
        "      filter_size=4,\n",
        "      activation=True,\n",
        "      regular_dot=False):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    # Put 1 into x\n",
        "    if not conv:\n",
        "      filter_size = in_dim\n",
        "    assert (in_dim % filter_size) == 0\n",
        "    num_windows = (in_dim // filter_size)\n",
        "    # one = MTensor(\n",
        "    #     torch.ones((n * num_windows), 1).to(self.device),\n",
        "    #     torch.ones((n * num_windows), 1, idx_dim).to(self.device),\n",
        "    # )\n",
        "    x = MTensor.reshape(x, (n * num_windows, filter_size))\n",
        "    # Sample W\n",
        "    if conv:\n",
        "      ### filter_size + 1\n",
        "      assert (sets * samples) % (filter_size) == 0\n",
        "      numw_windows = (sets * samples) // (filter_size)\n",
        "      sets, samples = numw_windows, (filter_size)\n",
        "    W_sets = MTensor.reshape(W, (sets, samples))\n",
        "    ## mdot: N x sets\n",
        "    # mdot: (N * num_windows) x numw_windows\n",
        "    mdot = x @ W_sets\n",
        "    if activation:\n",
        "      mdot.data = self.activation(mdot.data)\n",
        "    # mdot: N x num_windows x numw_windows\n",
        "    if conv:\n",
        "      ### Várias \"imagens\" coladas em um sentido\n",
        "      mdot = MTensor.reshape(mdot, (n, num_windows, numw_windows))\n",
        "    return mdot\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    channels = 1\n",
        "    img_h, img_w = img_dim, img_dim\n",
        "    filter_whs = [(3, 3), (3, 3)]\n",
        "    strides = [2, 1]\n",
        "    filter_w, filter_h = filter_whs[0]\n",
        "    stride = strides[0]\n",
        "    filter_area = filter_w * filter_h\n",
        "    filter_volume = channels * filter_area\n",
        "    self.all_pools = [x[:4]]\n",
        "    idx = idx2d(\n",
        "        channels,\n",
        "        img_h, img_w,\n",
        "        filter_w, filter_h,\n",
        "        stride=stride,\n",
        "        device=self.device\n",
        "    )\n",
        "    x = x[:, idx]\n",
        "    ###\n",
        "    pool = x\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      if conv:\n",
        "        pool = self._W_step(\n",
        "            pool,\n",
        "            self.MW[:, wl: wr],\n",
        "            self.sets[step],\n",
        "            self.samples[step],\n",
        "            random=False,\n",
        "            conv=conv,\n",
        "            filter_size=filter_volume,\n",
        "            activation=activate,\n",
        "        )\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        filter_volume = channels * filter_area\n",
        "        pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # assert img_dim % stride == 0\n",
        "        img_h = (img_h - filter_h + stride) // stride\n",
        "        img_w = (img_w - filter_w + stride) // stride\n",
        "        assert img_h * img_w == img_area\n",
        "        # cols = pool.data.shape[1] // rows\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        filter_w, filter_h = filter_whs[nxt_conv_step]\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_area = filter_w * filter_h\n",
        "        filter_volume = channels * filter_area\n",
        "        if nxt_conv:\n",
        "          idx = idx2d(\n",
        "              channels,\n",
        "              img_h, img_w,\n",
        "              filter_w, filter_h,\n",
        "              stride=stride,\n",
        "              device=self.device\n",
        "          )\n",
        "          pool = pool[:, idx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mlldpkcPFvk"
      },
      "source": [
        "#### MModule II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oipx_P9qYUUb"
      },
      "outputs": [],
      "source": [
        "class MModule2(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "    self._prev_idx = None\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    # filter_whs = [(3, 3, 1), (3, 3, 1), (3, 3, 1), (3, 3, 1), (3, 3, 1), (3, 3, 1)]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1] # [1, 1, 1, 1, 1, 1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0]) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    # idxw = idxhood(\n",
        "    #     mw.idx,\n",
        "    #     filter_whs[0],\n",
        "    #     strides[0]\n",
        "    # ) ### FIX\n",
        "    # mw = mw[:, idxw]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        # pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step]\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "      # param_stride = (wl + wr) // 2 # wr\n",
        "      # next_wr = param_stride + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      # wl, wr = param_stride, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MModule III"
      ],
      "metadata": {
        "id": "4NH27yFEuqtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ],
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MModule IV"
      ],
      "metadata": {
        "id": "vCh8kNiFl15G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(\n",
        "        x.idx[0],\n",
        "        feat_samples[0],\n",
        "        num_sets=feat_sets[0],\n",
        "        sample=True\n",
        "    )\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # Pdb().set_trace()\n",
        "      pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      if step < n_layers - 1:\n",
        "        # pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      # pool: N x num_windows x numw_windows\n",
        "      self.all_pools.append(pool[:4])\n",
        "      nxt_step = step + 1\n",
        "      idxx = idxhood(\n",
        "          pool.idx[0],\n",
        "          feat_samples[nxt_step],\n",
        "          num_sets=feat_sets[nxt_step],\n",
        "          sample=True,\n",
        "      )\n",
        "      pool = pool[:, idxx]\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ],
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  y_pred = 10.0 * y_pred.data\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, d=idx_dim)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNheVxvNNK30"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 50\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    (2, 3, 3),\n",
        "    (2, 3, 3),\n",
        "    # (2, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    hidden_dim,\n",
        "]\n",
        "\n",
        "sets = [samp[0] for samp in samples[1:-1]] + [1, num_classes]\n",
        "_samples = [int(np.prod(samp)) for samp in samples]\n",
        "conv_params = int(np.array(_samples[:-1]).dot(np.array(sets[:-1])))\n",
        "# conv_params = int(np.prod(np.array(samples[:-1])))\n",
        "n_params = int(np.array(_samples).dot(np.array(sets)))\n",
        "# n_params = conv_params + hidden_dim * num_classes\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  # model = MModule2(\n",
        "  model = MModule3(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ],
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5tP_tfMAjw",
        "outputId": "da7f13b4-ace3-4667-9721-d95f2372d4a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([4, 784]), torch.Size([4, 392, 2])]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "ZRWVQRznvaer",
        "outputId": "0e3ef0a8-d6cb-4853-bfcb-9002ecdd57b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([392, 2])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11b971a5-7b73-4315-97a2-ea7e20e7ad66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784, 3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"af567639-5d69-4561-81ca-677168ac37a9\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"af567639-5d69-4561-81ca-677168ac37a9\")) {                    Plotly.newPlot(                        \"af567639-5d69-4561-81ca-677168ac37a9\",                        [{\"x\":[-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.9285714030265808,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.8571428656578064,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7857142686843872,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.7142857313156128,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.6428571343421936,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5714285969734192,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.4285714328289032,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.3571428656578064,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2857142984867096,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.2142857164144516,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.1428571492433548,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,-0.0714285746216774,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.0714285746216774,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2142857164144516,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.3571428656578064,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.6428571343421936,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.7857142686843872,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808,0.9285714030265808],\"y\":[-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808,-1.0,-0.9285714030265808,-0.8571428656578064,-0.7857142686843872,-0.7142857313156128,-0.6428571343421936,-0.5714285969734192,-0.5,-0.4285714328289032,-0.3571428656578064,-0.2857142984867096,-0.2142857164144516,-0.1428571492433548,-0.0714285746216774,0.0,0.0714285746216774,0.1428571492433548,0.2142857164144516,0.2857142984867096,0.3571428656578064,0.4285714328289032,0.5,0.5714285969734192,0.6428571343421936,0.7142857313156128,0.7857142686843872,0.8571428656578064,0.9285714030265808],\"z\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter3d\",\"scene\":\"scene\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,0.45],\"y\":[0.0,1.0]}},\"scene2\":{\"domain\":{\"x\":[0.55,1.0],\"y\":[0.0,1.0]}},\"height\":600,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('af567639-5d69-4561-81ca-677168ac37a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([392, 2, 3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"24750007-f08a-4964-ba5a-79c77eeb2958\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"24750007-f08a-4964-ba5a-79c77eeb2958\")) {                    Plotly.newPlot(                        \"24750007-f08a-4964-ba5a-79c77eeb2958\",                        [{\"x\":[-4.0521368980407715,-4.814864158630371,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.5084228515625,-5.161924362182617,-5.5084228515625,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.508423328399658,-5.161923885345459,-5.5084228515625,-5.161923885345459,-5.5084228515625,-4.51885986328125,-5.162936687469482,-4.318215847015381,-4.9533185958862305,-4.05213737487793,-4.814864635467529,-4.05213737487793,-4.814864635467529,-4.05213737487793,-4.8148651123046875,-4.05213737487793,-4.814864635467529,-4.05213737487793,-4.8148651123046875,-4.05213737487793,-4.8148651123046875,-4.05213737487793,-4.814864635467529,-4.05213737487793,-4.814864635467529,-4.05213737487793,-4.814864635467529,-4.05213737487793,-4.8148651123046875,-4.0521368980407715,-4.814864635467529,-4.0521368980407715,-4.814864635467529,-4.052136421203613,-4.814864158630371,-3.8978354930877686,-4.603098392486572,-3.730710029602051,-4.493435859680176,-3.730710029602051,-4.493436336517334,-3.730710029602051,-4.493436336517334,-3.7307097911834717,-4.493436336517334,-3.7307097911834717,-4.493436336517334,-3.7307095527648926,-4.493436336517334,-3.7307095527648926,-4.493436336517334,-3.7307093143463135,-4.493435859680176,-3.7307093143463135,-4.493435859680176,-3.7307095527648926,-4.493436336517334,-3.7307093143463135,-4.493435859680176,-3.7307095527648926,-4.493436336517334,-3.7307093143463135,-4.493435859680176,-3.5764074325561523,-4.281670093536377,-3.4092800617218018,-4.172007083892822,-3.4092800617218018,-4.172007083892822,-3.4092798233032227,-4.1720075607299805,-3.4092795848846436,-4.172007083892822,-3.4092798233032227,-4.1720075607299805,-3.4092795848846436,-4.1720075607299805,-3.4092795848846436,-4.172007083892822,-3.4092795848846436,-4.172007083892822,-3.4092795848846436,-4.172007083892822,-3.4092795848846436,-4.172007083892822,-3.4092798233032227,-4.172007083892822,-3.4092798233032227,-4.1720075607299805,-3.4092798233032227,-4.1720075607299805,-3.2549784183502197,-3.9602413177490234,-3.087852716445923,-3.850579261779785,-3.087852716445923,-3.850579261779785,-3.0878524780273438,-3.850579261779785,-3.087852716445923,-3.850579261779785,-3.087852716445923,-3.8505795001983643,-3.0878524780273438,-3.850579261779785,-3.0878524780273438,-3.850579261779785,-3.0878522396087646,-3.8505795001983643,-3.0878522396087646,-3.8505795001983643,-3.0878524780273438,-3.8505795001983643,-3.0878522396087646,-3.850579261779785,-3.0878522396087646,-3.8505797386169434,-3.0878520011901855,-3.8505795001983643,-2.9335501194000244,-3.638813018798828,-2.766422748565674,-3.5291502475738525,-2.766422748565674,-3.5291502475738525,-2.766422748565674,-3.5291502475738525,-2.766422748565674,-3.5291502475738525,-2.7664225101470947,-3.5291504859924316,-2.7664225101470947,-3.5291502475738525,-2.7664225101470947,-3.5291502475738525,-2.7664225101470947,-3.5291502475738525,-2.7664225101470947,-3.5291502475738525,-2.7664225101470947,-3.5291502475738525,-2.7664225101470947,-3.5291502475738525,-2.7664225101470947,-3.5291502475738525,-2.7664225101470947,-3.5291502475738525,-2.612121820449829,-3.317384719848633,-2.444995641708374,-3.2077221870422363,-2.444995641708374,-3.2077221870422363,-2.444995641708374,-3.2077224254608154,-2.444995164871216,-3.2077221870422363,-2.444995641708374,-3.2077221870422363,-2.444995164871216,-3.2077221870422363,-2.444995164871216,-3.2077221870422363,-2.444995164871216,-3.2077221870422363,-2.444995164871216,-3.2077221870422363,-2.444995164871216,-3.2077221870422363,-2.444995164871216,-3.2077226638793945,-2.4449949264526367,-3.2077224254608154,-2.4449949264526367,-3.2077224254608154,-2.2906930446624756,-2.9959559440612793,-2.123565912246704,-2.886293411254883,-2.123565912246704,-2.886293411254883,-2.123565912246704,-2.886293411254883,-2.123565912246704,-2.8862931728363037,-2.123565912246704,-2.886293411254883,-2.123565912246704,-2.886293411254883,-2.123565912246704,-2.8862931728363037,-2.123565912246704,-2.886293411254883,-2.123565912246704,-2.886293411254883,-2.123565912246704,-2.8862931728363037,-2.123565912246704,-2.8862931728363037,-2.123565912246704,-2.8862931728363037,-2.123565912246704,-2.8862931728363037,-1.969264030456543,-2.674527168273926,-1.8021377325057983,-2.5648646354675293,-1.8021376132965088,-2.5648646354675293,-1.8021376132965088,-2.5648646354675293,-1.8021376132965088,-2.5648646354675293,-1.8021377325057983,-2.5648651123046875,-1.8021376132965088,-2.5648648738861084,-1.8021376132965088,-2.5648648738861084,-1.8021374940872192,-2.5648648738861084,-1.8021376132965088,-2.5648646354675293,-1.8021374940872192,-2.5648648738861084,-1.8021373748779297,-2.5648648738861084,-1.8021373748779297,-2.5648648738861084,-1.8021373748779297,-2.5648648738861084,-1.6478358507156372,-2.3530988693237305,-1.4807090759277344,-2.243436336517334,-1.480709195137024,-2.243436336517334,-1.480709195137024,-2.243436336517334,-1.4807090759277344,-2.243436336517334,-1.480709195137024,-2.243436336517334,-1.4807090759277344,-2.243436336517334,-1.4807090759277344,-2.243436336517334,-1.4807089567184448,-2.243436336517334,-1.4807090759277344,-2.243436336517334,-1.480709195137024,-2.243436336517334,-1.4807089567184448,-2.243436098098755,-1.4807089567184448,-2.243436098098755,-1.4807089567184448,-2.243436336517334,-1.3264071941375732,-2.031670331954956,-1.1592806577682495,-1.9220077991485596,-1.1592806577682495,-1.9220077991485596,-1.1592806577682495,-1.9220077991485596,-1.15928053855896,-1.92200767993927,-1.159280776977539,-1.9220077991485596,-1.15928053855896,-1.92200767993927,-1.15928053855896,-1.92200767993927,-1.1592806577682495,-1.9220077991485596,-1.1592806577682495,-1.9220077991485596,-1.15928053855896,-1.92200767993927,-1.1592804193496704,-1.9220077991485596,-1.1592804193496704,-1.9220077991485596,-1.1592804193496704,-1.9220077991485596,-1.0049785375595093,-1.7102417945861816,-0.8378516435623169,-1.600579023361206,-0.8378516435623169,-1.600579023361206,-0.8378516435623169,-1.600579023361206,-0.8378516435623169,-1.600579023361206,-0.837851881980896,-1.600579023361206,-0.8378518223762512,-1.6005791425704956,-0.8378518223762512,-1.6005791425704956,-0.8378517627716064,-1.600579023361206,-0.8378517627716064,-1.600579023361206,-0.8378516435623169,-1.600579023361206,-0.8378516435623169,-1.600579023361206,-0.8378516435623169,-1.600579023361206,-0.8378516435623169,-1.600579023361206,-0.6835498809814453,-1.388812780380249,-0.5164234042167664,-1.2791504859924316,-0.5164234042167664,-1.2791504859924316,-0.5164234042167664,-1.2791504859924316,-0.5164234638214111,-1.2791506052017212,-0.5164234638214111,-1.2791506052017212,-0.5164233446121216,-1.2791506052017212,-0.5164233446121216,-1.2791506052017212,-0.5164232850074768,-1.2791507244110107,-0.5164232850074768,-1.2791507244110107,-0.5164234638214111,-1.2791506052017212,-0.5164231657981873,-1.2791504859924316,-0.5164231657981873,-1.2791504859924316,-0.5164231657981873,-1.2791504859924316,-0.36212173104286194,-1.0673847198486328,-0.19499479234218597,-0.9577219486236572,-0.19499485194683075,-0.9577218890190125,-0.19499479234218597,-0.9577219486236572,-0.19499479234218597,-0.957722008228302,-0.19499491155147552,-0.9577219486236572,-0.1949947327375412,-0.9577219486236572,-0.19499479234218597,-0.9577219486236572,-0.19499467313289642,-0.957722008228302,-0.1949947327375412,-0.9577219486236572,-0.19499467313289642,-0.9577219486236572,-0.19499459862709045,-0.9577220678329468,-0.19499456882476807,-0.9577218890190125,-0.19499465823173523,-0.957722008228302,-0.04069281369447708,-0.7459560036659241,0.12643380463123322,-0.636293351650238,0.12643374502658844,-0.636293351650238,0.12643374502658844,-0.636293351650238,0.126433864235878,-0.6362934112548828,0.12643367052078247,-0.6362934112548828,0.12643392384052277,-0.6362934112548828,0.126433864235878,-0.6362934112548828,0.126433864235878,-0.636293351650238,0.12643392384052277,-0.636293351650238,0.12643380463123322,-0.636293351650238,0.12643399834632874,-0.636293351650238,0.12643399834632874,-0.6362934708595276,0.12643396854400635,-0.6362934112548828,0.28073573112487793,-0.4245273470878601,0.4478623867034912,-0.31486475467681885,0.4478623867034912,-0.3148646950721741,0.4478623867034912,-0.3148646950721741,0.447862446308136,-0.31486475467681885,0.4478622078895569,-0.3148648142814636,0.44786232709884644,-0.31486475467681885,0.447862446308136,-0.31486475467681885,0.44786250591278076,-0.3148648142814636,0.447862446308136,-0.3148648142814636,0.44786250591278076,-0.31486478447914124,0.44786253571510315,-0.3148648142814636,0.44786256551742554,-0.31486475467681885,0.44786256551742554,-0.3148648738861084,0.6021642684936523,-0.10309886932373047,0.7692911624908447,0.006563782691955566,0.7692911624908447,0.006563782691955566,0.7692911624908447,0.006563782691955566,0.7692911624908447,0.006563782691955566,0.7692910432815552,0.006563782691955566,0.7692910432815552,0.006563842296600342,0.7692911624908447,0.006563782691955566,0.7692911624908447,0.006563961505889893,0.7692911624908447,0.006563901901245117,0.7692910432815552,0.006563842296600342,0.7692911624908447,0.006563961505889893,0.7692911624908447,0.006563961505889893,0.7692911624908447,0.006563961505889893,0.923592746257782,0.21832966804504395,1.09071946144104,0.3279922604560852,1.09071946144104,0.3279922604560852,1.09071946144104,0.3279922604560852,1.0907193422317505,0.32799232006073,1.09071946144104,0.32799232006073,1.09071946144104,0.32799232006073,1.0907193422317505,0.32799232006073,1.0907193422317505,0.32799232006073,1.0907193422317505,0.32799232006073,1.09071946144104,0.32799232006073,1.0907195806503296,0.32799232006073,1.0907195806503296,0.32799232006073,1.0907195806503296,0.32799232006073,1.2450217008590698,0.5397582650184631,1.412148356437683,0.649420976638794,1.412148356437683,0.649420976638794,1.412148356437683,0.649420976638794,1.4121482372283936,0.649420976638794,1.4121479988098145,0.649420976638794,1.4121482372283936,0.6494208574295044,1.412148356437683,0.6494209170341492,1.4121482372283936,0.6494210362434387,1.4121482372283936,0.6494210958480835,1.4121482372283936,0.6494209170341492,1.4121484756469727,0.6494210362434387,1.4121484756469727,0.6494210362434387,1.4121484756469727,0.6494210362434387,1.5664503574371338,0.8611868619918823,1.7335766553878784,0.9708496332168579,1.7335766553878784,0.9708495736122131,1.7335765361785889,0.9708496332168579,1.733576774597168,0.9708496332168579,1.7335764169692993,0.9708495140075684,1.733576774597168,0.9708495736122131,1.733576774597168,0.9708495736122131,1.7335766553878784,0.970849335193634,1.7335766553878784,0.9708495736122131,1.7335768938064575,0.9708495736122131,1.7335768938064575,0.9708494544029236,1.7335768938064575,0.9708495736122131,1.7335768938064575,0.9708495140075684,1.8878782987594604,1.1826153993606567,2.0550053119659424,1.2922780513763428,2.0550053119659424,1.2922781705856323,2.0550053119659424,1.2922780513763428,2.0550053119659424,1.2922780513763428,2.0550053119659424,1.2922780513763428,2.0550053119659424,1.2922780513763428,2.0550050735473633,1.2922779321670532,2.0550053119659424,1.2922779321670532,2.0550053119659424,1.2922780513763428,2.0550050735473633,1.2922779321670532,2.0550053119659424,1.2922778129577637,2.0550055503845215,1.2922778129577637,2.0550053119659424,1.2922778129577637,2.2093071937561035,1.5040438175201416,2.3764333724975586,1.613706350326538,2.3764333724975586,1.613706350326538,2.3764333724975586,1.613706350326538,2.3764336109161377,1.6137064695358276,2.3764333724975586,1.6137064695358276,2.3764336109161377,1.6137064695358276,2.3764336109161377,1.6137064695358276,2.3764336109161377,1.613706350326538,2.3764336109161377,1.613706350326538,2.3764336109161377,1.6137064695358276,2.3764336109161377,1.6137065887451172,2.3764336109161377,1.613706350326538,2.3764336109161377,1.6137065887451172,2.530735969543457,1.825472354888916,2.6978628635406494,1.9351356029510498,2.6978628635406494,1.9351356029510498,2.6978628635406494,1.9351356029510498,2.6978628635406494,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.6978631019592285,1.9351356029510498,2.8521645069122314,2.1469013690948486,3.0192902088165283,2.256563425064087,3.0192902088165283,2.256563425064087,3.0192902088165283,2.256563425064087,3.0192904472351074,2.256563425064087,3.0192902088165283,2.256563425064087,3.0192904472351074,2.256563425064087,3.0192904472351074,2.256563425064087,3.0192906856536865,2.256563425064087,3.0192906856536865,2.256563425064087,3.0192904472351074,2.256563425064087,3.0192904472351074,2.256563186645508,3.0192904472351074,2.256563425064087,3.0192906856536865,2.256563425064087,3.1735928058624268,2.468329906463623,3.3407201766967773,2.5779926776885986,3.3407201766967773,2.5779926776885986,3.3407201766967773,2.5779924392700195,3.340719699859619,2.5779926776885986,3.3407204151153564,2.5779926776885986,3.3407199382781982,2.5779926776885986,3.3407199382781982,2.5779926776885986,3.3407201766967773,2.5779926776885986,3.3407201766967773,2.5779926776885986,3.3407199382781982,2.5779926776885986,3.3407199382781982,2.5779922008514404,3.3407199382781982,2.5779926776885986,3.3407199382781982,2.5779922008514404,3.4950218200683594,2.7897584438323975,3.6621475219726562,2.899420976638794,3.6621477603912354,2.899420976638794,3.662147283554077,2.899420976638794,3.6621479988098145,2.8994204998016357,3.662147283554077,2.899420738220215,3.6621477603912354,2.8994204998016357,3.6621477603912354,2.8994204998016357,3.6621475219726562,2.8994204998016357,3.6621475219726562,2.8994204998016357,3.6621479988098145,2.8994204998016357,3.6621477603912354,2.8994202613830566,3.6621479988098145,2.8994204998016357,3.6621477603912354,2.8994204998016357,4.524179935455322,3.481839418411255,3.983577013015747,3.2208495140075684,3.983577013015747,3.2208497524261475,3.983577013015747,3.2208495140075684,3.983577013015747,3.2208497524261475,3.983577251434326,3.2208495140075684,3.983577251434326,3.2208495140075684,3.983577013015747,3.2208495140075684,3.983577251434326,3.2208497524261475,3.983577251434326,3.2208497524261475,3.983577013015747,3.2208495140075684,3.983577251434326,3.2208497524261475,3.983577251434326,3.2208497524261475,3.983577251434326,3.2208497524261475,3.983577251434326,3.2208497524261475,5.269730567932129,4.039390563964844,5.269730567932129,4.039390563964844,5.269731044769287,4.039391040802002,5.269731044769287,4.039391040802002,5.269731044769287,4.039391040802002,5.269731044769287,4.039390563964844,5.269731044769287,4.039391040802002,5.269731044769287,4.039391040802002,5.269731044769287,4.039390563964844,5.269731044769287,4.039391040802002,5.269731044769287,4.039390563964844,5.269731044769287,4.039391040802002,4.717174530029297,3.6886420249938965],\"y\":[-3.4149460792541504,-2.5832600593566895,-3.1897940635681152,-2.0695419311523438,-2.5469374656677246,-1.4266846179962158,-1.9040802717208862,-0.7838279008865356,-1.2612230777740479,-0.14097058773040771,-0.6183659434318542,0.5018863677978516,0.02449113130569458,1.1447436809539795,0.6673482656478882,1.7876007556915283,1.3102054595947266,2.430457830429077,1.9530625343322754,3.073315143585205,2.595919609069824,3.716172218322754,3.238776922225952,4.359029293060303,3.881633758544922,5.001886367797852,4.8531999588012695,5.899555683135986,-3.7446534633636475,-2.9497017860412598,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078033924102783,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220889449119568,0.3095966577529907,0.12076818943023682,0.9524539113044739,0.7636253237724304,1.5953110456466675,1.4064825773239136,2.238168239593506,2.049339771270752,2.881025552749634,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809596538543701,4.6207685470581055,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831521987915,-2.4506609439849854,-1.6189748048782349,-1.8078036308288574,-0.976117730140686,-1.1649466753005981,-0.33326053619384766,-0.5220894813537598,0.30959653854370117,0.12076801061630249,0.9524537324905396,0.7636251449584961,1.595310926437378,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809597015380859,4.6207685470581055,5.452454090118408,-4.023829936981201,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078033924102783,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220889449119568,0.3095966577529907,0.12076818943023682,0.9524539113044739,0.7636253237724304,1.5953110456466675,1.4064825773239136,2.238168239593506,2.049339771270752,2.881025552749634,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809596538543701,4.620768070220947,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506609439849854,-1.6189748048782349,-1.8078036308288574,-0.9761173725128174,-1.164946436882019,-0.33326053619384766,-0.5220894813537598,0.30959653854370117,0.12076801061630249,0.9524537324905396,0.7636251449584961,1.595310926437378,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350536823272705,4.166739463806152,3.9779109954833984,4.809597015380859,4.6207685470581055,5.452454090118408,-4.023829936981201,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078033924102783,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220889449119568,0.3095966577529907,0.12076818943023682,0.9524539113044739,0.7636253237724304,1.5953110456466675,1.4064825773239136,2.238168239593506,2.049339771270752,2.881025552749634,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809597015380859,4.620768070220947,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506609439849854,-1.6189746856689453,-1.8078036308288574,-0.9761173725128174,-1.164946436882019,-0.33326053619384766,-0.5220894813537598,0.30959653854370117,0.12076801061630249,0.9524537324905396,0.7636250853538513,1.595310926437378,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350536823272705,4.166739463806152,3.9779112339019775,4.809597015380859,4.6207685470581055,5.452454090118408,-4.023829936981201,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.450660467147827,-1.6189748048782349,-1.8078033924102783,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220891237258911,0.3095966577529907,0.12076807022094727,0.9524538516998291,0.7636252045631409,1.5953110456466675,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.166740417480469,3.9779109954833984,4.809597015380859,4.620768070220947,5.452454090118408,-4.023829936981201,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506609439849854,-1.618975043296814,-1.8078036308288574,-0.976117730140686,-1.1649463176727295,-0.33326029777526855,-0.5220891833305359,0.30959653854370117,0.12076812982559204,0.9524539709091187,0.7636252045631409,1.5953110456466675,1.406482458114624,2.238168239593506,2.049339771270752,2.881025552749634,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779112339019775,4.809597015380859,4.620767593383789,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078036308288574,-0.9761179685592651,-1.1649463176727295,-0.33326029777526855,-0.5220891237258911,0.30959653854370117,0.12076801061630249,0.9524540901184082,0.7636251449584961,1.595311164855957,1.406482458114624,2.238168239593506,2.049339771270752,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779107570648193,4.809597015380859,4.620767593383789,5.45245361328125,-4.023829936981201,-3.363999843597412,-3.093517780303955,-2.2618319988250732,-2.4506609439849854,-1.6189751625061035,-1.8078036308288574,-0.9761180877685547,-1.1649463176727295,-0.3332604169845581,-0.5220893025398254,0.30959653854370117,0.12076801061630249,0.9524539709091187,0.7636250853538513,1.5953110456466675,1.406482219696045,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350536823272705,4.1667399406433105,3.9779112339019775,4.809597015380859,4.620768070220947,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.807803750038147,-0.9761179685592651,-1.1649463176727295,-0.3332604169845581,-0.5220891237258911,0.3095966577529907,0.12076818943023682,0.9524538516998291,0.7636252641677856,1.5953110456466675,1.4064823389053345,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809596538543701,4.620768070220947,5.452454090118408,-4.023829936981201,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506609439849854,-1.618975043296814,-1.8078036308288574,-0.9761179685592651,-1.164946436882019,-0.333260178565979,-0.5220891237258911,0.30959653854370117,0.12076812982559204,0.9524539709091187,0.7636252045631409,1.595311164855957,1.406482458114624,2.238168478012085,2.049339771270752,2.881025552749634,2.6921963691711426,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779112339019775,4.809597015380859,4.620767593383789,5.452454090118408,-4.023829936981201,-3.363999605178833,-3.093518018722534,-2.261831760406494,-2.4506609439849854,-1.6189748048782349,-1.8078036308288574,-0.9761179685592651,-1.1649463176727295,-0.333260178565979,-0.5220892429351807,0.3095967769622803,0.12076812982559204,0.9524540901184082,0.7636252045631409,1.5953110456466675,1.406482458114624,2.238168478012085,2.049339771270752,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779107570648193,4.809597015380859,4.620767593383789,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506609439849854,-1.6189748048782349,-1.8078036308288574,-0.9761179685592651,-1.1649463176727295,-0.33326029777526855,-0.5220892429351807,0.3095968961715698,0.12076807022094727,0.9524540901184082,0.7636252045631409,1.595311164855957,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779107570648193,4.809597015380859,4.620767593383789,5.45245361328125,-4.023829936981201,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506607055664062,-1.618975043296814,-1.8078036308288574,-0.976117730140686,-1.1649463176727295,-0.33326029777526855,-0.5220891833305359,0.30959653854370117,0.12076812982559204,0.9524538516998291,0.7636252045631409,1.595311164855957,1.406482458114624,2.238168478012085,2.049339771270752,2.881025552749634,2.692196846008301,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779107570648193,4.809597015380859,4.620767593383789,5.45245361328125,-4.023830413818359,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.807803750038147,-0.9761179685592651,-1.1649463176727295,-0.33326029777526855,-0.5220890641212463,0.3095966577529907,0.12076818943023682,0.9524538516998291,0.7636252045631409,1.5953110456466675,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809596538543701,4.620768070220947,5.452454090118408,-4.023829936981201,-3.363999843597412,-3.093517780303955,-2.2618319988250732,-2.4506609439849854,-1.6189751625061035,-1.8078036308288574,-0.9761180877685547,-1.1649463176727295,-0.33326029777526855,-0.5220893621444702,0.3095967769622803,0.12076801061630249,0.9524539709091187,0.7636250853538513,1.5953110456466675,1.406482219696045,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350536823272705,4.1667399406433105,3.9779112339019775,4.809597015380859,4.620768070220947,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.807803750038147,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220891237258911,0.3095966577529907,0.12076818943023682,0.9524538516998291,0.7636252045631409,1.5953110456466675,1.4064823389053345,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809596538543701,4.620768070220947,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506607055664062,-1.618975043296814,-1.8078036308288574,-0.9761179685592651,-1.1649463176727295,-0.33326029777526855,-0.5220892429351807,0.3095968961715698,0.12076812982559204,0.9524539709091187,0.7636251449584961,1.595311164855957,1.4064823389053345,2.238168239593506,2.049339771270752,2.8810253143310547,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809597015380859,4.620767593383789,5.45245361328125,-4.023829936981201,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078036308288574,-0.9761179685592651,-1.1649463176727295,-0.33326029777526855,-0.5220891237258911,0.30959653854370117,0.12076812982559204,0.9524538516998291,0.7636252045631409,1.5953110456466675,1.406482458114624,2.238168478012085,2.049339771270752,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809597015380859,4.620767593383789,5.45245361328125,-4.023830413818359,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.4506609439849854,-1.6189746856689453,-1.8078036308288574,-0.9761178493499756,-1.1649463176727295,-0.33326053619384766,-0.5220892429351807,0.30959653854370117,0.12076801061630249,0.9524537324905396,0.7636250853538513,1.595310926437378,1.406482219696045,2.238168239593506,2.0493392944335938,2.8810253143310547,2.6921966075897217,3.5238821506500244,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809597015380859,4.6207685470581055,5.452454090118408,-4.023830413818359,-3.363999605178833,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078036308288574,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220889449119568,0.3095966577529907,0.12076818943023682,0.9524539113044739,0.7636253237724304,1.5953110456466675,1.4064825773239136,2.238168239593506,2.049339771270752,2.881025552749634,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809596538543701,4.6207685470581055,5.452454090118408,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831521987915,-2.4506609439849854,-1.6189746856689453,-1.8078036308288574,-0.9761173725128174,-1.1649465560913086,-0.33326053619384766,-0.5220894813537598,0.30959653854370117,0.12076801061630249,0.9524537324905396,0.7636250853538513,1.595310926437378,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350536823272705,4.166739463806152,3.9779109954833984,4.809597015380859,4.6207685470581055,5.452454090118408,-4.023829936981201,-3.363999843597412,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078036308288574,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220889449119568,0.3095966577529907,0.12076818943023682,0.9524539113044739,0.7636253237724304,1.5953110456466675,1.4064825773239136,2.238168239593506,2.049339771270752,2.881025552749634,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.166740417480469,3.9779109954833984,4.809596538543701,4.6207685470581055,5.452454566955566,-4.023830413818359,-3.363999843597412,-3.093518018722534,-2.261831760406494,-2.4506609439849854,-1.6189748048782349,-1.8078036308288574,-0.9761178493499756,-1.1649465560913086,-0.33326053619384766,-0.5220894813537598,0.30959653854370117,0.12076801061630249,0.9524537324905396,0.763624906539917,1.595310926437378,1.406482458114624,2.238168239593506,2.049339532852173,2.8810253143310547,2.6921963691711426,3.5238823890686035,3.3350536823272705,4.166739463806152,3.9779112339019775,4.809597015380859,4.620768070220947,5.45245361328125,-3.613831043243408,-2.9941246509552,-3.093517780303955,-2.261831760406494,-2.4506607055664062,-1.6189748048782349,-1.8078036308288574,-0.9761179685592651,-1.1649460792541504,-0.3332604169845581,-0.5220889449119568,0.3095966577529907,0.12076818943023682,0.9524539113044739,0.7636253237724304,1.5953110456466675,1.4064825773239136,2.238168239593506,2.049339771270752,2.881025552749634,2.6921966075897217,3.5238823890686035,3.3350539207458496,4.1667399406433105,3.9779109954833984,4.809596538543701,4.6207685470581055,5.452454090118408,-3.414945125579834,-2.5832600593566895,-2.8018345832824707,-1.9684137105941772,-2.158977508544922,-1.3255566358566284,-1.5161203145980835,-0.6826995611190796,-0.8732632398605347,-0.03984224796295166,-0.2304062843322754,0.6030148267745972,0.4124510884284973,1.2458720207214355,1.055308222770691,1.888729214668274,1.6981654167175293,2.531586170196533,2.341022491455078,3.174443483352661,2.983879804611206,3.817300796508789,3.626736640930176,4.460157871246338,4.269594192504883,5.103014945983887,5.07415246963501,6.035097122192383],\"z\":[-1.544488787651062,-1.3068645000457764,-1.4622188806533813,-1.4562097787857056,-1.4622187614440918,-1.4562098979949951,-1.4622187614440918,-1.456209659576416,-1.4622188806533813,-1.4562097787857056,-1.4622187614440918,-1.456209659576416,-1.4622187614440918,-1.456209659576416,-1.4622187614440918,-1.456209659576416,-1.4622187614440918,-1.456209659576416,-1.4622187614440918,-1.456209659576416,-1.4622187614440918,-1.4562095403671265,-1.4622188806533813,-1.456209659576416,-1.4622187614440918,-1.4562095403671265,-1.728798270225525,-1.62261164188385,-1.394199013710022,-1.1875009536743164,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444890260696411,-1.3068643808364868,-1.3267446756362915,-1.0141907930374146,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.544488549232483,-1.3068643808364868,-1.5444884300231934,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068643808364868,-1.5444890260696411,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.326744556427002,-1.0141907930374146,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.3267446756362915,-1.014190912246704,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068643808364868,-1.5444884300231934,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.544488549232483,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.326744556427002,-1.0141907930374146,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.326744556427002,-1.014190912246704,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444886684417725,-1.3068643808364868,-1.5444884300231934,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.326744556427002,-1.0141907930374146,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068642616271973,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.326744794845581,-1.014190912246704,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.3267446756362915,-1.0141907930374146,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488787651062,-1.3068645000457764,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.3267446756362915,-1.0141907930374146,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.326744794845581,-1.0141907930374146,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068642616271973,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.3267446756362915,-1.014190912246704,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.544488549232483,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.326744556427002,-1.0141907930374146,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488787651062,-1.3068645000457764,-1.544488787651062,-1.3068642616271973,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.3267446756362915,-1.0141907930374146,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488787651062,-1.3068645000457764,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.326744556427002,-1.0141907930374146,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.3267446756362915,-1.0141907930374146,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.326744556427002,-1.0141907930374146,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.326744794845581,-1.0141907930374146,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.326744794845581,-1.014190912246704,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488787651062,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.3267444372177124,-1.0141907930374146,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.5444889068603516,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.544488787651062,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068643808364868,-1.326744556427002,-1.014190912246704,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.5444886684417725,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.544488549232483,-1.3068642616271973,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.5444890260696411,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.326744794845581,-1.0141907930374146,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444890260696411,-1.3068643808364868,-1.326744794845581,-1.014190912246704,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444886684417725,-1.3068643808364868,-1.5444884300231934,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.326744556427002,-1.0141907930374146,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.326744794845581,-1.014190912246704,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444884300231934,-1.3068642616271973,-1.5444886684417725,-1.3068643808364868,-1.5444884300231934,-1.3068643808364868,-1.5444886684417725,-1.3068643808364868,-1.544488549232483,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.5444886684417725,-1.3068643808364868,-1.5444886684417725,-1.3068645000457764,-1.5444890260696411,-1.3068645000457764,-1.5444886684417725,-1.3068645000457764,-1.6322427988052368,-1.1723613739013672,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068642616271973,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444889068603516,-1.3068643808364868,-1.5444890260696411,-1.3068643808364868,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.5444889068603516,-1.3068645000457764,-1.544488787651062,-1.3068645000457764,-1.9475620985031128,-1.5476288795471191,-1.9475620985031128,-1.5476288795471191,-1.9475620985031128,-1.5476287603378296,-1.9475622177124023,-1.5476288795471191,-1.9475616216659546,-1.5476287603378296,-1.9475622177124023,-1.5476288795471191,-1.9475619792938232,-1.5476288795471191,-1.9475620985031128,-1.5476287603378296,-1.9475619792938232,-1.5476288795471191,-1.9475620985031128,-1.5476287603378296,-1.9475619792938232,-1.5476288795471191,-1.9475618600845337,-1.5476287603378296,-1.8832573890686035,-1.684814691543579],\"type\":\"scatter3d\",\"scene\":\"scene\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,0.45],\"y\":[0.0,1.0]}},\"scene2\":{\"domain\":{\"x\":[0.55,1.0],\"y\":[0.0,1.0]}},\"height\":600,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('24750007-f08a-4964-ba5a-79c77eeb2958');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treino (b)"
      ],
      "metadata": {
        "id": "lQbo5JtHw3bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 50\n",
        "start_mode = False\n",
        "valid_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "config = {\n",
        "    # 2 Convs + 1 fully-connected\n",
        "    \"features\": {\n",
        "        \"sets\":    [392,    392,    1,],\n",
        "        \"samples\": [18,     18,     784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [2,      2,      num_classes,],\n",
        "        \"samples\": [(3, 3), (3, 6), (hidden_dim, 1),],\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "xGn5VTZPw-1K",
        "outputId": "f0414629-67ec-45d6-888e-54ff491cce95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABRQAAAEmCAYAAAATGxxdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACMNElEQVR4nOzdd3hUZfrG8e/MpIdU0iCF0CH03otKURQBOyBIdVWwsWvh5659dVdZ7IpSRFQUV0FREEGUXgKE3ktIQiCd9D4zvz+CUVbQBJKclPtzXbk0M3PO3Ie8mcw85znva7Lb7XZEREREREREREREysBsdAARERERERERERGpOVRQFBERERERERERkTJTQVFERERERERERETKTAVFERERERERERERKTMVFEVERERERERERKTMVFAUERERERERERGRMlNBUURERERERERERMpMBUUREREREREREREpMwejA1QEm83G2bNn8fDwwGQyGR1HRERERERERESkRrHb7WRlZdGwYUPM5j/uQawVBcWzZ88SGhpqdAwREREREREREZEaLS4ujpCQkD98zBUVFN955x1effVVEhIS6NChA2+99Rbdu3e/7OPT09N56qmnWLp0KWlpaTRq1IjXX3+dYcOGAfDyyy+zdOlSjhw5gqurK7179+bf//43LVu2LFMeDw8PoOSAPT09r+SQqr2ioiJWr17NkCFDcHR0NDqOSKXSeJe6RONd6gqNdalLNN6lLtF4l7qkto/3zMxMQkNDS+tsf6TcBcUlS5YwY8YM5syZQ48ePXj99dcZOnQoR48eJSAg4HePLywsZPDgwQQEBPDll18SHBxMTEwM3t7epY9Zv34906ZNo1u3bhQXF/N///d/DBkyhEOHDuHu7v6nmX65zNnT07NWFxTd3Nzw9PSslYNW5Lc03qUu0XiXukJjXeoSjXepSzTepS6pK+O9LNMJlrugOHv2bKZOncrEiRMBmDNnDitWrGDBggU8+eSTv3v8ggULSEtLY8uWLaX/2OHh4Rc9ZtWqVRd9v3DhQgICAti1axf9+/cvb0QRERERERERERGpJOUqKBYWFrJr1y5mzpxZepvZbGbQoEFs3br1ktssX76cXr16MW3aNL755hv8/f0ZM2YMTzzxBBaL5ZLbZGRkAODr63vJ+wsKCigoKCj9PjMzEyipFBcVFZXnkGqMX46rth6fyG9pvEtdovEudYXGutQlGu9Sl2i8S11S28d7eY6rXAXFlJQUrFYrgYGBF90eGBjIkSNHLrnNqVOn+Omnnxg7diwrV67kxIkTPPDAAxQVFfHMM8/87vE2m41HHnmEPn360LZt20vu8+WXX+a555773e2rV6/Gzc2tPIdU46xZs8boCCJVRuNd6hKNd6krNNalLtF4l7pE413qkto63nNzc8v82Epf5dlmsxEQEMAHH3yAxWKhS5cuxMfH8+qrr16yoDht2jQOHDjApk2bLrvPmTNnMmPGjNLvf5k0csiQIbV6DsU1a9YwePDgWn2dvghovEvdovEudYXGutQlGu9Sl2i81012ux2r1YrVasVutxsdp8oUFxezZcsWevfujYNDpZfUKpzJZMJisWCxWC45T+IvVwCXRbmO3s/PD4vFQmJi4kW3JyYmEhQUdMltGjRogKOj40WXN7du3ZqEhAQKCwtxcnIqvX369Ol89913bNiw4Q+Xp3Z2dsbZ2fl3tzs6Otb6F7C6cIwiv9B4l7pE413qCo11qUs03qUu0XivOwoLCzl37ly5utlqC7vdTlBQEOfOnSvTwiXVlZubGw0aNLioJgeU63e4XAVFJycnunTpwtq1axk5ciRQ0oG4du1apk+ffslt+vTpw+LFi7HZbJjNZgCOHTt2UXC73c6DDz7IsmXLWLduHY0bNy5PLBERERERERERqWQ2m43o6GgsFgsNGzbEycmpRhfWystms5GdnU29evVKa1w1id1up7CwkOTkZKKjo2nevPkVH0e5+zNnzJjBPffcQ9euXenevTuvv/46OTk5pas+jx8/nuDgYF5++WUA7r//ft5++20efvhhHnzwQY4fP85LL73EQw89VLrPadOmsXjxYr755hs8PDxISEgAwMvLC1dX1ys6MBERKbujCVm8uOIQY3uEcX3bBkbHERERERGRaqiwsBCbzUZoaGitX8PiUmw2G4WFhbi4uNTIgiKAq6srjo6OxMTElB7LlSh3QfHOO+8kOTmZp59+moSEBDp27MiqVatKF2qJjY296B81NDSUH374gUcffZT27dsTHBzMww8/zBNPPFH6mPfeew+AgQMHXvRcH374IRMmTLiCwxIRkbI6kZTN2HnbSMku5GhCFte2CsTJoWb+cRQRERERkcpXU4tpUqIifn5XNIPk9OnTL3uJ87p16353W69evdi2bdtl91eXJvAUEalOYlJzSouJAElZBXy79yy3drn8PLYiIiIiIiJSt6mkLCJSR505n8uYudtJzCygZaAHU/uVzF87b1O0TvSIiIiIiIjIZamgKCJSByVk5DNm7nbi0/No4u/OJ1N6MO2aZrg6Wjh8LpMtJ1ONjigiIiIiIlItNWnShNdff/2q9hEeHn7V+zCSCooiInVMclYBY+ZtIzYtlzBfNxZP6Ym/hzPebk7c3rXkUud5G08ZnFJERERERKRiDBw4kEceeaTC9rd9+3buvffeCttfTaSCoohIHZKWU8jd87ZzKjmHYG9XFk/tQZDXr6t6TerTGJMJfj6azImkLAOTioiIiIiIVB273U5xcXGZHuvv718nV7n+LRUURUTqiIzcIsbN387RxCwCPZ35dEoPQnwu/iMY7ufO4NaBAMzfFG1ETBERERERqUHsdju5hcVV/lXWed8nTJjA+vXreeONNzCZTJhMJk6fPs26deswmUx8//33dOnSBWdnZzZt2sTJkycZMWIEgYGB1KtXj27duvHjjz9etM//veTZZDIxb948Ro0ahZubG82bN2f58uXl+neMjY1lxIgR1KtXD09PT+644w4SExNL79+7dy/XXHMNHh4eeHp60qVLF3bu3AlATEwMw4cPx8fHB3d3d9q0acPKlSvL9fzldUWrPIuISM2SlV/EPR9GcvBsJn71nPh0Sk/C/dwv+dip/Zuw+lAiX0XF89chLfGr51zFaUVEREREpKbIK7IS8fQPVf68h54fipvTn5e13njjDY4dO0bbtm15/vnngZIOw9OnTwPw5JNPMmvWLJo0aYKPjw9xcXEMGzaMf/7znzg7O7No0SKGDx/O0aNHCQkJuezzPPfcc7zyyiu8+uqrvPXWW4wdO5aYmBh8fX3/NKPNZistJq5fv57i4mKmTZvGnXfeybp16wAYO3YsnTp14r333sNisbBnzx4cHR0BmDZtGoWFhWzYsAF3d3cOHTpEvXr1/vR5r4YKiiIitVxuYTGTFu5gT1w63m6OfDKlB80CLv/HpWsjHzqEeLH3TAafbIvhkUEtqjCtiIiIiIhIxfHy8sLJyQk3NzeCgoJ+d//zzz/P4MGDS7/39fWlQ4cOpd+/8MILLFu2jOXLl/PAAw9c9nkmTJjA6NGjAXjppZd48803iYyM5Prrr//TjGvXrmX//v1ER0cTGhoKwKJFi2jTpg07duygW7duxMbG8thjj9GqVSsAmjdvXrp9bGwst956K+3atQNKOigrmwqKIiK1WH6RlSkf7WTH6fN4uDjwyeQetAry/MNtTCYTU/o14cHPdvPx1hjuG9AUF0dLFSUWEREREZGaxNXRwqHnhxryvBWha9euF32fnZ3Ns88+y4oVKzh37hzFxcXk5eURGxv7h/tp37596f+7u7vj6elJUlJSmTIcPnyY0NDQ0mIiQEREBN7e3hw+fJhu3boxY8YMpkyZwscff8ygQYO4/fbbadq0KQAPPfQQ999/P6tXr2bQoEHceuutF+WpDJpDUUSkliootnLfJ7vYcjIVdycLH03qTttgrzJte0PbIIK9XUnNKeTr3fGVnFRERERERGoqk8mEm5NDlX+ZTKYKye/ufvFUUH/7299YtmwZL730Ehs3bmTPnj20a9eOwsLCP9zPL5cf//bfxWazVUhGgGeffZaDBw9y44038tNPPxEREcGyZcsAmDJlCqdOnWLcuHHs37+frl278tZbb1XYc1+KCooiIrVQkdXGg4t3s+5oMi6OZhZM6EbnMJ8yb+9gMTOxTzgA8zZFY7OVbcJjERERERGR6sbJyQmr1Vqmx27evJkJEyYwatQo2rVrR1BQUOl8i5WldevWxMXFERcXV3rboUOHSE9PJyIiovS2Fi1a8Oijj7J69WpuueUWPvzww9L7QkNDue+++1i6dCl//etfmTt3bqVmVkFRRKSWsdrsPLpkD6sPJeLkYGbe+G70aFK/3Pu5o1so9ZwdOJGUzfrjyZWQVEREREREpPKFh4ezfft2Tp8+TUpKyh92DjZv3pylS5eyZ88e9u7dy5gxYyq00/BSBg0aRLt27Rg7dixRUVFERkYyfvx4BgwYQNeuXcnLy2P69OmsW7eOmJgYNm/ezI4dO2jdujUAjzzyCD/88APR0dFERUXx888/l95XWVRQFBGpRWw2O499uZfv9p3D0WLi/bu70Le53xXty9PFkbu6lczhMW/jqYqMKSIiIiIiUmX+9re/YbFYiIiIwN/f/w/nQ5w9ezY+Pj707t2b4cOHM3ToUDp37lyp+UwmE9988w0+Pj7079+fQYMG0aRJE5YsWQKAxWIhNTWV8ePH06JFC+644w5uuOEGnnvuOQCsVivTpk2jdevWXH/99bRo0YJ33323UjNrURYRkVrCbrfz1NcHWBoVj8Vs4q3RnbmmVcBV7XNCn3A+3HKazSdSOXg2gzYNyzYHo4iIiIiISHXRokULtm7detFt4eHh2O2/n9opPDycn3766aLbpk2bBlDaqXjq1CnM5l979C61n/T09D/M9L+XUYeFhfHNN99c8rFOTk589tlnl91XZc+XeCnqUBQRqQXsdjvPfXuIzyJjMZvgtTs7cn3boKveb4iPGzdc2M/8TdFXvT8RERERERGp+VRQFBGp4ex2O/9adYSFW04D8MptHbi5Q8MK2/+Ufk0A+HbvWRIz8ytsvyIiIiIiIlIzqaAoIlLDvf7jcd5fXzLH4T9HteW2LiEVuv+Ood50C/ehyGrnowtFSxEREREREam7VFAUEanB3vn5BG+sPQ7A0zdFMLZHo0p5nsl9S7oUP90eS25hcaU8h4iIiIiIiNQMKiiKiNRQ8zdF8+oPRwF44vpWTOrbuNKea3BEII3qu5GRV8SXu85U2vOIiIiIiEj1d6lFSKTmqIifnwqKIiI10MfbYnjhu0MAPDKoOfcPbFqpz2cxm5jUp6RgOX9TNFab3kCIiIiIiNQ1jo6OAOTm5hqcRK7GLz+/X36eV8KhosKIiEjV+GJnHP/4+gAA9w1oysPXNa+S5729awiz1xwjJjWXHw8nMrTN1a8iLSIiIiIiNYfFYsHb25ukpCQA3NzcMJlMBqeqOjabjcLCQvLz8zGba16Pnt1uJzc3l6SkJLy9vbFYLFe8LxUURURqkG/2xPPEV/sAmNgnnCeub1llf8DdnBwY2yOMd9edZN7GUyooioiIiIjUQUFBJZ8Dfikq1iV2u528vDxcXV1rdCHV29u79Od4pVRQFBGpIb7ff44ZX+zFboexPcJ4+qaIKv8jdk/vcOZuPMWO0+fZE5dOx1DvKn1+ERERERExlslkokGDBgQEBFBUVGR0nCpVVFTEhg0b6N+//1VdLmwkR0fHq+pM/IUKiiIiNcDaw4k89PlurDY7t3UJ4YURbQ05Ixbo6cLwDg1ZGhXPvI2neHtM5yrPICIiIiIixrNYLBVSmKpJLBYLxcXFuLi41NiCYkWpeRd8i4jUMRuPJ3P/J1EUWe0M79CQf9/aHrPZuPb6KX2bAPD9gQTOnNdkzCIiIiIiInWNCooiItXYtlOpTF20k0KrjaFtApl9RwcsBhYTASIaetKnWX2sNjsLN582NIuIiIiIiIhUPRUURUSqqV0x55m0cAf5RTaubRXAW6M742ipHi/bv3Qpfr4jjqz8ujVvioiIiIiISF1XPT6ZiojIRfadSWfCgkhyC630bebHu2M74+RQfV6yB7Twp1lAPbILilmyI87oOCIiIiIiIlKFqs+nUxERAeDQ2UzGzY8kq6CY7o19+WB8F1wcq9dkx2azicl9GwPw4ebTFFttBicSERERERGRqqKCoohINXI8MYtx87eTkVdEpzBvFkzohpuTg9GxLmlUp2DquzsRn57H9wcSjI4jIiIiIiIiVUQFRRGRaiI6JYex87aTmlNI22BPFk7sTj3n6llMBHBxtHB3z0YAzNt4CrvdbnAiERERERERqQoqKIqIVANxabmMnbuNpKwCWgV58PGkHni5Ohod60+N69UIJwcze89ksDPmvNFxREREREREpAqooCgiYrBzGXmMmbeNsxn5NPV35+PJPfBxdzI6Vpn41XPmlk7BQEmXooiIiIiIiNR+V1RQfOeddwgPD8fFxYUePXoQGRn5h49PT09n2rRpNGjQAGdnZ1q0aMHKlSuvap8iIrVBUlY+Y+duJy4tj0b13Vg8tSf+Hs5GxyqXXxZnWX0okdMpOQanERERERERkcpW7oLikiVLmDFjBs888wxRUVF06NCBoUOHkpSUdMnHFxYWMnjwYE6fPs2XX37J0aNHmTt3LsHBwVe8TxGR2iA1u4Cxc7dzKiWHYG9XFk/tSaCni9Gxyq15oAcDW/pjt8OHm6ONjiMiIiIiIiKVrNwFxdmzZzN16lQmTpxIREQEc+bMwc3NjQULFlzy8QsWLCAtLY2vv/6aPn36EB4ezoABA+jQocMV71NEpKbLyC1i3PxIjidlE+jpzOKpPQj2djU61hWb2q8JAF/sPEN6bqHBaURERERERKQylWv50MLCQnbt2sXMmTNLbzObzQwaNIitW7decpvly5fTq1cvpk2bxjfffIO/vz9jxozhiSeewGKxXNE+CwoKKCgoKP0+MzMTgKKiIoqKispzSDXGL8dVW49P5Ldq+3jPyi9mwsKdHDqXiV89JxZN6EpDT6cafbzdwjxpFViPI4nZfLL1NH/p39joSDVGbR/vIr/QWJe6RONd6hKNd6lLavt4L89xlaugmJKSgtVqJTAw8KLbAwMDOXLkyCW3OXXqFD/99BNjx45l5cqVnDhxggceeICioiKeeeaZK9rnyy+/zHPPPfe721evXo2bm1t5DqnGWbNmjdERRKpMbRzvBVZ477CF6CwT7g52JjfN5ciO9Vz61a5m6eJh4kiihbnrjtEg8zAOWvarXGrjeBe5FI11qUs03qUu0XiXuqS2jvfc3NwyP7ZcBcUrYbPZCAgI4IMPPsBisdClSxfi4+N59dVXeeaZZ65onzNnzmTGjBml32dmZhIaGsqQIUPw9PSsqOjVSlFREWvWrGHw4ME4OjoaHUekUtXW8Z5fZGXqx1FEZ53H08WBRRO70qZh7XnNGlRsY83sjSRlFWAL6ciwjg2NjlQj1NbxLvK/NNalLtF4l7pE413qkto+3n+5ArgsylVQ9PPzw2KxkJiYeNHtiYmJBAUFXXKbBg0a4OjoiMViKb2tdevWJCQkUFhYeEX7dHZ2xtn596ugOjo61sof6G/VhWMU+UVtGu8FxVamfb6bbdHnqefswEeTutMxzMfoWBXK0RHu6R3Oqz8cZcGWWG7rGobJZDI6Vo1Rm8a7yB/RWJe6RONd6hKNd6lLaut4L88xleuCNCcnJ7p06cLatWtLb7PZbKxdu5ZevXpdcps+ffpw4sQJbDZb6W3Hjh2jQYMGODk5XdE+RURqkiKrjWmf7mbDsWRcHS0smNCNTrWsmPiLsT3CcHW0cPhcJltPphodR0RERERERCpBuWe4mjFjBnPnzuWjjz7i8OHD3H///eTk5DBx4kQAxo8ff9ECK/fffz9paWk8/PDDHDt2jBUrVvDSSy8xbdq0Mu9TRKSmKrbaeOTzPfx4OBEnBzPz7ulK98a+RseqNN5uTtzeNQSAuRtPGZxGREREREREKkO551C88847SU5O5umnnyYhIYGOHTuyatWq0kVVYmNjMZt/rVOGhobyww8/8Oijj9K+fXuCg4N5+OGHeeKJJ8q8TxGRmshqs/PYl/tYsf8cjhYT74/rQp9mfkbHqnST+jTm420x/Hw0mRNJWTQL8DA6koiIiIiIiFSgK1qUZfr06UyfPv2S961bt+53t/Xq1Ytt27Zd8T5FRGoam83OU8v2s2x3PA5mE++M6cw1LQOMjlUlwv3cGdw6kNWHEpm/KZqXb2lvdCQRERERERGpQOW+5FlERP6Y3W7n2W8P8vmOOMwmeP2ujgxpc+lFpmqrKf2aAPBVVDwp2QUGpxEREREREZGKpIKiiEgFstvtvLTyMIu2xmAywazbO3BT+4ZGx6py3cJ96BDiRWGxjU+2xRgdR0RERERERCqQCooiIhVo9ppjzN0YDcBLo9pxS+cQgxMZw2QyMflCl+LHW2PIL7IanEhEREREREQqigqKIiIV5O2fjvPWTycAeHZ4BKO7hxmcyFjD2gYR7O1Kak4hX++ONzqOiIiIiIiIVBAVFEVEKsC8jaeYtfoYADNvaMWEPo0NTmQ8B4uZCb3DAZi3KRqbzW5sIBERERGRWiIyOo0Fm6LJLSw2OorUUSooiohcpUVbT/PiisMAzBjcgr8MaGpwourjzu6h1HN24ERSNuuPJxsdR0RERESkxotPz+OeBZE8/90hhry2gfXH9D5bqp4KiiIiV2HJjlie/uYgAA8MbMqD1zYzOFH14uniyJ3dQoGSLk4REREREbk6zy0/SN6FOcrPnC8pLj7y+W5SswsMTiZ1iQqKIiJX6Ovd8Ty5dD8Ak/s25rGhLTGZTAanqn4m9gnHbILNJ1I5dDbT6DgiYpDCYhsx2VBstRkdRUREpMZaeziR1YcScTCbWPZAbyb1aYzZBF/vOcug2etZGnUGu11TDUnlU0FRROQKrNh3jhlf7MFuh7t7hvH3G1urmHgZIT5u3NCuAQDzNqlLUaSusdvtrD2cyI1vb2H2fgfunBvJ0YQso2OJiIjUOHmFVp5ZXnJ11OS+jekU5sPTwyNY+kAfWgV5cD63iBlf7GX8gkji0nINTiu1nQqKIiLltOZQIg9/vhubHW7vEsLzN7dVMfFPTO3XBIBv954lMTPf4DQiUlWOJ2YxfkEkkz/ayenUkg82++Izuemtjby19jhF6lYUEREps3d+PsGZ83k09HLhoeual97eMdSbbx/sy2NDW+LkYGbj8RSGvLaBeRtP6coAqTQqKIqIlMP6Y8lM+zSKYpudER0b8q9b22M2q5j4ZzqGetMt3Iciq52Ptpw2Oo6IVLL03EKeXX6Q69/YyMbjKThZzPylX2P+r2Mx17T0o8hq5z9rjjHync2aCkFERKQMTiRl8/6GkwA8c3Mb3J0dLrrf0WJm2jXNWPVwP3o09iWvyMqLKw4z6t0tHDybYURkqeVUUBQRKaMtJ1O4d9FOCq02bmgbxH9u74BFxcQym9y3pEvx0+2x5BYWG5xGRCpDsdXGx1tPM3DWOhZuOY3VZmdom0DWzOjP34Y0J9AV3h/bidfu7ICXqyMHz2Zy89ubmL3mGIXF6qAQERG5FLvdzj++PkCR1c61rQIYEhF42cc28a/HZ1N78q9b2uHh4sD++Axufnsz//r+CPkXFnIRqQgqKIqIlMHO02lM+WgnBcU2rmsVwBt3dcLBopfQ8hgcEUij+m5k5BXx5a4zRscRkQq2+UQKN765iX98c5D03CJaBnrw6ZQevD+uK43qu5c+zmQyMapTCGtm9Gdom0CKbXbeXHucm9/exP4z6qAQERH5X8v3nmXrqVScHcw8d3ObP51uyWw2cVf3MNbOGMCwdkFYbXbmrD/J9a9vYMuJlCpKLbWdPg2LiPyJvXHpTPhwB7mFVvo19+OdsZ1xctDLZ3lZzCYm9WkMwIJN0VhtWn1OpDaISc3h3kU7GTtvO0cTs/Bxc+SFkW1Z8VBf+jTzu+x2AR4uzLm7C2+P6YSvuxNHErIY+e5mXlmlDgoREZFfZOQV8cJ3hwF48NpmhPq6lXnbAE8X3h3bhQ/GdSHI04XTqbmMmbedx7/cS3puYWVFljpCn4hFRP7AwbMZjF8QSXZBMT0a+/LBuK64OFqMjlVj3d41BC9XR06n5vLj4USj44jIVcguKOZf3x9h8OwNrD6UiMVsYmKfcNb97RrG9WxUpi5uk8nETe0bsubR/tzUvgFWm513153kprc2sTv2fBUchYiISPU2e/VRUrILaOLvztT+Ta5oH0PaBLFmRn/G9WwEwBc7zzBo9nq+23cWu10n+eXKqKAoInIZxxKzGDc/koy8IjqHeTN/QjdcnVRMvBpuTg6M6REGwPyN0QanEZErYbPZ+WJnHANfXcec9ScptNro38KfVQ/345nhbfBycyz3PuvXc+btMZ2Zc3cX/Oo5cyIpm1vf28JLKw+rW1FEROqs/Wcy+HhbDAAvjmiLs8OVfxbxcCm5guDL+3rRLKAeKdmFTF+8mykf7eRsel5FRZY6RAVFEZFLOJWczdh520nLKaRdsBcLJ3Wn3v+spCZXZkLvcBwtJiJPp7E3Lt3oOCJSDjtPpzHinc08/uU+UrILaOznzoIJXfloYjeaB3pc9f6vbxvEmkf7M6pTMDY7fLDhFMPe2MjO02kVkF5ERKTmsNrsPPX1fmx2GNGxIb3/YBqR8uga7suKh/ryyKDmOFpMrD2SxODZ6/nowmJqImWlgqKIyP+IS8tl7LztJGcV0CrIg0WTuuPpUv6OG7m0QE8XhrdvCMC8TepSFKkJzqbn8dBnu7ltzlb2x2fg4ezA329szQ+P9OfaVoF/Ojl8efi4O/HanR2ZN74rgZ7OnErJ4fb3t/Lctwe1QryIiNQZiyNj2Xem5G/uUze2rtB9OztYeGRQC1Y+1I8ujXzIKbTyzPKD3DZnC8cSsyr0uaT2UkFRROQ3zqbnMXruNs5l5NMsoB6fTOmBj7uT0bFqncn9ShZnWbn/HPG6xEKk2sortPL6j8e49j/rWL73LCYTjO4eys+PDWRKvyaVukDVoIhAVj86gNu7hGC3w4ebT3P96xvZejK10p5TRESkOkjOKuCVVUcA+NvQlgR4uFTK8zQP9OC/f+nFCyPaUM/Zgd2x6dz45kZmrz5KQbGmHJE/poKiiMgFSZn5jJm7jTPn8wiv78biKT3wq+dsdKxaqU1DL3o3rY/VZmfhZnUpilQ3drud5XvPct1/1vH6j8fJL7LRvbEv307vy8u3tK+y10YvV0devb0DCyd2o4GXC7FpuYyeu41/fH2A7AJ1K4qISO308srDZOUX0zbYk7svLKRSWcxmE+N6hbNmRn8GtQ6gyGrnzZ9OMOyNjezQlCPyB1RQFBEBUrILGDNvO6dTcwnxcWXx1J4EeFbOmUApMbVfySp1n0fGkZVfZHAaEfnF/jMZ3D5nKw99tpuzGfkEe7vy7tjOLLm3J22DvQzJNLBlAKsf7c/o7iWLOn28LYahr21g0/EUQ/KIiIhUlq0nU1m6Ox6TCf45sh0Wc8VNK/JHGni5Mnd8V94Z0xm/es6cTM7h9jlbeWrZfjL1Xl0uQQVFEanz0nMLuXvedk4kZRPk6cJnU3vS0NvV6Fi13oAW/jT1dyeroJglO+KMjiNS5yVl5fPYf/dy8zub2BlzHldHC38d3IK1fx3AsHYNKnSexCvh4eLIy7e049MpPQjxcSU+PY+7529n5tJ9+qAjIiK1QmGxjX98cwCAsT3C6BDqXaXPbzKZuLF9A9bOGMCdXUMB+HR7LINnr+eHgwlVmkWqPxUURaROy8wvYtz8SI4kZOFXz5nFU3sQ6utmdKw6wWw2MeVCl+KHm09TbLUZnEikbiootjJn/UmunbWe/+46g90OozoF8/PfBvLgdc1xcbQYHfEifZr58cMj/Rnfq+QSsM8i4xj62gbWHU0yOJmIiMjVmbfpFCeSsvGr58RjQ1oZlsPLzZF/39aez6b2pLGfO4mZBfzl413c9/EuEjPzDcsl1YsKiiJSZ2UXFDNhQST74zPwdXdi8dQeNPGvZ3SsOmVUp2DquzsRn57HKp31FKlSdrud1QcTGPLaBv71/RGyC4rpEOLFV/f35rU7OxLkVX2nfXB3duD5EW35/N6eNKrvxrmMfCZ8uIO//XcvGbnqVhQRkZonLi2XN9ceB+D/hrXGy83R4ETQq2l9vn+4Hw8MbIqD2cSqgwkMmr2exdtjsdnsRscTg6mgKCJ1Ul6hlckLdxAVm46niwMfT+5Oi0APo2PVOS6OltKJpudujMZu1xsTkapwNCGLu+dv596PdxGTmkuAhzP/ub0Dyx7oQ5dGPkbHK7OeTUo+6Ezq0xiTCb7cdYbBr63nx0OJRkcTEREpl+e+PUR+kY0ejX0Z1SnY6DilXBwtPH59K5ZP70uHEC+y8ov5v2X7uWvuNk4mZxsdTwykgqKI1Dn5RVbu/Xgn26PTqOfswMeTe9CmoTELDQiM69UIJwcze+PS2RVz3ug4IrXa+ZxCnv7mADe8sYHNJ1JxcjAz7Zqm/Py3gdzaJQRzFU38XpHcnBx4engE//1LL5r4uZOUVcCURTt55PPdnM8pNDqeiIjIn1pzKJEfDyfiYDbx4si2hs9bfCkRDT1Z+kAf/nFTBK6OFiKj07jhjY28/dNxCos1dVFdpIKiiNQphcU2pn0axcbjKbg5WVg4sVuVT3YsF/Or58wtF87Czt14yuA0IrVTkdXGws3RDJy1jkVbY7DZ4fo2Qfz46AAeG9oKd2cHoyNeta7hvqx8uB9/6d8Eswm+3nOWwa9tYNWBc0ZHExERuazcwmKeXX4QgKn9m9C8Gl81ZTGbmNy3Masf7c+AFv4UFtuYtfoYw9/axO5YNQbUNSooikidUWy18fDnu1l7JAlnBzPz7ulK13Bfo2MJMLlvYwBWH0okJjXH4DQitcuGY8kMe2Mjz357iIy8IloFebB4ag/mjOtCWP3atQiVi6OFmcNa89X9vWkeUI+U7ALu+ySKaYujSM0uMDqeiIjI77z10wni0/MI9nbloWubGx2nTEJ93Vg4sRtv3NURX3cnjiZmcct7W3ju24PkFBQbHU+qiAqKIlInWG12/vrfvXx/IAEni5n3x3Whd1M/o2PJBc0DPRjY0h+7HRZsijY6jkitEJ2Sw5SPdjB+QSTHk7LxcXPkn6PasuKhfrX+9a9TmA/fPdSXadc0xWI2sWLfOQa/toFv957VXK0iIlJtHE/MYu6Gkit0nr25Da5OFoMTlZ3JZGJEx2B+nDGAWzoFY7fDh5tPM+S1Dfx8JMnoeFIFVFAUkVrPZrMzc+k+vtlzFgeziXfGdmZgywCjY8n/mNK3CQBf7DxDeq7mPRO5Upn5Rby08jBDXlvPj4eTcDCbmNSnMev+dg1jezTCUgPnSbwSzg4WHhvaiq8f6EOrIA/Scgp58LPd3PfJLpKy8o2OJyIidZzdbufvXx+g2GZnUOtABkcEGh3pivi6OzH7zo4smtSdEB9X4tPzmLhwBw99tpsUXR1Qq6mgKCK1mt1u5+nlB/hi5xnMJnjjrk419o91bdenWX1aBXmQV2RlcWSs0XFEahyrzc7nkbFcO2sdH2w4RZHVzsCW/qx6pD9PD4/Ay83R6IiGaBfixfLpfXn4uuY4mE38cDCRwbM3sDTqjLoVRUTEMMt2x7M9Og0XRzPPDI8wOs5V69/Cn9WP9mdqv8aYTbB871kGzV7Pl7v097a2UkFRRGotu93OiysO88m2WEwm+M8dHbixfQOjY8llmEwmpvQr6VL8aMtprRYnUg6R0Wnc/PYmnly6n5TsQpr4u/PhhG4snNidZgH1jI5nOCcHM48ObsHy6X1p09CTjLwiZnyxlykf7SQhQ92KIiJStTJyi/jnisMAPHRdc0J9a8ecxm5ODjx1YwRfT+tDRANP0nOL+Nt/9zJufqTmSa+Frqig+M477xAeHo6Liws9evQgMjLyso9duHAhJpPpoi8XF5eLHpOdnc306dMJCQnB1dWViIgI5syZcyXRRESAkmLiqz8cZf6F+fheHtWOUZ1CDE4lf+bmDg0J8HAmMbOA7/adNTqOSLV35nwu0xZHccf7Wzl4NhMPFwf+fmNrVj3cn2taaWqH/xXR0JOvp/Xhb0Na4GQxs/ZIEoNfW88XO+PUPSEiIlXm1dVHSM0ppFlAvdJpf2qT9iHefDO9D09c3wpnBzObTqQw9PUNvL/+JMVWNQ3UFuUuKC5ZsoQZM2bwzDPPEBUVRYcOHRg6dChJSZefdNPT05Nz586VfsXExFx0/4wZM1i1ahWffPIJhw8f5pFHHmH69OksX768/EckIkLJamnvrjsJwPMj2nBX9zCDE0lZODmYuad3OABzN0brA77IZeQWFjN79VGu+896Vuw7h9kEY3qEse5vA5nSrwlODroI5XIcLWamX9uc7x7qS4cQL7Lyi3n8y33c8+EO4tPzjI4nIiK13J64dD7dXjK9zwsj2tbav9mOFjP3D2zKD4/0p3fT+uQX2Xj5+yOMeGczB+IzjI4nFaDcI3f27NlMnTqViRMnlnYSurm5sWDBgstuYzKZCAoKKv0KDLx4/rItW7Zwzz33MHDgQMLDw7n33nvp0KHDH3Y+iohczvvrTzJ7zTEAnhrWmvG9wo0NJOUytkcYro4WDp/LZOvJVKPjiFQrdrudr3fHc+2s9bz50wkKim30bOLLdw/246VR7ahfz9noiDVGi0APvrq/N0/e0AonBzMbjiUz9LUNfLo9RiczRESkUlhtdv7+9X7sdrilUzC9mtY3OlKlC/dz59MpPXjltvZ4uTpy8GwmI97ZzMsrD5NXaDU6nlyFchUUCwsL2bVrF4MGDfp1B2YzgwYNYuvWrZfdLjs7m0aNGhEaGsqIESM4ePDgRff37t2b5cuXEx8fj91u5+eff+bYsWMMGTKknIcjInXdws3RvPz9EQD+OrgFU/vXvksIajtvNydu61JyefrcjacMTiNSfeyNS+fW97bwyJI9JGTmE+LjyntjO/PZ1J5ENPQ0Ol6N5GAxc9+Apqx8qB+dw7zJLijmqWUHGDtvO3FpuUbHExGRWuaTbTEciM/E08WBmcNaGx2nyphMJu7oGsqPMwZwU/sGWG123t9wiqGvb2DT8RSj48kVcijPg1NSUrBarb/rMAwMDOTIkSOX3KZly5YsWLCA9u3bk5GRwaxZs+jduzcHDx4kJKTkA+Nbb73FvffeS0hICA4ODpjNZubOnUv//v0vuc+CggIKCn5dfjwzMxOAoqIiioqKynNINcYvx1Vbj0/kt650vC/ZeYZnvz0EwP0DGnNf/3D9ztRQ43uG8Mn2GH4+mszh+PO1elEJvb7Ln0nKKmDWmuMs210yr6ibk4X7+jdmUu9GODtaKC4uNjhh2VTnsd7Ix5nFk7uxaFsss388zpaTqQx9fQOPDWnOmG6hmM0moyNKDVOdx7tIRdN4L5ukrAJe/eEoADMGN8fbxVzn/s28Xcy8dns7hrcP4pnlh4hNy+Xu+dsZ1akhM69vgY+bk9ER/1RtH+/lOS6TvRzXdJw9e5bg4GC2bNlCr169Sm9//PHHWb9+Pdu3by9TuNatWzN69GheeOEFAGbNmsXcuXOZNWsWjRo1YsOGDcycOZNly5Zd1A35i2effZbnnnvud7cvXrwYN7fasTqSiJTPjmQTn54wY8fEwAY2RjayYdLnvxpt3hEz+8+b6RVg466mmrxZ6p4iG6w7Z2LNGTMFtpIXtG7+NoaH2fCq/u+3a6zkPPjspIWTWSX/5s087dzVxIq/q8HBRESkRlt03MyuFDNh7nYebWelrp+ryrfCilgzGxNM2DFRz8HOLY1tdK5v1+c4A+Xm5jJmzBgyMjLw9PzjK2DKVVAsLCzEzc2NL7/8kpEjR5befs8995Cens4333xTpv3cfvvtODg48Nlnn5GXl4eXlxfLli3jxhtvLH3MlClTOHPmDKtWrfrd9pfqUAwNDSUlJeVPD7imKioqYs2aNQwePBhHR0ej44hUqvKO95X7E3j0v/uw2WFs91CeuakVJv0VqvF2nD7PmPk7SuY2+1t/6rvXzgqKXt/lf9ntdtYcTuLlVcc4c75kkZAOIV78fVhLOoZ6GxvuKtSksW6z2fk0Mo5Za46TW2jFxdHMjEHNGd8zDEtd/wQoZVKTxrvI1dJ4/3NbTqZyz8JdmE3w1V960ja4dtYtrsTu2HSe+uYgx5NyABjQwo/nh7emoXf1PJNX28d7ZmYmfn5+ZSooluuSZycnJ7p06cLatWtLC4o2m421a9cyffr0Mu3DarWyf/9+hg0bBvx6mbLZfPF0jhaLBZvt0h0pzs7OODv/ftJxR0fHWvkD/a26cIwivyjLeF99MIEZX+7HZoc7u4bywsh2ujStlujVzJ/2IV7sO5PB5zvjeWRQC6MjVSq9vgvA4XOZPP/tIbaeKlmQKNDTmSdvaMWIDsG15rWtpoz1Sf2aMrhNA574ah9bTqby0vdH+eFQEq/c1p6m/rV3GgapWDVlvItUBI33SysotvLcipIp4sb1bESn8Nq/EEt5dG/qz4qH+jNn/Une/ukE64+lcMNbW/jbkJbc0zu82p7Iq63jvTzHVO5VnmfMmMHcuXP56KOPOHz4MPfffz85OTlMnDgRgPHjxzNz5szSxz///POsXr2aU6dOERUVxd13301MTAxTpkwBwNPTkwEDBvDYY4+xbt06oqOjWbhwIYsWLWLUqFHljVcr2Wx2Zi47yP40E8VWXfYn8oufjyYxbXEUVpudkR0b8tItKibWJiaTiSn9ShbV+XhrDPlFWgVOaq+0nEKeWrafG9/cyNZTqTg5mHnw2mb89NeBjOoUotc2g4T6uvHplB68NKod9Zwd2BVznhve2Mic9Sf1nkxERMpk7oZTnErOwa+eMzOGtDQ6TrXk5GDmoeuas/LhfnQL9yG30Mrz3x3ilve2cCQh0+h4chnl6lAEuPPOO0lOTubpp58mISGBjh07smrVqtKFWmJjYy/qNjx//jxTp04lISEBHx8funTpwpYtW4iIiCh9zOeff87MmTMZO3YsaWlpNGrUiH/+85/cd999FXCINd+Wk6l8GRUPWPj2Pxu5o1sod3QNJdRX80VK3bXlRAr3fbyLIqudYe2CmHV7h2p79kqu3A1tg2jo5cLZjHy+3h3PXd3DjI4kUqGKrDY+3hrD6z8eIzO/ZHGVG9s14MkbWunvfDVhMpkY0yOMAS39efKrfWw8nsK/vj/C9/vP8ertHWgR6GF0RBERqaZiU3N566cTAPzjptZ4uda+jraK1CygHkvu7cVnO2L518oj7I1L56Y3N3HfgKZMv7YZLo4WoyPKb5RrDsXqKjMzEy8vrzJd410Txafn8dHmUyzeFk12UUnBxGSC/s39Gd09jOtaB+BoKXezqUi1VVRUxMqVKxk2bNglW653nE5j/PxI8oqsDGodwHt3d9HvQC02d8Mp/rnyMM0C6rHm0f61bn7MPxvvUnutO5rEC98d4mRyyZxBrRt48szwCHo2qZ2XQtWGsW632/nvzjO8sOIQWfnFOFnMPDyoOff2b6K/Q3KR2jDeRcpK4/3S7HY7kxbu4OejyfRuWp9Pp/Sode9jK1NCRj7PLD/ADwcTAWji585Lt7Qz/H1SbR/v5amv6Z1PDRDs7cpjQ1rwXGcrb97Znr7N/LDbYf2xZO77ZBe9//UTr/5whLi0XKOjilS63bHnmfjhDvKKrPRv4c87YzvrQ1wtd2f3UOo5O3AiKZt1x5KNjiNy1U4mZzPxw0gmfLiDk8k51Hd34uVb2vHdg30Nf5Msf8xkMnFHt1DWPDqAa1sFUGi18eoPRxn17mYOn9MlWSIi8qsfDiby89FkHC0mnh/RVsXEcgrycuH9cV2Zc3dnAjycOZWSw10fbGPm0v1k5BUZHU9QQbFGcTCXXP73yZQerH9sIPcPbIpfPSeSswp45+eT9H/1Z8YviGTVgXMUaV4fqYUOxGdwz4JIsguK6dnEl/fv7oKzg9reaztPF0fu7BYKwPyN0QanEblyGXlFvPjdIYa+toGfjybjYDYxtV9jfn5sIKO7a/XgmiTIy4X593TltTs74OXqyIH4TIa/tYnX1hyjsFjvwURE6rqcgmKe//YgAH/p35RmAVrM60pd37YBa2YMYEyPkqmPPouMZfDs9aw6cM7gZKKCYg3VqL47T1zfii1PXsd7YzvTr3lJ1+KGY8nc90kUvV7+iVdWHSE2VV2LUjscTchi3PztZOYX06WRD/Pv6Yark4qJdcXEPuGYTbDpRAqHzqoLSGoWq83O4u2xXDNrHfM2RVNss3NtqwB+eLQ/T90YgadL7btcpi4wmUyM6hTCmhn9GdomkGKbnTfWHufmtzdxID7D6HgiImKgN9ce52xGPiE+rky7ppnRcWo8L1dHXhrVjiX39qSJvztJWQXc90kU9y7aSUJGvtHx6iwVFGs4JwczN7RrwMeTe7DhsWuYdk1T/D2cScku4N11JV2L4+ZvZ+X+czpjLjXWyeRsxs7bxvncItqHePHhxG64O5d7TSmpwUJ83LihXQMA5m9Sl6LUHFtPpnLTW5v4v2X7ScsppKm/OwsndmPBhG409Ve3Qm0Q4OHCnLu78NboTvi6O3EkIYsR72zm1R+OUFCs1elFROqaowlZpe9Xnx/RRk0QFahHk/qsfKgfD17bDAezidWHEhk8ez2fbIvBZqvxy4PUOCoo1iJh9d14bGgrtjx5LXPu7sKAFv6YTLDxeAoPfBpF73+t5V/fH+F0So7RUUXKLCY1hzFzt5GSXUjrBp4smtRd3Tx11NR+TQBYvjeexEydiZTqLS4tlwc+3cXouds4fC4TTxcHnhkewapH+jOwZYDR8aSCmUwmhndoyOpH+3NjuwZYbXbe+fkkN725iT1x6UbHExGRKmK32/n71/spttkZ2iaQa1sFGh2p1nFxtPDXIS357qG+dAz1JqugmL9/fYA7P9jKiaQso+PVKSoo1kKOFjPXtw3io0nd2fDYNUy/phkBHs6kZBcyZ/1JBs5ax9h521ixT12LUr2dTc9jzNztJGYW0DygHp9M7o63m5PRscQgHUO96drIhyKrnUVbTxsdR+SScgqKmfXDUa6bvZ6V+xMwm+DunmGse+waJvZprEWkajm/es68M7Yz743tjF89J44nZXPLu5t5eeVh8ovUrSgiUtt9uesMO06fx9XRwtPD2xgdp1ZrFeTJV/f35pnhEbg5Wdhx+jzD3tjEGz8eV52jiuhdbS0X6uvG34a2ZPOT1/L+uC4MbFnStbj5RCrTFkfR6+W1vPz9YaLVtSjVTEYhjPtwJ/HpeTT2c+fTKT2oX8/Z6FhisCkXuhQ/2RZLbmGxwWlEfmWz2VkadYZr/7OOt38+QWGxjd5N67Py4X68OLIdvu46GVKX3NCuAWseHcDIjg2x2eH9DacY9uZGdsWkGR1NREQqSXpuIS9/fwSARwY1J9jb1eBEtZ/FbGJin8asmTGAa1r6U2i18dqPx7jprY3sijlvdLxaTwXFOsLRYmZomyAWTuzOxsev4aFrmxHo6UxqTiHvrz/FNbPWMfqDbXy796zm+xHDpWYX8M4hC7FpeYT4uPLplB4EeLoYHUuqgcERgTSq70ZGXhFf7TpjdBwRAHbHnueW97Yw44u9JGYWEOrryvvjuvDplB60CvI0Op4YxMfdidfv6sTc8V0J8HDmVHIOt83ZyvPfHiKvUO+1RERqm3+vOkpaTiEtAusxqW9jo+PUKcHeriyY0I03R3eivrsTxxKzuW3OFp755gDZBWpCqCwqKNZBIT5uzBjSks1PXMvc8V25tlUAJhNsPZXKg5/tptfLP/HSysOcSs42OqrUMclZBXy16wzjPtxJYp6JIE9nPpvak4Y6uycXWMwmJvUpeYM2f1M0Vk2+LAZKyMhnxpI9jHp3C3vi0nFzsvD49S1Z8+gAhrYJwmQyGR1RqoHBEYGseXQAt3UJwW6HBZujuf6NDWw7lWp0NBERqSBRsef5LDIWgBdHttMUJwYwmUzc3KEhP8749W/uR1tjGDx7PWsPJxodr1bSMql1mIPFzOCIQAZHBBKfnscXO+JYsiOOhMx8Pthwig82nKJnE19Gdw/j+rZBODtodSqpWMVWG7vj0ll/NJl1x5I4EJ9Zep+no52PJ3Ul1NfNwIRSHd3WJYT/rD7K6dRc1h5OZEibIKMjSR2TX2Rl3sZTvPPzSfIuzIt3W5cQHh/aUt3Ucklebo7Mur0DN7ZvwP8t3U9Mai53fbCN8b0a8cT1rXB31ltyEZGaqthq4+/LDgBwa+cQujf2NThR3ebj7sSs2zswsmMw/7dsP7FpuUz+aCc3tm/As8Pb4O+habQqit69CFDSIvzo4BY8eG0z1h1N5rPIWH4+msS2U2lsO5WGj5sjt3YO4a7uYTQLqGd0XKnBEjPzSwuIG4+nkJV/cQt6m4ae9G9Wn4Ds44TXdzcopVRn7s4OjO3ZiPfWnWTexmgVFKXK2O12vj+QwEsrD3PmfB4AncO8eWZ4GzqEehsbTmqEa1oG8MOj/Xl55WE+i4xj0dYYfjqSxL9vbU+fZn5GxxMRkSuwaGsMh85l4uXqyP8Na2V0HLmgb3M/fnikP6+vPca8jdGs2HeOTcdTeGpYa27vGqIrSSqACopyEQeLmUERgQyKCORseh5f7CzpWjyXkc+8TdHM2xRN98a+jLnQtejiqK5F+WNFVhs7T59n/bFk1h1N4khC1kX3e7s50q+5PwNa+NO/hR8BHi4UFRWxcuVxgxJLTXBPr3DmbjhF5Ok09salq5gjle7g2Qye//YQ26NLFtUI8nRh5rBW3Nyhod6QSrl4ujjy8i3tubFdQ574ah9nzucxdt52RncP4/+GtcLDxdHoiCIiUkaJmfnMXnMMgCeub6VFJKsZVycLM29ozfD2DXly6T4OxGfy+Ff7+HpPPC+Nake4nxpYroYKinJZDb1deWRQCx68tjnrjyWxeHscPx1JJDI6jcjoNLy/LelaHN09lGYBHkbHlWokPj2vpAvxaBJbTqZeNBGuyQTtQ7wZ0MKfgS396RDijcWsD+NSPkFeLtzcoSFLd8czb1M0b43uZHQkqaVSswuYtfoYn++IxW4HZwczfxnQlPsGNMHNSW+j5Mr1be7HD4/259/fH+HjbTF8FhnL+qNJvHxrewa08Dc6noiIlMEL3x0iu6CYjqHe3NUt1Og4chltg734+oE+fLj5NP9Zc5QtJ1MZ+voGHh7UnKn9mmjOyyukd8LypyxmE9e2CuTaVoGcy8jjvzvPsGRHHPHpeczfFM38TdF0D/dldI9QbmjbQF2LdVBBsZUd0edZfyyJdUeTOZ508YI+9d2d6N+ipAuxX3M/nbmTCjG5X2OW7o5n5f5zPHlDK4K1eI9UoMJiG4u2nuaNtcdLp2a4sX0DZt7QihAfze0qFaOeswMvjGzLsHYNeOKrfcSm5XLPgkhu7xLC32+KwMtV3Yo1TX6RlTPnczmRmElksommCVm0DvbRyVORWmjj8WS+23cOswleHNkWs37PqzUHi5mp/ZswtE0Q/7dsP5tOpPDKqqN8u/cc/761He1DvI2OWOOooCjl0sDLlYeua860a5qx4Xgyn22PZe2RJCJPpxF5Oo1nlx/ils7BjO4eRotAdS3WZnFpuaw7WlJA3HIytXRhAgCzCTqF+ZR2IbZt6KU/sFLh2jT0onfT+mw5mcrCzdE8dWOE0ZGklvj5SBIvfHeIUyk5QMncrs8Mb6NJ1qXS9Gpan1WP9OPVH46ycMtp/rvrDBuOJ/PSqHZc1zrQ6HjyP3IKiolJzSUmNYeYtJL/nk4p+e+5zHzs9l8eaeHTE1vxcHagY5g3ncN86NLIh45h3njq0naRGi2/yMo/vi5ZiGV8r3DaBnsZnEjKKqy+Gx9P7s7SqHheWHGIw+cyGfnOZib1acyMIS10BUo56F9KrojFbOKalgFc0zKAxMx8vtgRx+cXuhY/3HyaDzefpmsjH0Z3D+PG9uparA3yi6xsO5XK+mPJrD+aXPpB+xf+Hs4M+E0Xorebk0FJpS6Z0q8xW06m8nlkHA9d11xzj8lVOZGUxQvfHWb9sWQA/Oo58djQltzWJVTdRVLp3JwceGZ4G25s14DHvtxHdEoOkz/ayahOwTwzPEJ/V6tYRl5RSaEwNZeYlJL/xqaV/Dc5q+APt63n7ECYrysF2ZkkFDiQVVDMxuMpbDyeApRM/9Iy0INOFwqMXRr5EF7fTfOxitQg768/xenUXAI8nPnrkBZGx5FyMplM3NolhAEt/Xnhu0N8s+cs8zZFs+pgAi+Nakd/TT1SJiooylUL9HThweua88A1zdh4vGSF6B8PJ7Ez5jw7Y87z3LcHuaVzCKO7h9EySF2LNYXdbud06q9diNtOpVJQbCu932I20aXRr12IrYM81YUoVW5giwCa+rtzMjmHJTvimNKvidGRpAbKyC3i9bXH+HhrDMU2O44WExP7NGb6tc3URSRVrmu4L98/3I/Za44xb+Mplu2OZ+PxFF4c2Zbr22pV+4pit9tJyyksKRj+Uji88N/Y1BzO5xb94fY+bo40qu9OeH03wi7895fvfd2dKC4uZuXKlQy9fginUvPZFXueqJjz7Io5T2xaLkcSsjiSkMVnkbEA+Lo7lXYwdg7zpn2IN65OOiEvUh3FpObwzroTAPzjpgid0K7B/Oo588ZdnRjZKZi/LzvAmfN5jF8QyS2dgvn7TRH4uutk3h9RQVEqjMVsYmDLAAa2DCApM5//7jrDZ5GxnDmfx8Itp1m45TSdw7wZ06MRN7ZroDdJ1VBuYTFbT6ZeWJE5mdi03IvuD/J0YWDLki7EPs399EFbDGc2m5jctwn/t2w/H24+zYTe4ThoUmUpo2Krjc93xPGf1UdLiweDWgfw1I0RNNaqf2IgF0cL/zesNTe0DeKxL/dxIimb+z7ZxU3tG/DczW00F3EZ2Wx2krIKOJ2aQ2xqLqdTc4j5zX9/u2jcpfh7OF9UKGxU351G9d1o5OuOl1vZ3gNZzCYiGnoS0dCTcT0bAZCUlU9UTDq7Y0sKjPviM0jLKeTHw4n8eDgRAAeziTYNPenc6NcuxgZemitYxGh2u52nvzlIYbGNvs38uKl9A6MjSQW4pmUAqx/tz39WH+PDLdEs3R3PumPJPH1TBCM6NlQH+WWooCiVIsDThWnXNOP+AU3ZdCKFzyJjWXMokajYdKJi00u6FjsFM7pHGK2CPI2OW2fZ7XZOJmez7mgy648ls/1UGoXWX7sQHS0muoX7XuhCDKBFYD29mEq1c0vnYGatPkp8eh6rDiZwU/uGRkeSGmDLiRSe/+4QRxKyAGgeUI9/3BShS1ykWukU5sN3D/blzbXHeX/DKb7bd46tJ1N5bkTJpdH6mwxWm52z6XmlhcLYtFxOp5QUDGPScsgvsl12W5MJGnq5EubrRrjfxYXDMF833J0r56NSgIcL17cNKu04LSi2cvBsZmkH466Y8yRlFbD3TAZ7z2Tw4ebTADTwcikpMF7oZIxo6KmVSUWq2PcHElh/LBkni5nnR7TR63At4u7swNPDI7i5Y0Oe/GofRxKyeGTJHpbujuefI9sS6qtF+f6XCopSqcxmE/1b+NO/hT9JWfl8uesMn0fGEZuWy0dbY/hoawydwrwZ3T2Mm9o30ASoVSC7oJjNJ1JK50KMT8+76P5gb9fSLsTezfyoV0lvpkUqioujhbt7NuLNtceZuzFaH7LlT73z8wle/eEoAF6ujjw6qDljezbSB3OpllwcLTx+fStuaNuAx77cy5GELKYv3s13bc7xwsi2+HvU/m7FIquNM+fzSjoLS+czLCkgxqXlUmS1X3Zbi9lEiI9rSXehrxuN6rsRXt+dcD83QnzcqsU8384OFjqH+dA5zIcp/UpO+Man57Er5sJl0rHnOXwui3MZ+azYd44V+84B4OJopn2I94XLpEsulVb3qkjlyS4o5vlvDwFw34AmNPGvZ3AiqQwdQ7359sG+fLDhFG+sPc6GY8kMeW0Dfx3Sgol9Ghsdr1pRpUCqTICHCw8MbMZ9/Zuy+WRJ1+Lqg4nsjk1nd2w6L3x7iJGdSlaIjmiorsWKYrfbOZqYVdKFeDSZnTFpF73xdnIw06Pxr12ITf3dVYyRGmdcz0bMWX+SvXHp7Io5T9dwrcYrl/bJtpjSYuLYHmH8bUhLfDQ/jtQA7UK8WD69L2//fIJ3fz7BqoMJbItO5dnhbWrF5Vj5RVZi03JLV0/+7eXJZ9PzsdouXzR0spgJ9XUlvL57SZehn1tJ12F9d4J9XGvcyQKTyUSIT0nBc0THYKBkWpq9cRlEXbhMOir2POm5RURGpxEZnVa6bWM/99K5GLs08qF5QD3NcS1SQV5fc4yEzHzCfN144JpmRseRSuRoMTPtmmbc0DaImUv3sz06jRdXHGb53rO8eHOE0fGqDRUUpcqZzSb6NfenX3N/krMKSroWd8QSk5rLx9ti+HhbDB1CvRnTPZSb2jestMtNarOMvKKSLsQLlzInZOZfdH+j+m4MvFBA7NHEV52hUuP5ezgzqmMwS3bGMXfjKRUU5ZK+23eWf3xzAICHrm3GjCEtDU4kUj5ODmZmDG7B0DaBPP7lPg6ezeSRJXv4bt9Z/jmqHYGeLkZH/EPZBcXEXCgU/m/h8FxG/h9u6+poKZm/8EKH4a8LorjRwMu11q/E7ubkQK+m9enVtD5QMj/kqZQcon6z2MvxpGyiU3KITsnhq6gzAHg4O9AxzLu0wNgx1FsLSIhcgcPnMvlwy2kAnhvRplp0N0vla+Jfj8+m9uSLnXH8c+Vh9p3JYNScbVwTZObaIiuOjnX79VRVBDGUv4cz9w9syl/6N2HrqVQWR8ay+mACe+PS2RuXzgvfHWZkp4aM7h5Gm4ZeRsettmw2O4fOZV5YTCWJqNj0i87kuzia6dWkfmkXYrgWG5BaaHK/xizZGcfqQ4nEpObQqL7Gufxq4/FkHl2yB7u9pDPx0cEtjI4kcsXaNPTi62l9mLPuJG/+dJwfDycRGb2ef9wUwW1dQgztVszILeL0bwqFMb9ZPTklu+APt/VwdiDcz52w+m6/WQylpHDo7+Fc47swK5LZbKJZQD2aBdTjjq6hQMm/fVRcSYExKvY8u2PTySooZuPxFDYeTwFK5o1sGehx0VyMjeq76d9W5A/YbHb+/vUBrDY7N7QN4pqWAUZHkipkNpu4q3sY17YK4JnlB/n+QAI/njWz5VQaQ9vW7bnbVVCUasFsNtGnmR99mvmRkl3AVxdWiD6dmssn22L5ZFssHUK8GN09jOEd1LUIkJ5byIbjv3Yh/u+b9Cb+7gxsEcDAlv50b+yrs2hS67UI9GBAC3/WH0tmwaZonhvR1uhIUk3siUvnLx/voshq58b2DXh+RFt9eJYaz9Fi5sHrmjOkTRCPfbmXfWcyeOzLfazYf46XRrWjoXflrAhst9tJzSksKRKm/FosjEnNISYtl/QLK6Zfjq+702+6DN0ufJUUDn3cHPW7eRW83By5pmVAabGj2GrjaGLWr4u9xJ4nLi2PIwlZHEnIYvH2WADquzuVribdOcyH9iFeet8o8hv/3RXHrpjzuDlZeHq4LnetqwI8XXjv7i58vy+eT9ZGcW1LLeSnqoxUO371nPnLgKZM7deEbdGpfBYZx6oD5y6sdLefF747xIhOwYzpHkbb4LrTtWiz2dkXn8H6o8msO5bE3rh0fjudkJuThd5N/RjQ0p+BLfy1CpXUSVP7NWH9sWS+2HmGGYNb4uVWty9DEDiRlMXEDyPJLbTSt5kfs+/oUOsvjZS6pWWQB0vv783cjdG89uMx1h0tmTz+qRtbc1e30Csq0NlsdhKz8jmdkkts2q8Fw18KiDmF1j/cPsDDubRgGO53oXDoW9J56OWq1+Wq4mAx06ahF20aejGuVzgASVn5RMWkl87FuP9MBqk5haw5lMiaQ4kl25lNtAn2Ku1g7NzImwZelVOgFqnu0nIKefn7IwA8OqiFfheEQa0DKIy2GR2jWlBBUaots9lE76Z+9G7qR2p2BF9FneGzyDiiU3JYvD2WxdtjaRdc0rV4c8eGtXI14tTsAjYcL1lMZcPxFNJyCi+6v0VgPQa2DGBgC3+6hPvg7KCzyVK39WlWn1ZBHhxJyOLTyBgeGKgJs+uys+l5jJsfyfncIjqEePH+uC56nZRaycFi5v6BTRkcEchjX+5ld2w6M5fuZ8W+c7x8S7tLnmQstto4l5F/4fLkXGJ/22mYmktB8eU/LJlM0NDL9cLiJ+6/Xp58YTEUzc1cfQV4uHB92yCubxsEQEGxlQPxmey+UGDcGXOe5KyC0umHFmyOBqChl0tpF2OXRj60buBZ4xa7EbkS//7+COm5RbQK8mBCn3Cj44hUK/prLzVC/XrO3Nv/QtfiqTQ+i4xl1YEE9sdnsH/Zfl5ccYgRHUvmWmwf4m103CtmtdnZE5fO+qNJrDuWzP74DOy/6UKs5+xA32YlXYgDWvhX2uVMIjWVyWRiSr8m/O2/e/loy2mm9G2Ck4M+8NRFaTmFjJu/nXMZ+TT1d+fDid01XYbUes0C6vHlfb35cHM0s1YfZdOJFK5/fQMPXtccZwdz6arJsam5xJ3Ppch6+ZWTLWYToT6uv1n85NfCYaivq4rztYSzg6W0SDilX8kl7WfO5120mvThc1mczcjn7L5zfLfvHFAyP3eHEO/SuRg7N/LB193J4KMRqVi7YtJYsjMOgBdHtlURXeR/6J211Cgmk6l0hbu0nEKWRp1hcWQsp5Jz+Cwyjs8i42gb7FnStdihYY1YxS4pK790HsSNx1PIyLt47qHWDTwZeOEy5s6NfPSHTORPDO/QgH+vOkJiZgHf7TvLLZ1DjI4kVSynoJiJC3dwMjmHBl4uLJrcQx90pc6wmEtOrFzXOpAnvtxH5Ok0/nXhcr3/5eRgJsz3twug/Fo4bOjtqvccdZDJZCLU141QXzdGdAwGSl5T955JL52LMSo2nYy8IrZHp7E9Oq102yZ+7hfNxdg8oB5mTTEhNVSx1cZTyw4AcEfXELqG+xqcSKT6UUFRaixfdyem9GvC5L6NiYwu6VpceSCBA/GZPLXsAP9ccZibO/zStehVbSb5LrLa2B2bzrqjSaw7msyhc5kX3e/p4kC/FiUdiANa+BPo6WJQUpGaydnBwoTe4bz6w1HmbYxmVKfgavP7L5WvoNjKfZ/sYm9cOj5ujnw8uTvB6uaWOqixnzuf39uTT7bH8O3es9R3d6aR36+LoYTXdyfI00UFH/lT7s4OpdMQQckcm6dSci5a7OVEUjanUnI4lZLDl7vOAODh4kCnsF9Xk+4Q6lUjTvaLACzccpojCVl4uzny5A2tjY4jUi2poCg1nslkokeT+vRoUp9ncgpZujuexdtjOJmcw+c74vh8RxwRDTwZ3SOMER0b4mnAG5lzGXmlXYibjqeQVVB80f3tQ7wY0MKfgS396RDijYM6AkSuypjuYbz103EOnctk68lUejfzMzqSVAGrzc6ML/ay8XgKbk4WPpzYnWYBHkbHEjGM2WxifK9wxl9YkEOkIpjNJpoF1KNZQD3u6BYKQHpuIbvjfu1i3BOXTlZ+MRuOJbPhWHLJdiZoGeRJ5zDv0susw3zddNJPqp1zGXm8tuYYAE9e30pXOYhchgqKUqv4uDsxuW9jJvUJZ8fp83wWGcuK/ec4dC6Tf3x9gJdWHGZ4hwaM7h5Gx1DvSnsDU1hsY2dMWsmKzEeTOZqYdXFON0f6Xygg9mvuj18950rJIVJX+bg7cXuXUD7eFsO8TdEqKNYBdrudp785wIp953C0mHh/XBc6hnobHUtEpE7wdnPimpYBXNMyACi5XPRIQtZFczHGpeVx+Fwmh89l8un2WAD86jnRuXQ1aR/aBXvh4qj5OcVYL3x3iJxCK53DvLmja6jRcUSqLRUUpVYymUx0b+xL98a+PDM8gqVR8XwWGcvxpGy+2HmGL3aeoVWQB2N6hDGiYzBerlfftXjmfC7rLnQhbjmRQk6h9Td5oGOo94UuxADaBXth0SVGIpVqUt/GfLI9hp+OJHEiKUudarXca2uO8en2WEwmeP3OTvRr7m90JBGROsvBYqZtsBdtg71KO2STMvNLC4y7Ys5zID6TlOxCVh9KZPWhRAAcLSbaNPQq7WDsHOZDkJem/5Gqs+5oEiv3J2Axm/jnqHaaFkLkD1xRQfGdd97h1VdfJSEhgQ4dOvDWW2/RvXv3Sz524cKFTJw48aLbnJ2dyc/Pv+i2w4cP88QTT7B+/XqKi4uJiIjgq6++Iiws7EoiipTydnNiUt/GTOwTzq6Y8yyOjGXFvnMcScji6W8O8tLKw9zUvmSuxc5hZe9azC+ysuN0GuuOJrPuaBInk3Muut+vnhP9L8yD2L+5Pz5qlRepUo393BnUOpA1hxKZv+k0L9/SzuhIUkk+3BzNmz+dAOCFEW25sX0DgxOJiMj/CvB04fq2Dbi+bclrdEGxlQPxmRfNxZicVcCeuHT2xKUzf1M0AMHerhdWk/amSyNfWjXw0IJBUinyi6w8s/wgABN6h9O6gafBiUSqt3IXFJcsWcKMGTOYM2cOPXr04PXXX2fo0KEcPXqUgICAS27j6enJ0aNHS7//34LNyZMn6du3L5MnT+a5557D09OTgwcP4uKis1FScUwmE13Dfeka7sszN7Vh2e6SFaKPJWbz5a4zfLnrDC0DPRjdPZRRnULwcvt912JMak5pF+LWk6nkFf3ahWgxm+gc9msXYkQDT53REjHYlL6NWXMokaVRZ/jbkBbU1/QCtc43e+J57ttDAMwY3IK7ezYyOJGIiJSFs4OltBNxKiVTV5w5n3dRF+Phc5nEp+cRn57Ht3vPAuDqaKF9yMVdjDpxLxXh3XUniUnNJdDTmUcHtzA6jki1V+6C4uzZs5k6dWpp1+GcOXNYsWIFCxYs4Mknn7zkNiaTiaCgoMvu86mnnmLYsGG88sorpbc1bdq0vNFEyszLzZEJfRpzT+9womLT+Swylu/2neVoYhbPfnuIl78/wk3tG3Jnt1ByCosvzIWYxOnU3Iv2E+jpfGE15gD6NvO7ZBFSRIzTvbEv7UO82Hcmg0+2xfLwoOZGR5IK9PPRJP76xV6gpJPgwWubGZxIRESulMlkItTXjVBfN0Z0DAYgp6CYvXHppfMw7oo5T2Z+Mduj09genVa6bRN/d7qElczD2KtJfcL93I06DKmholNymLPuJABP39SGes6aHU7kz5Trt6SwsJBdu3Yxc+bM0tvMZjODBg1i69atl90uOzubRo0aYbPZ6Ny5My+99BJt2rQBwGazsWLFCh5//HGGDh3K7t27ady4MTNnzmTkyJFXdlQiZWQymUrPbv7jpgi+3l0y1+KRhCy+ijrDV1FnLnq8g9lE13AfBrQIYGBLf1oFeWhlOpFqzGQyMblvYx7+fA8fbzvNXwY00WTvtcSumPPc/8kuim12RnRsyNM3Rej1WESklnF3dqB3M7/SxdVsNjunUrJLOxh3xZznZHIOpy58/XdXyXv3vw5uwfRrm+nvgpTJLwu7FVpt9G/hz7B2l2+GEpFflaugmJKSgtVqJTAw8KLbAwMDOXLkyCW3admyJQsWLKB9+/ZkZGQwa9YsevfuzcGDBwkJCSEpKYns7Gz+9a9/8eKLL/Lvf/+bVatWccstt/Dzzz8zYMCA3+2zoKCAgoKC0u8zMzMBKCoqoqioqDyHVGP8cly19fiqAzcHGNMtmNFdG7LnTAZLdp7h+wOJeLk60r+5H/2b16dXk/p4uPz6a1NcXGxg4tpL410q0uBWfjTwcuFcRj5Ld8Vye5cQoyNdROO9/I4nZjNpYST5RTb6N6/PSyMisFqLsVr/fFsxjsa61CUa75WnkY8LjXwacEvHkrkY03OL2HMmnajYdHacPs/OmHT+s+YYp5KzeGFEG5wdNN9iZavp433l/gQ2Hk/BycHM08Na6jOe/KGaPt7/THmOy2S32+1lffDZs2cJDg5my5Yt9OrVq/T2xx9/nPXr17N9+/YyhWvdujWjR4/mhRdeKN3n6NGjWbx4cenjbr75Ztzd3fnss89+t49nn32W55577ne3L168GDc3t7Iejsif+uW3Qyc3RWq2n86a+CbGQpCrnSc7WPU7XYOl5sMbByxkFJkIr2fngQgrzmo6FRGRCzYlmPgq2owNE0097ExuacVdsxLJZeQXwz/3WMgsMnF9iJUbQstcHhGplXJzcxkzZgwZGRl4ev7xwkTl6lD08/PDYrGQmJh40e2JiYl/OEfibzk6OtKpUydOnDhRuk8HBwciIiIuelzr1q3ZtGnTJfcxc+ZMZsyYUfp9ZmYmoaGhDBky5E8PuKYqKipizZo1DB48GEdH/UWU2k3jXSpav/wifpy1gYQ8Kx4tutO/uZ/RkUppvJddanYBd83bQUZRLs0D3Fk8uTvemru2xtBYl7pE4904w4AbTqTw0Of7OJlVzAfRnswd14nw+ppXsbLU5PH+4sojZBbF0sjXjVmTeuGsqXHkT9Tk8V4Wv1wBXBblKig6OTnRpUsX1q5dWzq/oc1mY+3atUyfPr1M+7Barezfv59hw4aV7rNbt24XrQINcOzYMRo1uvRKjc7Ozjg7/36lTkdHx1r5A/2tunCMIr/QeJeK4uvoyF3dwpi/KZoPt8RyXUQDoyP9jsb7H8vKL2LKJ7s5nZpLsLcrH0/uib+Xi9Gx5AporEtdovFujGtbN+Cr++sxaeEOTqfmcvsHkXwwrivdG/saHa1Wq2nj/eDZDD7eFgvACyPbUs9N7yuk7GraeC+r8hxTuSeUmDFjBnPnzuWjjz7i8OHD3H///eTk5JSu+jx+/PiLFm15/vnnWb16NadOnSIqKoq7776bmJgYpkyZUvqYxx57jCVLljB37lxOnDjB22+/zbfffssDDzxQ3ngiIiKXNKF3OGYTbDqRwuFzZT/zJsbLL7IyddFODsRnUt/diU+m9CBIxUQREfkDLYM8WDatNx1CvUnPLWLsvG0s/Z8FF6Xustns/P3rA9jscGP7BvRv4W90JJEap9wFxTvvvJNZs2bx9NNP07FjR/bs2cOqVatKF2qJjY3l3LlzpY8/f/48U6dOpXXr1gwbNozMzEy2bNly0SXOo0aNYs6cObzyyiu0a9eOefPm8dVXX9G3b98KOEQREREI9XXjhnYlnYnzNkYbnEbKqthq4+HPd7PtVBr1nB34aFJ3GvvpsjUREflzAR4ufD61J8PaBVFktTPji73MXn2UciwjILXUkp1x7I5Np56zA0/fFPHnG4jI75TrkudfTJ8+/bKXOK9bt+6i71977TVee+21P93npEmTmDRp0pXEERERKZMpfRuzYt85lu+N54nrWxLgqS636sxut/PUsgP8cDARJ4uZD8Z3oW2wl9GxRESkBnF1svD26M68Wv8o7607yZs/neB0ai6v3NYeF82XVyelZhfwr++PAPDo4BYE6v2gyBUpd4eiiIhITdUpzIeujXwostr5aOtpo+PIn3jlh6Ms2RmH2QRvju5E76bVZzEdERGpOcxmE09c34pXbm2Pg9nE8r1nGTtvO6nZBUZHEwP86/sjZOQV0bqBJ/f0uvS6DSLy51RQFBGROmVKv8YAfLo9ltzCYoPTyOXM23iK99adBOClUe24vm2QwYlERKSmu6NbKIsmd8fTxYFdMecZ+e5mTiRlGR1LqtCO02n8d1fJXJovjmyLg0UlEZErpd8eERGpUwZHBBHm60Z6bhFf7dLk7NXRV7vO8OKKwwA8fn1L7uoeZnAiERGpLXo39WPpA30I83UjLi2PUe9uYfOJFKNjSRUostr4+7IDAIzuHkqXRj4GJxKp2VRQFBGROsViNjGpTzgA8zdFY7VpYvbq5MdDiTz+1T6gZM7L+wc0NTiRiIjUNs0C6vH1tD50beRDVn4x9yyIZMmOWKNjSSX7cHM0RxOz8HV34vGhrYyOI1LjqaAoIiJ1zu1dQ/F0ceB0ai5rDycaHUcuiIxOY9riKKw2O7d0Dub/hrXGZDIZHUtERGohX3cnPpnSgxEdG1Jss/PEV/v51/dHsOlEY610Nj2P1388DsCTN7TCx93J4EQiNZ8KiiIiUue4OzswpkfJJNzzNkYbnEYADp3NZPJHOygotjGodQD/vrU9ZrOKiSIiUnlcHC28fmdHHr6uOQBz1p9k2uIo8gqtBieTivb8t4fILbTSLdyH2zqHGB1HpFZQQVFEROqkCb3DcTCbiDydxt64dKPj1GkxqTnc82EkWfnFdA/35e0xnXHUJOkiIlIFTCYTjw5uwWt3dsDJYub7AwncNXcbSVn5RkeTCvLzkSRWHUzAYjbxwsi2OmEpUkH0bl1EROqkIC8XhndoCMC8TepSNEpSZj7j5keSnFVA6waezL2nKy6OFqNjiYhIHTOqUwifTOmBj5sje+PSGfXOFo4maAXomi6v0MrTy0sWYpnctzGtgjwNTiRSe6igKCIiddbkvo0BWLn/HPHpeQanqXsy8ooYvyCS2LRcwnzd+GhSN7xcHY2OJSIidVT3xr4se6APTfzciU/P49b3trD+WLLRseQqvLvuBHFpeTTwcim9tF1EKoYKiiIiUme1DfaiV5P6WG12Fm5Wl2JVyi+yMvWjnRxJyMKvnjMfT+5OgIeL0bFERKSOC/dzZ+kDvenZxJfsgmImLdzBx9tijI4lV+BkcjZz1p8E4JnhEbg7OxicSKR2UUFRRETqtKn9S7oUP4+MIyu/yOA0dUOx1cb0xVFEnk7Dw8WBRZO606i+u9GxREREAPB2c2LRpB7c2jkEq83OP74+wAvfHcKqFaBrDLvdztPfHKDIauealv4MbRNkdCSRWkcFRRERqdMGtgigib87WQXFLNkRZ3ScWs9ms/PEV/v58XASzg5m5t/TjYiGms9IRESqFycHM7Nub89jQ1sCMH9TNH/5eBc5BcUGJ5OyWL73LJtPpOLsYOa5m9tiMmkhFpGKpoKiiIjUaWaziSl9mwDw4ebTFFttBieqvex2Oy9/f5ivos5gMZt4Z0xnujf2NTqWiIjIJZlMJqZd04y3x3TCycHMj4cTueP9rSRkaAXo6iwzv4gXVxwGYPo1zQir72ZwIpHaSQVFERGp827pHIyvuxPx6XmsOphgdJxaa876U8zdWDJX5Su3tmdQRKDBiURERP7cTe0b8vm9Panv7sTBs5mMfGczB89mGB1LLmP26mMkZxXQxM+dewc0MTqOSK2lgqKIiNR5Lo4W7u7ZCIC5G6Ox2zVHUkVbsiOWf686AsDfb2zNrV1CDE4kIiJSdp3DfPh6Wh+aB9QjITOf2+dsZe3hRKNjyf84EJ/Boq2nAXhhZFucHSzGBhKpxVRQFBERAcb1bISTg5m9censijlvdJxaZdWBBGYu3Q/A/QObMqWfugVERKTmCfV148v7e9OvuR+5hVamLtrJgk06EVldWG12nlq2H5sdbu7QkD7N/IyOJFKrqaAoIiIC+Hs4M6pjMADzLlyWK1dvy8kUHvp8NzY73NUtlMcvTG4vIiJSE3m5OrJgQjdGdw/DZofnvzvEM8sPag7mauCzyFj2nsnAw9mBv9/Y2ug4IrWeCooiIiIXTO7XGIAfDiUQk5pjcJqa70B8Bvcu2kVhsY2hbQJ5caRWWRQRkZrP0WLmpVFt+b9hrTCZYNHWGKYs2klWfpHR0eqs5KwCXrkwtcpfh7QgwNPF4EQitZ8KiiIiIhe0CPRgQAt/7PaSFZ/lyp1KzuaeBZFkFxTTq0l93rirEw4Wve0QEZHawWQycW//prw3tgsujmbWHU3m9jlbiU/PMzpanfTy94fJzC+mTUPP0nmxRaRy6Z29iIjIb0y50KX4xc44MnLVaXAlEjLyGTc/ktScQtoGe/LB+C64OGpSdBERqX2ubxvEF3/phb+HM0cSshjx9mb2xqUbHatO2XYqlaVR8ZhM8M9R7XQCU6SK6DdNRETkN/o286NVkAe5hVYWR8YaHafGSc8tZPyC7cSn59HYz52FE7vj4eJodCwREZFK0z7Em2+m9aFVkAcp2QXc+cFWVh04Z3SsOqGw2MY/vj4AwJjuYXQM9TY2kEgdooKiiIjIb5hMJib3LelSXLglmsJiTbJeVrmFxUxauINjidkEejqzaFJ3/Oo5Gx1LRESk0jX0duXL+3szsKU/+UU27vskijnrT2oF6Eo2f1M0x5Oyqe/uxONDWxkdR6ROUUFRRETkf9zcsSH+Hs4kZhawYv9Zo+PUCEVWGw98GkVUbDpero4smtSDUF83o2OJiIhUmXrODswb35V7epXM4fev748wc+l+irQCdKU4cz6XN9ceB+D/hrXGy01XRIhUJRUURURE/oezg6X0w8DcDdHqLvgTNpudv/13L+uOJuPqaGHBhG60DPIwOpaIiEiVc7CYeW5EW54dHoHZBJ/viGPihzvIyNO8zBXtuW8PkVdkpXtjX27pHGx0HJE6RwVFERGRSxjboxEujmYOnctk66lUo+NUW3a7nee/O8Q3e87iYDbx3t2d6dLIx+hYIiIihprQpzHz7umKu5OFTSdSuPW9LcSl5Rodq9b48VAiaw4l4mA28eLItphMJqMjidQ5KiiKiIhcgo+7E7d1CQFg3sZog9NUX2//dIKFW04D8J87OjCwZYCxgURERKqJa1sF8t/7etPAy4UTSdmMfGczu2LOGx2rxssrtPLM8oMATOnXhBaBuipCxAgqKIqIiFzGpD6NMZngpyNJnEjKNjpOtfPxthj+s+YYAM8Oj2BER11uJCIi8lsRDT35elof2gZ7kppTyOi52/h2r+Znvhpv/XSc+PQ8gr1deei6ZkbHEamzVFAUERG5jCb+9biuVSBQsoqg/Oq7fWd5+psDADx0bTMm9GlscCIREZHqKdDThS/+0otBrQMpLLbx4Ge7eWvtcc3RfAVOJGUxd+MpAJ4ZHoGbk4PBiUTqLhUURURE/sDUfiWFsqVRZ0jNLjA4TfWw8Xgyjy7Zg90OY3uE8ejgFkZHEhERqdbcnBx4f1wXpvQteV/xnzXH+Ot/91JQbDU4Wc1ht9v5+9cHKLLaua5VAIMjAo2OJFKnqaAoIiLyB7o39qV9iBcFxTY+2RZrdBzD7YlL5y8f76LIaufG9g14foQmQhcRESkLi9nE32+K4MWRbbGYTSyNimfc/EjO5xQaHa1G+HpPPNtOpeHiaObZm9vo/YeIwVRQFBER+QMmk4nJF7oJPt52mvyiuttJcCIpi4kfRpJbaKVvMz9m39EBi1lv5kVERMrj7p6N+HBCNzycHYiMTuOW97YQnZJjdKxqLSOviH+uOAzAg9c2J9TXzeBEIqKCooiIyJ8Y1q4BDb1cSMku5Js98UbHMcTZ9LySLorcIjqEevP+uC44O1iMjiUiIlIj9W/hz5f39ybY25XolBxGvbuZ7adSjY5Vbc364Sgp2YU09Xdnar8mRscREVRQFBER+VOOFjMT+oQDMG9jdJ2bRD0tp5Bx87dzLiOfpv7ufDihG+7OmgRdRETkarQM8uDraX3oGOpNem4Rd8/fztKoM0bHqnb2xqXzyfYYAF4Y2RYnB5UxRKqDK/pNfOeddwgPD8fFxYUePXoQGRl52ccuXLgQk8l00ZeLi8tlH3/fffdhMpl4/fXXrySaiIhIpbirexjuThaOJ2Wz/liy0XGqTE5BMRMX7uBkcg4NvVz4eHIPfN2djI4lIiJSK/h7OPP5vT25sV0Diqx2Znyxl9mrj9a5k5eXY7WVLMRit8PIjg3p3dTP6EgickG5C4pLlixhxowZPPPMM0RFRdGhQweGDh1KUlLSZbfx9PTk3LlzpV8xMTGXfNyyZcvYtm0bDRs2LG8sERGRSuXp4sid3cKAki7FuqCg2Mp9n+xib1w6Pm6OLJrcg4berkbHEhERqVVcHC28NboTDwxsCsCbP53g4c/31Ol5m3/x6fYY9sdn4OHiwFM3RhgdR0R+o9wFxdmzZzN16lQmTpxIREQEc+bMwc3NjQULFlx2G5PJRFBQUOlXYODvl3ePj4/nwQcf5NNPP8XR0bG8sURERCrdxD7hmE2w6UQKh89lGh2nUlltJV0SG4+n4OZk4cOJ3WkWUM/oWCIiIrWS2Wzi8etb8cpt7XEwm1i+9yxj520nNbvA6GiGScrK59UfjgLw+NCW+Hs4G5xIRH6rXBMgFRYWsmvXLmbOnFl6m9lsZtCgQWzduvWy22VnZ9OoUSNsNhudO3fmpZdeok2bNqX322w2xo0bx2OPPXbR7ZdTUFBAQcGvL6yZmSUf6oqKiigqKirPIdUYvxxXbT0+kd/SeJfqKsjDkaERgXx/MJEPNpzklVvaXvU+q+N4t9vtPPPtYVbsO4ejxcS7YzrSJsi9WmWUmqc6jnWRyqLxLldqVIcgGng4Me2zPeyKOc+IdzYz9+5O1fqkXmWN9xe/PURWfjHtgj25vXND/T5JtVDbX9/Lc1zlKiimpKRgtVp/12EYGBjIkSNHLrlNy5YtWbBgAe3btycjI4NZs2bRu3dvDh48SEhICAD//ve/cXBw4KGHHipTjpdffpnnnnvud7evXr0aN7favXz8mjVrjI4gUmU03qU6amWC73Fg+Z54Oplj8aqg6QSr03hfGWvmh3gzJuyMbWol4+h2Vh41OpXUFtVprItUNo13uVLTW8H7hy2cOZ/HLe9uZmJLGy29qve8ihU53o9lmFh+yIIJO0N80/hh1fcVtm+RilBbX99zc3PL/NhKX6KxV69e9OrVq/T73r1707p1a95//31eeOEFdu3axRtvvEFUVBQmk6lM+5w5cyYzZswo/T4zM5PQ0FCGDBmCp6dnhR9DdVBUVMSaNWsYPHiwLgmXWk/jXaq79ZmRRMWmc869OaMHN7+qfVW38f7R1hh+2FpSPXx2eARjuocanEhqi+o21kUqk8a7VIQROYU8sHgPu2LT+eCIA8/f3Jrbu4QYHet3Knq8FxbbeOOdLUAuY7qHcd/w1lcfUqSC1PbX91+uAC6LchUU/fz8sFgsJCYmXnR7YmIiQUFBZdqHo6MjnTp14sSJEwBs3LiRpKQkwsLCSh9jtVr561//yuuvv87p06d/tw9nZ2ecnX8/f4Kjo2Ot/IH+Vl04RpFfaLxLdXVv/ybc90kUn+08w4ODWuDmdPXn56rDeP9mTzwvXmhFnDG4Bff0aWJoHqmdqsNYF6kqGu9yNQK9Hfl0ak+e+Gof3+w5y/99fYjY8wU8PrQlZnPZmnGqUkWN9w82neBUSi5+9Zx5/IbW+h2Saqm2vr6X55jKtSiLk5MTXbp0Ye3ataW32Ww21q5de1EX4h+xWq3s37+fBg0aADBu3Dj27dvHnj17Sr8aNmzIY489xg8//FCeeCIiIlVicEQQYb5upOcW8dWuM0bHqRA/H03ir1/sBWBC73AevLaZwYlERETExdHC63d25OHrSq6ImLP+JNMWR5FXWDtXgI5Ly+XNtccB+PuNrfFyrX0FG5HaotyrPM+YMYO5c+fy0UcfcfjwYe6//35ycnKYOHEiAOPHj79o0Zbnn3+e1atXc+rUKaKiorj77ruJiYlhypQpANSvX5+2bdte9OXo6EhQUBAtW7asoMMUERGpOBaziUl9wgGYvykam616z2n0Z3bFnOf+T3ZRbLMzsmNDnr4poszTkIiIiEjlMplMPDq4Ba/f2REni5nvDyRw19xtJGXlGx2tQtntdp5dfpCCYhu9mtRnRMeGRkcSkT9Q7oLinXfeyaxZs3j66afp2LEje/bsYdWqVaULtcTGxnLu3LnSx58/f56pU6fSunVrhg0bRmZmJlu2bCEiIqLijkJERKSK3d41FE8XB06n5vLj4cQ/36CaOpaYxaSFO8gvsjGwpT+v3t6hWl5GJSIiUteN7BTMJ1N64OPmyN64dEa9s4WjCVlGx6owqw8lsvZIEo4WEy+MbKOTmyLV3BVN+jR9+nSmT59+yfvWrVt30fevvfYar732Wrn2f6l5E0VERKoTd2cHxvRoxJz1J5m3KZohbco2l3B1EpeWy7j528nIK6JzmDfvju2Mo6Xc5xpFRESkinRv7MuyB/owaeEOTqXkcOt7W3hnbGcGtPA3OtpVyS0s5rnlBwGY2q8JzQI8DE4kIn9GnxpERESu0D29G+FgNhEZnca+M+lGxymXlOwCxi+IJDGzgBaB9VgwoVuFLC4jIiIilSvcz52lD/SmZxNfsguKmbRwBx9vizE61lV5Y+1xzmbkE+ztyoPXNjc6joiUgQqKIiIiV6iBlyvDO5TM7zNvY7TBacouK7+IexZEEp2SQ7C3K4sm9cDbzcnoWCIiIlJG3m5OLJrUg9u6hGC12fnH1wd44btDWGvgvM7HErOYf+F91HM3t8HVyWJwIhEpCxUURURErsLkvo0BWLH/HPHpeQan+XP5RVamLtrJwbOZ1Hd34pMpPQjycjE6loiIiJSTk4OZV29rz2NDSxYznb8pmr98vIucgmKDk5Wd3W7n718foNhmZ3BEIIMiAo2OJCJlpIKiiIjIVWgb7EWvJvWx2ux8tOW00XH+ULHVxsOf72bbqTTqOTvw0aTuNPZzNzqWiIiIXCGTycS0a5rx9phOODmY+fFwIne8v5WEjJqxAvRXUfFERqfh6mjhmeFauFWkJlFBUURE5CpN6VfSpfjZ9liy8osMTnNpdrudp5Yd4IeDiThZzHwwvgttg72MjiUiIiIV4Kb2Dfn83p7Ud3fi4NlMRryziQPxGUbH+kPpuYW8vPIwAA9d15wQHzeDE4lIeaigKCIicpWuaRlAE393sgqK+WLnGaPjXNIrPxxlyc44zCZ4c3Qnejf1MzqSiIiIVKDOYT58Pa0PzQPqkZhZwB3vb+XHQ4lGx7qsV344SmpOIc0D6pVOISMiNYcKiiIiIlfJbDaVvhFesCmaYqvN4EQXm7fxFO+tOwnAy7e04/q2QQYnEhERkcoQ6uvGl/f3pl9zP3ILrUz9eCcLNkVjt1evxVp2x57ns8hYAF4Y2RYnB5UmRGoa/daKiIhUgFs7h+Dj5kh8eh4/HKw+3QBf7TrDiytKLid64vpW3NktzOBEIiIiUpm8XB1ZMKEbo7uHYbfD898d4pnlB6vNCc9iq42/f30Aux1u6RxMzyb1jY4kIldABUUREZEK4OJoYVzPRgDM3XiqWnQC/Hgokce/2gfA1H6NuW9AE4MTiYiISFVwtJh5aVRbnhrWGpMJFm2NYcqindViruePt8Vw8Gwmni4O/N+w1kbHEZErpIKiiIhIBRnXKxwni5k9celExZ43NEtkdBrTFkdhtdm5tXMI/zesNSaTydBMIiIiUnVMJhNT+zdhzt1dcHW0sO5oMrfP2Up8ep5hmZIy8/nP6mMAPH59K/zqORuWRUSujgqKIiIiFcTfw5mRnRoCMHdDtGE5Dp3NZPJHOygotjGodQD/vrWdiokiIiJ11NA2QXzxl14EeDhzJCGLEW9vZm9cuiFZXlhxmOyCYjqEejO6u6ZhEanJVFAUERGpQFP6lVxW/MOhBGJSc6r8+WNScxi/IJKs/GK6h/vy9pjOOFj0515ERKQuaxfixdfT+tAqyIOU7ALu/GArqw6cq9IMm46n8O3es5hN8M+RbbGYdbJTpCbTJwwREZEK1CLQg/4t/LHb4cPNp6v0uZMy8xk3P5KU7AJaN/Bk7j1dcXG0VGkGERERqZ4aervy5f29uaalP/lFNu77JIo5609WybzPBcVWnv7mAADje4XTNtir0p9TRCqXCooiIiIVbGq/xgB8sTOOjNyqmfw8I6+I8QsiiU3LJczXjY8mdcPL1bFKnltERERqhnrODswd35V7epUsJPev748wc+l+iip5Bej315/iVEoO/h7OzBjSolKfS0SqhgqKIiIiFaxvMz9aBXmQW2hlcWRspT9ffpGVqR/t5EhCFv4eznwyuQcBHi6V/rwiIiJS8zhYzDw3oi3PDo/AbILPd8Qx4cNIMvIq5yRoTGoOb/98AoC/39gaTxed8BSpDVRQFBERqWAmk4nJfUu6FBduiaawuPLO+hdbbUxfHEXk6TQ8XBxYNKk7YfXdKu35REREpHaY0Kcx8+7piruThc0nUrn1vS3EpeVW6HPY7XaeWX6QwmIbfZrV5+YODSt0/yJiHBUURUREKsHNHRvi7+FMYmYBK/afrZTnsNnsPPHVfn48nISzg5n593SjdQPPSnkuERERqX2ubRXIf+/rTQMvF04kZTPync3sijlfYfv/4WAC644m42Qx8/yItphMWohFpLZQQVFERKQSODtYSucnmrcxusInPLfb7bz8/WG+ijqDxWzi3bGd6d7Yt0KfQ0RERGq/iIaefD2tD22DPUnNKWT03G18u/fqT4bmFBTz3LeHAPjLgCY09a931fsUkepDBUUREZFKMrZHI1wczRw8m8nWU6kVuu85608xd2M0AK/c2p7rWgdW6P5FRESk7gj0dOGLv/RicEQghcU2HvxsN2+tPX5VJ0Rf//EY5zLyCfV1Zdo1zSowrYhUByooioiIVBIfdydu6xIClHQpVpQlO2L596ojQMnk5rdeeA4RERGRK+Xm5MCcu7swtV/JPND/WXOMv/53LwXF1nLv60hCJgs2nwbg+Zvb4uJoqcioIlINqKAoIiJSiSb1aYzJBD8dSeJEUvZV72/VgQRmLt0PwP0DmzKlX5Or3qeIiIgIgMVs4qkbI/jnqLZYzCaWRsUzbn4k53MKy7wPm83O35cdwGqzc32bIK5pFVCJiUXEKCooioiIVKIm/vW4rlXJ5cjzN11dl+KWkyk89NlubHa4q1sojw9tWRERRURERC4ytkcjPpzQDQ9nByKj07jlvS1Ep+SUadsvo86wM+Y8bk4Wnh4eUclJRcQoKiiKiIhUsl8uHVoadYbU7IIr2seB+AzuXbSLQquNoW0CeXGkVkoUERGRytO/hT9fPdCbYG9XolNyGPXuZrb/yZzQ53MKeXnlYQAeGdScht6uVRFVRAyggqKIiEgl697Yl3bBXhQU2/hkW2y5tz+VnM09CyLJLiimV5P6vHFXJxws+hMuIiIilatFoAdfT+tDx1Bv0nOLuHv+dr7adeayj//3qiOczy2iZaAHE/s0rsKkIlLV9GlERESkkplMJqZc6FL8eNtp8ovKPrl5QkY+4+ZHkppTSNtgTz4Y30UTm4uIiEiV8fdw5vN7e3JjuwYUWe389b97mb366O9WgN4dm87nO+IAeHFUWxx18lOkVtNvuIiISBUY1q4BDbxcSMku5Js98WXaJj23kPELthOfnkcTP3cWTuyOh4tjJScVERERuZiLo4W3RnfigYFNAXjzpxM8/Pme0pOkVjs8/W3Jpc63dwmhW7ivYVlFpGqooCgiIlIFHC1mJvYJB2DexujfndX/X7mFxUxauINjidkEejqzaHJ3/Oo5V0FSERERkd8zm008fn0rXrmtPQ5mE8v3nmXsvO2k5hSyMcHEkYQsvFwdefKGVkZHFZEqoIKiiIhIFbmzWxjuThaOJ2Wz/ljyZR9XZLXxwKdRRMWm4+XqyMeTexDi41aFSUVEREQu7Y6uoSya3B1PFwd2xZzntve3szK2pLTw5A2tqK8ToCJ1ggqKIiIiVcTL1ZE7u4UBMH9T9CUfY7PZ+dt/97LuaDKujhYWTOhGi0CPqowpIiIi8od6N/Vj2bQ+NKrvxpnzeRTYTHQM9eLOrqFGRxORKqKCooiISBWa2Cccswk2Hk/h8LnMi+6z2+08/90hvtlzFgeziffu7kyXRj4GJRURERG5vKb+9Vj2QB96N/HF3cHOCzdHYDabjI4lIlVEBUUREZEqFOrrxg1tGwC/71J866cTLNxyGoD/3NGBgS0DqjqeiIiISJn5ujvx0cSuvNDVSqsgXVEhUpeooCgiIlLFJvdrDMA3e+JJyioA4NPIOGavOQbAs8MjGNEx2LB8IiIiIuVhUWOiSJ1zRQXFd955h/DwcFxcXOjRoweRkZGXfezChQsxmUwXfbm4uJTeX1RUxBNPPEG7du1wd3enYcOGjB8/nrNnz15JNBERkWqvc5gPXRr5UGS188n2WHanmHjuu8MAPHRdcyb0aWxwQhERERERkcsrd0FxyZIlzJgxg2eeeYaoqCg6dOjA0KFDSUpKuuw2np6enDt3rvQrJiam9L7c3FyioqL4xz/+QVRUFEuXLuXo0aPcfPPNV3ZEIiIiNcCUviVFw0XbYvn4hBm7Hcb1bMSjg5obnExEREREROSPOZR3g9mzZzN16lQmTpwIwJw5c1ixYgULFizgySefvOQ2JpOJoKCgS97n5eXFmjVrLrrt7bffpnv37sTGxhIWFlbeiCIiItXekDZBhPq6EpeWB5i4sW0Qz97cBpNJ1wyJiIiIiEj1Vq6CYmFhIbt27WLmzJmlt5nNZgYNGsTWrVsvu112djaNGjXCZrPRuXNnXnrpJdq0aXPZx2dkZGAymfD29r7k/QUFBRQUFJR+n5lZskpmUVERRUVF5TmkGuOX46qtxyfyWxrvUlfc27cx/1h+iFZeNv45oiU2azE2q9GpRCqHXtulLtF4l7pE413qkto+3stzXCa73W4v64PPnj1LcHAwW7ZsoVevXqW3P/7446xfv57t27f/bputW7dy/Phx2rdvT0ZGBrNmzWLDhg0cPHiQkJCQ3z0+Pz+fPn360KpVKz799NNL5nj22Wd57rnnfnf74sWLcXNzK+vhiIiIGMpuh7O5EOSmycxFRERERMRYubm5jBkzhoyMDDw9Pf/wsZVeUPxfRUVFtG7dmtGjR/PCCy/87r5bb72VM2fOsG7dusuGv1SHYmhoKCkpKX96wDVVUVERa9asYfDgwTg6OhodR6RSabxLXaLxLnWFxrrUJRrvUpdovEtdUtvHe2ZmJn5+fmUqKJbrkmc/Pz8sFguJiYkX3Z6YmHjZORL/l6OjI506deLEiRMX3V5UVMQdd9xBTEwMP/300x8Gd3Z2xtnZ+ZL7ro0/0N+qC8co8guNd6lLNN6lrtBYl7pE413qEo13qUtq63gvzzGVa5VnJycnunTpwtq1a0tvs9lsrF279qKOxT9itVrZv38/DRo0KL3tl2Li8ePH+fHHH6lfv355YomIiIiIiIiIiEgVKfcqzzNmzOCee+6ha9eudO/enddff52cnJzSVZ/Hjx9PcHAwL7/8MgDPP/88PXv2pFmzZqSnp/Pqq68SExPDlClTgJJi4m233UZUVBTfffcdVquVhIQEAHx9fXFycqqoYxUREREREREREZGrVO6C4p133klycjJPP/00CQkJdOzYkVWrVhEYGAhAbGwsZvOvjY/nz59n6tSpJCQk4OPjQ5cuXdiyZQsREREAxMfHs3z5cgA6dux40XP9/PPPDBw48AoPTURERERERERERCpauQuKANOnT2f69OmXvG/dunUXff/aa6/x2muvXXZf4eHhlGNdGBERERERERERETFQueZQFBERERERERERkbpNBUUREREREREREREpsyu65Lm6+f/27j+myvrv4/jrAAInBQ1U5CQoyzQlBAklxZVMyjWjsVWI08Rc9UdYAmoSDnWiojYaIwS1uZgrM1fZD6gtJKFk/kCJpkaA6dTlFCsFlDTGOfcf3Z7v93xT7nN/5XAR5/nYznb8nIvj63LvOa+X149bl0y3tbUZnMR1Ojs71dHRoba2tn75aHLg3zHvcCfMO9wFsw53wrzDnTDvcCf9fd5v9WrO3JqwXxSK7e3tkqSQkBCDkwAAAAAAAAD/XO3t7Ro8eHC325hs/eCJKFarVRcuXJCfn59MJpPRcVyira1NISEhOn/+vPz9/Y2OA7gU8w53wrzDXTDrcCfMO9wJ8w530t/n3Wazqb29XRaLRR4e3d8lsV+coejh4aGRI0caHaNX+Pv798uhBW6HeYc7Yd7hLph1uBPmHe6EeYc76c/z/n+dmXgLD2UBAAAAAAAA4DQKRQAAAAAAAABOo1D8h/Dx8dHq1avl4+NjdBTA5Zh3uBPmHe6CWYc7Yd7hTph3uBPm/V/6xUNZAAAAAAAAAPQOzlAEAAAAAAAA4DQKRQAAAAAAAABOo1AEAAAAAAAA4DQKRQAAAAAAAABOo1D8B9iyZYtGjx4tX19fxcbG6siRI0ZHAnpcXl6eJk+eLD8/Pw0fPlxJSUlqbGw0OhbQKzZu3CiTyaT09HSjowAu8csvv2j+/PkKDAyU2WxWRESEjh49anQsoMd1dXUpJydHYWFhMpvNuv/++5Wbmyueg4n+4Ntvv1ViYqIsFotMJpM+/fRTh89tNptWrVql4OBgmc1mJSQkqLm52ZiwwF3qbt47Ozu1YsUKRUREaODAgbJYLFqwYIEuXLhgXGADUCj2cR9++KEyMzO1evVq1dXVKTIyUrNmzVJLS4vR0YAeVV1drbS0NB06dEgVFRXq7OzUE088oevXrxsdDXCp2tpabdu2TRMnTjQ6CuASV65cUVxcnAYMGKCvvvpKP/74o/Lz83XvvfcaHQ3ocZs2bVJJSYmKiorU0NCgTZs2afPmzXr77beNjgbctevXrysyMlJbtmy57eebN29WYWGhtm7dqsOHD2vgwIGaNWuWbty40ctJgbvX3bx3dHSorq5OOTk5qqur0yeffKLGxkY9/fTTBiQ1jsnGf5f1abGxsZo8ebKKiookSVarVSEhIXr11VeVlZVlcDrAdS5fvqzhw4erurpajz76qNFxAJe4du2aoqOjVVxcrHXr1ikqKkoFBQVGxwJ6VFZWlmpqavTdd98ZHQVwuaeeekpBQUHasWOHfe2ZZ56R2WzWe++9Z2AyoGeZTCbt3btXSUlJkv46O9FisWjp0qVatmyZJKm1tVVBQUEqLS1VSkqKgWmBu/Of8347tbW1mjJlis6ePavQ0NDeC2cgzlDsw/78808dO3ZMCQkJ9jUPDw8lJCTo4MGDBiYDXK+1tVWSFBAQYHASwHXS0tI0e/Zsh7/ngf7m888/V0xMjJ577jkNHz5ckyZN0jvvvGN0LMAlpk2bpsrKSjU1NUmSfvjhBx04cEBPPvmkwckA1zpz5owuXrzo8G+awYMHKzY2lmNXuIXW1laZTCYNGTLE6Ci9xsvoALizX3/9VV1dXQoKCnJYDwoK0k8//WRQKsD1rFar0tPTFRcXp4ceesjoOIBL7N69W3V1daqtrTU6CuBSp0+fVklJiTIzM5Wdna3a2lq99tpr8vb2VmpqqtHxgB6VlZWltrY2Pfjgg/L09FRXV5fWr1+vefPmGR0NcKmLFy9K0m2PXW99BvRXN27c0IoVKzR37lz5+/sbHafXUCgC6HPS0tJ04sQJHThwwOgogEucP39eS5YsUUVFhXx9fY2OA7iU1WpVTEyMNmzYIEmaNGmSTpw4oa1bt1Ioot/Zs2eP3n//fe3atUvh4eGqr69Xenq6LBYL8w4A/VBnZ6eSk5Nls9lUUlJidJxexSXPfdjQoUPl6empS5cuOaxfunRJI0aMMCgV4FqLFy9WWVmZ9u/fr5EjRxodB3CJY8eOqaWlRdHR0fLy8pKXl5eqq6tVWFgoLy8vdXV1GR0R6DHBwcGaMGGCw9r48eN17tw5gxIBrrN8+XJlZWUpJSVFERERev7555WRkaG8vDyjowEudev4lGNXuJNbZeLZs2dVUVHhVmcnShSKfZq3t7cefvhhVVZW2tesVqsqKys1depUA5MBPc9ms2nx4sXau3evvvnmG4WFhRkdCXCZmTNn6vjx46qvr7e/YmJiNG/ePNXX18vT09PoiECPiYuLU2Njo8NaU1OTRo0aZVAiwHU6Ojrk4eF4iOXp6Smr1WpQIqB3hIWFacSIEQ7Hrm1tbTp8+DDHruiXbpWJzc3N2rdvnwIDA42O1Ou45LmPy8zMVGpqqmJiYjRlyhQVFBTo+vXreuGFF4yOBvSotLQ07dq1S5999pn8/Pzs91oZPHiwzGazwemAnuXn5/e3+4MOHDhQgYGB3DcU/U5GRoamTZumDRs2KDk5WUeOHNH27du1fft2o6MBPS4xMVHr169XaGiowsPD9f333+utt97SokWLjI4G3LVr167p1KlT9l+fOXNG9fX1CggIUGhoqNLT07Vu3To98MADCgsLU05OjiwWS7dPxgX6qu7mPTg4WM8++6zq6upUVlamrq4u+/FrQECAvL29jYrdq0w2m81mdAh0r6ioSG+++aYuXryoqKgoFRYWKjY21uhYQI8ymUy3XX/33Xe1cOHC3g0DGGDGjBmKiopSQUGB0VGAHldWVqY33nhDzc3NCgsLU2Zmpl566SWjYwE9rr29XTk5Odq7d69aWlpksVg0d+5crVq1ym0OMNF/VVVVKT4+/m/rqampKi0tlc1m0+rVq7V9+3ZdvXpV06dPV3FxscaOHWtAWuDudDfva9asueMVdfv379eMGTNcnK5voFAEAAAAAAAA4DTuoQgAAAAAAADAaRSKAAAAAAAAAJxGoQgAAAAAAADAaRSKAAAAAAAAAJxGoQgAAAAAAADAaRSKAAAAAAAAAJxGoQgAAAAAAADAaRSKAAAA6LOqqqpkMpl09epVo6MAAADgf1EoAgAAAAAAAHAahSIAAAAAAAAAp1EoAgAA4I6sVqvy8vIUFhYms9msyMhIffTRR5L+dTlyeXm5Jk6cKF9fXz3yyCM6ceKEw3d8/PHHCg8Pl4+Pj0aPHq38/HyHz2/evKkVK1YoJCREPj4+GjNmjHbs2OGwzbFjxxQTE6N77rlH06ZNU2Njo2t3HAAAAHdEoQgAAIA7ysvL086dO7V161adPHlSGRkZmj9/vqqrq+3bLF++XPn5+aqtrdWwYcOUmJiozs5OSX8VgcnJyUpJSdHx48e1Zs0a5eTkqLS01P7zCxYs0AcffKDCwkI1NDRo27ZtGjRokEOOlStXKj8/X0ePHpWXl5cWLVrUK/sPAACAvzPZbDab0SEAAADQ99y8eVMBAQHat2+fpk6dal9/8cUX1dHRoZdfflnx8fHavXu35syZI0n6/fffNXLkSJWWlio5OVnz5s3T5cuX9fXXX9t//vXXX1d5eblOnjyppqYmjRs3ThUVFUpISPhbhqqqKsXHx2vfvn2aOXOmJOnLL7/U7Nmz9ccff8jX19fFfwoAAAD4T5yhCAAAgNs6deqUOjo69Pjjj2vQoEH2186dO/Xzzz/bt/v3sjEgIEDjxo1TQ0ODJKmhoUFxcXEO3xsXF6fm5mZ1dXWpvr5enp6eeuyxx7rNMnHiRPv74OBgSVJLS8td7yMAAAD+/7yMDgAAAIC+6dq1a5Kk8vJy3XfffQ6f+fj4OJSK/y2z2ezUdgMGDLC/N5lMkv66vyMAAAB6H2coAgAA4LYmTJggHx8fnTt3TmPGjHF4hYSE2Lc7dOiQ/f2VK1fU1NSk8ePHS5LGjx+vmpoah++tqanR2LFj5enpqYiICFmtVod7MgIAAKBv4wxFAAAA3Jafn5+WLVumjIwMWa1WTZ8+Xa2traqpqZG/v79GjRolSVq7dq0CAwMVFBSklStXaujQoUpKSpIkLV26VJMnT1Zubq7mzJmjgwcPqqioSMXFxZKk0aNHKzU1VYsWLVJhYaEiIyN19uxZtbS0KDk52ahdBwAAQDcoFAEAAHBHubm5GjZsmPLy8nT69GkNGTJE0dHRys7Otl9yvHHjRi1ZskTNzc2KiorSF198IW9vb0lSdHS09uzZo1WrVik3N1fBwcFau3atFi5caP89SkpKlJ2drVdeeUW//fabQkNDlZ2dbcTuAgAAwAk85RkAAAD/lVtPYL5y5YqGDBlidBwAAAD0Eu6hCAAAAAAAAMBpFIoAAAAAAAAAnMYlzwAAAAAAAACcxhmKAAAAAAAAAJxGoQgAAAAAAADAaRSKAAAAAAAAAJxGoQgAAAAAAADAaRSKAAAAAAAAAJxGoQgAAAAAAADAaRSKAAAAAAAAAJxGoQgAAAAAAADAaRSKAAAAAAAAAJz2P4agqoBR5QBVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13178327679634094 -0.7788511514663696 0.5482463836669922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "1SknOTQ7O9BS",
        "jdZ8zHIcPQPS",
        "3mlldpkcPFvk",
        "4NH27yFEuqtg",
        "vCh8kNiFl15G",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "Lyzd22RQX-Yg",
        "Y-K_7fUh2anJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMO8AUjRT0QT/SGYUOk96TH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}