{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf23aca-beca-419e-c21f-85a02ed6622f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_root/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 165215068.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 50431179.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_root/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 122025044.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 10589510.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 312726304.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 114711831.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 160401971.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5309511.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  x = x.resize((img_dim, img_dim))\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "\n",
        "bsize = 32\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, d=2):\n",
        "  idx = np.zeros((rows, cols, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      # idx[row, col, 0] = (1 + row) / rows\n",
        "      # idx[row, col, 1] = (1 + col) / cols\n",
        "      idx[row, col, 0] = 2.0 * ((row + 1) / rows) - 1.0\n",
        "      idx[row, col, 1] = 2.0 * ((col + 1) / cols) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _sgbmd(u, v, idxu, idxv, sim=None, f=None, normalize=True) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Slow General Batch Maromba Dot\"\n",
        "  Slower, more general, implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  sim: index similarity function\n",
        "  f: value function\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  sim = Pairwise(sim)\n",
        "  f = Pairwise(f)\n",
        "  ###\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  ###\n",
        "  # sims: (M * N) x 1 x (d_u * d_v)\n",
        "  # vals: (M * N) x (d_u * d_v) x d_val\n",
        "  sims = sim(idxu, idxv).reshape(m * n, 1, d_u * d_v) ###\n",
        "  norm = 1.0\n",
        "  if normalize:\n",
        "    # norm: (M * N) x 1\n",
        "    norm = sims.sum(dim=-1)\n",
        "  vals = f(u, v)\n",
        "  vals = vals.reshape(m * n, d_u * d_v, d_val)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.bmm(sims, vals).squeeze(1)\n",
        "  eps = 1e-8\n",
        "  dot = (dot / (norm + eps)).reshape(m, n, d_val)\n",
        "  return dot\n",
        "\n",
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  # Pdb().set_trace()\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  # normalizer: M x N x 1\n",
        "  idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv ** 6.0\n",
        "  # idxuv = nn.functional.relu(idxuv - bias) ###\n",
        "  mag = 2.0 # 10.0 # 200.0\n",
        "  idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # idxuv = nn.functional.gumbel_softmax(\n",
        "  #     6.0 * idxuv - 3.0, dim=2, hard=False, tau=0.2\n",
        "  # )\n",
        "  # idxuv = get_eye(m, d_u, d_v, n, idxuv.device)\n",
        "  # idxuv = idxuv / (idxuv.sum(dim=2).unsqueeze(2) + 1e-6)\n",
        "  # Pdb().set_trace()\n",
        "  # normalizer = idxuv.reshape(m, d_u * d_v, n).sum(dim=1).reshape(m, n, 1)\n",
        "  # normalizer = 1.0 - 1e-6\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  # dot = dot / (normalizer + 1e-6)\n",
        "  return dot\n",
        "\n",
        "def _gbmd(u, v, idxu, idxv, kernel=None, idx_part=None) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"General Batch Maromba Dot\"\n",
        "  Shorter implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u\n",
        "  v: N x d_v\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u = u.shape\n",
        "  n, d_v = v.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  assert (m, d_u, d_idx) == idxu.shape\n",
        "  assert (n, d_v, d_idx) == idxv.shape\n",
        "  if kernel:\n",
        "    idxu = kernel(idxu, idx_part)\n",
        "    idxv = kernel(idxv, idx_part)\n",
        "  # uidxu: M x d_idx\n",
        "  # vidxv: N x d_idx\n",
        "  uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "  vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "  dot = uidxu @ vidxv.T\n",
        "  ### Under experimentation\n",
        "  normalizer = idxu.sum(dim=1) @ idxv.sum(dim=1).T\n",
        "  dot = dot / (normalizer + 1e-8) ###\n",
        "  ###\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    # kernel = _cosine_kernel\n",
        "    # mdot = _gbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1]),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1]),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel=kernel,\n",
        "    #     idx_part=self._idx_part,\n",
        "    # )\n",
        "    # mdot = _sgbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     f=vecprod,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = _nsbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # _kernel_idx # _fast_kernel_idx # _fast_kernel_idx_sum\n",
        "    # midx = _fast_kernel_idx_sum(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel,\n",
        "    #     self._idx_part,\n",
        "    # )\n",
        "    # midx = _sgbmd(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     # f=vecsum,\n",
        "    #     f=vecmean,\n",
        "    # )\n",
        "    ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # midx = norm_normalize(\n",
        "    #     norm_normalize(_nsbmd(aidx, onesb, aidx, bidx))\n",
        "    #     + norm_normalize(_nsbmd(onesa, bidx, aidx, bidx))\n",
        "    # )\n",
        "    # midx = norm_normalize(_nsbmd(aidx, bidx, aidx, bidx))\n",
        "    midx = (\n",
        "        _nsbmd(aidx, onesb, aidx, bidx)\n",
        "        + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    # Pdb().set_trace()\n",
        "    ###\n",
        "    # midx = norm_normalize(\n",
        "    #     norm_normalize(_rdot(aidx, onesb, aidx, bidx))\n",
        "    #     + norm_normalize(_rdot(onesa, bidx, aidx, bidx))\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sampling functions"
      ],
      "metadata": {
        "id": "1SknOTQ7O9BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def idx2d(\n",
        "    channels: int,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    stride: int=2,\n",
        "    dilation: int=1,\n",
        "    device=\"cpu\"\n",
        "  ):\n",
        "  idx = []\n",
        "  dilh = 1 + dilation * (h - 1)\n",
        "  dilw = 1 + dilation * (w - 1)\n",
        "  for row in range(0, rows - (dilh - 1), stride):\n",
        "    for col in range(0, cols - (dilw - 1), stride):\n",
        "      for ch in range(channels):\n",
        "        for drow in range(0, dilh, dilation):\n",
        "          for dcol in range(0, dilw, dilation):\n",
        "            idx.append(\n",
        "                cols * rows * ch\n",
        "                + cols * (row + drow)\n",
        "                + (col + dcol)\n",
        "            )\n",
        "  idx = torch.tensor(idx).long().to(device)\n",
        "  return idx\n",
        "\n",
        "def unsort(idxs):\n",
        "  ridxs = [0 for _ in idxs]\n",
        "  for i, idx in enumerate(idxs):\n",
        "    ridxs[idx] = i\n",
        "  ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "  return ridxs\n",
        "\n",
        "def get_perms(tmp_idx):\n",
        "  idxs, _idxs = [], []\n",
        "  for dim in range(tmp_idx.shape[-1]):\n",
        "    ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "    idxs.append(ordering.cpu().detach())\n",
        "    _idxs.append(unsort(ordering).cpu().detach())\n",
        "  return idxs, _idxs\n",
        "\n",
        "def resort(k, src, tgt):\n",
        "  assert src == 0 or tgt == 0\n",
        "  global idxs, _idxs\n",
        "  if tgt == 0:\n",
        "    return idxs[src][k]\n",
        "  return _idxs[tgt][k]\n",
        "\n",
        "def hoods(dims, k0, w, _min=0, _max=None):\n",
        "  assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "  if len(dims) == 0:\n",
        "    return [k0] # [k0.item()]\n",
        "  _hoods = []\n",
        "  global idxs, _idxs\n",
        "  _k0d = resort(k0, 0, dims[-1]) #, idxs, _idxs)\n",
        "  for _w in range(-(w[-1] // 2), w[-1] // 2 + 1):\n",
        "    # k0d = min(_max, max(_min, _k0d + _w))\n",
        "    k0d = torch.clip(_k0d + _w, min=_min, max=_max)\n",
        "    _hoods += hoods(\n",
        "        dims[:-1],\n",
        "        resort(\n",
        "            k0d,\n",
        "            dims[-1], 0,\n",
        "            # idxs, _idxs\n",
        "        ),\n",
        "        w[:-1],\n",
        "        # idxs, _idxs,\n",
        "        _min, _max\n",
        "    )\n",
        "  return _hoods\n",
        "\n",
        "idxs, _idxs = None, None\n",
        "\n",
        "def idxhood(xidx, ws, stride):\n",
        "  \"\"\"\n",
        "  xidx: in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  dims = tuple(range(xidx.shape[-1]))\n",
        "  global idxs, _idxs\n",
        "  idxs, _idxs = get_perms(xidx)\n",
        "  pivots = torch.tensor([piv for piv in range(0, len(xidx), stride)]).long()\n",
        "  all_hoods = hoods(dims, pivots, ws, 0, len(xidx) - 1)\n",
        "  # all_hoods = torch.tensor(all_hoods).long().T.reshape(-1)\n",
        "  all_hoods = torch.cat(all_hoods, dim=0).reshape(len(all_hoods), -1).T\n",
        "  all_hoods = all_hoods.reshape(-1)\n",
        "  return all_hoods"
      ],
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MModule"
      ],
      "metadata": {
        "id": "jdZ8zHIcPQPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MModule(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _W_step(\n",
        "      self,\n",
        "      x: MTensor,\n",
        "      W: MTensor,\n",
        "      sets,\n",
        "      samples,\n",
        "      random=True,\n",
        "      conv=False,\n",
        "      filter_size=4,\n",
        "      activation=True,\n",
        "      regular_dot=False):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    # Put 1 into x\n",
        "    if not conv:\n",
        "      filter_size = in_dim\n",
        "    assert (in_dim % filter_size) == 0\n",
        "    num_windows = (in_dim // filter_size)\n",
        "    # one = MTensor(\n",
        "    #     torch.ones((n * num_windows), 1).to(self.device),\n",
        "    #     torch.ones((n * num_windows), 1, idx_dim).to(self.device),\n",
        "    # )\n",
        "    x = MTensor.reshape(x, (n * num_windows, filter_size))\n",
        "    # Sample W\n",
        "    if conv:\n",
        "      ### filter_size + 1\n",
        "      assert (sets * samples) % (filter_size) == 0\n",
        "      numw_windows = (sets * samples) // (filter_size)\n",
        "      sets, samples = numw_windows, (filter_size)\n",
        "    W_sets = MTensor.reshape(W, (sets, samples))\n",
        "    ## mdot: N x sets\n",
        "    # mdot: (N * num_windows) x numw_windows\n",
        "    mdot = x @ W_sets\n",
        "    if activation:\n",
        "      mdot.data = self.activation(mdot.data)\n",
        "    # mdot: N x num_windows x numw_windows\n",
        "    if conv:\n",
        "      ### Várias \"imagens\" coladas em um sentido\n",
        "      mdot = MTensor.reshape(mdot, (n, num_windows, numw_windows))\n",
        "    return mdot\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    channels = 1\n",
        "    img_h, img_w = img_dim, img_dim\n",
        "    filter_whs = [(3, 3), (3, 3)]\n",
        "    strides = [2, 1]\n",
        "    filter_w, filter_h = filter_whs[0]\n",
        "    stride = strides[0]\n",
        "    filter_area = filter_w * filter_h\n",
        "    filter_volume = channels * filter_area\n",
        "    self.all_pools = [x[:4]]\n",
        "    idx = idx2d(\n",
        "        channels,\n",
        "        img_h, img_w,\n",
        "        filter_w, filter_h,\n",
        "        stride=stride,\n",
        "        device=self.device\n",
        "    )\n",
        "    x = x[:, idx]\n",
        "    ###\n",
        "    pool = x\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      if conv:\n",
        "        pool = self._W_step(\n",
        "            pool,\n",
        "            self.MW[:, wl: wr],\n",
        "            self.sets[step],\n",
        "            self.samples[step],\n",
        "            random=False,\n",
        "            conv=conv,\n",
        "            filter_size=filter_volume,\n",
        "            activation=activate,\n",
        "        )\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        filter_volume = channels * filter_area\n",
        "        pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # assert img_dim % stride == 0\n",
        "        img_h = (img_h - filter_h + stride) // stride\n",
        "        img_w = (img_w - filter_w + stride) // stride\n",
        "        assert img_h * img_w == img_area\n",
        "        # cols = pool.data.shape[1] // rows\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        filter_w, filter_h = filter_whs[nxt_conv_step]\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_area = filter_w * filter_h\n",
        "        filter_volume = channels * filter_area\n",
        "        if nxt_conv:\n",
        "          idx = idx2d(\n",
        "              channels,\n",
        "              img_h, img_w,\n",
        "              filter_w, filter_h,\n",
        "              stride=stride,\n",
        "              device=self.device\n",
        "          )\n",
        "          pool = pool[:, idx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ],
      "metadata": {
        "id": "tQoFxrDIPScK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MModule II"
      ],
      "metadata": {
        "id": "3mlldpkcPFvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Oipx_P9qYUUb"
      },
      "outputs": [],
      "source": [
        "class MModule2(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(3, 3, 1), (3, 3, 2)]\n",
        "    strides = [4, 1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0]) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    # Pdb().set_trace()\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    mw = MTensor.reshape(\n",
        "        self.MW[0, wl: wr],\n",
        "        (self.sets[0], self.samples[0])\n",
        "    )\n",
        "    # idxw = idxhood(\n",
        "    #     mw.idx,\n",
        "    #     filter_whs[0],\n",
        "    #     strides[0]\n",
        "    # ) ### FIX\n",
        "    # mw = mw[:, idxw]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step]\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  y_pred = 10.0 * y_pred.data\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, d=idx_dim)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tmp_idx = template_x_idx[0].reshape(-1, 3)[:, :2]\n",
        "# idxs, _idxs = get_perms(tmp_idx)\n",
        "# sampled = hoods([0, 1], 14 * 28 + 14, [3, 3], idxs, _idxs, 0, 783)\n",
        "# sampled = np.array([[idx // 28, idx % 28] for idx in sampled])\n",
        "# # print(sampled)\n",
        "# plt.scatter(sampled[:, 0], sampled[:, 1])"
      ],
      "metadata": {
        "id": "OisDCAuLCmQ8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNheVxvNNK30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d9a78405-c216-4497-9b77-4cc4180ad955"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.002988651394844055 0.5782769322395325\n",
            "0.000750127190258354 0.577780544757843\n"
          ]
        }
      ],
      "source": [
        "hidden_dim = 1176\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    1 * 3 * 3,\n",
        "    2 * 3 * 3,\n",
        "    # 4 * 8 * 3 * 3,\n",
        "    hidden_dim,\n",
        "]\n",
        "sets = [\n",
        "    # out_ch\n",
        "    2,\n",
        "    2,\n",
        "    # 1,\n",
        "    num_classes\n",
        "]\n",
        "n_params = int(np.array(samples).dot(np.array(sets)))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  model = MModule2(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3) # 1e-2\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  print(model.W.mean().item(), model.W.std().item())\n",
        "  print(model.W_idx.mean().item(), model.W_idx.std().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(24, 4), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5tP_tfMAjw",
        "outputId": "a5c2be37-d2b3-48f1-b98d-69813f80e345"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([4, 784]), torch.Size([4, 169, 2]), torch.Size([4, 121, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 2) // 2, (img_dim - 2) // 2, 2),\n",
        "    (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  for ch in range(shapes[idx][2]):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(img_.mean(), img_.min(), img_.max())\n",
        "    plt.imshow(img_)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  idx_ = idx[:, 0].numpy()\n",
        "  plt.figure(figsize=(4, 4))\n",
        "  plt.scatter(idx_[:, 0], idx_[:, 1], marker=\"+\")\n",
        "  plt.grid()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt-a46cmSBmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b09e1aba-6831-4e59-c841-2d2bc15edbfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>),\n",
              " tensor(0.5751, device='cuda:0', grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "### Ordenar pelo índice\n",
        "# filters = model.W_idx[0, :25].reshape(1, 5, 5, idx_dim)\n",
        "# print(filters)\n",
        "model.W_idx.mean(), model.W_idx.std()\n",
        "# for filter in filters:\n",
        "#   filter = filter.cpu().detach().numpy()\n",
        "#   plt.imshow(filter)\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.W_idx.mean(), model.W_idx.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnweClNF0-Ik",
        "outputId": "6000465f-4501-4e62-a171-74aa55e3a8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>),\n",
              " tensor(0.5751, device='cuda:0', grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPdqOyP9Sdx1"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(train_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "jdZ8zHIcPQPS",
        "3mlldpkcPFvk",
        "QQRFtDATXUmH",
        "039kGqbPXp4d"
      ],
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhXB2QUmY4ugkxULNyYeH+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}