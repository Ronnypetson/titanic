{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6dxGxcHAx5P"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 3\n",
        "img_dim = 32\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  return transform(x).reshape(-1)\n",
        "  # return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 32 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "# SOURCE_DATASET = FashionMNIST\n",
        "SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ],
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0):\n",
        "  idx = np.zeros((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = int(np.log((d_u + d_v) // 2)) * 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    ###\n",
        "    mdot = _nsbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # ###\n",
        "    midx = (\n",
        "        _nsbmd(aidx, onesb, aidx, bidx)\n",
        "        + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    # midx = _nsbmd(aidx, bidx, aidx, bidx)\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _rdot(aidx, onesb, aidx, bidx)\n",
        "    #     + _rdot(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "def idx2d(\n",
        "    channels: int,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    stride: int=2,\n",
        "    dilation: int=1,\n",
        "    device=\"cpu\"\n",
        "  ):\n",
        "  idx = []\n",
        "  dilh = 1 + dilation * (h - 1)\n",
        "  dilw = 1 + dilation * (w - 1)\n",
        "  for row in range(0, rows - (dilh - 1), stride):\n",
        "    for col in range(0, cols - (dilw - 1), stride):\n",
        "      for ch in range(channels):\n",
        "        for drow in range(0, dilh, dilation):\n",
        "          for dcol in range(0, dilw, dilation):\n",
        "            idx.append(\n",
        "                cols * rows * ch\n",
        "                + cols * (row + drow)\n",
        "                + (col + dcol)\n",
        "            )\n",
        "  idx = torch.tensor(idx).long().to(device)\n",
        "  return idx\n",
        "\n",
        "def unsort(idxs):\n",
        "  ridxs = [0 for _ in idxs]\n",
        "  for i, idx in enumerate(idxs):\n",
        "    ridxs[idx] = i\n",
        "  ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "  return ridxs\n",
        "\n",
        "def get_perms(tmp_idx):\n",
        "  idxs, _idxs = [], []\n",
        "  for dim in range(tmp_idx.shape[-1]):\n",
        "    ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "    idxs.append(ordering.cpu().detach())\n",
        "    _idxs.append(unsort(ordering).cpu().detach())\n",
        "  return idxs, _idxs\n",
        "\n",
        "def resort(k, src, tgt):\n",
        "  assert src == 0 or tgt == 0\n",
        "  global idxs, _idxs\n",
        "  if tgt == 0:\n",
        "    return idxs[src][k]\n",
        "  return _idxs[tgt][k]\n",
        "\n",
        "def hoods(dims, k0, w, _min=0, _max=None):\n",
        "  assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "  if len(dims) == 0:\n",
        "    return [k0] # [k0.item()]\n",
        "  _hoods = []\n",
        "  global idxs, _idxs\n",
        "  _k0d = resort(k0, 0, dims[-1]) #, idxs, _idxs)\n",
        "  for _w in range(-(w[-1] // 2), (w[-1] // 2) + (w[-1] % 2)):\n",
        "    # k0d = min(_max, max(_min, _k0d + _w))\n",
        "    k0d = torch.clip(_k0d + _w, min=_min, max=_max)\n",
        "    _hoods += hoods(\n",
        "        dims[:-1],\n",
        "        resort(\n",
        "            k0d,\n",
        "            dims[-1], 0,\n",
        "            # idxs, _idxs\n",
        "        ),\n",
        "        w[:-1],\n",
        "        # idxs, _idxs,\n",
        "        _min, _max\n",
        "    )\n",
        "  return _hoods\n",
        "\n",
        "idxs, _idxs = None, None\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods\n",
        "\n",
        "def _idxhood(xidx, ws, stride):\n",
        "  \"\"\"\n",
        "  xidx: in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  dims = tuple(range(xidx.shape[-1]))\n",
        "  global idxs, _idxs\n",
        "  idxs, _idxs = get_perms(xidx)\n",
        "  pivots = torch.tensor([piv for piv in range(0, len(xidx), stride)]).long()\n",
        "  all_hoods = hoods(dims, pivots, ws, 0, len(xidx) - 1)\n",
        "  # all_hoods = torch.tensor(all_hoods).long().T.reshape(-1)\n",
        "  all_hoods = torch.cat(all_hoods, dim=0).reshape(len(all_hoods), -1).T\n",
        "  all_hoods = all_hoods.reshape(-1)\n",
        "  # Pdb().set_trace()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    self.activation = nn.ELU()\n",
        "    # self.activation = nn.ReLU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    # _W = nn.Parameter(\n",
        "    #     2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    # )\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _std = 0.01\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((*shape, idxdim), device=device)\n",
        "    # )\n",
        "    _W_idx = _std * torch.randn((*shape, idxdim), device=device)\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=torch.zeros(n, 1, idx_dim).to(device),\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      pool = (\n",
        "          MTensor.reshape(\n",
        "              pool, (n * feat_sets[step], -1)\n",
        "          )\n",
        "          @ mw\n",
        "      )\n",
        "      # pool = (\n",
        "      #     MTensor.reshape(pool, (n * feat_sets[step], -1))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      self.all_pools.append(pool[:4])\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim) ### offset=0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "HNheVxvNNK30",
        "outputId": "a715741a-0caa-4df5-e31c-dff9c944cde0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e5120073ada2>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# model = MModule(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# model = MModule2(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   model = MModule3(\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0midx_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MModule3' is not defined"
          ]
        }
      ],
      "source": [
        "hidden_dim = 50\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    (2, 3, 3),\n",
        "    (2, 3, 3),\n",
        "    # (2, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    hidden_dim,\n",
        "]\n",
        "\n",
        "sets = [samp[0] for samp in samples[1:-1]] + [1, num_classes]\n",
        "_samples = [int(np.prod(samp)) for samp in samples]\n",
        "conv_params = int(np.array(_samples[:-1]).dot(np.array(sets[:-1])))\n",
        "# conv_params = int(np.prod(np.array(samples[:-1])))\n",
        "n_params = int(np.array(_samples).dot(np.array(sets)))\n",
        "# n_params = conv_params + hidden_dim * num_classes\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  # model = MModule2(\n",
        "  model = MModule3(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "xGn5VTZPw-1K",
        "outputId": "9b323af0-8107-41c3-f43d-9a70e489402c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABR0AAAESCAYAAABw5XIsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACG2ElEQVR4nOzdd3yT5frH8U/Svfem0AJlrwIFkSHKEBEVxMFQxIFHLRwBj8fxcy/Uw1ERFTe4cDMUEGUc9i4tlLJnSxe0pZu2aZPfH4UqMgtt0/F9v1550Tx5nidXQ+4muXJf92WwWCwWRERERERERERERKqI0doBiIiIiIiIiIiISP2ipKOIiIiIiIiIiIhUKSUdRUREREREREREpEop6SgiIiIiIiIiIiJVSklHERERERERERERqVJKOoqIiIiIiIiIiEiVUtJRREREREREREREqpSttQOoKWazmZSUFNzc3DAYDNYOR0REREREREREpE6xWCzk5eURHByM0XjhuYwNJumYkpJCaGiotcMQERERERERERGp05KSkmjUqNEF92kwSUc3Nzeg/EFxd3e3cjQiF2cymfjjjz8YOHAgdnZ21g5HxGo0FkQ0DkRA40DkNI0FEY0Da8rNzSU0NLQiz3YhDSbpeLqk2t3dXUlHqRNMJhPOzs64u7vrj6g0aBoLIhoHIqBxIHKaxoKIxkFtcClLF6qRjIiIiIiIiIiIiFQpJR1FRERERERERESkSinpKCIiIiIiIiIiIlWqwazpKCIiIiIiIiIiNaesrAyTyVTl5zWZTNja2lJUVERZWVmVn7+hs7e3x2i88nmKSjqKiIiIiIiIiEiVsVgspKWlkZ2dXW3nDwwMJCkp6ZIamkjlGI1GwsPDsbe3v6LzVCrpOGXKFObMmcPu3btxcnLi6quv5o033qBly5bnPeaTTz7hyy+/ZMeOHQB06dKF1157jW7dulXsY7FYeP755/nkk0/Izs6mZ8+ezJgxg4iIiIp9srKymDBhAr/++itGo5Hhw4czbdo0XF1dK/s7i4iIiIiIiIhINTmdcPT398fZ2bnKE4Nms5n8/HxcXV2rZEae/MlsNpOSkkJqaiqNGze+ov+7SiUdV65cSXR0NFFRUZSWlvL0008zcOBAdu7ciYuLyzmPWbFiBSNHjuTqq6/G0dGRN954g4EDB5KQkEBISAgAb775Ju+++y5ffPEF4eHhPPvss1x//fXs3LkTR0dHAEaPHk1qaipLlizBZDJx77338uCDDzJ79uzL/uXrE7PZwlcbjjA0MgQPJ7WLFxEREREREZGaV1ZWVpFw9PHxqZb7MJvNlJSU4OjoqKRjNfDz8yMlJYXS0lLs7C4/x1SppOPixYvPuD5r1iz8/f2JiYmhT58+5zzmm2++OeP6p59+ys8//8yyZcsYM2YMFouFd955h2eeeYZbbrkFgC+//JKAgADmzZvHiBEj2LVrF4sXL2bz5s107doVgOnTpzN48GCmTp1KcHBwZX6Neum5X3bw9YZE1uzP4OO7u2h6sYiIiIiIiIjUuNNrODo7O1s5Erlcp8uqy8rKai7p+Hc5OTkAeHt7X/IxhYWFmEymimMOHTpEWloa/fv3r9jHw8OD7t27s379ekaMGMH69evx9PSsSDgC9O/fH6PRyMaNGxk2bNhZ91NcXExxcXHF9dzcXKD8yV8di5ha27COQXy/OYklO9N5f/k+/tEn3NohyRU6/Tytj89XkcrQWBDROBABjQOR0zQWpLYzmUxYLBYsFgtms7la7sNisVT8W1330ZCd/v8zmUzY2NiccVtl/vZcdtLRbDYzceJEevbsSbt27S75uCeeeILg4OCKJGNaWhoAAQEBZ+wXEBBQcVtaWhr+/v5nBm5ri7e3d8U+fzdlyhRefPHFs7b/8ccf9TbbfmsTA98ftOG/S/ZyMnk3LTws1g5JqsCSJUusHYJIraCxIKJxIAIaByKnaSxIbWVra0tgYCD5+fmUlJRU633l5eVV6/kbqpKSEk6ePMmqVasoLS0947bCwsJLPs9lJx2jo6PZsWMHa9asueRjXn/9db777jtWrFhRsVZjdXnqqaeYPHlyxfXc3FxCQ0MZOHAg7u7u1Xrf1nKDxYJpbgJzYlP49ogj8x7uQZBH9T7OUn1MJhNLlixhwIABVzSdWaSu01gQ0TgQAY0DkdM0FqS2KyoqIikpCVdX12rL/VgsFvLy8nBzc9PyctWgqKgIJycn+vTpc9b/4elK4ktxWUnH8ePHs2DBAlatWkWjRo0u6ZipU6fy+uuvs3TpUjp06FCxPTAwEID09HSCgoIqtqenp9OpU6eKfY4dO3bG+UpLS8nKyqo4/u8cHBxwcHA4a7udnV29/sP82q0d2J2Wz87UXB79YTvfP9gDe1stqlqX1ffnrMil0lgQ0TgQAY0DkdM0FqS2Kisrw2AwYDQaq63Jy+mS6tP3UxuFhYUxceJEJk6caNVzXA6j0YjBYDjn35nK/N2p1P+MxWJh/PjxzJ07l+XLlxMefmnrBr755pu8/PLLLF68+Ix1GQHCw8MJDAxk2bJlFdtyc3PZuHEjPXr0AKBHjx5kZ2cTExNTsc/y5csxm8107969Mr9CvedoZ8OHd3XB3dGW2MRsXl2409ohiYiIiIiIiIjUan379q3S5N7mzZt58MEHq+x8dVGlko7R0dF8/fXXzJ49Gzc3N9LS0khLS+PkyZMV+4wZM4annnqq4vobb7zBs88+y+eff05YWFjFMfn5+UB5VnrixIm88sor/PLLL8THxzNmzBiCg4MZOnQoAK1bt2bQoEGMGzeOTZs2sXbtWsaPH8+IESPUufocGvs48/adnQD4Yv0R5sUmWzcgEREREREREZE6zmKxnLXG4fn4+fnV254il6pSSccZM2aQk5ND3759CQoKqrh8//33FfskJiaSmpp6xjElJSXcdtttZxwzderUin3+/e9/M2HCBB588EGioqLIz89n8eLFZ9SNf/PNN7Rq1Yp+/foxePBgevXqxccff3wlv3u91q91ABOuaw7AU3Pi2ZOmxVVFREREREREpGZZLBYKS0qr/HKypOyi+5zucn0xY8eOZeXKlUybNg2DwYDBYODw4cOsWLECg8HAb7/9RpcuXXBwcGDNmjUcOHCAW265hYCAAFxdXYmKimLp0qVnnDMsLIx33nmn4rrBYODTTz9l2LBhODs7ExERwS+//FKpxzIxMZFbbrkFV1dX3N3dueOOO0hPT6+4fdu2bVx77bW4ubnh7u5Oly5d2LJlCwBHjhzhpptuwsvLCxcXF9q2bcuiRYsqdf+VVak1HS/lP2vFihVnXD98+PBFjzEYDLz00ku89NJL593H29ub2bNnX/Rc8qeJ/VsQl5TN6n0ZPPR1DPPH98TdUWt+iIiIiIiIiEjNOGkqo81zv1vlvne+dD3O9hdPfU2bNo29e/fSrl27ityUn59fRU7rySefZOrUqTRt2hQvLy+SkpIYPHgwr776Kg4ODnz55ZfcdNNN7Nmzh8aNG5/3fl588UXefPNN/vOf/zB9+nRGjx7NkSNH8Pb2vmiMZrO5IuG4cuVKSktLiY6O5s4776zIxY0ePZrIyEhmzJiBjY0NcXFxFWswRkdHU1JSwqpVq3BxcWHnzp24urpe9H6vxGV3r5baz8ZoYNqISG6avoZDGQU8/uM2Pryrizo7iYiIiIiIiIic4uHhgb29Pc7OzudsWPzSSy8xYMCAiuve3t507Nix4vrLL7/M3Llz+eWXXxg/fvx572fs2LGMHDkSgNdee413332XTZs2MWjQoIvGuGzZMuLj4zl06BChoaEAfPnll7Rt25bNmzcTFRVFYmIijz/+OK1atQIgIiKi4vjExESGDx9O+/btAWjatOlF7/NKKelYz3m72PPB6M7c/uF6fk9I56NVB3nommbWDktEREREREREGgAnOxt2vnR9lZ7TbDaTl5uHm7vbBbtXO9nZVMn9/b0pcn5+Pi+88AILFy4kNTWV0tJSTp48SWJi4gXP06FDh4qfXVxccHd359ixY5cUw65duwgNDa1IOAK0adMGT09Pdu3aRVRUFJMnT+aBBx7gq6++on///tx+++00a1aeA/rnP//Jww8/zB9//EH//v0ZPnz4GfFUh9rZV1yqVMdQT56/uQ0Aby7ezboDGVaOSEREREREREQaAoPBgLO9bZVfnOxtLrpPVVV6uri4nHH9X//6F3PnzuW1115j9erVxMXF0b59e0pKSi54ntOlzn99bMxmc5XECPDCCy+QkJDAjTfeyPLly2nTpg1z584F4IEHHuDgwYPcfffdxMfH07VrV6ZPn15l930uSjo2EKO6NWZ450aYLfDPb2NJyymydkgiIiIiIiIiIrWCvb09ZWVll7Tv2rVrGTt2LMOGDaN9+/YEBgZeUk+TK9G6dWuSkpJISkqq2LZz506ys7Np06ZNxbYWLVowadIk/vjjD2699VZmzpxZcVtoaCgPPfQQc+bM4bHHHuOTTz6p1piVdGwgDAYDrwxtR+sgdzLyS3jkmxhKSqsumy4iIiIiIiIiUleFhYWxceNGDh8+TEZGxgVnIEZERDBnzhzi4uLYtm0bo0aNqtIZi+fSv39/2rdvz+jRo9m6dSubNm1izJgxXHPNNXTt2pWTJ08yfvx4VqxYwZEjR1i7di2bN2+mdevWAEycOJHff/+dQ4cOsXXrVv73v/9V3FZdlHRsQJzsbfjwrs64OdqyNTGb1xbtsnZIIiIiIiIiIiJW969//QsbGxvatGmDn5/fBddnfOutt/Dy8uLqq6/mpptu4vrrr6dz587VGp/BYGD+/Pl4eXnRp08f+vfvT9OmTfn+++8BsLGxITMzkzFjxtCiRQvuuOMObrjhBl588UUAysrKiI6OpnXr1gwaNIgWLVrwwQcfVGvMaiTTwDTxceGdOztx/xdbmLXuMJGNPbmlU4i1wxIRERERERERsZoWLVqwfv36M7aFhYVhsVjO2jcsLIzly5efsS06OvqM638vtz7XebKzsy8Y09/P0bhxY+bPn3/Ofe3t7fn222/Pe67qXr/xXDTTsQHq1zqA8dc2B+DJn+PZk5Zn5YhERERERERERKQ+UdKxgZo0oAW9I3w5aSrj4a9jyCsyWTskERERERERERGpJ5R0bKBsjAamjYgk2MORgxkFPP7j9nNO9RUREREREREREaksJR0bMG8Xez64qwv2NkYWJ6Tx8aqD1g5JRERERERERETqASUdG7hOoZ48d1MbAN5YvJv1BzKtHJGIiIiIiIiI1HVms9naIchlqqpKWHWvFkZ3b8zWxBPM2ZrMhG+3smBCbwI9HK0dloiIiIiIiIjUMfb29hiNRlJSUvDz88Pe3h6DwVCl92E2mykpKaGoqAijUfPpqpLFYuH48eMYDAbs7Oyu6FxKOgoGg4FXh7ZnZ0ouu9PyiJ69lW/HXYW9rQauiIiIiIiIiFw6o9FIeHg4qamppKSkVMt9WCwWTp48iZOTU5UnNKU8T9SoUSNsbGyu6DxKOgoATvY2fHR3F4ZMX0PMkRO8tmgXL9zc1tphiYiIiIiIiEgdY29vT+PGjSktLaWsrKzKz28ymVi1ahV9+vS54tl4cjY7O7srTjiCko7yF018XHj7jk488OUWZq07TGRjT27pFGLtsERERERERESkjjldnlsdSUEbGxtKS0txdHRU0rEWU/2snKF/mwCir20GwJM/x7M3Pc/KEYmIiIiIiIiISF2jpKOcZfKAlvRq7stJUxkPfRVDXpHJ2iGJiIiIiIiIiEgdoqSjnMXGaGDaiE4EezhyMKOAx3/cXmXt0kVEREREREREpP5T0lHOycfVgfdHd8bOxsDihDQ+WX3Q2iGJiIiIiIiIiEgdoaSjnFdkYy+eu6m8g/Ubi/ew4WCmlSMSEREREREREZG6QElHuaC7ujfm1sgQyswWxs+OJT23yNohiYiIiIiIiIhILaeko1yQwWDg1WHtaRXoRkZ+MdHfbMVUZrZ2WCIiIiIiIiIiUosp6SgX5WRvw4d3dcHNwZYtR04wZdFua4ckIiIiIiIiIiK1mJKOcknCfF347x0dAfh87SEWbE+xckQiIiIiIiIiIlJbVSrpOGXKFKKionBzc8Pf35+hQ4eyZ8+eCx6TkJDA8OHDCQsLw2Aw8M4775y1z+nb/n6Jjo6u2Kdv375n3f7QQw9VJny5QgPbBvJw32YA/Pun7exLz7NyRCIiIiIiIiIiUhtVKum4cuVKoqOj2bBhA0uWLMFkMjFw4EAKCgrOe0xhYSFNmzbl9ddfJzAw8Jz7bN68mdTU1IrLkiVLALj99tvP2G/cuHFn7Pfmm29WJnypAo8NaMHVzXwoLCnjoa9jyC8utXZIl81isbDpUBY/bEmipFTrVIqIiIiIiIiIVBXbyuy8ePHiM67PmjULf39/YmJi6NOnzzmPiYqKIioqCoAnn3zynPv4+fmdcf3111+nWbNmXHPNNWdsd3Z2Pm/iUmqGrY2Rd0dGMuTdNRw4XsC/f9rG+6M6YzAYrB3aJTucUcCc2GTmxh4lKeskACv3HOfdkZHYGOvO7yEiIiIiIiIiUltVKun4dzk5OQB4e3tXSTAAJSUlfP3110yePPmsRNY333zD119/TWBgIDfddBPPPvsszs7O5zxPcXExxcXFFddzc3MBMJlMmEymKou3IfJwMPLuiA6M/mwzi+LT+Hjlfu7rGWbtsC4ou9DEwh1pzI9LITYpp2K7i70NJWVmFsan4uVsy3M3tqo1CdTTz1M9X6Wh01gQ0TgQAY0DkdM0FkQ0DqypMo+5wWKxWC7nTsxmMzfffDPZ2dmsWbPmko4JCwtj4sSJTJw48bz7/PDDD4waNYrExESCg4Mrtn/88cc0adKE4OBgtm/fzhNPPEG3bt2YM2fOOc/zwgsv8OKLL561ffbs2edNVErlrE4z8NMhG4xYiG5bRnN3a0d0plIz7Mw2sPm4gYQTBsos5clEAxZaeVro6muhg7eFHScMfLnPiAUDg0PLuL7RZQ0JEREREREREZF6rbCwkFGjRpGTk4O7+4UTQZeddHz44Yf57bffWLNmDY0aNbqkYy4l6Xj99ddjb2/Pr7/+esFzLV++nH79+rF//36aNWt21u3nmukYGhpKRkbGRR8UuTQWi4V//bSDX7an4udqz7xHeuDv5mD1mLYdzWH+tlQWxqdxovDPDHyrQDeGdQpiSIegs+L8akMiLy3cDcBLN7dmZFRojcZ9LiaTiSVLljBgwADs7OysHY6I1WgsiGgciIDGgchpGgsiGgfWlJubi6+v7yUlHS+rvHr8+PEsWLCAVatWXXLC8VIcOXKEpUuXnnf24l91794d4LxJRwcHBxwczk6A2dnZ6QlZhV6/rQN70vPZk57HxB+2M3vcVdjZVKo/UZVIyipkXmwyc2OTOZjxZ2MjfzcHhkaGMCwyhNZB5x8M9/VuxomTpUxfvp8Xft2Fv7sTg9oF1UToF6XnrEg5jQURjQMR0DgQOU1jQUTjwBoq83hXKulosViYMGECc+fOZcWKFYSHh1c6uAuZOXMm/v7+3HjjjRfdNy4uDoCgoNqRGGqonO1t+fDuLtw8fQ2bD5/g9d928+yQNjVy33lFJn6LT+PnrUfZeCirYrujnZFBbQO5tXMjejb3veTmMJMHtCAjv5hvNyXxz2/j+OI+e3o086mu8EVERERERERE6q1KJR2jo6OZPXs28+fPx83NjbS0NAA8PDxwcnICYMyYMYSEhDBlyhSgvDHMzp07K35OTk4mLi4OV1dXmjdvXnFus9nMzJkzueeee7C1PTOsAwcOMHv2bAYPHoyPjw/bt29n0qRJ9OnThw4dOlz+by9VItzXhal3dOQfX8Xw2ZpDRDb2ZEiH4IsfeBlKy8ys3p/BnK3J/JGQRnGpGQCDAXo09eHWzo0Y1C4QV4fKT+I1GAy8fEs7MvNL+GNnOg9+uYXv/nEVbYM9qvrXEBERERERERGp1yqVmZkxYwYAffv2PWP7zJkzGTt2LACJiYkYjX+W16akpBAZGVlxferUqUydOpVrrrmGFStWVGxfunQpiYmJ3HfffWfdr729PUuXLuWdd96hoKCA0NBQhg8fzjPPPFOZ8KUaXd82kIeuacaHKw/w75+20yrQjeb+blVybovFQkJKLnNjk5kfl0JG/p9rdTb3d+XWziEM7RRCsKfTFd+XrY2Rd0dGMubzTWw6lMU9n2/m54d70MTH5YrPLSIiIiIiIiLSUFS6vPpi/ppIhPLmMZdy3MCBA8+7X2hoKCtXrrykGMV6/jWwBduSsll/MJN/fBXD/PG9LmvG4WlpOUXMj0tmztZk9qTnVWz3drHn5o7BDO/ciHYh7hgMl1Y+fakc7Wz4ZExX7vxoPbvT8hjz+SZ+euhq/KzcJEdEREREREREpK64/IyQyN/Y2hiZPiqSIe+u4cDxAp74aTvvjYqsVFKwsKSU3xPSmLM1mTX7Mzidh7a3NTKgdQC3dg6hTwu/am9W4+Fkx5f3dWP4h+s4klnI2Jmb+O7Bq3Bz1AK1IiIiIiIiIiIXo6SjVClfVwfeH92ZER+vZ2F8KpFrPHmgd9MLHlNmtrD+QCZzYo+yeEcahSVlFbdFhXlxa+dGDG4fhIdTzSb8/N0d+fK+7tw2Yx0JKbn846sYZt4bhYOtTY3GISIiIiIiIiJS1yjpKFWuSxMvnrmxDc//ksCU33bToZEn3cK9z9pvb3oec7YmMy82mbTcoortYT7ODItsxLDIEBr7ONdk6GcJ93Vh1r3dGPHxetYdyGTS93FMH9n5kjtii4iIiIiIiIg0REo6SrUY06MJWxNPMD8uhejZW1k4oRf+7o5k5BfzS1wKc2KPsiM5t2J/Dyc7hnQI4tbOjejc2LPK12m8Eu0befDxmK7cO3Mzi+LT8HbZwcu3tKtVMYqIiIiIiIiI1CZKOkq1MBgMTLm1PbtT89iTnse4r2LwcbFn5d7jlJnLF2q0szHQt6U/wzuHcG0r/1pdttyzuS9v39mJ8d9u5esNifi6OjCxfwtrhyUiIiIiIiIiUisp6SjVxtnelhl3deaW99ayLSm7YnunUE9u7RzCkA7BeLvYWy/ASrqxQxBZBW15dn4C7yzdh6+rA3dd1cTaYYmIiIiIiIiI1DpKOkq1aurnyvujOzN9+T66h/swrHMIzfxcrR3WZbu7RxjH84p5d/l+np2/A28Xewa3D7J2WCIiIiIiIiIitYqSjlLt+rTwo08LP2uHUWUmDWjB8fwSvt2UyMTv4vB0suPq5r7WDktEREREREREpNYwWjsAkbrGYDDwytB2DGobSEmZmQe/imFHco61wxIRERERERERqTWUdBS5DDZGA++M6MRVTb3JLy5l7MzNHMkssHZYIiIiIiIiIiK1gpKOIpfJ0c6Gj8d0pXWQOxn5xdz92SaO5RVZOywREREREREREatT0lHkCrg72vHFfVE09nYmMauQsZ9vJrfIZO2wRERERERERESsSklHkSvk7+bIV/d3w9fVnp2puTz45RaKTGXWDktERERERERExGqUdBSpAk18XJh1bzdcHWzZcDCLid/FUWa2WDssERERERERERGrUNJRpIq0C/Hg4zFdsLcxsjghjWfn78BiUeJRRERERERERBoeJR1FqtDVzXx5Z0QnDAaYvTGRt5fus3ZIIiIiIiIiIiI1TklHkSo2uH0QL93SDoB3l+3jq/WHrRuQiIiIiIiIiEgNU9JRpBrcfVUTHu0XAcBzvySwcHuqlSMSEREREREREak5SjqKVJOJ/SMY3b0xFgtM+j6OdfszrB2SiIiIiIiIiEiNUNJRpJoYDAZeuqUdg9sHUlJmZtyXW9iRnGPtsEREREREREREqp2SjiLVyMZo4O07O9GjqQ8FJWWMnbmJwxkF1g5LRERERERERKRaKekoUs0cbG34eEwX2ga7k5Ffwt2fb+RYbpG1wxIRERERERERqTZKOorUADdHO2bd240mPs4kZZ3knpmbyS0yWTssEREREREREZFqoaSjSA3xc3Pgq/u64+vqwK7UXMZ9sYUiU5m1wxIRERERERERqXJKOorUoMY+znxxXxRuDrZsPJTFo9/FUma2WDssEREREREREZEqVamk45QpU4iKisLNzQ1/f3+GDh3Knj17LnhMQkICw4cPJywsDIPBwDvvvHPWPi+88AIGg+GMS6tWrc7Yp6ioiOjoaHx8fHB1dWX48OGkp6dXJnyRWqFtsAcfj+mKvY2R3xPSeWbeDiwWJR5FREREREREpP6oVNJx5cqVREdHs2HDBpYsWYLJZGLgwIEUFJy/G29hYSFNmzbl9ddfJzAw8Lz7tW3bltTU1IrLmjVrzrh90qRJ/Prrr/z444+sXLmSlJQUbr311sqEL1Jr9Gjmw7QRnTAY4NtNiby9ZK+1QxIRERERERERqTK2ldl58eLFZ1yfNWsW/v7+xMTE0KdPn3MeExUVRVRUFABPPvnk+QOxtT1vUjInJ4fPPvuM2bNnc9111wEwc+ZMWrduzYYNG7jqqqsq82uI1Ao3tA/ilaHt+L+5O3h3+X58XB245+owa4clIiIiIiIiInLFKpV0/LucnBwAvL29rziQffv2ERwcjKOjIz169GDKlCk0btwYgJiYGEwmE/3796/Yv1WrVjRu3Jj169efM+lYXFxMcXFxxfXc3FwATCYTJpO6BkvtcEfnYNJzTvLu8gO88GsCno42DG5fnnw//TzV81UaOo0FEY0DEdA4EDlNY0FE48CaKvOYX3bS0Ww2M3HiRHr27Em7du0u9zQAdO/enVmzZtGyZUtSU1N58cUX6d27Nzt27MDNzY20tDTs7e3x9PQ847iAgADS0tLOec4pU6bw4osvnrX9jz/+wNnZ+YriFalKTS3QO8DI6nQjk3/cxp74WFp6/rnG45IlS6wYnUjtobEgonEgAhoHIqdpLIhoHFhDYWHhJe972UnH6OhoduzYcdbai5fjhhtuqPi5Q4cOdO/enSZNmvDDDz9w//33X9Y5n3rqKSZPnlxxPTc3l9DQUAYOHIi7u/sVxyxSlQaZLUz6YTu/JaTzxQF7vrqvK638nVmyZAkDBgzAzs7O2iGKWI3JZNJYkAZP40BE40DkNI0FEY0DazpdSXwpLivpOH78eBYsWMCqVato1KjR5Zzigjw9PWnRogX79+8HIDAwkJKSErKzs8+Y7Zienn7edSAdHBxwcHA4a7udnZ2ekFLr2AHvjIwkd9Zm1u7PZNxXsXw3rnwtVD1nRcppLIhoHIiAxoHIaRoLIhoH1lCZx7tS3astFgvjx49n7ty5LF++nPDw8EoHdyny8/M5cOAAQUFBAHTp0gU7OzuWLVtWsc+ePXtITEykR48e1RKDSE1zsLXho7u70i7EncyCEu6dFUNOibWjEhERERERERGpvErNdIyOjmb27NnMnz+/Yq1FAA8PD5ycnAAYM2YMISEhTJkyBYCSkhJ27txZ8XNycjJxcXG4urrSvHlzAP71r39x00030aRJE1JSUnj++eexsbFh5MiRFee///77mTx5Mt7e3ri7uzNhwgR69OihztVSr7g62DLr3m7cNmMdhzMLeS/BhmNu++nY2Jv2IR4EuDtgMBisHaaIiIiIiIiIyAVVKuk4Y8YMAPr27XvG9pkzZzJ27FgAEhMTMRr/nECZkpJCZGRkxfWpU6cydepUrrnmGlasWAHA0aNHGTlyJJmZmfj5+dGrVy82bNiAn59fxXFvv/02RqOR4cOHU1xczPXXX88HH3xQmfBF6gRfVwe+ur87t36wlmP5Jby34iBwsOK29iHutA/xoF2IB+0beRDo7qhEpIiIiIiIiIjUKpVKOloslovuczqReFpYWNhFj/vuu+8uel5HR0fef/993n///YvuK1LXhXo7M++RHrz1w3LMXqHsTMlj37E8MvKL+d+e4/xvz/GKfX1d7csTkKcTkSEeBHkoESkiIiIiIiIi1nPZ3atFpHr5uznQJ8jC4MHtsLOz42RJGTtTc9mRnEN8cg47knPYdyyfjPwSVuw5zoq/JCJ9XP6WiGzkQbASkSIiIiIiIiJSQ5R0FKkjnOxt6NLEiy5NvCq2FZn+kog8Wp6M3Hcsn8yCElbuPc7KvWcmItuGeJxRnh3i6aREpIiIiIiIiIhUOSUdReowRzsbOjf2onPjMxORu/4yIzI+OZd96XlkFpSwau9xVv0lEentYk/b4PIkZPtTMyKViBQRERERERGRK6Wko0g942hnQ2RjLyL/lojcnZZXXpZ9akbk3vQ8sgpKWL0vg9X7Mir29XK2qyjNPj0jspGXEpEiIiIiIiIicumUdBRpABztbOgU6kmnUM+KbUWmMvacTkSemhW5Jy2PE4WmsxKRns52ZzSqaa9EpIiIiIiIiIhcgJKOIg2Uo50NHUM96fiXRGRx6ZmJyO1Hy2dEZp8jEdkq0I150T1xtLOxQvQiIiIiIiIiUpsp6SgiFRxsbejQyJMOjTwrtv09ERmfnMPu1Dx2p+WxYs9xBrULtF7AIiIiIiIiIlIrKekoIhd0rkTkKwt28umaQyyKT1XSUURERERERETOYrR2ACJS9wzuEATAsl3pFJnKrByNiIiIiIiIiNQ2SjqKSKVFhnoS7OFIQUkZK/cet3Y4IiIiIiIiIlLLKOkoIpVmMBi4oX35bMdF8alWjkZEREREREREahslHUXksgxuf7rE+phKrEVERERERETkDEo6ishliQz1JMjDkfziUlbvy7B2OCIiIiIiIiJSiyjpKCKXxWg0VHSuVom1iIiIiIiIiPyVko4ictluPFVivXRnOsWlKrEWERERERERkXJKOorIZevc2ItAd0fyiktZvVcl1iIiIiIiIiJSTklHEblsKrEWERERERERkXNR0lFErsiNHcpLrJfsUom1iIiIiIiIiJRT0lFErkiXxl74uzmQV1TK2v0qsRYRERERERERJR1F5AoZjQZuOFVivXB7mpWjEREREREREZHaQElHEblig091sV6yM42SUrOVoxERERERERERa1PSUUSuWNcwb/zcHMhVibWIiIiIiIiIoKSjiFQBm7+WWKuLtYiIiIiIiEiDp6SjiFSJ0yXWfySoxFpERERERESkoVPSUUSqRFSYN76u5SXW6w6oxFpERERERESkIatU0nHKlClERUXh5uaGv78/Q4cOZc+ePRc8JiEhgeHDhxMWFobBYOCdd965rPP27dsXg8FwxuWhhx6qTPgiUo1sjAYGtQsAYJFKrEVEREREREQatEolHVeuXEl0dDQbNmxgyZIlmEwmBg4cSEFBwXmPKSwspGnTprz++usEBgZe0XnHjRtHampqxeXNN9+sTPgiUs0qSqx3pmMqU4m1iIiIiIiISENlW5mdFy9efMb1WbNm4e/vT0xMDH369DnnMVFRUURFRQHw5JNPXtF5nZ2dz5u4FBHr6x7ug6+rPRn5Jaw7kMk1LfysHZKIiIiIiIiIWEGlko5/l5OTA4C3t3eVBHOx837zzTd8/fXXBAYGctNNN/Hss8/i7Ox8znMUFxdTXFxccT03NxcAk8mEyWSq0nhFqsPp52lde74OaO3Pt5uPsmBbMleHe1o7HKkH6upYEKlKGgciGgcip2ksiGgcWFNlHnODxWKxXM6dmM1mbr75ZrKzs1mzZs0lHRMWFsbEiROZOHFipc/78ccf06RJE4KDg9m+fTtPPPEE3bp1Y86cOec8zwsvvMCLL7541vbZs2efN1EpIldub46B93fa4Gxr4ZUuZdioXZWIiIiIiIhIvVBYWMioUaPIycnB3d39gvte9kzH6OhoduzYcckJxys974MPPljxc/v27QkKCqJfv34cOHCAZs2anXWep556ismTJ1dcz83NJTQ0lIEDB170QRGpDUwmE0uWLGHAgAHY2dlZO5xLNrDMzLf/WUlWgQmvVt3p1dzH2iFJHVdXx4JIVdI4ENE4EDlNY0FE48CaTlcSX4rLSjqOHz+eBQsWsGrVKho1anQ5p7ji83bv3h2A/fv3nzPp6ODggIODw1nb7ezs9ISUOqWuPWft7OD6tkF8uymRP3Yd49rWWodVqkZdGwsi1UHjQETjQOQ0jQURjQNrqMzjXanCR4vFwvjx45k7dy7Lly8nPDy80sFV1Xnj4uIACAoKqpIYRKTq3Hiqi/XvCemUqou1iIiIiIiISINTqZmO0dHRzJ49m/nz5+Pm5kZaWhoAHh4eODk5ATBmzBhCQkKYMmUKACUlJezcubPi5+TkZOLi4nB1daV58+aXdN4DBw4we/ZsBg8ejI+PD9u3b2fSpEn06dOHDh06VM0jISJV5qqm3ni72JNVUMKGg1n0ivC1dkgiIiIiIiIiUoMqNdNxxowZ5OTk0LdvX4KCgiou33//fcU+iYmJpKamVlxPSUkhMjKSyMhIUlNTmTp1KpGRkTzwwAOXfF57e3uWLl3KwIEDadWqFY899hjDhw/n119/vdLfX0Sqga2NkevbBgCwMD71InuLiIiIiIiISH1TqZmOl9LoesWKFWdcDwsLu+hxF7s9NDSUlStXXvS+RaT2GNw+iG83JfFHQhov39IWW7WxFhEREREREWkwlAUQkWpxVVMfvJztyCwoYdOhLGuHIyIiIiIiIiI1SElHEakWdjZGBrYp71ytEmsRERERERGRhkVJRxGpNoM7nO5inUaZ+eLLM4iIiIiIiIhI/aCko4hUm6ub+eDpbEdGfgkbD2VaOxwRERERERERqSFKOopItSkvsS7vYr1IJdYiNaq0zGztEEREREREpAFT0lFEqtXg9uUl1ot3pKvEWqQGlJktPPbDNqJeXcqWw2riJCIiIiIi1qGko4hUq57NffFwsiMjv5jNSoCIVCuLxcLLC3by89ajnCg08cTP2ykuLbN2WCIiIiIi0gAp6Sgi1crOxsgAlViL1IjP1hxi1rrDALg52HLgeAEfrTxo3aBERERERKRBsrV2ACJS/93YPoifYo7y2440nr+pLTZGg7VDEql3FmxP4ZWFuwD4v8Gt8Xd34NHv4njvf/u5qWMw4b4uVo5QpPLKzBZMZWbKzBZKyyyYzOYztpnKLJSazZSWWSg1WygtM5/6t3xfA9A1zBtXB73lFREREalpegcmItWuZ3Nf3B1tOZ5XzJbDWXRv6mPtkETqlY0HM5n8/TYAxl4dxgO9wwH4KeYoq/dl8My8eL6+vzsGgxL+UrWKTGV8uvogiVmFfyb+zGZMZZaK5GDp6Z//lhw817a/nqPUbMFSBUsBB7o78uZtHejTwu/KTyYiIiIil0xJRxGpdva2Rga0CeTnrUdZFJ+qpKNIFdqXnse4L7dQUmbm+rYBPDukTUVy8ZWh7Rj49irW7s9kXlwywyIbWTlaqU9yTpoY98UWNtXwer02RgO2py82RuxsDKe2GbG1Kd9uZ2PExmjgeF4xablFjPl8E3dd1ZinbmiNi2Y9ioiIiNQIvesSkRpxY4fypOPpEmujSqxFrtix3CLGztxMblEpnRt7Mm1E5BnLFzTxceGf/SL4z+97eHnBLvq28MfLxd6KEUt9cSyviHs+38yu1FzcHG0Z17spjnbGvyT+/kwA2toYK5KEp5OBtjZ//mxnPPWvzV/2PZVItDvH+SozY7ewpJTXf9vNl+uP8PWGRFbvy2Dq7R2JCvOuxkdHREREREBJRxGpIT2b++LmaMuxvGJiEk/oA5/IFcovLuXeWZtJzj5JuK8Ln94ThaOdzVn7jevdlPlxyexNz+f133bzxm0drBCt1CeJmYXc/flGjmQW4uvqwJf3daNNsLu1wzonZ3tbXrqlHQPbBPLvn7ZxJLOQOz5az7jeTZk8oMU5x4yIiIiIVA11rxaRGuFga8OA1uVdrBduVxdrkSthKjPzyDdbSUjJxdfVni/u7Yb3eWYw2tsaeW1YewC+35LEpkM1Wwor9cuu1FyGf7iOI5mFhHo78fPDPWptwvGvekX4snhSH27r0giLBT5edZCbpq8h/miOtUMTERERqbeUdBSRGjO4fRAAv+1IxWyugu4AIg2QxWLh/+bGs2rvcZzsbPjsniga+zhf8JiuYd6M7BYKwNNz4ykpNddEqFLPbDmcxZ0fred4XjGtAt34+aGraeJTd7qiuzvaMfX2jnwypiu+rg7sO5bPsA/W8s7SvZjKNCZEREREqpqSjiJSY3q38MXNwZb03GK2Jp6wdjgiddK0Zfv4YctRjAZ4b1QkHUM9L+m4Jwa1wtfVnv3H8vl41YHqDVLqnf/tPsZdn20kt6iUrk28+P7BHvi7O1o7rMsyoE0Af0zqw+D2gZSaLbyzdB/DPljL3vQ8a4cmIiIiUq8o6SgiNcbB1ob+bU6VWMerxFqksn7YnMQ7S/cB8PLQdvQ7tWTBpfB0tufZIW0AeHf5fg5nFFRLjFL/zItNZtyXWygymbm2pR9f3d8dD2c7a4d1Rbxd7Hl/VGemjeiEh5MdO5JzGTJ9DR+vOkCZZuKLiIiIVAklHUWkRlWUWMenqcRapBJW7j3OU3PjARh/bXNGd29S6XPc3DGY3hG+lJSaeWbeDiwWjUG5sJlrDzHx+zhKzRaGRYbw8ZiuONnXj+YrBoOBWzqF8MekPvRt6UdJqZnXFu1mxMfrOZKppLyIiIjIlVLSUURqVO8IX1wdbEnLLSI2Kdva4YjUCTuSc3jk6xjKzBZujQzhsYEtLus8BoOBV4a2w8HWyJr9GcyPS6niSKW+sFgsvPXHHl78dScA9/YM47+3d8TOpv69dQxwd2Tm2Chev7U9LvY2bD58gkHvrOarDUeUmBcRERG5AvXvnaOI1GqOdjb0a+0PwCKVWItcVFJWIffO2kxBSRk9m/vw+vAOGAyGyz5fEx8X/tkvAoCXF+wku7CkqkKVeqLMbOGZeTt4d/l+AP41sAXPDWmD0Xj5z7vazmAwMKJbYxZP7EP3cG9Omsp4dt4Oxny+idSck9YOT0RERKROUtJRRGrcnyXW6mItciHZhSXcO2tzRbfgGXd1wd72yl+6x/VuSoS/K5kFJbyxeHcVRCr1RUmpmX9+F8s3GxMxGOCVoe0Yf13EFSW665JQb2e+HXcVzw1pg4OtkdX7Mhj49irmbD2qWY8iIiIilaSko4jUuGta+OFib0NKThFxR7OtHY5IrVRkKuPBL2PYfyyfIA9HZt4bhbtj1TTvsLc18uqw9gB8uymJzYezquS8UrcVFJdy/xebWbg9FTsbA9NHRnLXVZVfO7SuMxoN3NcrnIX/7E3HUE/yikqZ/MM2/vFVDBn5xdYOT0RERKTOUNJRRGpceYl1edfdRdtVYi3yd2azhcd+3Mamw1m4Odoy695uBHk4Vel9dAv3ZkRUKABPz4mnpNRcpeeXuuVEQQmjP93I6n0ZONvb8PnYKIZ0CLZ2WFbV3N+Vnx/qwePXt8TOxsAfO9MZ+PYqFu/Q65aIiIjIpVDSUUSsoqLEekeaStZE/mbKb7sqZpt9dHcXWga6Vcv9PHlDK3xc7Nl3LJ9PVh+slvuQ2i815yS3f7SeuKRsPJ3t+OaB7vSO8LN2WLWCrY2R6GubMz+6F60C3cgqKOGhr7cy6fs4cgpN1g5PpE4zlZlJyirEVKYvvURE6itbawcgIg1T35Z+ONvbkJx9km1Hc+gU6mntkERqhZlrD/HJ6kMATL29I1c38622+/J0tufZIW2Y+H0c7y7bx43tgwjzdam2+5Pa5+DxfO7+bBPJ2ScJdHfkq/u7ERFQPUnuuqxNsDvzx/dk2tJ9fLjyAHNjk1l3IIM3hnegb0t/a4cnUmsVlpRyJLOQI5mFJGYVVPx8JKuAlOwiyswWgjwc+WRMV9qFeFg7XBERqWKVmuk4ZcoUoqKicHNzw9/fn6FDh7Jnz54LHpOQkMDw4cMJCwvDYDDwzjvvnHO/999/n7CwMBwdHenevTubNm064/aioiKio6Px8fHB1dWV4cOHk56eXpnwRaQWcbSz4bpW6mIt8leLd6Ty0oKdADwxqBW3dAqp9vu8pVMwvZr7Ulxq5tn5OzTzuAGJP5rD7R+uJzn7JE19Xfjp4R5KOF6Ag60N/x7Uip8evpqmvi6k5xYzduZmnp4bT0FxqbXDE7EKi8VCVkEJsYknmB+XzLvL9jH5hzhum7GOqFeX0ua537lh2moe+jqG1xbt5puNiazZn0FS1knKzBYMBkjNKeKOj9azZKc+24mI1DeVmum4cuVKoqOjiYqKorS0lKeffpqBAweyc+dOXFzOPTOisLCQpk2bcvvttzNp0qRz7vP9998zefJkPvzwQ7p3784777zD9ddfz549e/D3L09KTJo0iYULF/Ljjz/i4eHB+PHjufXWW1m7dm0lf2URqS1ubB/Egu2pLNyeylM3tGow3VFFzmXL4Swe/S4OiwXuuqoxD13TtEbu12Aw8MrQdgx8ZxWr92Xwy7aUGkl2inWtO5DBg1/GkF9cSvsQD2bdG4WPq4O1w6oTOjf2YuE/e/PG4t3MWneY2RsTWb3vOFNv60j3pj7WDk+kypnNFtJyiypmKx7OLCTx1GzFI5mF5BVdOOnu6WxHE29nGvu4EObjTGNvZ5qc+tnBzobxs7eyel8GD361hadvaM0DvcP1nlBEpJ6oVNJx8eLFZ1yfNWsW/v7+xMTE0KdPn3MeExUVRVRUFABPPvnkOfd56623GDduHPfeey8AH374IQsXLuTzzz/nySefJCcnh88++4zZs2dz3XXXATBz5kxat27Nhg0buOqqq846Z3FxMcXFf3YYzM3NBcBkMmEyaQ0eqf1OP0/r8/O1Z1MvnOyMJGefZOvhTDo0UlmNnK0hjIWDxwt44IstFJea6dfKj2duaElpac3NnArxsOeRa5ryzrL9vPTrTno29cLDqWo6ZUvVqMpx8MfOdCb+sB1TmYWrwr34YFQkbg7Gej3GqpqtAf7vhhb0a+nLE3N2kJR1khGfbODeHk2Y1L85jnY21g6xXmoIrwfWUlJqJjn7JIlZhRzJKv+3/HKSpBMnL9psLMDdoTyZ6O1MY28nGv/l34u9nnw0uhMvL9zNt5uP8uqiXew/lsvzQ1pjZ6P2A+ejsSCicWBNlXnMDZYrqKPav38/ERERxMfH065du4vuHxYWxsSJE5k4cWLFtpKSEpydnfnpp58YOnRoxfZ77rmH7Oxs5s+fz/Lly+nXrx8nTpzA09OzYp8mTZowceLEc86gfOGFF3jxxRfP2j579mycnZ0r9XuKSPWZtddIbKaR64LN3NJEC4lLw5NbAu/ssCGz2EATVwvj25Rhb4V8RakZ3txuQ/pJA1f7m7mzmcZjfbQ+3cD3B41YMNDB28yYCDN2+lx/RYpKYe4RIxuOlT+QAU4WRjcvo4mrlQMT+ZviMsgoguNFBjKLIKPIQEZx+b8nisHC+WcXGg0WvB3A18GCnyP4OFrwdQRfRws+Dlzx65bFAivTDMw7XP73KcLdzH0tzTirA4GISK1TWFjIqFGjyMnJwd3d/YL7XvafcbPZzMSJE+nZs+clJRzPJyMjg7KyMgICAs7YHhAQwO7duwFIS0vD3t7+jITj6X3S0tLOed6nnnqKyZMnV1zPzc0lNDSUgQMHXvRBEakNTCYTS5YsYcCAAdjZ1d8ZR4bGacR+v529hc7ccENvldPIWerzWCgsKeWuz7eQWZxLY28nvh/XzaolroHtshj92RbWHTPyz5u706WJl9VikTNVxTj4ePUhvlu/D4Dbu4Tw0k2tsdVMoipxK7B8z3GemZdAen4J0xLseKhPOI9c0xR7Wz3GVaU+vx5UtbwiE3FJOcQkZrM1MZu96flkFpRc8BgnO+OpGYp/na3oTBMfJ4LcHav978WNwA17jjPph+3sy4WPD7ryyd2daeKjCSN/p7EgonFgTacriS/FZScdo6Oj2bFjB2vWrLncU1QrBwcHHBzO/uBmZ2enJ6TUKfX9OTugbTBOdgkczS5iz7GTtFeJtZxHfRsLpWVmJv0YR3xyLt4u9nx5X3cCvazbObpnRAB3dg3l+y1JPPfrLhZM6K2ESS1zOePAYrEw5bfdfLzqIAAPXdOMJwa11Jc8Vez6dsF0C/fluV8S+HVbCu+vOMiKvRm8dUcnWgaqQU9VMJWZySoGo41tvXo9uFIWi4WjJ04Sc+QEW45kseXwCfak53GuejYvZ7uKtRVPr7PYxMeZJj7O+Lk6WP3vwsB2wfzk48r9szZzKLOQ2z7eyEd3ddF6qedR394biVwOjYOaV5nH+7KSjuPHj2fBggWsWrWKRo0aXc4pKvj6+mJjY3NWJ+r09HQCAwMBCAwMpKSkhOzs7DNmO/51HxGpm5zsbbi2lR+L4tNYGJ+qpKM0CBaLhWfn72D57mM42hn59J6uhPlaN+F42lODW7F0Vzp70/P5ZPVBoq9tbu2Q5AqUlpl5ak48P8YcBeDpwa14sE8zK0dVf3m52DN9ZCTXtw3gmXk7SEjJ5abpa5g8sAXjejfFxqhE7+UqM1t48OtY1uy35T87ltMq0I02we60CfKgTbA7LQPccLLG2hRWUFpmZldqXnmC8cgJthzOIj23+Kz9Gns707WJF13CvOgQ4kkTX2fcHWv/B/PWQe7MG9+TcV/GsC0pm7s+28hrw9pze9dQa4cmIiKVVKmko8ViYcKECcydO5cVK1YQHh5+xQHY29vTpUsXli1bVrGmo9lsZtmyZYwfPx6ALl26YGdnx7Jlyxg+fDgAe/bsITExkR49elxxDCJiXYPbB7EoPo1F8amafSMNwvv/28+3m5IwGuDdEZF0blx7ypg9ne15ZkhrJn2/jXeX7eOmDsE0VmlbnVRkKmPCt7Es2ZmOjdHA67fqQ3tNGdIhmG7h3jz1czzLdh/j9d92s2RnOv+9vWOt+YKhrvlw5QHW7M8EoLCkjK2nyoZPMxqgmZ/rqUSke8W/9aEre26RidjEbGIOlycZ45KyKSwpO2MfW6OBtiEedG3iVZFo9HdztFLEV87fzZHvH7yKx37cxsLtqTz+03YOZhTw+MCWGJW8FxGpMyqVdIyOjmb27NnMnz8fNze3ivUUPTw8cHJyAmDMmDGEhIQwZcoUoLxRzM6dOyt+Tk5OJi4uDldXV5o3L589MXnyZO655x66du1Kt27deOeddygoKKjoZu3h4cH999/P5MmT8fb2xt3dnQkTJtCjR49zdq4Wkbrlulb+ONoZScwqJCEll3Yhmu0o9dfPMUeZ+sdeAF64uS0D29a+GftDO4XwU8xR1u7P5Jn5O/ji3ih9GVDH5BaZGPfFFjYeysLe1sh7IyNr5XOtPvN3c+TTe7ryY8xRXvp1JzFHTnDDtNU8NbgVd3VvosRJJcQmnuCtJeV/N+9sWsbYG3uz93ghO1Nz2ZlSfsksKGHfsXz2HctnflxKxbGB7o4VCci2weXJyFAv51r7+FssFpKzT7Ll8IVLpd0dbencxIuoMG+6NPGiYyPPejfT09HOhukjImnq68L05fuZseIAh44X8Padnerd7yoiUl9VKuk4Y8YMAPr27XvG9pkzZzJ27FgAEhMTMRr/XP8pJSWFyMjIiutTp05l6tSpXHPNNaxYsQKAO++8k+PHj/Pcc8+RlpZGp06dWLx48RnNZd5++22MRiPDhw+nuLiY66+/ng8++KAy4YtILeVsb8u1Lf35bUd5iXV9TDpaLBaW7TqGjY2B7uHeONurHWNDtHrfcZ74eTsA/7imKWN6hFk3oPMwGAy8fEs7Bk1bzaq9x/l1eyo3dwy2dlhyiTLyi7nn800kpOTi6mDLp/d05Sqth2YVBoOBO7qGcnUzHx7/cTvrD2by3PwE/khI543bOhDi6WTtEGu9vCITj34XR5nZwuB2AfRwTaa5vyutQ7y4pVMIUP4aeyyvuDwBeSoRmZCSw+HMQtJyi0jLLWL57mMV53R1sKV1kNupRGR5eXZEgCsOtjWfyPp7qXTM4ROk5Radtd9fS6W7NvEmwt+11iZOq5LRaOCxgS0J93XhyZ/jWZyQRvJH6/n0nq4EuNfdmZwiIg1FpcurL+Z0IvG0sLCwSzpu/PjxFeXU5+Lo6Mj777/P+++/f9FziUjdM7h9EL/tKC+x/vf19a/E+uuNiTw7bwcA9jZGosK96B3hR+8IX1oHujeIDw4N3c6UXB7+eiulZgs3dwzmietbWTukC2rq58r4a5vz1pK9vPTrTq6J8MPDufavBdbQJWUVMubzTRzKKMDX1Z5Z93arl1/k1DWNvJz55oHufLn+MK8v3s2a/RkMensVH9zVmd4RftYOr1Z7bn4CiVmFhHg68fLNbVjzv+Sz9jEYDAS4OxLg7si1rfwrtucXl7I79c9E5M7UXHan5ZFfXMrmwyfYfPhExb62RgPN/c8uz/Z0tq/S3yfvVKn0lsqUSjfxwr+BJ9hu7dyIUG9n/vFVDPHJOQx9fy2f3tOVtsH6+yYiUptpqo2I1ArXtfLHwdbIkczycqn69CZyR3IOL/9avsyEj4s9mQUlrN2fydr9mbz+G/i6OtA7wpfeEb70ivCt02swybmlZJ/k3lmbyC8u5aqm3vzn9g51ItH8j2uaMj8umQPHC3jj9928Nqy9tUOSC9iTlseYzzeSnltMiKcTXz/QnXCtH1hrGI0GxvYMp08LPx77cRuxidlEf7OVXyf0oomP/p/OZW7sUebGJmM0wLQRnXB3qtwXH64OtnQN86ZrmHfFNlOZmYPHC9iZmnNqRmR5MjK70MTutDx2p+Uxhz8TmyGeTmclIht5OV3Sl6OnS6Vjjpw4VS59gj1puZj/Nh/DzdGWLhUJRm86hda/UumqEBXmzbxHenLvrE0cOF7A7R+uZ9qISAa0Cbj4wSK1nNlsqRPvDUUqS0lHEakVXBxs6dvSj98T0lkUn1pvko65RSaiZ2+lpMxM/9b+fDKmKwczCli99zir92Ww/mAmGfnFzI1NZm5s+Yec1kHu9InwpXeEH13DvHC00wePuiznpImxMzeRnltMiwBXPrq7q1VK+C6Hg60Nrw1rz50fb2D2xkSGdw6hSxPvix8oNS7myAnum7WZnJMmWgS48uV93Qn00BcYtVFTP1e+f7AHd368ntjEbB76eitzHr5aSaa/OZJZwDNzyysEHu3Xgq5h3phMpis+r52NkZaBbrQMdGPYqRWgLBYLqTlFFbMhE1Jy2JmaS1LWSZKzyy9LdqZXnMPd0faMztltgtxp7u+K0cAllUqHejsR1cS7wZVKV4XGPs7MeaQn42dvZfW+DB78agtP39CaB3qH17sqGWkYkrIKefynbWw5fIJWQW50beJNVJg3UWGa4Sz1g5KOIlJrDG4fdCrpmMa/Btb9EmuLxcJTP8dzJLO8LGzq7R0xGAw083OlmZ8rY3uGU1JqJubICVbvK09CxifnsCs1l12puXy06iCOdka6h/vQO8KXPi38iPB3rfOPS0NSXFrGP77awt70fALcHZh5bzc8KjlTx9q6N/Xhjq6N+GHLUZ6es4MF/+yFnY3x4gdKjVmx5xgPf72Vk6YyIht7MnNsVJWXhErVsrc1MmN0F4ZMX82u1FyenhvPW3d01N/3U0xlZv75XRwFJWV0C/Nm/HXNq/X+DAYDwZ5OBHs60f8vs+ZyTprOKM9OSMll37E8cotK2XAwiw0Hsyr2tbcxYmtjOHepdLA7XZp40zWsfDajEglXxsPJjs/HRvHCLwl8szGRVxft4mBGPi/d0k6vT1KnzI9L5pm5O8grLgVgR3IuO5JzmbXuMHBqLdcwr4okZDM/fQ6QukdJRxGpNfq1DsDe1sihjAJ2pebRJtjd2iFdka83HGFhfCq2RgPTR0WeMwlgb2ukRzMfejTz4d+DIDO/mDX7M1i9L4PV+46TnlvMyr3HWbn3OCzcRaC7Y3kpdgs/ejX3xdtFiYXaymy28PiP29lwMAtXB1tmju1WZ5tGPHVDa5buOsae9Dw+XX2Ih/s2s3ZIcsr8uGQe+2EbpWYL17TwY8ZdndWoqo4I9HDkvVGdGf3pRubGJtMp1JN7rg6zdli1wltL9rItKRt3R1veHtEJGyvNAvRwsqN7Ux+6/6URU0mpmf3H8s9oWLMzNZe8olJKylQqXVPsbIy8MrQdzfxceWXhTr7dlMSRzEJmjO6i9Yel1sstMvH8/ISKKqfOjT157qa2JGUVsuVwFpsPn2BXWi6JWYUkZhUyZ2v5fl7OdnRp4k23cC+6hnnTLtgDe1sl2qV207tSEak1XB1s6dvCjz92lpdY1+WkY/zRHF5esAuAJ29oRefGXpd0nI+rA7d0CuGWTiFYLBb2puezet9xVu3LYOPBTNJyi/gx5ig/xhzFYID2IR6n1oP0o3NjL73xqEXe/H0Pv2xLwdZoYMZdnev089nLxZ7/G9yax37cxrRle7mxfRCNfZytHVaD9+X6wzz/SwIWC9zUMZj/3t5RfwPqmKua+vDUDa14ZeEuXl6wkzbB7kSFNewlDNbtz+DDlQcAeGN47evwbW9rLC+pDnaHLuXbLBYLR0+cpLi0jKa+KpWuKQaDgft6hRPm68yE2bGsO5DJsA/W8vnYKMK0nq3UUjFHsnj0uziOnjiJ0QD/7BfB+GubY2tjpFOoJzd1DAbKE5Onm05tPpxFXFI2JwpNLN2VztJd5cs9ONiWHxMVVj6TunMTL9wdlXSX2kVJRxGpVW7sEFSRdHxsYIs6WUJw5jqOAdzfK/yyzmMwGCrWnXqgd1OKTGVsPpzF6n0ZrNp7nN1peWw/msP2ozm8/78DuNjb0KOZT0VX7HBflzr5+NUHX60/XPGh+fXhHepFd9pbO4fwU8xR1h/M5Jn5O/ji3ig9v6zEYrEwbdk+3lm6D4AxPZrwwk1tleioo+7vFU5cUjYLtqfyyDdbWTihV4Mtv80qKGHSD3FYLDCyWyg3tA+ydkiXxGAwEOqtL2Ks5bpWAfz08NXcP2szBzMKGPrBWj66q8sZM1RFrK20zMz05fuZvnwfZgs08nJi2ohO510r293Rjmta+HFNi/L3kCWlZhJScthy+ASbD5evG5tVUMLGQ1lsPFS+1IPBAK0C3YkKK58JGRXmRZBH7friRhoeJR1FpFa5rpU/9rZGDmYUsCc9j1aBdWt2mMVi4cmft5OYVb6O439vr7o1uhztbE4lFP14enBrjuUWVZRhr96XQWZBCUt3HWPprmNAecfNPi386BPhy9XNfFVuVEP+SEjj+V8SAHhsQAtu69LIyhFVDYPBwKvD2jHondWs2nucBdtTK76Nl5pjNlt44ZcEvlh/BIBH+0UwsX+EEsB1mMFg4I3hHdibnsfe9HyiZ29l9rirGtzadBaLhX//tJ303GKa+bnw7JA21g5J6pDWQe7MG9+TcV/GsC0pm7s+28hrw9pze9dQa4cmQlJWIRO/jyPmyAkAhnYK5qWh7So1K9He1khkYy8iG3sxrk9TLBYLBzMKKsqxtxzO4nBmYcXa8F+eep8Q4un0lySkGldJzVPSUURqFTdHO/pE+LF0VzqLtqfWuaTjl+uPsCg+DTsbA++P7lytiT5/d0eGd2nE8C6NMJst7EzNrUhCbjl8guTsk3y7KZFvNyViNEDHUE/6RPjRp4UvHRt5YtvAPtDWhNjEE/zzu1jMp2bpVHfzg5rW1M+V6Gub8/bSvbz46076tPCrc41x6rJSMzz2UzwL4tMAePHmtloDsJ5wcbDlo7u7cvP0NWw+fIJXF+7ihZvbWjusGvX1hiMs3ZWOvY2Rd0dGam1SqTR/N0e+f/AqHvthGwvjU3n8p+0czCjg8YEtlWQRq5kXm8yz88qbxbg52PLy0HYMjQy54vP+tTnlnVGNATiWV0TM4RPlScgjWSSk5JKcfZLkuJPMi0sBwN3Rlq6nyrG7hXnTvpEHDrZad1aqj17NRaTWubFDIEt3pbMwPpVJA+pOifX2o9m8uvD0Oo6t6RTqWWP3bTQaaBfiQbsQDx7u24zCklI2Hsxi1alZkPuP5RObmE1sYjbTlu3DzcGWq5v7nJoJ6aeysCpwOKOA+7/YQpHJzLUt/Xj5lnZ15rlbGQ/1bcr8bckcPF7Af37fzStD21s7pAahsKSUT/cY2ZWdhq3RwH/v6Mgtna78Q4vUHuG+Lrx1ZyfGfbmFWesOE9nYs8H8H+9Jy+OVU6+fT9zQirbBHlaOSOoqRzsbpo+MpKmfC9OX72fGigMcOl7A23d2UkMfqVG5RSaenbeD+aeSfV2aePHOnZ2q9T23v5sjN7QPqliaIr+4lLjE7FPl2FlsPZJNblEpy3cfY/nu8sooe1sjHRt5VJRjd2nsreooqVJKOopIrdOvdQD2NkYOHC9gb3o+LQPdrB3SReWc/HMdx4FtArivZ5hV43G2t+XaVv5c28ofgOTsk6w51ZBmzb4Mck6a+D0hnd8TyheiDvNx5pG+zbkjSmVIlyMzv5h7Zm4iq6CE9iEevDeqc72dSepga8OrQ9sz8pMNfLMxkWGRjejS5NIaJcnlSc4+SfQ3MezKNuJoZ+TDu7rQt6W/tcOSajCgTQATrmvO9OX7eeLn7bQIcKN1UN2a8V9ZRaYyJny7leJSM31b+ln99VPqPqPRwGMDWxLu68KTP8ezOCGN5I/W8+k9XQlooOulSs3acri8WUxy9klsjAb+eV0E0dc2q/H3hq4OtvSK8KVXhC8ApjIzu1JzK8qxNx8+QUZ+MZtPzY6cceq4lgFudA3zqmhQE+LpVC+/SJeaoaSjiNQ67o529Gnhy9Jdx1gYn1rrk44Wi4UnftpOUtZJGnk58Z/bqm4dx6oS4unEnVGNuTOqMWVmC/HJOazeWz4LcmviCQ5nFvLvn7ezPTmb529q2+DWErsSJ0vKuP+LLRzJLCTU24nPx0bh4lC/X157NPPhti6N+CnmKP83N55fJ/TSc6aaLNiewtNz4sktKsXJxsKssV3p3qzuNyaS85vYvwXbjuawau9x/vFVDL+O71WvZ528unAXe9Pz8XV1YGoVroMscmvnRoR6O/Pgl1uIT85h6Ptr+fSerppJK9WmtMzMu8v3896pZjGh3k68c2dkrfly1s7GSIdGnnRo5Mn9vcKxWCwcySwsnwl5+ASbj2Rx8Hj5uvp70vP4ZmMiAG2D3Zk5NqrBNjmTK6NPCCJSKw0+VRawKD7VypFc3BfrDrM4oXwdx/dGVe86jlXBxmigU6gnE/pF8MNDPYh9bgCPDWiBwQBfb0jkrk83kplfbO0w64Qys4UJ38YSl5SNp7Mds+7thp+bg7XDqhFPD26Nl7Mdu9Py+GzNIWuHU+/kF5fyrx+3MX52LLlFpXRo5M5j7cvo3NjT2qFJNbMxGnh3RCcaeTmRmFXIxO9jMZst1g6rWvyRkMZXG8qbHbx1R0d8XRvG30+pOVFh3syL7kkzPxdSc4q4/cP1LNmZbu2wpB5KzCzkjo/W8+6y8oTjrZEhLPpn71qTcDwXg8FAmK8Lt3cN5Y3bOrD8sb5seaY/H93dhXG9w+kU6omt0UBCSi4PfhVDkanM2iFLHaSko4jUSv3bBGBnY2D/sXz2pedZO5zz2n40m1cXla9D9VQNr+NYVdwc7ZjQL4JP7u6Kq4MtGw9lcfN7a9mVmmvt0Go1i6W8i/DSXenY2xr5dExXmvm5WjusGuPtYs//3VjeXfadpXtJyiq0ckT1R1xSNje+u5qfYo5iMMD4a5vz3QPd8HOydmRSUzyd7fnwri442Br5357jvLt8n7VDqnJpOUX8++ftAIzrHU6fFprBK9WjiY8Lcx7pSa/mvhSWlPHgV1v4ZNVBLJb6mcyXmmWxWJiz9SiD313N1sRs3BxsmTaiE2/d2Qm3SnSnri18XR24vm0g/3djG+ZF92TJ5GvwcLIjLimbJ37ernEjlaako4jUSu6OdvSOKP8AsrCWznY8vY6jqczC9W0DuLeOr0PVv00Acx+5miY+ziRnn2T4jHUs3lE7H3trKy4t48Vfd/LVhiMYDDDtzk50DfO2dlg1bnjnEK5q6k2Rycyz83fojegVKjNbeG/5PobPWMeRzEKCPRz5btxV/Ov6lipfb4DahXjw6rDyRk3Tlu3jf6cW/a8PyswWJn0fR3ahibbB7vzr+pbWDknqOQ8nO2beG8Wo7o2xWODVRbt4em48pjKztUOTOiznpIlHv4tj8g/byC8uJSrMi0WP9q5XTcDCfV2YMboztkYD8+NS+GDFAWuHJHWM3sGKSK1Vm0usLRYL//5pW8U6jm/WwnUcL0dEgBvzo/+cDfDQ11t5e8neelvadzn2H8tn2PvrmLXuMADPDWlT0SWwoTEYDLw6rD32NkZW7DnOovg0a4dUZyVnn2TkJxuY+sdeyswWbuwQxG+P9qF7Ux9rhyZWdFuXRtx9VRMsFnj0u1iOZBZYO6Qq8dGqA6w/mImTnQ3vjozEwVZdhaX62dkYeXVoO54d0gaDAb7dlMQ9n28ip9Bk7dCkDtp8OIvB01bzy7YUbIwGJg9owbfjrqrW7tTWcnVzX164uS0A//l9D4t36P2eXDolHUWk1hpwqsR6b3o++4/VrhLrWesO83tCOnY2Bt4f1RkPp7pXPnE+ns72zLo3ivt6hgPlM2we/iaGguJSK0dmXRaLhe82JXLT9DXsTM3Fy9mOT8d05d5Tj1ND1czPlYf7NgPghV8TyC3Sh7fKWrA9hRveWcWmQ1m42Nsw9faOvDcystavDys149khbejc2JPcolL+8VUMJ0vq9ppacUnZvPXHXgBevLltg1qWQqzPYDBwf69wPh3TFRd7G9YdyGTYjLUczqgfCX2pfqVlZt76Yw93frSe5OyThHo78cM/evDPfhE13p26Jt11VRPu6dEEgEnfx7EjOcfKEUldUX9HhYjUeR5OdvRq7gvAwu215xu1uKRsXju1juP/DW5Nxzq4juPF2NoYee6mNrx5WwfsbYz8npDO8BnrGuy6fdmFJTzyzVaenBPPSVMZvZr7snhiH/q3CbB2aLXCw32b0dTXheN5xfxn8R5rh1Nn/L1ZTMdQTxb+sze3dWlUL2ZOS9WwtzXywegu+Lraszstj6fm1N01tfKKTPzz21hKT83mvb1rI2uHJA1Uv9YB/PTw1QR7OHLweAFDP1jLxoOZ1g5LarkjmQXc/tF63l2+v7xZTOfa3yymKj07pA29I3w5aSpj3JdbOJZXZO2QpA5Q0lFEarXaVmKdU2hi/Kl1HAe1DeSeq8OsHVK1uqNrKN8+eBV+bg7sTsvj5vfWsO5AhrXDqlEbDmZyw7TV/LajvEP504Nb8eV93Qhwd7R2aLWGo50NrwxrB8DXG4+wNfGElSOq/c7VLOanh3oQ5uti7dCkFgr0cOS9UZ2xMRqYF5fCF6eWd6hrnpufQGJWISGeTrw2rL2S62JVrYPcmTe+Jx1DPckuNHHXZxv5cUuStcOSWshisfBzzFEGT1tNbGI2bo62vDsykrfuqJvNYi6XrY2R90Z2pumpbvAPfqmO1nJxSjqKSK02sE0gtkYDe9Lz2H8s36qxWCwWHv9pG0dPlJdSvHFbhwbxgalLEy9+Gd+TDo08OFFo4u7PNvHl+sN1dqbNpTKVmZn6+x5GfrKB1Jwiwn1dmPNwTx7s0wyjsf7/v1fW1c18Gd65ERYLPD1Hi/Ofz9+bxYR4OqlZjFySq5r68NQNrQB4ZeEuNh/OsnJElTM39ihzY5MxGmDaiE71alkSqbv83Rz5/sGruLF9EKYyC4//tJ03Fu/WWtZSIeekiQnfxvLYj9soKCkjKsyL3x7tzc0dg60dmlV4ONvx2T1RFR2tn1RHa7kIvbsVkVrNw9mOnqdKrH+z8mzHz9ce5o+d6djbGPlgVJcG9YEpyKN8vZqhnYIpM1t4bn4CT8+Np6S0fiaWEjMLuf3D9bz3v/1YLHBn11AWTOhF+0Ye1g6tVvu/G1vj5WzH7rQ8Pl9zyNrh1Dp/bxYzpEMQix7trWYxcsnu7xXOkA5BlJotPPLNVo7l1o3StiOZBTwzdwcAj/ZrQdcwbytHJPInRzsbpo+MZMJ1zQGYseIAj3yztc6vnypXbtOh8mYxC7anYmM08NiAFnz3YA8aedW/ZjGVcbqj9enZ9+poLReipKOI1Ho3niqxXmjFpGNcUjav/3ZqHccbWzfI5JOjnQ1v39mJJ29oVdH1cfSnG8jIL7Z2aFVqbuxRBr+7mrik8vKZ90ZF8sZtHXBxsLV2aLWet4s9Tw9uDcA7S/c12DVAz+VczWKmj4xsUF9eyJUzGAy8MbwDLQJcOZ5XzCPfbK31X/6Yysz887s4CkrK6BbmzfhTiR2R2sRoNPDYwJa8dUdH7G2MLE5I446P1rM3PU+zuBogU5mZ//6xhxEflzeLaeztzE8P9WBCvwhsVO0CnN3R+veE2rP+vtQuSjqKSK03sG0AtkYDu9PyOHi85kuscwpNRH9Tvo7j4PaBjDnVua0hMhgMPHRNMz6/Jwo3B1s2Hz7BLe+trRcd7PKKTEz6Po5J328jv7i0onxmSIeGWT5zuW7r0oju4d6cNJXx3PwdDf7DWn5xKY/98GezmE6hnix6VM1i5PK5ONjy0d1dcXOwZcuRExWNzWqrt5fsZVtSNu6Otrw9opM+sEutdmvnRnwzrjteznbEJ+cw8O1VdH55CQ98sZkPVuxn48FMrWFXzx3JLOD2D9cz/VSzmOGdG7Ho0d5ENm4YzWIq4+6rmlR8Lpr0fRw7U3KtHJHURko6ikit5+lsz9WnSqxruqGMxWLhXz9tq/iW8/XhDWMdx4u5tpU/c6N70tTXheTsk9z24ToWbE+xdliXbWviCQa/u5q5scnYGA1MHtCCb8dd1eDLZy6HwWDg1WHtsbMx8L89x/ltR8P95js28QQ3vruan7cexWiACdc158eHetDER81i5MqE+7rw9p2dAJi17jBzY49aN6DzWLc/gxkry8vuXh/egRBPJytHJHJxUWHezIvuSe8IXxxsjZwoNLF01zHeXLyHOz/eQLvnf+eW99fy0q87Wbg9lfQ6ssyBXJjFYuGnU81iTle7TB8ZyX/v6Iirql3O67khbejV3JfCkjIe+GKzOlrLWTR6RKROuLF9IKv2HmdhfBrjr4uosfv9bM0hlpxax/H9UZ1xb0Ad6i6mub8rc6N7MuHbWFbtPc742bHsTs1j8oAWdabRSpnZwowV+3l76T7KzBYaeTkxbUQnujTRemNXorm/Kw/3bc67y/bxwi8J9IrwbVBj5+/PqxBPJ96+sxPdwvW8kqrTv00AE65rzvTl+3lqTjwtA9xpE+xu7bAqZBWUMOmHOCwWGBEVyuBTS6WI1AVNfFz46v7ulJSaSUjJIebICbYmnmDL4RMcyytmW1I225Ky+Xxt+frFIZ5OdGniVXFpFeiGrZqD1Rk5hSb+b148C7aXT27oFubN2yM66YuSS2B76jPSsA/WcjCjgH98FcO3467C0c7G2qFJLVGpv4RTpkwhKioKNzc3/P39GTp0KHv27LnocT/++COtWrXC0dGR9u3bs2jRojNuNxgM57z85z//qdgnLCzsrNtff/31yoQvInXYwDaB2BgN7ErN5VBGQY3cZ2ziCV7/bTcAzwxpmOs4XoyHkx0zx0bxYJ+mALz3v/08+FUMeUUmK0d2cSl/a+pxU8dgFj3aWwnHKvJI32aE+7pwLK+Yqb9f/L1CfZGcfZKRH5/dLEYJR6kOE/u3oE8LP4pMZh76Ooacwtrxt9disfDvn7aTnltMMz8XnrupjbVDErks9rZGIht78UDvpnwwugsbn+7HmieuZdqITozp0YS2we4YDeV/+3/ZlsLzvyQwZPoaOrz4B6M+2cB//9jD//YcI+dk7RibcraNBzO5YdqqimYxj1/fkm8fvEoJx0rwcLbj03u64u5oS2xiNk/NiW/wy+vInyo103HlypVER0cTFRVFaWkpTz/9NAMHDmTnzp24uJy7VGjdunWMHDmSKVOmMGTIEGbPns3QoUPZunUr7dq1AyA19cxyyd9++43777+f4cOHn7H9pZdeYty4cRXX3dzcKhO+iNRhXi72XN3Mh9X7MlgUn0r0tdW7EH12YQnjZ8dSarZwY/sg7r6q4a7jeDE2RgNPD25Nq0A3npwTz9Jd6dz6wTo+vadrrS0j/S0+lSfnxJNz0oSLvQ0v3dKOWzuHqHS+Cjna2fDq0HaM+nQjX204wq2dG9Ep1NPaYVWrX7el8PTcePKKSvW8khphYzTw7ohODJm+hsSsQiZ+H8tn90RZfbb51xuOsHRXeZXAuyMjcbZXcZXUDwaDgUZezjTycuaWTiEAFBSXsi0pmy1HTlTMiMwrKmXdgUzWHcisOLZFgCtdmnjRuXH5bMhwXxe9PliRqczMO0v38sGKA1gs0MTHmWkjIuv9e5Xq0tTPlQ9Gd+GemZuYG5tMRIArj/RV4zCpZNJx8eLFZ1yfNWsW/v7+xMTE0KdPn3MeM23aNAYNGsTjjz8OwMsvv8ySJUt47733+PDDDwEIDAw845j58+dz7bXX0rRp0zO2u7m5nbWviDQcg9sH1UjS0WKx8K8fy9dxbOLjzJTh7fWm8BLc2rkRTf1cefDLLew7ls/N763l/VGd6RXha+3QKhSWlPLygp18uykJgI6NPJg2IpIw39qZHK3rrm7uy62dQ5izNZmn5sTz6/ie9bLcLL+4lOfnJ/Dz1vJ19TqFejJtRKdam3SX+sXT2Z4P7+rC8Bnr+N+e40xbto9JA1pYLZ49aXm8srC8uc0TN7SibbCqBKR+c3Gw5ermvhXrj5vNFvYfz2fL4T+TkIcyCtibns/e9PyK9yDeLvYVCcguTbzo0MhDJak15HBGAY9+H8e2pGygvAneCze31dqNV6hXhC8v3NSGZ+cn8J/f99Dcz5WBbZW/aeiuaFTl5JR3K/X2Pn/J0Pr165k8efIZ266//nrmzZt3zv3T09NZuHAhX3zxxVm3vf7667z88ss0btyYUaNGMWnSJGxtz/0rFBcXU1xcXHE9N7e8k5LJZMJk0vR2qf1OP0/1fP3TdS18sDEaSEjJZX96Dk28q6fJx+drD7N01zHsbAxMu6MDTjb6f7hUbQNdmPNQdx75No7tR3O5Z+YmnhrUgjFXNb7sxG1VjYWElFwm/7idgxmFGAzwYK9w/nldM+xtjfr/rUb/HhjB8l3H2JWay6erD3B/zzBrh1Sl4pKyeeyneBKzTmI0wEN9mjL+2qbY2VTt80qvCXIhLf2deenm1jwxJ4Fpy/bRNsiVa1v61XgcRaYyxs+OobjUzDURvtzdLUTjQBqkcG9Hwr2DuL1z+VqmmQUlxCVmE5OYTWxSNtuTc8kqKGHprnSW7koHwM7GQJsgdzo39iQy1IPOjT0JcHc85/k1Fi6PxWJhTmwKLy/cTUFJGe6Otrx8cxsGtw8ELHo8q8CIriHsTs3lm01JTPw+ju8e6EbroOqpUNU4sJ7KPOYGy2UW25vNZm6++Ways7NZs2bNefezt7fniy++YOTIkRXbPvjgA1588UXS09PP2v/NN9/k9ddfJyUlBUfHP//IvvXWW3Tu3Blvb2/WrVvHU089xb333stbb711zvt94YUXePHFF8/aPnv2bJyd1Y1UpK56f6eRvTlGhjQuY0BI1a8VcjgPpiXYYLYYuD28jF6BWo/kcpjM8P1BI5uPl89q6+5n5o6mZmytMMnNbIGVqQZ+TTRSZjHgYWfhrggzLTz0f1tTNhwz8O0BG+yNFp7qVIa3g7UjunJmCyxNNvBbkhEzBrzsLdwdUUaz2tPHQxqgHw8aWZNuxMnGwr86lOF77nxFtfnpoJHV6Ubc7Cz8u0MZ7vY1e/8idUWpGY4WwKE8Q8Ul13T2l7PeDhbC3f68BDmDjYpvLktOCcw5bCQus/zNaDM3C3dF1I/3JLVNmRk+3F3+mc3L3sLk9no9qG8KCwsZNWoUOTk5uLtf+M3vZc90jI6OZseOHRdMOF6Ozz//nNGjR5+RcATOmC3ZoUMH7O3t+cc//sGUKVNwcDj7L8VTTz11xjG5ubmEhoYycODAiz4oIrWByWRiyZIlDBgwADu7htP19WJy/Y7y7C87OVTqyeDBPar03NmFJl7/YD1mSxGD2wXw6h0dVFZ9BW62WJi57ghv/L6XjceNlDh68f7ITvi5Ve7d3ZWMheN5xTwxZwerj5SvqTSgtT+vDm2Dl7Pe+dSkGywW9n++hc2HT7AyP5CPh0bW6bGVkn2Sx36KZ8upsqwb2wfy0k2tcXeqvr/Vek2QS9G/1Mxdn28mNimHH1M8+eHB7jjZ10y55rJdx1i9Pg6AaSO70LsaltbQOJD6ymKxkJxdxNbE7IrLnvQ8sooNZBUbiMko38/Z3oaOjTzoFOKG44kDPDCsP/b2ek9zPgXFpSzZdYz521JZdyATswVsjQYeva4Z43qHY2Pl9W/rsz79TNz20UYOZxYy55gPX93bFYcqXj5ArwnWc7qS+FJcVtJx/PjxLFiwgFWrVtGoUaML7hsYGHjWjMb09PRzrs24evVq9uzZw/fff3/RGLp3705paSmHDx+mZcuWZ93u4OBwzmSknZ2dnpBSp+g5e6bBHYJ5/tedJKTkkZprorFP1cxcNpstPDk3jtScIsJ8nHnjto7Y2+txv1L/6BtBq2BPJszeSmxSDsM/2sjHd3e9rE7glR0L/9t9jH/9uI3MghIc7Yw8O6QNo7pdfpm3XJkpt7bnhmmrWbE3g2V7MrmhfZC1Q7os1m4Wo9cEuRA7O5hxV1eGTF/N7vR8nvt1F2/f2anan59pOUU8NS8BgAd6hXNdm+od3xoHUh+F+9sT7u/O8K6NgfL1grclZZevDZl4gtgjJ8grLmX9wSzWH8wCbPnh6AaGdAjmxg5BtA/x0HscoLTMzNoDmczdepTfE9I5aSqruK1LEy+eG9KGjmoWU+187ez4bGwUw95fS2xSDs/9upv/3tGxWp6jek2oeZV5vCuVdLRYLEyYMIG5c+eyYsUKwsPDL3pMjx49WLZsGRMnTqzYtmTJEnr0OHuG0meffUaXLl3o2LHjRc8bFxeH0WjE39+/Mr+CiNRxPq4OXNXUh3UHMlm0I5WHrmlWJef9dM1Blu0+hr2tkfdGdcbNUS9cVeWaFn7Mi+7JA19u4eDxAm77cB1v3tahoutjVSsylfH6b7uZte4wAK0C3Zg+MpKIgOpZT0YuTXN/Nx6+phnvLt/PU3Pj+WNnOuG+LmdcXGrxAu5qFiN1RaCHI++N6szoTzcyLy6FTqGejO158ffsl6vMbGHyD3GcKDTRNtidxwedPRlARCrP1cGWns196fmXBjX7juUTc+QEa/cfZ2lCKsnZRXy06iAfrTpIEx9nbmwfxI0dgmgT5N6gEpAWi4WElFzmbE3ml20pZOT/2dshzMeZYZGNGBoZrNfsGtbsLx2t58QmExHgxsN9q+azm9QdlXp3Hx0dzezZs5k/fz5ubm6kpaUB4OHhgZOTEwBjxowhJCSEKVOmAPDoo49yzTXX8N///pcbb7yR7777ji1btvDxxx+fce7c3Fx+/PFH/vvf/551v+vXr2fjxo1ce+21uLm5sX79eiZNmsRdd92Fl5fXZf3iIlJ3DW4fVJ50jK+apGPMkSzeWLwHgOeGtKFdiDptVrWmfq7Mi+7Jo9/G8r89x3n0uzh2pebx+PUtq7S0ZW96Hv/8NpbdaXkA3NszjCcGtVI3yFrikWub89uONPYdy2dubPJZtwe4O5xKQLrS9FQiMszXhcbezthbY0HQU2ITT/Dod3EkZhViNMD4a5szoV8EdvWwE7fUD1c19eGpG1rxysJdvLJwF21DPIgKO3/jxyvx0aoDrDuQiZOdDe+OjMTBVn9vRaqD0WigZaAbLQPduL1zEPN+PYpT0y78tvMYy3cd40hmIR+sOMAHKw7Q1NeFGzsEMaRDMC0D6++XrkdPFDI/LoW5scnsP5Zfsd3bxZ6bOgQxNDKETqGeDSoBW9v0ivDl+Zva8Nz8BN78fTfN/V0Z0CbA2mFJDapU0nHGjBkA9O3b94ztM2fOZOzYsQAkJiZiNP75Jvzqq69m9uzZPPPMMzz99NNEREQwb9482rVrd8Y5vvvuOywWyxkNZ05zcHDgu+++44UXXqC4uJjw8HAmTZp0VldsEWkYBrUL5Ln5O9h+NIekrEJCr6CL9YmCEibMjqXMbGFIhyBGd29chZHKX7k72vHpPVH85/c9fLjyAB+uPMDe9DzeGdEJ9yucWWqxWPh6YyKvLNhJcakZHxd7pt7ekWtbaTZ8beJoZ8O86J6s3HucQxkFFZfDGQVkFpSQnltMem4xGw5mnXGcjdFAIy+nihmRTU8lJsP9XAhyd8RYTWsylZktfPC//byzbB9lZgshnk68fWcnuoVXT/JGpCrd3yucbUdz+HVbCo98s5WFE3rhf55OuJcrLimbt/7YC8CLN7elmZ9rlZ5fRM7P3gaubxvAkE6NKCwpZfnuYyzYlsr/9hzjYEYB05fvZ/ry/UT4u1YkIJv71/0xmnPSxKL4VObGJrPp0J/vFxxsjQxoE8CwyBD6tPDTF4O1yJgeYexNz+PrDYk8+l0sPz98Na2D1Gejobjs7tV1TW5uLh4eHpfUXUekNjCZTCxatIjBgwdrjYpzGPnxBtYfzOSpG1rxj8uc7Wg2W3jgyy0s332McF8XfhnfU2XVNWR+XDL//mk7xaVmmvm58MmYrjQ9z4fVi42FrIISnvh5O0t2lq8f3KeFH1Nv74C/Ww23bZUrklNo4lBmAYcy8jl0vICDf0lKFpaUnfc4B1vjWWXaTf3Kk5JeznaXPbvh6IlCJn+/jU2Hyz/Q3NQxmFeGtsOjGpvFXIheE+RyFJaUMuz9dexJz6NrEy9mj7uqymYN5xWZuPHdNSRmFXJjhyDeG1n9DaI0DkTKXWgs5BeXsmxXOr9uS2XV3uOUlJkrbmsV6MaQUwnIMN+6U2pcUmpmxZ5jzI1NZtmuYxW/k8EAV4X7MKxzCIPaBV7xl9hSfUxlZsbO3MTa/ZmEeDoxf3xPfF2vrHW4XhOspzL5tdq7eJKIyAUM7hDE+oPlJdaXm3T8ZPVBlles4xiphGMNuqVTCOG+Ljz4ZQwHjhcw9P21TB/VmWta+FXqPOv2ZzDphzjSc4uxtzHyxA2tuPfqsGqb+SbVx8PZjk7OnnT62+LuFouFY3nFHDx+OgmZz6GM8qRkUlYhxaVmdqflVZTUn3FOJ7uzEpKXsn7kL9tS+D8rNosRqSrO9rZ8eHcXbp6+hi1HTvDaol28cHPbKjn3c/MTSMwqJMTTideGtdf4EKklXB1suaVTCLd0CiG3yMSShHQWxqeyet/xitfLqX/spW2wO0M6BDOkQ9AVVQ1VF4vFwtbEE8zZmszC+FSyC00Vt7UIcGVYZCNu6RRMsKeTFaOUS2VnY+T9UZ0Z+v5aDmcW8o+vYpg9rruW5GgAlHQUkTppUNtAnp+/g22XWWK95XAWb/5evo7j8ze1oW2w1nGsaR0aefLLhJ489FUMWxOzuXfmJp4e3Jr7e4Vf9MNrSamZt5bs5aNVB7BYoJmfC9NGRGo9znrIYDAQ4O5IgLsjPZr5nHFbaZmZ5OyT5bMijxecUbKdnH2SnJMm4pKyiUvKPuu851o/spG3E5+sOlTRLCaysSfv3KlmMVK3hfu68PadnXjgyy3MWneYjqEeDItsdEXnnBt7lLmxyRgNMG1EJ6vNABaRC3N3tGN4l0YM79KInEITvyeksSA+lbX7M0hIySUhJZc3Fu+mYyMPhnQIZnCHIEKsnMQ7eDyfeXEpzItNJjGrsGK7v5sDt3QKZlhkI1oHuemLjjrI09meT++JYtgHa4k5coKn5sTz39urp6O11B5KOopIneTn5kC3cG82HMxi8Y40xvVpesnHZhWUMOHb8nUcb+4YzKhuWsfRWvzdHPn2wat4dt4OfthylFcW7mJnai6vDWt/3uYvhzIKePS7WLYfzQFgZLfGPDukNc72eklraGxtjDTxcaGJjwvX/q1hbpGpjMOZBWeUah8+9e+F1o8E1CxG6p3+bQKYcF1zpi/fz1Nz4mkZ4E6b4Mtbbigxs5Bn5yUA8M9+EXStpgY1IlK1PJztuCMqlDuiQskqKClPQG5PYf2BTLYdzWHb0RxeXbSLzo09ubFDMDe2DyLQo2aWqsnML2bB9lTmxCaz7S9fFDrb2zCoXSC3RjaiRzOfKm0+KNbR3N+VD0Z3ZuzMzczZmkyLALcqaQwqtZc+oYlInTW4fRAbDmaxMD71kpOOZrOFx36IIzWniHBfF167VSVh1uZga8MbwzvQOsidVxbuYs7WZA4eL+Cju7sQ8JemBxaLhZ9ijvLc/B0UlpTh4WTH67e254b2QVaMXmorRzsbWgW60yrw7MTKhdaPDPJwZMqtHdQsRuqdif1bsO1oDqv2Huehr2P4dXwvPJwrN0PRVGZmwnex5BeXEhXmxfhrm1dTtCJSnbxd7BnZrTEjuzXmeF4xixPSWLAthU2Hs9iamM3WxGxeWbiTqCbe3NghiBvaB1b5WtlFpjKW7ExnXmwyK/cep9Rc3mrCxmigd4QvwyJDGNAmQF8q10O9I/x4bkgbnv8lgTcW76aZnzpa12cawSJSZw1qF8jzvyQQl5RNcvbJSyoH+WjVQf635zgOtuXrirheYF03qTkGg4F7e4YT4e9G9OytxCVlc9P0NXw8pittA10oLIVJP8azMD4NgO7h3rx9Zyet4yOX5ULrR+pLCKmvbIwG3h3RiZveK2/+MvH7WD67J6pSa+C+vWQv25KycXe05Z0RkdhqJrBInefn5sDdVzXh7quacCy3iEXxqSzYnsqWIyfYdDiLTYezeOHXBLqHezOkQzA3tAvE5zIbgJSZLWw8mMmc2GQW70gjv7i04rYOjTwY2imEmzoG4+d2ZQ1GpPYb06MJe9Pz+GZjIhO/i+XnR64+5xfFUvfp07aI1Fn+bo5EhXmz6VAWv8Wn8kDvC8923Hw4i6l/lK/j+MLNbS+7tEyqT68IX34Z35MHvtjCvmP53PHReh7uE85X223IKk7Dxmhg8oAWPHRNM5XYSJVTwlHqO09ne2aM7sLwGev4357jTFu2j0kDWlzSsev2ZzBj5QEAXh/ewerrvolI1fN3d2Rsz3DG9gwnNeckC7eXJyDjkrLZcDCLDQezeP6XBHo09WFIhyCubxuIl4v9Rc+7Oy2XubHJzI9NIS23qGJ7iKcTwyJDGBoZQnN/1+r81aSWMRgMvHBzWw5lFLDuQCb3z9pSJR2tpfZR0lFE6rQb2wex6VB5ifWFko5ZBSVMmF2+juMtnYIZERVag1FKZTTxcWHOI1cz6fs4lu46xrTlBwADoV5OvDsyksjGXtYOUUSkzmoX4sFrw9rz2I/bmLZsHx1DPbiu1YXL2rIKSpj0QxwWC4yICmWwlrUQqfeCPJx4oHdTHujdlKSsQhbFp7IwPpXtR3NYsz+DNfszeGbeDno292VIhyAGtgk8Y8mGtJwiftmWzNzYFHal5lZsd3e05cYOwQyLDKFrE69KzbaW+sXOxsgHo//saP3QVzF8o47W9Y6SjiJSp93QLpAXfk0gNjGblOyT5yy3NZstTPo+jrTcIpr6uvDqMK3jWNu5Odrx8d1dKzpUd/Iq46N/9MDbTTNrRESu1PAujYhLyuarDUeY+F0cv4zvRZjvubu0WywW/v3TdtJzi2nq58JzN7Wp4WhFxNpCvZ35xzXN+Mc1zTiSWcCC7aks3J7KztRcVu49zsq9x3naJp4+EX50b+rNqr0ZrD2QgaV8mUbsbAxc18qfYZEhXNvKX0klqfDXjtZbjpzg/+bu4D+3ddBntXpEC7GISJ3m7+5IVJPyhg+/7Ug75z4frjrAyr2n1nEcrXUc6wqj0cC/rm/Jtmf7cVeEGTdH/b+JiFSVZ4e0oXNjT3KLSnno6xgKS0rPud/XG46wdFc69jZG3h0RqaYOIg1cEx8Xoq9tzqJHe7P8sWt4bEALWga4YSqzsGz3MV5btJs1+8sTjlFhXrw6rB2b/68/H93dlUHtgpRwlLM093fl/VGdMRrgp5ijfLzqoLVDkiqkpKOI1Hk3tA8EYFF86lm3bTqUxX//2AvAize3pXWQ1nGsa+zUqEBEpMrZ2xr5YHQXfF3t2Z2Wx1Nz4rGcnpZ0yp60PF5ZuAuAfw9qSbsQD2uEKiK1VFM/Vyb0i+D3SX1YMqkPj/aL4JoWfjw2oAWr/30tPz50NaO7N8HT+eLrPkrD1qdFeUdrgNcX72bpznQrR3RlikxlJGYWWjuMWkGf5ESkzruhXfnaUjFHTpCac7Jie2Z+MRO+3UqZ2cLQTsHcqXUcRUREKgR6OPLeqM7YGA3Mj0th1rrDFbcVmcr457exFJeauaaFH/f1DLdeoCJS60UEuDFpQAu+uK8bE/pFEOrtbO2QpI655+owRnVvjMUCj34Xy+603IsfVItk5hfz45YkHvoqhs4vL2H8t1utHVKtoKSjiNR5gR6OdG1S3lzkt/jyEmuz2cKkH7ZVrEGldRxFRETOdlVTH54e3BqAVxfuYvPhLABeW7SLPel5+Lo6MPX2jmr2ICIi1cpgMPDizW3p0dSHgpIyHvhiC5n5xdYO67wsFgv70vOYseIAw2eso+urS3n8p+0sTkijsKSMY7nFFBSfe+mShkSLsohIvTC4fRBbjpxgUXwq9/UKZ8bKA6w6tY7jB6M746J1HEVERM7pvp5hxCVl8+u2FB75ZisT+0fw5fojAPz3jo74uTlYOUIREWkIKjpaf7CWI5mFPPR1DF8/UHs6WpvKzGw+nMXSncdYtjudI38roW4b7E7/1gH0bx1AuxB3TXpBSUcRqSduaB/ISwt2suXICebHJfPfP/YA8NItbWkVqHUcRUREzsdgMPDG8PbsTctjT3oe/zd3BwAP9ArnmhZ+Vo5OREQaEi8Xez67pyvD3l/H5sMneGbuDt60YkfrnJMmVu49ztKd6azYc4zcoj9nL9rbGOnRzIf+bQLo18qfYE8nq8RYmynpKCL1QpCHE12aeBFz5AQTv4/DYoFbI0O4o6vWcRQREbkYZ3tbPry7CzdPX0NecSltg915fFBLa4clIiINUHN/N6aPiuS+WZv5MeYoLQLcGNenaY3df2JmIUt2pbNsVzqbDmVRav6z0Zq3iz3XtfKnf2t/ekX44aqKugvSoyMi9cYN7QKJOXICiwWa+bnw8tB2mtIuIiJyicJ9XZh5bxQ/bjnK+Oua15pyNhERaXj6tvTn2SFtePHXnbz22y6a+rnQr3VAtdxXmdlCXFI2S08lGvem559xe4S/K/1aBzCgjT+dQr2w0TrHl0xJRxGpNwa3D+LNxXswGuGD0V20jqOIiEgldQ3zpmuYt7XDEBERYezVYexNz+fbTYn889tY5jzSk5aBblVy7oLiUlbvy2DZrnSW7z5GZkFJxW02RgPdwrzp3yaA/q39aeLjUiX32RDpE7mI1BvBnk7MeeRqHO2MNPevmhcjERERERERqXkGg4GXbmnLoYx8NhzM4v4vNjM/uic+rpfX4Cw15yTLdh1j6a501h3IpKTUXHGbm6MtfVuWl033beGPh7NdVf0aDZqSjiJSr7QL8bB2CCIiIiIiIlIF7GyMzBjdpaKj9cNfb+XrB7pzKQXOFouFhJRclu5KZ+mudHYk555xe2Nv51Pdpv2JCvfGzsZYPb9EA6ako4iIiIiIiIiI1Ep/7Wi96XAWz8yL55WbW59z3yJTGesPZrJ0Z3nZdGpOUcVtBgN0buxFv9b+DGgdQHN/V/UAqGZKOoqIiIiIiIiISK31147WP2w5SjNfZwJP3ZaZX8zy3eVl06v3ZVBYUlZxnLO9Db0jfOnfOoBrW/nje5ml2XJ5lHQUEREREREREZFarW9Lf/7vxja8vGAnr/++lz6BRr74ZBOxSdlYLH/uF+juSL/W/vRvE0CPpj442tlYL+gGTklHERERERERERGp9e7rGcb+Y3l8uymJlalGIBuAdiHup9ZnDKBtsLvKpmsJJR1FRERERERERKTWMxgMvHhzO0ylZnYdSuKOXm0Z2C6IIA8na4cm56Cko4iIiIiIiIiI1An2tkamDGvLokVHGNwtFDs7O2uHJOdRqX7gU6ZMISoqCjc3N/z9/Rk6dCh79uy56HE//vgjrVq1wtHRkfbt27No0aIzbh87diwGg+GMy6BBg87YJysri9GjR+Pu7o6npyf3338/+fn5lQlfREREREREREREakClko4rV64kOjqaDRs2sGTJEkwmEwMHDqSgoOC8x6xbt46RI0dy//33Exsby9ChQxk6dCg7duw4Y79BgwaRmppacfn222/PuH306NEkJCSwZMkSFixYwKpVq3jwwQcrE76IiIiIiIiIiIjUgEqVVy9evPiM67NmzcLf35+YmBj69OlzzmOmTZvGoEGDePzxxwF4+eWXWbJkCe+99x4ffvhhxX4ODg4EBgae8xy7du1i8eLFbN68ma5duwIwffp0Bg8ezNSpUwkODq7MryEiIiIiIiIiIiLV6IrWdMzJyQHA29v7vPusX7+eyZMnn7Ht+uuvZ968eWdsW7FiBf7+/nh5eXHdddfxyiuv4OPjU3EOT0/PioQjQP/+/TEajWzcuJFhw4addb/FxcUUFxdXXM/NzQXAZDJhMpkq94uKWMHp56mer9LQaSyIaByIgMaByGkaCyIaB9ZUmcf8spOOZrOZiRMn0rNnT9q1a3fe/dLS0ggICDhjW0BAAGlpaRXXBw0axK233kp4eDgHDhzg6aef5oYbbmD9+vXY2NiQlpaGv7//mYHb2uLt7X3Gef5qypQpvPjii2dt/+OPP3B2dq7MrypiVUuWLLF2CCK1gsaCiMaBCGgciJymsSCicWANhYWFl7zvZScdo6Oj2bFjB2vWrLncU1QYMWJExc/t27enQ4cONGvWjBUrVtCvX7/LOudTTz11xgzL3NxcQkNDGThwIO7u7lccs0h1M5lMLFmyhAEDBqgblzRoGgsiGgcioHEgcprGgojGgTWdriS+FJeVdBw/fnxFM5dGjRpdcN/AwEDS09PP2Jaenn7e9RsBmjZtiq+vL/v376dfv34EBgZy7NixM/YpLS0lKyvrvOdxcHDAwcHhrO12dnZ6QkqdouesSDmNBRGNAxHQOBA5TWNBROPAGirzeFcq6WixWJgwYQJz585lxYoVhIeHX/SYHj16sGzZMiZOnFixbcmSJfTo0eO8xxw9epTMzEyCgoIqzpGdnU1MTAxdunQBYPny5ZjNZrp3737JsUPlMrIi1mQymSgsLCQ3N1d/RKVB01gQ0TgQAY0DkdM0FkQ0DqzpdF7tdJ7tgiyV8PDDD1s8PDwsK1assKSmplZcCgsLK/a5++67LU8++WTF9bVr11psbW0tU6dOtezatcvy/PPPW+zs7Czx8fEWi8ViycvLs/zrX/+yrF+/3nLo0CHL0qVLLZ07d7ZERERYioqKKs4zaNAgS2RkpGXjxo2WNWvWWCIiIiwjR4685NiTkpIsgC666KKLLrrooosuuuiiiy666KKLLrrocgWXpKSki+biDBbLpaQmyxkMhnNunzlzJmPHjgWgb9++hIWFMWvWrIrbf/zxR5555hkOHz5MREQEb775JoMHDwbg5MmTDB06lNjYWLKzswkODmbgwIG8/PLLZzSgycrKYvz48fz6668YjUaGDx/Ou+++i6ur6yXFbjabSUlJwc3N7by/h0htcnod0qSkJK1DKg2axoKIxoEIaByInKaxIKJxYE0Wi4W8vDyCg4MxGo0X3LdSSUcRqTm5ubl4eHiQk5OjP6LSoGksiGgciIDGgchpGgsiGgd1xYVTkiIiIiIiIiIiIiKVpKSjiIiIiIiIiIiIVCklHUVqKQcHB55//nkcHBysHYqIVWksiGgciIDGgchpGgsiGgd1hdZ0FBERERERERERkSqlmY4iIiIiIiIiIiJSpZR0FBERERERERERkSqlpKOIiIiIiIiIiIhUKSUdRUREREREREREpEop6SgiIiIiIiIiIiJVSklHEStbtWoVN910E8HBwRgMBubNm3fG7WPHjsVgMJxxGTRokHWCFakmU6ZMIer/27u7kCYbP4zjl2VW5EtM8w0zTMESnaE91AjEsnypg8R5EAUpSFHMSD0ojE6iIKmDLEjpKDpoCUUSBSH24iAwUGNoQUIjyMiXEJRcaJJ7Dvo3WGk9/Nm81X0/MJj37oPrwJ+X+3nv9p9/FBERodjYWJWWlqq/v9/nnMnJSdlsNkVHRys8PFxWq1XDw8MGJQb877/MQX5+/m+dcOzYMYMSA4HR3Nwss9msyMhIRUZGymKx6PHjx97X6QMEg7/NAX2AYNTQ0KCQkBDV1NR4j9EJCxtLR8Bgbrdb2dnZun79+pznFBcXa3Bw0Pu4c+fOPCYEAs/hcMhms+nly5dqb2/X9PS0CgsL5Xa7vefU1tbq4cOHunv3rhwOhz59+qSysjIDUwP+9V/mQJKOHDni0wmXLl0yKDEQGElJSWpoaFBPT4+6u7u1a9cu7d+/X2/evJFEHyA4/G0OJPoAwaWrq0s3btyQ2Wz2OU4nLGwhHo/HY3QIAD+EhISotbVVpaWl3mOVlZUaGxv77QpIYCn7/PmzYmNj5XA4lJeXp/Hxca1bt052u13l5eWSpLdv32rz5s3q7OzU9u3bDU4M+N+vcyD9uLJly5YtamxsNDYcMM9MJpMuX76s8vJy+gBB6+ccVFVV0QcIKhMTE8rJyVFTU5MuXLjg/d7nPcLCx5WOwCLQ0dGh2NhYpaen6/jx4xodHTU6EhBQ4+Pjkn78ci1JPT09mp6e1u7du73nbNq0ScnJyers7DQkIxBov87BT7dv31ZMTIwyMzNVX1+vr1+/GhEPmBffv39XS0uL3G63LBYLfYCg9Osc/EQfIFjYbDbt27fP52e/xHuExSDU6AAA/qy4uFhlZWVKSUmRy+XSmTNnVFJSos7OTi1fvtzoeIDfzczMqKamRjt27FBmZqYkaWhoSGFhYVq7dq3PuXFxcRoaGjIgJRBYs82BJB08eFAbNmxQYmKient7dfr0afX39+v+/fsGpgX8r6+vTxaLRZOTkwoPD1dra6syMjLkdDrpAwSNueZAog8QPFpaWvTq1St1dXX99hrvERY+lo7AAnfgwAHv86ysLJnNZqWmpqqjo0MFBQUGJgMCw2az6fXr13rx4oXRUQDDzDUHR48e9T7PyspSQkKCCgoK5HK5lJqaOt8xgYBJT0+X0+nU+Pi47t27p4qKCjkcDqNjAfNqrjnIyMigDxAUBgYGdPLkSbW3t2vVqlVGx8H/gY9XA4vMxo0bFRMTo3fv3hkdBfC76upqPXr0SM+fP1dSUpL3eHx8vL59+6axsTGf84eHhxUfHz/PKYHAmmsOZrNt2zZJohOw5ISFhSktLU25ubm6ePGisrOzdfXqVfoAQWWuOZgNfYClqKenRyMjI8rJyVFoaKhCQ0PlcDh07do1hYaGKi4ujk5Y4Fg6AovMx48fNTo6qoSEBKOjAH7j8XhUXV2t1tZWPXv2TCkpKT6v5+bmasWKFXr69Kn3WH9/vz58+OBzbyNgMfvbHMzG6XRKEp2AJW9mZkZTU1P0AYLazzmYDX2ApaigoEB9fX1yOp3ex9atW3Xo0CHvczphYePj1YDBJiYmfP4i+f79ezmdTplMJplMJp07d05Wq1Xx8fFyuVw6deqU0tLSVFRUZGBqwL9sNpvsdrsePHigiIgI7z1YoqKitHr1akVFRamqqkp1dXUymUyKjIzUiRMnZLFY+K90WDL+Ngcul0t2u1179+5VdHS0ent7VVtbq7y8PJnNZoPTA/5TX1+vkpISJScn68uXL7Lb7ero6FBbWxt9gKDxpzmgDxAsIiIifO5tLUlr1qxRdHS09zidsLCxdAQM1t3drZ07d3q/rqurkyRVVFSoublZvb29unXrlsbGxpSYmKjCwkKdP39eK1euNCoy4HfNzc2SpPz8fJ/jN2/eVGVlpSTpypUrWrZsmaxWq6amplRUVKSmpqZ5TgoEzt/mICwsTE+ePFFjY6PcbrfWr18vq9Wqs2fPGpAWCJyRkREdPnxYg4ODioqKktlsVltbm/bs2SOJPkBw+NMcDAwM0AfA/9AJC1uIx+PxGB0CAAAAAAAAwNLBPR0BAAAAAAAA+BVLRwAAAAAAAAB+xdIRAAAAAAAAgF+xdAQAAAAAAADgVywdAQAAAAAAAPgVS0cAAAAAAAAAfsXSEQAAAAAAAIBfsXQEAAAAAAAA4FcsHQEAAAAAAAD4FUtHAAAAAAAAAH7F0hEAAAAAAACAX/0LWzaZSgpiTCEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [1024,    1024,    1,],\n",
        "        \"samples\": [25,      1,       1024,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [4,       1,       num_classes,],\n",
        "        \"samples\": [(75, 1), (1, 4),  (1024, 1),],\n",
        "        \"is conv\": [True,    True,    False,]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  # optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  # widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    .reset_index()\n",
        "    .sort_values(\"epoch\", ascending=True)\n",
        "    .tail(30)[[\"train loss\"]]\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "ilOucSYLd2zy",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "_T9hF3Uoi3tF",
        "1SknOTQ7O9BS",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "Lyzd22RQX-Yg"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMtHXVJyrYqEAq98KsP3FB3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}