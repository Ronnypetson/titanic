{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4999db92-bcaa-4497-c336-03afddae7ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16378271.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 305526.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5464257.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 10118217.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16385127.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 328649.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5404483.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 12686414.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ],
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx\n",
        "\n",
        "def _cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = (row + offset)\n",
        "        idx[row, col, ch, 1] = (col + offset)\n",
        "        idx[row, col, ch, 2] = (ch  + offset)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "def poly1norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  idxu = (0.5 ** 0.5) * torch.cat([idxu, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "def poly2norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  _idxu = idxu.reshape((-1, d_idx, 1))\n",
        "  middle = (\n",
        "      torch.bmm(_idxu, _idxu.permute(0, 2, 1))\n",
        "      .reshape((*idxu.shape[:-1], d_idx ** 2))\n",
        "  )\n",
        "  idxu = 0.5 * torch.cat([(2.0 ** 0.5) * idxu, middle, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _knndot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"k-NN Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  num_neigh = 1\n",
        "  dots = []\n",
        "  q_idxu = idxu.cpu().detach().numpy().reshape(-1, d_idx)\n",
        "  for _pos in range(n):\n",
        "    neigh = NearestNeighbors(n_neighbors=num_neigh)\n",
        "    neigh.fit(idxv[_pos].cpu().detach().numpy().reshape(-1, d_idx))\n",
        "    n_idxu = neigh.kneighbors(\n",
        "        q_idxu, return_distance=False\n",
        "    ).reshape(-1)\n",
        "    n_idxu = torch.from_numpy(n_idxu).long()\n",
        "    _v = v[_pos].reshape(-1, d_val)[n_idxu].reshape(m, d_u, d_val)\n",
        "    # _dot: M x d_val x d_val\n",
        "    _dot = torch.bmm(_v.permute(0, 2, 1), _v)\n",
        "    # _dot: M x 1 x d_val\n",
        "    _dot = torch.diagonal(_dot, dim1=1, dim2=2).unsqueeze(1)\n",
        "    dots.append(_dot)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.cat(dots, dim=1)\n",
        "  return dot\n",
        "\n",
        "def _ibmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  v: N x d_v x d_valv\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu, d_valv = u.shape[-1], v.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: N x d_idx x d_valv\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxv: M x d_u x (d_valv * N)\n",
        "  idxv = (\n",
        "      torch.matmul(idxu.unsqueeze(1), idxv)\n",
        "      .permute(0, 2, 3, 1)\n",
        "      .reshape(m, d_u, d_valv * n)\n",
        "  )\n",
        "  # idxv: M x d_valu x (d_valv * N)\n",
        "  idxv = torch.bmm(u.permute(0, 2, 1), idxv)\n",
        "  if d_valv == 1:\n",
        "    # idxv: M x N x d_valu\n",
        "    idxv = idxv.reshape(m, d_valu, n).permute(0, 2, 1)\n",
        "  else:\n",
        "    # idxv: M x N x d_valu or error\n",
        "    idxv = idxv.reshape(m, d_valu, d_valv, n).permute(0, 3, 1, 2)\n",
        "    idxv = torch.diagonal(idxv, dim1=2, dim2=3)\n",
        "  return idxv\n",
        "\n",
        "def _fbmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Fast Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # uidxu: M x d_val x d_idx\n",
        "  # idxvv: N x d_idx x d_val\n",
        "  uidxu = torch.bmm(u.permute(0, 2, 1), idxu)\n",
        "  idxvv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # dot: M x N x d_val\n",
        "  dot = (\n",
        "    (\n",
        "        uidxu.reshape(m * d_val, d_idx)\n",
        "        @ (\n",
        "            idxvv\n",
        "            .permute(0, 2, 1)\n",
        "            .reshape(n * d_val, d_idx)\n",
        "            .T\n",
        "          )\n",
        "    ).reshape(m, d_val, n, d_val)\n",
        "    .permute(0, 2, 1, 3)\n",
        "  )\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = 2 * int(np.log((d_u + d_v) // 2)) + 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "# def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, idx_part)\n",
        "#   kidxv = k(idxv, idx_part)\n",
        "#   d_idx_k = kidxu.shape[-1]\n",
        "#   assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "#   assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "#   sidx = (\n",
        "#       (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "#       + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "#   )\n",
        "#   sidx = sidx / norm\n",
        "#   sidx = sidx.repeat(batch_m, 1, 1)\n",
        "#   return sidx\n",
        "\n",
        "# def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "#   # iTki_kjTj: M x N x d_idx x d_idx\n",
        "#   iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "#   diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "#   ###\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   diag = diag / norm\n",
        "#   ###\n",
        "#   diag = diag.repeat(batch_m, 1, 1)\n",
        "#   return diag\n",
        "\n",
        "# def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # ski: (M * N) x d_idx\n",
        "#   # skj: (M * N) x d_idx\n",
        "#   # norm: M x N x 1\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "#   skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "#   # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "#   # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "#   idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "#   idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "#   kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "#   kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "#   # sikiT: M x d_idx x d_idx\n",
        "#   # sjkjT: N x d_idx x d_idx\n",
        "#   sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "#   sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "#   sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "#   sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "#   del kidxu\n",
        "#   del kidxv\n",
        "#   del idxu\n",
        "#   del idxv\n",
        "#   # sikiT: (M * N) x d_idx x d_idx\n",
        "#   # sjkjT: (M * N) x d_idx x d_idx\n",
        "#   sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "#   # skjjT = sjkjT.permute(0, 2, 1)\n",
        "#   # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "#   # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "#   xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "#   # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "#   # xor_idx = diag_sikiT_skjjT\n",
        "#   xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "#   xor_idx = xor_idx / norm\n",
        "#   return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    ###\n",
        "    # _nsbmd\n",
        "    # _rdot\n",
        "    # _knndot\n",
        "    # _fbmd\n",
        "    # _ibmd\n",
        "    ###\n",
        "    mdot = _ibmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones((*self.idx.shape[:-1], 1)).to(self.idx.device)\n",
        "    onesb = torch.ones((*b.idx.shape[:-1], 1)).to(b.idx.device)\n",
        "    # ###\n",
        "    midx = (\n",
        "        _ibmd(aidx, onesb, aidx, bidx)\n",
        "        + _ibmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # xidx = xidx / np.linalg.norm(xidx, axis=-1)[:, None]\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    # self._ones_idx = _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # self.activation = nn.ELU()\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.LeakyReLU()\n",
        "    self._probe = nn.Linear(self._feat_samples[-1], 10).to(device)\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    # _mag = 1.0\n",
        "    # _W = nn.Parameter(\n",
        "    #     _mag * torch.rand(shape, device=device) - (_mag / 2.0)\n",
        "    # )\n",
        "    # _mag = 10.0\n",
        "    # _W_idx = _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    # _mag = 0.001\n",
        "    # _template = _mag * torch.rand((1, idxdim), device=device) - (_mag / 2.0)\n",
        "    # _num_idx = np.prod(shape)\n",
        "    # _pos = torch.tensor([[pos + 1.0] for pos in range(_num_idx)]).to(device)\n",
        "    # _W_idx = nn.Parameter(_pos @ _template)\n",
        "    _mag = 1000.0\n",
        "    _W_idx = nn.Parameter(\n",
        "      _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    )\n",
        "    _std = 0.01\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((*shape, idxdim), device=device)\n",
        "    # )\n",
        "    # _W_idx = _std * torch.randn((*shape, idxdim), device=device)\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      ###\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      maromba_only = True\n",
        "      if maromba_only or (step < n_layers - 1):\n",
        "        pool = (\n",
        "            MTensor.reshape(\n",
        "                pool, (n * feat_sets[step], -1)\n",
        "            )\n",
        "            @ mw\n",
        "        )\n",
        "      else:\n",
        "        pool = self._probe(pool.data.reshape(n, -1))\n",
        "        pool = MTensor(\n",
        "            pool,\n",
        "            torch.zeros((*pool.shape, self._idx_dim)).to(pool.device)\n",
        "        )\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 100 # 3 # 10\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim, mag=1000.0)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rows, cols, d = 28, 28, 1000\n",
        "# template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=d, mag=1000.0)\n",
        "# tidx = template_x_idx.detach().numpy()\n",
        "# # plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# # fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "\n",
        "# ntidx = tidx / (np.linalg.norm(tidx, axis=-1)[:, None] + 1e-6)\n",
        "# # plot_df = pd.DataFrame({\"x\": ntidx[:, 0], \"y\": ntidx[:, 1], \"z\": ntidx[:, 2]})\n",
        "# # fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "\n",
        "# dots = ntidx @ ntidx.T\n",
        "# exp = 1.0\n",
        "# # dots = ((dots + 1.0) / 2.0) ** exp\n",
        "# ref = 1 / (rows * cols)\n",
        "# print((dots.mean(axis=-1) / ref).mean())\n",
        "# print()\n",
        "# _idx = 0 # (rows*cols) // 2\n",
        "# import seaborn as sns\n",
        "# sns.heatmap(dots[_idx].reshape(rows, cols))"
      ],
      "metadata": {
        "id": "x0gnLj8YEQno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizações"
      ],
      "metadata": {
        "id": "8_m1YvjxBdj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ],
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "7271e322-38e9-4a12-cf97-3dd3ef17cef1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABQsAAAESCAYAAABaVYODAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnlklEQVR4nO3dd3iUVfrG8e/MZNIb6b1AEnqTJh2kqyh2xRUV3bUAFiy7+nMVdHdd64q9iw2sFBUUkA7Sew0JBJKQRhLS2yQzvz8C0UgNkEwS7s915UrmnXlnnpfkZODmOecYbDabDREREREREREREbnoGe1dgIiIiIiIiIiIiDQOCgtFREREREREREQEUFgoIiIiIiIiIiIixygsFBEREREREREREUBhoYiIiIiIiIiIiByjsFBEREREREREREQAhYUiIiIiIiIiIiJyjIO9CzgbVquVtLQ0PDw8MBgM9i5HRERERERERESkSbHZbBQWFhISEoLReOr+wSYRFqalpREeHm7vMkRERERERERERJq0lJQUwsLCTnl/kwgLPTw8gOqL8fT0tHM1F57FYmHhwoUMHz4cs9ls73JEmh2NMZH6pTEmUr80xkTqj8aXSP3SGGtcCgoKCA8Pr8nZTqVJhIXHpx57eno227DQ1dUVT09PDR6ReqAxJlK/NMZE6pfGmEj90fgSqV8aY43TmZb40wYnIiIiIiIiIiIiAigsFBERERERERERkWMUFoqIiIiIiIiIiAjQRNYsFBERERERERGRhlFVVYXFYjnv57FYLDg4OFBWVkZVVdUFqExOx2w2YzKZzvt5FBaKiIiIiIiIiAg2m42MjAzy8vIu2PMFBQWRkpJyxk015MLw9vYmKCjovP68FRaKiIiIiIiIiEhNUBgQEICrq+t5B3xWq5WioiLc3d0xGrUSXn2y2WyUlJSQlZUFQHBw8Dk/l8LCRmDjoaMk5BvYlpqPl6sTLo4mXB0dcHU04eRgVPouIiIiIiIiIvWqqqqqJij09fW9IM9ptVqpqKjA2dlZYWEDcHFxASArK4uAgIBznpKssLAReOaHPezLMvHm7nUn3Gc0gJujw7EA8fcQ0cXRhNuxr12dqo+7mE24OZlwcXTA7djjj399PID849cmo0JIEREREREREaFmjUJXV1c7VyLn4/j3z2KxKCxsyiJ9XSkoLMTo6EKppYriiioqKq0AWG1QWF5JYXnlBX9dJwdjrQDS1ckBV7Op1tcujtUBZM1jHE24OTkQ7OVMuI8r/u5O6nwUERERERERaSb0b/ym7UJ8/xQWNgJvj+3C/PnzufzyAZjNZgAqq6yUWqooqaj+KC6v/P12eWX1Z8sfvq6o/lxaUUVxRWXNedXHKin+w302W/XrlldaKa+0crTk3Hc4cjYbCW/hSriPKxE+roS1cCHCp/p2uI8r7k76ERMRERERERERaSqU5DRSDiYjHiYjHs7mC/q8NpuN8krrKQPI4opKSmuCxj+Gjr9/XVhmIS2vjLT8UsosVhKyikjIKjrp6/m4OVYHh38IESN8XAlv4UqwtzNmk9YsEBERERERERFpLBQWXmQMBgPOZhPOZhM+bo7n9VwVlVbS8kpJzi0h5WgJybklpOaW1nydV2Iht7iC3OIKtqXknXC+yWgg2Mu5JjyM8K3dmejr5qj2ZxERERERERFpUFFRUTz00EM89NBDdn0Oe1FYKOfM0cFIlJ8bUX5uJ72/oMxCSm4JKbml1Z+PhYjVX5dSUWkl9WgpqUdLgZwTznd1NNVMcQ73cakVKoa3cMXF8dwW6hQRERERERGR5mPQoEF06dKF11577YI834YNG3BzO3nWcTFQWCj1xtPZTPsQL9qHeJ1wn9Vq40hReU14mPynUDGjoIySiiriMwuJzyw86fP7uTvVDhF9XAk7djvYy0W7PYuIiIiIiIgIUL0sW1VVFQ4OZ47C/P39G6CixkthodiF0Wgg0NOZQE9nekT5nHB/eWUVh48en+J8LEQ8Fiom55ZQWFZJdlE52UXlbEnOO+F8B6OB0BYuhLdwJSbAnc7hXnQO8ybK1w2jQkQRERERERGRM7LZbJRaqs75fKvVSmlFFQ4VlRiNdduzwMVsOqulye644w6WL1/O8uXLmTZtGgBJSUkcPHiQwYMHM3/+fJ566il27NjBwoULCQ8PZ/Lkyaxdu5bi4mLatm3L888/z9ChQ2ue889TiA0GAx988AHz5s1jwYIFhIaG8sorr3DVVVed9fUkJyczadIkFi9ejNFoZOTIkbzxxhsEBgYCsG3bNh566CE2btyIwWAgNjaW9957j+7du3Po0CEmTpzIqlWrqKioICoqipdeeonLL7+8Dn+iZ09hoTRKTg4mWvq709Lf/aT355dYak1r/mOoePhoKRVVVg7llHAop4RVidk153k6O9ApzJvO4V50CvOmS7g3gZ7ODXVZIiIiIiIiIk1GqaWKdk8vsMtr7352BK6OZ46tpk2bxr59++jQoQPPPvssUN0ZePDgQQD+8Y9/8PLLL9OyZUtatGhBSkoKl19+Of/+979xcnLis88+Y/To0cTHxxMREXHK15k6dSovvvgiL730Em+88Qa33norhw4dwsfnxAaoP7NarVx99dW4u7uzfPlyKisrmTBhAjfddBPLli0D4NZbb6Vr16688847mEwmtm7ditlcventhAkTqKioYMWKFbi5ubF7927c3U+el1wICgulSfJyNePl6kWH0BOnOFdZbWQWlNWEiLvTC9iems/Ow/kUlFWyKjG7VoAY6OlE5zBvOod70znMm45hXni5XNhdqEVERERERETkwvPy8sLR0RFXV1eCgoJOuP/ZZ59l2LBhNbd9fHzo3Llzze3nnnuO2bNn88MPPzBx4sRTvs4dd9zBLbfcAsB//vMfXn/9ddavX8/IkSPPWOPixYvZsWMHSUlJhIeHA/DZZ5/Rvn17NmzYQI8ePUhOTuaxxx6jTZs2AMTGxtacn5yczHXXXUfHjh0BaNmy5Rlf83woLJRmx2Q0EOLtQoi3C71a+tYct1RZic8oZHtqPttS8tiWmse+zEIyC8pZuDuThbszax7b0s+NzuHedArzonO4N+2CPXE2a0MVERERERERuXi4mE3sfnbEOZ9vtVopLCjEw9PjnKYhXwjdu3evdbuoqIgpU6Ywb9480tPTqayspLS0lOTk5NM+T6dOnWq+dnNzw9PTk6ysrLOqYc+ePYSHh9cEhQDt2rXD29ubPXv20KNHDyZPnszdd9/N559/ztChQ7nhhhto1aoVAA888AD33XcfCxcuZOjQoVx33XW16rnQFBbKRcNsMtIhtLobcWyv6tbikopKdqUVHAsPq0PE5NwSDmQXcyC7mNlbDgPVayC2Cfaonrp8rAsxJsBdm6iIiIiIiIhIs2UwGM5qKvCpWK1WKh1NuDo61DksvFD+vKvxo48+yqJFi3j55ZeJiYnBxcWF66+/noqKitM+z/EpwccZDAasVusFq3PKlCmMHTuWefPm8fPPP/PMM8/w1Vdfcc0113D33XczYsQI5s2bx8KFC3n++ed55ZVXmDRp0gV7/T9SWCgXNVdHB3pE+dTaZCW3uILtqXlsS8mv/pyaR3ZRBTsPF7DzcAEz1iUfO9dEh1AvOh/rPuwc5k1YC5ezWoBVRERERERERC4MR0dHqqrObiOW1atXc8cdd3DNNdcA1Z2Gx9c3rC9t27YlJSWFlJSUmu7C3bt3k5eXR7t27WoeFxcXR1xcHA8//DC33HILn3zySU2d4eHh3Hvvvdx777088cQTfPDBBwoLRRqKj5sjg1oHMKh1AFC9+1Nafll19+Gx6cs7UvMprqhifVIu65Nya53bOez3zVM6hXnh6+5kr0sRERERERERafaioqJYt24dBw8exN3d/bSbjsTGxjJr1ixGjx6NwWDgn//85wXtEDyZoUOH0rFjR2699VZee+01Kisruf/++xk4cCDdu3entLSUxx57jOuvv57o6GhSU1PZsGED1113HQAPPfQQo0aNIi4ujqNHj7J06VLatm1bb/UqLBQ5A4PBQKi3C6HeLlzeMRio3kTlwJEitqbkVa+BmJrHnvQCcosrWBp/hKXxR2rOD2vhcmwDleoQsWOoF25OGnoiIiIiIiIiF8Kjjz7K7bffTrt27SgtLSUpKemUj3311VcZP348ffr0wc/Pj7///e8UFBTUa30Gg4G5c+cyadIkBgwYgNFoZOTIkbzxxhsAmEwmcnJyGDduHJmZmfj5+XHttdcydepUAKqqqpgwYQKpqal4enoycuRI/ve//9VbvUosRM6ByWggNtCD2EAPbuhe3UJcXlnFnvRCtqfmsfVYF+KB7GJSj5aSerSUeTvSATAaIDbAo2bzlM5h3rQO8sDRwT7rN4iIiIiIiIg0ZXFxcaxZs6bWsaioKGw22wmPjYqKYsmSJbWOTZgwodbtP09LPtnz5OXlnbamPz9HREQEc+fOPeljHR0dmTlz5imf63io2FDqFBY+//zzzJo1i7179+Li4kKfPn144YUXaN269SnP+eCDD/jss8/YuXMnAN26deM///kPPXv2PL/KRRoZJwcTXcKrpx+P6119rKDMws7U/JrNU7an5pGWX0Z8ZiHxmYV8uykVAEcHI+2CPekU5lUdQga4ExvgrinMIiIiIiIiItKg6hQWLl++nAkTJtCjRw8qKyt58sknGT58OLt37z5hd5njli1bxi233EKfPn1wdnbmhRdeYPjw4ezatYvQ0NALchEijZWns5k+MX70ifGrOZZVUMa21PyaDsTtqfnkl1rYmlJ9+49auJqJDfCg1bHwMDbQnZgAd4I8nbWRioiIiIiIiIhccHUKC3/55Zdat6dPn05AQACbNm1iwIABJz3nyy+/rHX7ww8/5Pvvv2fx4sWMGzeujuWKNH0Bns4Ma+fMsHaBQHU786GcEral5rE7rYDErCISsopIOVrC0RIL6w/msv5gbq3ncHdyICagOjisCRH9PQhr4YLRqBBRRERERERERM7Nea1ZmJ+fD3DaXWb+rKSkBIvFctpzysvLKS8vr7l9fKFJi8WCxWI5x2obr+PX1ByvTc5OqJcjoV4BXN4+oOZYaUUVSTnFJGYVk3ikiP1Hqr8+lFtCUXnlSTsRnc1Gon3diAlwI8bfnVb+bsQEuBPh44LZdPGuiagxJlK/NMZE6pfGmEj90fgS+Z3FYsFms2G1Wi/Y7sDH1/o7/rxS/6xWKzabDYvFgslkqnXf2f6uM9hOtkrjWb74VVddRV5eHqtWrTrr8+6//34WLFjArl27cHZ2PuljpkyZUrPjyx/NmDEDV1fXcylXpNmotEJ2GWSUGsgogcxSAxmlBrJKodJ28q5Ck8GGvzMEudgIdD322cVGgAuYL94MUURERERERI5xcHAgKCiIsLAwnJy0fn5TVV5eTmpqKunp6VRVVdW6r6SkhLFjx5Kfn4+np+cpn+Ocw8L77ruPn3/+mVWrVhEWFnZW5/z3v//lxRdfZNmyZXTq1OmUjztZZ2F4eDjZ2dmnvZimymKxsGjRIoYNG4bZbLZ3OdJEVVltpB4tJTGriMQjxSRmFbE/u5j9R4opqag66TlGA4S3cCUmwK26C9HfnZgAN1r6ueHm1Hw2S9cYE6lfGmMi9UtjTKT+aHyJ/M5qtZKUlITJZMLf3x+z2Xzea+XbbDaKi4txc3PTuvv17Hg34ZEjR6iqqiI6OhqjsXZ3UEFBAX5+fmcMC88pDZg4cSI//fQTK1asOOug8OWXX+a///0vv/7662mDQgAnJ6eTpthms7lZ/wJv7tcn9csMxAQ5EhPkVeu41WojLf9YiJhVREJmEYlHikjILKSgrJJDuSUcyi1h8d4jtc4L9XY56bqIXq5N92dUY0ykfmmMidQvjTGR+qPxJVKtZcuWpKenk56efkGez2azUVpaiouLi8LCBuLq6kpwcDCOjo4n3He2v+fqFBbabDYmTZrE7NmzWbZsGdHR0Wd13osvvsi///1vFixYQPfu3evykiJynoxGA2EtXAlr4cqg1r+viWiz2ThSWF6zoUpCVmFNoJhdVMHhvFIO55WyfF/tENHfw4kY/+rwMNrPjUhfVyJ93Qhv4Yqjg+Y0i4iIiIiINFWOjo5ERERQWVl5whTWc2GxWFixYgUDBgxQIN8ATCYTDg4O5x3M1iksnDBhAjNmzGDu3Ll4eHiQkZEBgJeXFy4uLgCMGzeO0NBQnn/+eQBeeOEFnn76aWbMmEFUVFTNOe7u7ri7u59X8SJy7gwGAwGezgR4OtMnxq/WfUeLK451H9YOEdPzyzhSWM6RwnLWHMipdY7RACHeLkT5uhHh60rUsRAxyteNCB9XXBxrL6wqIiIiIiIijY/BYLhg3bYmk4nKykqcnZ0VFjYhdQoL33nnHQAGDRpU6/gnn3zCHXfcAUBycnKtOdHvvPMOFRUVXH/99bXOeeaZZ5gyZUrdKxaRetfCzZEebj70iKq9a3lhmYX9R4pJyCwk8UgRh7JLOJhTzKGcEkotVaQeLSX1aCkknvicgZ5Ox8LD6hAx0te1Jlj0dNabhoiIiIiIiEhjUOdpyGeybNmyWrcPHjxYl5cQkUbMw9lMl3BvuoR71zpus9k4UlTOoZwSDmZXh4eHcks4lFNMUnYxhWWVZBaUk1lQzvqk3BOe19fN8Vg3Yu0QMcrXjRau57+oroiIiIiIiIicneaz3amI2I3BYCDAw5kAD+cTuhFtNht5JZaa8PBgdvXn47eziyrIKa7+2JKcd8Jzezg7nHRqc5SvK/4eTgoSRURERERERC4ghYUiUq8MBgMt3Bxp4eZ4QkciVE9tPpRTcqwbsbjW1OaMgjIKyyrZcTifHYfzTzjXxWw6tsFK7W7ESF9Xgr1cMBkVJIqIiIiIiIjUhcJCEbErD2czHUK96BDqdcJ9ZZYqknP/OLW5+vPBnGIOHy2l1FLF3oxC9mYUnnCuo8lImE/1hivhLZwpyTDgf/Ao7UK98XY9cQt5EREREREREVFYKCKNmLPZRFygB3GBHifcV1Fp5XBeaXUXYnYxB3NKqoPFnGJSckuoqLJy4EgxB44UHzvDxLcfbQCqN1uJC/Sg9bHnjgvyIDbAHTcn/UoUERERERGRi5v+ZSwiTZKjg5FoPzei/dygde37qqw20vJKa8LDA1mFrNmVRD6uHM4rq9lsZWVCdq3zwn1cagLE1kHVn1v6u+HkYGrAKxMRERERERGxH4WFItLsmIwGwn1cCfdxpW+MHxaLhfnW/Vx++QDKqiAhq4h9GYXEZxayL7OQ+IwisovKScktJSW3lF/3ZNV6rmg/tz+EiO7EBXoQ6eumNRFFRERERESk2VFYKCIXFQ9nM5dEtOCSiBa1jucUlbMvs6g6PMwsrAkTC8sqScwqIjGriHk70mse7+RgJCbAvTpEDPKo+Rzi5awdmkVERERERKTJUlgoIgL4ujvR292J3q18a47ZbDYyCsqqQ8Q/dCLuyyykzGJlV1oBu9IKaj2Pu5MDcYHuNdOYj4eIfu5ODX1JIiIiIiIiInWmsFBE5BQMBgPBXi4Ee7kwMM6/5niV1Ubq0RLiM45NYz4WJu4/UkRReSWbk/PYnJxX67l83RxrrYXYOsid2EAPPJ3NDXxVIiIiIiIiIqemsFBEpI5MRgORvm5E+roxvH1QzfGKSisHc4p/DxGPfT6UW0JOcQVrDuSw5kBOrecK8XIm9o8hYqAHMQHuuDhqUxURERERERFpeAoLRUQuEEcHI3HHNkL5o9KKKhKziv6woUr15/T8MtKOfSzfd+T35zEZualHOBMGxxDk5dzQlyEiIiIiIiIXMYWFIiL1zMXRRMcwLzqGedU6nl9qIeFPG6rEZxRytMTC52sP8fXGFP7SK5L7BrXC30NrHoqIiIiIiEj9U1goImInXi5mukf50D3Kp+aYzWZjzYEcXl24j42HjvLx6iRmrk9mXJ9I7hnQCh83RztWLCIiIiIiIs2d0d4FiIjI7wwGA31a+fHtvb35bHxPOod7U2qp4r3lB+j/whJeXhBPfonF3mWKiIiIiIhIM6WwUESkETIYDAyI82fO/X346PbutA/xpLiiijeXJtLvhSW89us+CsoUGoqIiIiIiMiFpbBQRKQRMxgMDGkbyE+T+vHuX7rRJsiDwvJKXvs1gf4vLOWtpYkUl1fau0wRERERERFpJhQWiog0AQaDgZEdgpj/QH/eHNuVVv5u5JdaeGlBPP1fXMr7K/ZTWlFl7zJFRERERESkiVNYKCLShBiNBq7sFMLChwfyv5s6E+XrSm5xBf+Zv5f+Ly7l41VJlFkUGoqIiIiIiMi5UVgoItIEmYwGrukaxq+TB/Li9Z0Ia+FCdlE5z/60m4EvLeXzNQcpr1RoKCIiIiIiInWjsFBEpAlzMBm5sXs4Sx4ZxH+u6UiIlzOZBeX8c+4uLnt5OV+tT8ZSZbV3mSIiIiIiItJEKCwUEWkGHB2MjO0VwdLHBjH1qvYEeDhxOK+Uf8zawZBXlvPdplQqFRqKiIiIiIjIGSgsFBFpRpwcTNzeJ4oVjw/mqSva4ufuSHJuCY9+u43h/1vB3K2HqbLa7F2miIiIiIiINFIKC0VEmiFns4m7+7dkxeOD+ceoNrRwNXMgu5gHv9rKyNdWMH9HOlaFhiIiIiIiIvInCgtFRJoxV0cH7h3YihWPD+aRYXF4OjuQkFXE/V9u5oo3VrFwVwY2m0JDERERERERqVansPD555+nR48eeHh4EBAQwJgxY4iPjz/jed9++y1t2rTB2dmZjh07Mn/+/HMuWERE6s7D2cykIbGs/PtlPDAkFncnB/akF/C3zzdx9VurWRqfpdBQRERERERE6hYWLl++nAkTJrB27VoWLVqExWJh+PDhFBcXn/Kc3377jVtuuYW77rqLLVu2MGbMGMaMGcPOnTvPu3gREakbLxczk4fFsfLxwdw/qBWujia2p+Zz5ycbuO6d31iVkK3QUERERERE5CJWp7Dwl19+4Y477qB9+/Z07tyZ6dOnk5yczKZNm055zrRp0xg5ciSPPfYYbdu25bnnnuOSSy7hzTffPO/iRUTk3LRwc+TxkW1Y8fhg/to/GicHI5uT8/jLR+u46f21rD2QY+8SRURERERExA4czufk/Px8AHx8fE75mDVr1jB58uRax0aMGMGcOXNOeU55eTnl5eU1twsKCgCwWCxYLJbzqLhxOn5NzfHaRBoDjbFT83Iy8vjwWO7oHcF7K5KYuSGF9Um53Pz+Wvq09OGhITF0jfC2d5nSyGmMidQvjTGR+qPxJVK/NMYal7P9Phhs5zjfzGq1ctVVV5GXl8eqVatO+ThHR0c+/fRTbrnllppjb7/9NlOnTiUzM/Ok50yZMoWpU6eecHzGjBm4urqeS7kiInIW8sph4WEja7MMVNkMALT1tjIq3Eqku52LExERERERkXNWUlLC2LFjyc/Px9PT85SPO+fOwgkTJrBz587TBoXn6oknnqjVjVhQUEB4eDjDhw8/7cU0VRaLhUWLFjFs2DDMZrO9yxFpdjTG6mYskHq0lLeXH2DWljT25BnZk2dkSBt/HrisFe2Cm9/vYTk/GmMi9UtjTKT+aHyJ1C+Nscbl+MzdMzmnsHDixIn89NNPrFixgrCwsNM+Nigo6IQOwszMTIKCgk55jpOTE05OTiccN5vNzfqHq7lfn4i9aYydvegAMy/d0IWJl8UybXECc7YcZvHeIyzee4RRHYJ4eFgccYEe9i5TGhmNMZH6pTEmUn80vkTql8ZY43C234M6bXBis9mYOHEis2fPZsmSJURHR5/xnN69e7N48eJaxxYtWkTv3r3r8tIiImIHkb5uvHpjFxY+PJCrOodgMMDPOzMY8doKJs3cwv4jRfYuUURERERERC6gOnUWTpgwgRkzZjB37lw8PDzIyMgAwMvLCxcXFwDGjRtHaGgozz//PAAPPvggAwcO5JVXXuGKK67gq6++YuPGjbz//vsX+FJERKS+xAS48/otXZkwOIbXft3Hzzsz+HFbGvO2p9Ex1IvYQA/iAt2PffYgxMsZg8Fg77JFRERERESkjuoUFr7zzjsADBo0qNbxTz75hDvuuAOA5ORkjMbfGxb79OnDjBkzeOqpp3jyySeJjY1lzpw5dOjQ4fwqFxGRBtc6yIN3/tKNXWn5/G9RAr/uyWRbaj7bUvNrPc7dyYGYAHfiAt2JC/SoCRODPBUiioiIiIiINGZ1CgvPZuPkZcuWnXDshhtu4IYbbqjLS4mISCPWPsSLD2/vzqGcYnalFbAvs5CEzCL2ZRaSlF1MUXklW1Py2JqSV+s8D2cH4o53IQZ41Hzt7+GkEFFERERERKQROOfdkEVERCJ93Yj0dePyjsE1xyoqrRzMKWZfZiH7MotIyCxkX2YhB3NKKCyrZNOho2w6dLTW83i5mH+fxhzwezein7ujQkQREREREZEGpLBQREQuKEcH47GOwdq7JZdXVpGUXcy+zCL2ZVQHiAlZRRzKKSa/1MKGg0fZcLB2iNjC1VwzhTku0ONYN6I7vu5ODXlJIiIiIiIiFw2FhSIi0iCcHEy0CfKkTZAndP79eJmliv1HimqmMe/LLCIhq5Dk3BKOllhYn5TL+qTcWs/l5+5YExwe31QlLtAdb1fHBr4qERERERGR5kVhoYiI2JWz2UT7EC/ah3jVOl5aUR0i1prOnFVISm4p2UUVZBflsOZATq1z/D2cTlgPMTbQAy8Xc0Ne0kVlc/JRZqw9REGmkUsKygj31Z+1iIiIiEhTprBQREQaJRdHEx1CvegQWjtELC6vJDGrqGYa8/HNVQ7nlXKksJwjheWsTqwdIgZ6OhEX6EH3SB/G9Y6khZs6EM/X7rQCXl0Uz697so4dMbLklZVc3jGY8f2i6RLubc/yRERERETkHCksFBGRJsXNyYHO4d50/lMYVVReScIfdmXel1XdjZieX0ZmQTmZBeWsTMjm/RX7ua13FH/tH621D8/B/iNF/G/RPn7ang6A0QBXdQpmZ1IaiQXww7Y0ftiWxiUR3ozvF83I9kE4mIx2rlpERERERM6WwkIREWkW3J0c6BrRgq4RLWodLyizkJBZxJ70AmauT2ZXWgHvLt/Pp78d5Lbekfy1f0v8PRQanklKbgmvL07g+82pWG3Vx67sFMzDw+KI8HZi/vwUIrv04/N1qfy4LY3NyXlsnrGFEC9nbusdxS09w7WmpIiIiIhIE6CwUEREmjVPZzPdIlvQLbIFt/aKYPGeLF5fksD21HzeX3GAz9YcZGzPSO4d2JIAT2d7l9voZBWU8ebSRGauT8ZSVZ0SDm0bwORhrWkX4gmAxWIBoH2IJ6/c2Jm/j2rNl2uT+XLdIdLyy3jhl71MW7yP6y4J486+UcQEeJzy9URERERExL4UFoqIyEXDYDAwtF0gQ9oGsGzfEab9msDWlDw+Xp3EF+sOMbZnBPcMbEmwl4u9S7W73OKKmg7M8korAP1i/HhkeNwJ3Zt/FuDhzMPD4rh/cCt+3JbOx6uS2J1ewJfrkvlyXTID4/wZ3y+aAbF+GAyGhrgcERERERE5SwoLRUTkomMwGBjcOoBBcf6sTMhm2uIENh06yvTfDjJjXTI39gjjvkExhHpffKFhQZmFD1cm8fGqJIrKKwHoFtmCR4e3pncr3zo9l5ODieu7hXHdJaGsS8rl41VJLNqTyfJ9R1i+7wit/N24s280114Siquj/koiIiIiItIY6G/mIiJy0TIYDAyI86d/rB9r9ufw2uIE1ifl8sXaZL7ekML13cK5f1Arwn1c7V1qvSupqOTT3w7x3or95JVUTytuF+zJYyNaM6i1/3l1ABoMBi5t6culLX1Jzinh0zUH+XpDCvuPFPPUnJ28tCCeW3pGMK53JCEXYUArIiIiItKYKCwUEZGLnsFgoE+MH31i/Fh7IIfXFyfw2/4cZq5P5tuNKVx7SSgTBscQ6etm71IvuPLKKmauS+bNpfvJLioHoJW/G5OHtWZUhyCMxgs7TTjC15V/XtmOh4bG8t2mVD5ZfZDk3BLeXb6fD1YeYFSHIMb3i+aSM0x1FhERERGR+qGwUERE5A+Od8BtOJjL64sTWJmQzTcbU/l+82HGdAll4mUxRPs1/dCwssrK95tTeX1xIofzSgEI93HhoSFxjOkaiukCh4R/5uFs5s6+0YzrHcWSvVl8vCqJNQdy+Gl7Oj9tT6dLuDfj+0UzqkMQZpOxXmsREREREZHfKSwUERE5iR5RPnx+Vy82HTrKG0sSWBZ/hO83pzJ7SypXd6nuNIwJcLd3mXVmtdr4cXsar/2aQFJ2MQCBnk5MuiyWG7uH4+jQsMGcyWhgWLtAhrULZHdaAZ+sTmLu1jS2puTxwMwtBHk6c1vvSMb2jKCFm2OD1iYiIiIicjFSWCgiInIa3SJbMP3OnmxLyeP1xQks3pvF7C2HmbP1MFd2CmHSZTHEBXrYu8wzstlsLNqdyauL9rE3oxAAHzdH7h/Uir9cGomz2WTnCqFdiCcv3dCZv49qw4x1yXy25hAZBWW8tCCeN5YkcE3XMMb3jSK2Cfx5i4iIiIg0VQoLRUREzkLncG8+uqMHOw/n8/riBBbuzuTHbWn8tD2NyzsEM/GyGNoGe9q7zBPYbDZWJmTzysJ4tqXmA+Dh7MDf+rfkzn7RuDs1vr8K+Lk78cCQWO4Z2JJ529P5aFUSu9IKmLk+mZnrk+kf68f4vtEMjPO/4GsqioiIiIhc7BrfvxBEREQasQ6hXrw/rju70vJ5c0kiP+/MYN6OdObtSGdE+0AmXRZLh1Ave5cJwIaDuby0IJ71SbkAuJhN3Nk3ir8NaIm3a+Of0uvkYOLaS8K4pmsoGw4e5eNVSSzcncHKhGxWJmTT0s+NO/tGce0lYbg1wtBTRERERKQp0t+sRUREzkH7EC/e+Us34jMKeWNJAvN2pLNgVyYLdmUytG0ADwyJpVOYt11q23k4n5cXxrMs/ggAjiYjt14awf2DYvD3cLJLTefDYDDQM9qHntE+pOSW8Nmag3y1PoUD2cX8c+4uXloQzy09IxjXJ4pQbxd7lysiIiIi0qQpLBQRETkPrYM8eHPsJTyYWcibSxP5cVsav+7J4tc9WQxu7c8DQ2LpGtGiQWpJyCzk1UX7+HlnBlC9eciN3cOYdFksIc0kRAv3ceX/rmjHg0Pj+H5TKp+sTuJgTgnvrTjAh6uSGNE+kPF9o+kW2QKDQVOURURERETqSmGhiIjIBRAb6MG0m7vywJBY3lqayJwth1kaf4Sl8UfoH+vHQ0Nj6RbpUy+vfSinmGm/JjB762FsNjAY4OrOITw0NI4oP7d6eU17c3dy4PY+Udx2aSRL47P4ZPVBViVmM39HBvN3ZNApzIvxfaO5vGNwg+/wLCIiIiLSlCksFBERuYBa+bvz6o1deOCy6tBw1pbDNWvs9Y3x5YHLYunV0veCvFZ6fimvL07k240pVFptAIxoH8jkYa1pHXRx7BhsNBoY0jaQIW0D2ZtRwPTVB5m15TDbU/N56Out/Gf+Hsb1juSWnhH4uje9KdgiIiIiIg1NYaGIiEg9iPJz46UbOjPpsljeXpbId5tSWZ2Yw+rEHHpF+/Dg0Fh6t/Q9p6my2UXlvL10P1+sO0RFpRWAAXH+PDo8zm7rJDYGbYI8+e91nXhsRGtmrk/mszWHyCos5+WF+3h9SSLXdAnlzn5RtAlqfLtWi4iIiIg0FgoLRURE6lGEryv/va4TEy+L4Z1l+/lmYwrrknIZ+8E6ekS14IEhsfSL8Tur0DC/xML7K/fzyeqDlFRUAdAzyodHR7SmZ3T9THFuinzdnZh4WSx/G9CKn3em89GqJLan5vP1xhS+3pjCwDh/nr+2Y7NZx1FERERE5EJSWCgiItIAwlq48u9rOjJhcAzvLt/PV+tT2HDwKLd9tJ5LIrx5YEgsA+P8TxoaFpdX8snqJN5fcYCCskoAOoV58cjw1gyIPbug8WLk6GDk6i6hXNU5hM3JR/l41UF+3pnO8n1HuOL1lbx6UxcGtw6wd5kiIiIiIo1KnVf8XrFiBaNHjyYkJASDwcCcOXPOeM6XX35J586dcXV1JTg4mPHjx5OTk3Mu9YqIiDRpId4uPHt1B1Y8Ppg7+0bh5GBkc3Ied3yygTFvrWbxnkxstur1B8ssVXy48gADXlzKywv3UVBWSetAD967rRtzJ/Q9ZbgotRkMBrpF+vDWrZew+JFBdAj15GiJhTs/2cCLv+ylsspq7xJFRERERBqNOoeFxcXFdO7cmbfeeuusHr969WrGjRvHXXfdxa5du/j2229Zv349f/3rX+tcrIiISHMR5OXMM6Pbs/Lvg7m7XzTOZiPbUvO569ONjH5zFW8sTmDQS8v417w95BRXEOXryrSbuzD/wf6MaB+kkPAcRfu58d29fbjt0kgA3l62n7EfriOzoMzOlYmIiIiINA51noY8atQoRo0addaPX7NmDVFRUTzwwAMAREdHc8899/DCCy/U9aVFRESanQAPZ566sh33DmrFBysP8PmaQ+w8XMDOwwUAhHg588CQWK7rFobZVOf/45OTcDabeG5MB3pG+/DErB2sT8rl8mkrmXZzV/rF+tm7PBERERERu6r3NQt79+7Nk08+yfz58xk1ahRZWVl89913XH755ac8p7y8nPLy8prbBQXV/2CyWCxYLJb6LrnBHb+m5nhtIo2Bxpg0BV5ORh4dGsP43hF88tshViXmMKZLMDd3D8PJbAJrFRZrlb3LPKmmOsZGtvOndUAvHvhqG3szi7jt43VMHNSSCYNaYTKqc1Maj6Y6xkSaAo0vkfqlMda4nO33wWA7vjDSOTAYDMyePZsxY8ac9nHffvst48ePp6ysjMrKSkaPHs3333+P2Ww+6eOnTJnC1KlTTzg+Y8YMXF1dz7VcERERkRNUVMGsg0bWZFV3bsZ5Wbktxoqno50LExERERG5gEpKShg7diz5+fl4enqe8nH1Hhbu3r2boUOH8vDDDzNixAjS09N57LHH6NGjBx999NFJzzlZZ2F4eDjZ2dmnvZimymKxsGjRIoYNG3bKAFVEzp3GmEj9ai5jbO7WNP75w25KLVb83R35342d6BXtY++yRJrNGBNpjDS+ROqXxljjUlBQgJ+f3xnDwnqfhvz888/Tt29fHnvsMQA6deqEm5sb/fv351//+hfBwcEnnOPk5ISTk9MJx81mc7P+4Wru1ydibxpjIvWrqY+x63tE0jnCh/u/3ExCVhHjPtnII8Nbc9/AVhg1LVkagaY+xkQaM40vkfqlMdY4nO33oN5XSi8pKcForP0yJpMJgPNoahQRERG54GIDPZg7sS/XXRKG1QYvLYjnzukbyC2usHdpIiIiIiINos5hYVFREVu3bmXr1q0AJCUlsXXrVpKTkwF44oknGDduXM3jR48ezaxZs3jnnXc4cOAAq1ev5oEHHqBnz56EhIRcmKsQERERuUBcHR145cbOvHh9J5wcjCzfd4TLp61k48Fce5cmIiIiIlLv6hwWbty4ka5du9K1a1cAJk+eTNeuXXn66acBSE9PrwkOAe644w5effVV3nzzTTp06MANN9xA69atmTVr1gW6BBEREZEL78bu4cyd2JeW/m5kFJRx0/treW/5fqxWzYwQERERkearzmsWDho06LTTh6dPn37CsUmTJjFp0qS6vpSIiIiIXbUJ8uSHif34v9k7mLs1jed/3sv6pFxeubEz3q7aLllEREREmp96X7NQREREpClzd3LgtZu68O9rOuDoYGTx3iyueH0VW5KP2rs0EREREZELTmGhiIiIyBkYDAZu7RXJrPv6EOnryuG8Um58bw0frUrShm0iIiIi0qwoLBQRERE5Sx1CvfhxUj8u7xiEpcrGcz/t5t4vNpFfarF3aSIiIiIiF4TCQhEREZE68HQ289bYS5gyuh1mk4EFuzK58o2V7EjNt3dpIiIiIiLnTWGhiIiISB0ZDAbu6BvNd/f2IayFCym5pVz3zm98vuagpiWLiIiISJOmsFBERETkHHUO92bepP4MaxdIRZWVf87dxaSZWygs07RkEREREWmaFBaKiIiInAcvVzPv39aNp65oi4PRwE/b07nqzdXsTiuwd2kiIiIiInWmsFBERETkPBkMBu7u35Kv7+lNiJczSdnFXPP2amauT9a0ZBERERFpUhQWioiIiFwg3SJbMO+B/gxu7U95pZUnZu1g8jfbKC6vtHdpIiIiIiJnRWGhiIiIyAXUws2Rj27vweMjW2MyGpi95TBXvbmKfZmF9i5NREREROSMFBaKiIiIXGBGo4H7B8Uw4+5eBHg4sf9IMVe9uYrvNqXauzQRERERkdNSWCgiIiJST3q19GX+g/3pH+tHmcXKo99u4/HvtlFaUWXv0kRERERETkphoYiIiEg98nN3YvqdPZk8LA6DAb7ZmMqYt1az/0iRvUsTERERETmBwkIRERGRemYyGnhgSCxf3tULP3cn4jMLGf3GKuZuPWzv0kREREREalFYKCIiItJA+sT4Mf/Bflza0oeSiioe/GorT87eQZlF05JFREREpHFQWCgiIiLSgAI8nPny7kt54LIYDAaYsS6Za9/+jYPZxfYuTUREREREYaGIiIhIQzMZDUwe3prpd/bEx82R3ekFXPnGKubvSLd3aSIiIiJykVNYKCIiImInA+P8mfdAP3pEtaCovJL7v9zMM3N3Ul6packiIiIiYh8KC0VERETsKNjLhRl/vZR7BrYE4NM1h7jh3TWk5JbYuTIRERERuRg52LsAERERkYud2WTkiVFt6Rnlw+RvtrE9NZ8rXl/Ji9d3pn+sn73LOysGA7iYTRgMBnuXIiIiIiLnQWGhiIiISCMxpG0g8x/sz8QZm9mSnMe9X2yyd0l1EurtwpiuIVzTNYyYAHd7lyMiIiIi50DTkEVEREQakVBvF77+W2/u7heN2dS0uvQO55Xy1tL9DH11OVe9uYpPVieRXVRu77JEREREpA7UWSgiIiLSyDg6GHnqynY8PrINVpvN3uWclYoqK8vjjzB7y2GW7zvC9tR8tqfm8695exgY58+YrqEMbxeIs9lk71JFRERE5DQUFoqIiIg0Uo4OTWcSiLPZxOjOIYzuHEJ2UTk/bktj9pbDbE/NZ8neLJbszcLdyYFRHYK4pmsol7b0xWhsWp2TIiIiIheDOv8NdMWKFYwePZqQkBAMBgNz5sw54znl5eX83//9H5GRkTg5OREVFcXHH398LvWKiIiISCPn5+7EnX2j+WFiP36dPJCJg2MI9XahqLySbzelMvbDdfR9YQn//Xkv+zIL7V2uiIiIiPxBnTsLi4uL6dy5M+PHj+faa689q3NuvPFGMjMz+eijj4iJiSE9PR2r1VrnYkVERESkaYkJcOfREa2ZPCyODQdzmbP1MD9tTyc9v4x3l+/n3eX7aRfsybWXhHJV5xACPJ3tXbKIiIjIRa3OYeGoUaMYNWrUWT/+l19+Yfny5Rw4cAAfHx8AoqKi6vqyIiIiItKEGY0GerX0pVdLX54Z3Z4le7OYtfkwy+Kz2J1ewO55Bfxn/h76xfpzTdcQRrQPwtVRK+aIiIiINLR6/xvYDz/8QPfu3XnxxRf5/PPPcXNz46qrruK5557DxcXlpOeUl5dTXv77znkFBQUAWCwWLBZLfZfc4I5fU3O8NpHGQGNMpH5pjEldmYBhbfwY1saP3OIKft6ZwZxt6WxNyWfFviOs2HcEV8edDG8bwNVdQujd0gfTRby+ocaYSP3R+BKpXxpjjcvZfh8MNtu5b7FnMBiYPXs2Y8aMOeVjRo4cybJlyxg6dChPP/002dnZ3H///QwePJhPPvnkpOdMmTKFqVOnnnB8xowZuLq6nmu5IiIiItKIHSmFjdlGNhwxkFP+ezjoabbRzc9GD38roW52LFBERESkCSspKWHs2LHk5+fj6el5ysfVe1g4fPhwVq5cSUZGBl5eXgDMmjWL66+/nuLi4pN2F56sszA8PJzs7OzTXkxTZbFYWLRoEcOGDcNsNtu7HJFmR2NMpH5pjMmFZrPZ2JKSz9xtaczfkUle6e//C9460J2ruwQzulMwQRfJ+oYaYyL1R+NLpH5pjDUuBQUF+Pn5nTEsrPdpyMHBwYSGhtYEhQBt27bFZrORmppKbGzsCec4OTnh5OR0wnGz2dysf7ia+/WJ2JvGmEj90hiTC6lXK396tfJnylVWlsZnMXvzYZbszSI+s4gXFyTw0sIE+rTy5ZquYYzsEIS7U/Nf31BjTKT+aHyJ1C+NscbhbL8H9f63qr59+/Ltt99SVFSEu7s7APv27cNoNBIWFlbfLy8iIiIiTZijg5ER7YMY0T6I/BIL83akM3tLKhsOHmV1Yg6rE3N4as4OhrcL4ppLQukf44eDyWjvskVERESarDqHhUVFRSQmJtbcTkpKYuvWrfj4+BAREcETTzzB4cOH+eyzzwAYO3Yszz33HHfeeSdTp04lOzubxx57jPHjx59ygxMRERERkT/zcjUztlcEY3tFkJJbwpwth5m95TAHsov5YVsaP2xLw8/dias6h3BN11A6hHpiMFy8G6OIiIiInIs6h4UbN25k8ODBNbcnT54MwO2338706dNJT08nOTm55n53d3cWLVrEpEmT6N69O76+vtx4443861//ugDli4iIiMjFKNzHlUlDYpl4WQzbUvOZs+UwP2xLI7uonI9XJ/Hx6iRiAty5pmsoY7qGEuqt/6QWERERORt1DgsHDRrE6fZEmT59+gnH2rRpw6JFi+r6UiIiIiIip2UwGOgS7k2XcG/+74q2rNh3hFlbDrNodyaJWUW8tCCelxbE0yvah2svCWVUx2A8nbVmkoClysrR4goCLpKNckRERM5W818JWkREREQuCmaTkSFtAxnSNpCCMgu/7Mhg1pZU1h7IZV1S9cfTc3cxtF0gV3YMpmOYF6HeLpqqfBFavu8Iz8zdycGcEga19udvA1rSu6WvfhZERERQWCgiIiIizZCns5kbe4RzY49wDueV1qxvmJhVxLzt6czbnn7scQ60Cfak3bGPtsGexAa642w22fkKpD4czivluR9388uujJpjy+KPsCz+CJ3CvLhnQCtGdgjCZFRoKCIiFy+FhSIiIiLSrIV6uzBhcAz3D2rFrrQCZm0+zG/7s0nMKqKgrJL1SbmsT8qtebzJaKClnxttj4WHbYM9aBfsib+HkzrPmqiKSisfrjrAG4sTKbVUYTIauKNPFNdeEspX61P4ZmMK21PzmTBjM5G+rtzdvyU3dAtTaCwiIhclhYUiIiIiclEwGAx0CPWiQ6gXAOWVVSRmFbEnvZA96QU1H0dLLCRkFZGQVcQP29Jqzvd1c6wJD9sGe9IuxJNW/u6YTUZ7XZKchVUJ2Tz9w04OHCkGoGeUD8+OaU+bIE8AnhvjxYNDY/lszSE+W3OQQzkl/HPOTl5btI/b+0Rx26WRtHBztOcliIiINCiFhSIiIiJyUXJyMNE+xIv2IV41x2w2G5kF5exJL2D3sY896QUczC4mp7iCVYnZrErMrnm8o8lITIB7rQ7EtsGeCpcagfT8Uv41b0/NlHM/d0eevLwt13QNPaFD1M/dicnD4rh3YEu+2ZDCByuTOJxXyquL9vHOsv3c1COcu/pFE+7jao9LERERaVAKC0VEREREjjEYDAR5ORPk5czgNgE1x0srqojPrN2BuDe9kMLyyppQ8Y+CPJ1rOhCPf0T7uWktvAZgqbLy8aokpi1OoKSiCqMBxvWO4uFhcXi5nH4nbFdHB+7oG81fLo1k/s4M3lu+n11pBUz/7SCfrz3EFR2D+duAljXdqSIiIs2RwkIRERERkTNwcTTRJdybLuHeNcdsNhupR0trug+rPwpJzi0ho6CMjIIylsYfqXm8s9lI68DfpzC3DfakTZAHHs6nD7Dk7P22P5tn5u4iIasIgEsivHluTIda3aNnw8Fk5KrOIYzuFMzqxBzeW7GflQnZ/LAtjR+2pdE/1o97BrSib4x2UBYRkeZHYaGIiIiIyDkwGAyE+7gS7uPKiPZBNccLyyzszfi9C3F3eiHxGQWUWaxsS81nW2p+recJ93GhbdDvHYjtgj0J93FRCFUHmQVl/Hvenpo1Jn3cHPnHqDZcf0kYxvPo5jQYDPSL9aNfrB87D+fz/ooDzNuRzsqEbFYmZNM+xJO/DWjJFR2DcdDalSIi0kwoLBQRERERuYA8nM30iPKhR5RPzbEqq42DOcW1OhD3pBeQnl9GSm4pKbmlLNydWfN4dycH2gRVdyG2DnTDVmGPK2n8LFVWPv3tIK/9mkBReSUGA/ylVySPDm+Nl+uF7djsEOrF67d05bERrfloVRJfb0hhV1oBD361lZcWxHN3v2hu7BGOq6P+iSUiIk2b3slEREREROqZyWiglb87rfzdubJTSM3xo8UV7Mn4PTzcnVZAYlYRReWVbDx0lI2HjgJgNJhYVbqVWy+Nol+M33l1yzUX65NyeXruTvZmFALQOdybf13dgY5h9bueYLiPK1Ouas+DQ2L5fO0hpv92kNSjpUz5cTevLU5gXO8obu8dia+7U73WISIiUl8UFoqIiIiI2EkLN0f6tPKjTyu/mmOWKiv7jxTVdCCuPZDN9tQCFuzOYsHuLMJ9XLi5RwQ3dA8jwMPZjtXbx5HCcp6fv4dZWw4D0MLVzN9HtuHG7uENGqK2cHPkgSGx/LV/S77bnMoHKw6QnFvC64sTeG/5fm7sHs7d/aOJ9HVrsJpEREQuBIWFIiIiIiKNiNlkpE2QJ22CPLmmK1gsFj74dj7pLtHM2ZZOSm4pLy2I53+L9jG0bSBje0VcFN2GlVVWvlh7iFcW7qPw2JTjm3tE8PiI1rRwc7RbXS6OJm67NJKxPSP4ZWcG763Yz/bUfD5fe4gv1x1iVIdg7hnYkk5h3narUUREpC4UFoqIiIiINHKhbvDXy9vy5BXt+Wl7GjPXJ7M5OY9fdmXwy66MZt9tuOlQLk/N2cWe9AIAOoV58ezVHWrtTm1vJqOBKzoFc3nHINYeyOW9FftZFn+EeTvSmbcjnd4tfblnYEsGxvlr8xoREWnUFBaKiIiIiDQRLo4mbugezg3dw9mbUcDMdcnM2nK42XYbZheV88LPe/l2UyoAXi5mHhvRmlt6RmBqpNdmMBjo3cqX3q182ZNewAcrDvDDtjTWHMhhzYEc2gR5cM/AllzZKQSzdlAWEZFGSGGhiIiIiEgT1CbIk6lXd+Afo9oyb0c6M9YdajbdhlVWGzPWJ/PSL3spKKsE4Kbu4Tw+snWT2jikbbAnr97UhUdGtObjVUnMXJ/M3oxCHv56Gy/9Es9d/Vtyc49w3Jz0zzIREWk89K4kIiIiItKEuTiauL5bGNd3Czttt+EtvSLo3wS6DbckH+Wfc3ey83D1lOP2IZ48e3UHukW2sHNl5y7U24V/XtmOBy6L5Yt1h/hk9UHS8st47qfdTPt1H7f1juSOPtH4ezSdIFRERJovhYUiIiIiIs3En7sNZ65PZtOhozXdhmEtXLilZ+PsNswtruClBXv5akMKNht4ODvw2IjW3NorstFOOa4rL1czEwbHcFe/aGZvOcwHKw5wILuYt5bu54OVSVx3SRh/7R9NS393e5cqIiIXMYWFIiIiIiLNzJ+7Db9an8L3m1NJPdr4ug2tVhtfbUjhxQV7ySuxAHDdJWH8Y1SbZttp52w2cUvPCG7sHs6i3Zm8t2I/W5LzmLk+ma82JDOiXRD3DGxJ14im200pIiJNl8JCEREREZFmrE2QJ1Ouas/fR7Y5fbdhtzACPBu223B7ah7/nLOTban5x2r14LkxHegR5dOgddiLyWhgZIcgRrQPZOOho7y3fD+/7smq+d70jPbhngEtGdw6oNFPHxf5swW7MjhaXMGYrqE4m032LkdE6kBhoYiIiIjIReCP3YbxGYXMXJ9st27DvJIKXloQz4z1ydhs4O7kwORhcYzrHYnDRbhDsMFgoEeUDz2ifEjILOT9FQeYs/Uw65NyWZ+US2yAO38b0JIxXUO1g7I0ehWVVp79aRdfrE0GYNriBB4cEst13cL08yvSRCgsFBERERG5yLQO8rBLt6HVauO7Tan895e95BZXAHBN11CeGNWmwbsaG6vYQA9euqEzjwxvzSerk/hyXTIJWUU89t12Pl1zkGk3d6WV1jSURiqrsIwJX25mw8GjGAzg6+ZEen4Z/5i1g3eX7+fhYXGM7hSiTlmRRk5hoYiIiIjIRepk3Yaz6qnbcOfhfJ6eu5PNyXkAxAW68+zVHbi0pe8FuprmJcjLmScub8uEy2KYuS6Zd5bvZ+fhAq58fRVTrmrHjd3DMRgUuEjjsSX5KPd9sZmMgjI8nByYdksX+rTy48t1yby9NJGDOSU8+NVW3lm2n0eHt2ZI2wD9DIs0UgoLRURERESkVrfh/B3pzLhA3Yb5pRZeXRjP52sPYbWBm6OJh4fFcXufKE1JPAuezmbuGdiKMV1DmfzNVlYn5vD373ewfN8Rnr+mE16uZnuXKMI3G1J4as5OKqqsxAS48/5t3Wp29b6rXzQ39wjnk9VJvLfiAHszCrn7s410Cffm8RGt6RPjZ+fqReTPFBaKiIiIiEgNF0cT13UL47pTdBu+umgfQ9sGMLZX5Gm7DW02G7M2H+b5n/eQXVQ95Xh05xCeuqItgZpyXGeBns58Pr4XH6w8wEsL4pm/I4MtyXn876Yu6s4Uu/nz+oQj2gfyyo1dcHeqHTW4OTkw8bJY/nJpJO+vOMAnqw+yNSWPsR+uo08rXx4d0ZpLtPu3SKNR5//KW7FiBaNHjyYkJASDwcCcOXPO+tzVq1fj4OBAly5d6vqyIiIiIiLSwI53G67/v6G8ckNnuke2oMpqY8GuTG7/eD0DXlrKm0sSyCooq3XenvQCbnxvDY98u43sogpa+bsx4+5evHFLVwWF58FoNHDPwFbMur8PUb6upOeXccsHa3llYTyWKqu9y5OLTFZhGbd+uJYv1iZjMMAjw+J459ZuJwSFf+Tt6sjjI9uw/PFB3NEnCrPJwG/7c7j27d+4+9ON7EkvaMArEJFTqXNnYXFxMZ07d2b8+PFce+21Z31eXl4e48aNY8iQIWRmZtb1ZUVERERExE6czb93G+7LLGTGut+7DV9euI///ZrA0LYB3Ng9nNWJOXy65iBVVhuujiYeGBLL+L7RODpoyvGF0inMm3kP9Gfqj7v4ZmMqbyxJZFViNtNu6kqEr6u9y5OLwMnWJ7ysTeBZnx/g4cyUq9pzd/9oXl+cwHebUvl1TyaL92YyulMIDw+LI9rPrR6vQEROp85h4ahRoxg1alSdX+jee+9l7NixmEymOnUjioiIiIhI4xEXWN1t+I9Rx9Y2XJfMxkNHWbArkwW7fm8KuLxjEE9d0Y4Qbxc7Vtt8uTk58OL1nRkQ588Ts3awJTmPy19fyXNj2nNN1zB7lyfN2OnWJ6yrsBauvHh9Z+4Z2Ir/LdrHT9vT+WFbGvN2pHNDtzAeGBKr3yEidtAgaxZ+8sknHDhwgC+++IJ//etfZ3x8eXk55eXlNbcLCqpbkS0WCxaLpd7qtJfj19Qcr02kMdAYE6lfGmMi9auxjjETMLpjIKM7BpKQWcTXm1L5cXs6/u5O/H1kHP2PbVrQ2Opubka09afDhN48+t0ONh7K4+Gvt7F0TxZTRrfFw1lL1J9JYx1fjVFFpZV//7yXGetTARjWNoAXr+uAu5PDef/5RXg78b8bOvLXfpH879dElu3L5qsNKXy/OZVbe4Zz74BofN2dLsRlSAPTGGtczvb7YLDZbLZzfRGDwcDs2bMZM2bMKR+TkJBAv379WLlyJXFxcUyZMoU5c+awdevWU54zZcoUpk6desLxGTNm4OqqtnoREREREZE/qrLBr4cN/JJixIoBXycb42KriPKwd2XSHBRUwCf7TBwoNGDAxqhwK8NCbZxif6PzllQIPyWbSCyofgFHo41BwTYGh1hxVQYucs5KSkoYO3Ys+fn5eHp6nvJx9TrMqqqqGDt2LFOnTiUuLu6sz3viiSeYPHlyze2CggLCw8MZPnz4aS+mqbJYLCxatIhhw4ZhNpvtXY5Is6MxJlK/NMZE6pfGmJyt0cDm5Dwe+XY7qXllvL7bzKTBrbh3QDSm+kp1mjiNrzPbmpLHf77aRmZhOe5ODrx6Q0cGt/av99e932Zj9f5cXv01gR2HC1h42MDaHEf+2i+Kcb0jcHVUatgUNLUxtju9gDaBHhib6e/M4zN3z6ReR1dhYSEbN25ky5YtTJw4EQCr1YrNZsPBwYGFCxdy2WWXnXCek5MTTk4nthibzeYm8cN1rpr79YnYm8aYSP3SGBOpXxpjcjZ6tfJn/kMDeGr2Tn7YlsZrixP57UAu/7upC6Fa++2UNL5O7kKuT3guBrcNYlCbQBbuzuSVhfHsyyzilV8T+XRtChMHt+KWXhE4OZgarB45d419jB0pLOfFX/by7aZUXriuIzf1iLB3SfXibL8H9RoWenp6smPHjlrH3n77bZYsWcJ3331HdHR0fb68iIiIiIjIRcfT2cy0m7swqLU//5yzk/VJuYx6bQX/va4Tl3cMtnd50gRUVFp59qddfLE2GYAR7QN55cYuuDs1fDefwWBgRPsghrYN5Idth/nfogSSc0uY8uNuPliZxINDYrn2klAcTNpxXerOUmXl098OMu3XBArLKwFIyCyyc1X2V+eRXlRURGJiYs3tpKQktm7dio+PDxERETzxxBMcPnyYzz77DKPRSIcOHWqdHxAQgLOz8wnHRURERERE5MIwGAxce0kY3SJb8MBXW9mWksf9X27mpu7hPHNVO03hlFPKKixjwpeb2XDwKAYDTB4ax4TBMXaflmkyGrimaxhXdgrhm40pvLE4kcN5pTz+/XbeXb6fh4fFcUXHYLvXKU3HyoQjTP1xN4lZ1eFgpzAvplzVnksiWti5Mvur8zvExo0bGTx4cM3t42sL3n777UyfPp309HSSk5MvXIUiIiIiIiJyTiJ93fju3t689us+3l62n683prDhYC7Tbu5KxzAve5cnjcyW5KPc98VmMgrK8HByYNotXbisTaC9y6rFbDJya69IrrskjC/WHuKtpYkcyC5m0swtvL1sP4+NiGNw6wAMBoWGcnIpuSX8a95uFuzKBMDXzZHHR7bmhm7hCpuPqXNYOGjQIE63gfL06dNPe/6UKVOYMmVKXV9WREREREREzoHZZOSxEW3oF+PPw19v5UB2Mde+s5rHRrTm7n4t9Y9jAey/PmFdOZtN3N2/JTf1COfjVQf5cOUB9qQXMH76Ri6J8OaxEW3o3crX3mVKI1JaUcU7yxJ5d8UBKiqtmIwGxvWO5KGhcXi5NN71FO1Bk/pFREREREQuAr1b+fLLQ/0Z2T4IS5WN/8zfy7iP15NVUGbv0sSOKiqtPDVnB49/v52KKisj2gcyZ0LfRh0U/pGHs5kHh8ay4vHB3DOwJc5mI5uT87jlg7Xc9tE6tqXk2btEsTObzca87ekMeWUZry9JpKLSSp9Wvvz8YH+eGd1eQeFJKCwUERERERG5SHi7OvLOXy7h+Ws74mw2sioxm5HTVvLr7kx7lyZ2kFVYxq0fruWLtckYDPDIsDjeubWbXTYyOV8t3Bx5YlRbVjw2mHG9IzGbDKxMyObqt1bzt882Ep9RaO8SxQ72ZhRwywdrmTBjM2n5ZYR6u/DuXy7hy7t7ERfoYe/yGq2m9xtAREREREREzpnBYOCWnhH0iPLhgZlb2J1ewN2fbWRc70ievLwtzmaTvUuUBtAU1ic8FwGezjx7dQf+2r8l0xYnMGtzKgt3Z7JoTyZXdw7h4WFxRPq62btMqWd5JRX8b9E+Pl97CKsNnByM3DeoFfcMaIWLo37HnYk6C0VERERERC5CMQHuzJ7Qh7v7RQPw2ZpDXPXmKvZmFNi5Mqlv32xI4ab31pJRUEZMgDtzJ/ZtFkHhH4X7uPLyDZ1Z+PAALu8YhM0Gc7amMeSV5Tw5ewfp+aX2LlHqQZXVxox1yQx+eRmfrqkOCkd1CGLxIwN5aGicgsKzpM5CERERERGRi5STg4mnrmxH/zh/HvlmG/syi7jqzdX83+VtGdc7UjvKNjMVlVae/WkXX6xNBmBE+0BeubFLk5x2fLZiAjx4+9Zu7Dycz8sL41kWf4QZ65L5blMq4y6N5L5BrfB1d7J3mXIBbDyYyzM/7GJXWvV/eMQGuDPlqvb0jfGzc2VNjzoLRURERERELnID4/z55aH+DG7tT0WllWd+2MVdn24ku6jc3qXJBdKc1ic8Fx1CvZh+Z0++vbc3PaN8qKi08uGqJAa8uJRXF8ZTUGaxd4lyjjILynj4661c/+4adqUV4OHswNNXtmP+g/0VFJ4jhYUiIiIiIiKCn7sTH9/Rgymj2+HoYGTJ3ixGvraS5fuO2Ls0OU9bko9y1Rur2XDwKB5ODnx0e3cmDYnFaLz4Okd7RPnw9T2X8un4nnQM9aK4oorXlyQy4MWlLNiVYe/ypA7KK6t4Z9l+Br+8jNlbDmMwwM09wln66CDG94vGbFLkda4ujv9CEBERERERkTMyGAzc0TeaXi19eWDmFhKyirj94/Xc3S+ax0a2xslB6301Nd9sSOGpOTupqLISE+DO+7d1o6W/u73LsiuDwcDAOH8GxPqxYFcGLy/cR2JWEfd+sYl/jGzD3wa01BT8Rm7p3iye/Wk3SdnFAHSN8GbK6PZ0Dve2b2HNhGJWERERERERqaVtsCc/TurHuN6RAHy4Kolr3vqNxKwiO1cmZ6ui0spTc3bw+PfbqaiyMqJ9IHMm9L3og8I/MhgMjOwQzC8P9ucvl0Zgs8HzP+/l799vp6LSau/y5CQOZhczfvoG7py+gaTsYvzcnXjlhs58f28fBYUXkDoLRURERERE5ATOZhPPXt2B/rH+PP7dNnanF3DlGyt5ZnR7bu4Rrs6rRiyrsIwJX25mw8GjGAwweWgcEwbHXJTTjs+Gg8nIc1d3IMbfnWd/2s03G1NJzi3h3b90w9vV0d7lCVBcXsmbSxP5aGUSFVVWHIwGxveLZtJlMXg4m+1dXrOjsFBEREREREROaVi7QH55aACTv9nK6sQcnpi1g+XxR/jvdR2bVJBiqbKSlldKcm4JKbnVnw9lF7E/1chG6x7ah3rTNtiT1kEeOJub7nTrLclHue+LzWQUlOHh5MC0W7pwWZtAe5fV6B2fgh/p68akmVtYeyCXa97+jY9u765uTDuy2Wz8sC2N/8zfQ2ZB9YZLA+L8efrKdsQE6PtSXxQWioiIiIiIyGkFejrz+fhefLDyAC8vjOeXXRlsTcnjfzd1oXcrX3uXB1SHCrnFFSTnlpCcW0Lq0VKSc0pqbqfnl2K1nexMI/vWpQAp1bcMEOXnRttgT9oFe9I22IM2QZ4Eezk3+m5KrU94/ga3CeC7+3pz1/SNJGUXc83bv/HOXy6hTyvtqtvQdh7OZ8oPu9h46CgAET6u/PPKdgxtG9Dox2JTp7BQREREREREzshoNHDPwFb0aeXHA19tISm7mLEfruX+Qa14aGhcg+w8WmapIvXosQAwp4SUo8c7BauPlVRUnfZ8JwcjET6uhPu4EuHjSoiXE0n7duMa1JL4zGL2pBeQU1zBgSPFHDhSzLzt6TXnermYa4LD6hDRk9hA90bRhVhRaeXZn3bxxdpkAEa0D+SVG7vg7qR/8p+LNkGezJnQl799vpEtyXmM+2g9/xrTgZt7Rti7tItCbnEFLy+MZ+b6ZGw2cDGbmHhZDHf1i24U4+1ioN8cIiIiIiIictY6hnnx06R+PPvjbr7emMJbS/ezKjGH12/uQqSv23k9t9VqI7OwrGaacHJuCam5v3cHZhWWn/Z8gwGCPJ0J93ElvEV1IBjh61IdELZwxd/DqVZHksViYX7eLi4f2Rqz2YzNZuNIYTl7MgrZk15Q87H/SDH5pRbWHshl7YHcmvNNRgPRx7oQ2wZ7VH8O8iTQ06nBOp+0PmH98PdwYuZfL+Wx77bz47Y0/jFrBweyi/n7yDaY9GdbLyqrrMxYn8wrC/eRX2oBYHTnEJ4Y1YYQbxc7V3dxUVgoIiIiIiIideLm5MAL13diQJw/T8zazraUPC6ftpLnxnTgmq6hpw3KCsssNesGHu8ITDn6+9ThM+1C6+HkUNMZGOHrSngLl5rboS1ccHI4984jg8FAgKczAZ7ODIzzrzleXllFQmYRe9IL2PuHIPFoiYXErCISs4r4cdvvz9PC1UzbYE/aBP0eIsYGup9XbSej9Qnrl7PZxOs3d6GVvxuv/ZrA+ysOcOBIMdNu7oKbujYvqLUHcpjywy72ZhQC0CbIg6lXtadXy8axzMHFRj/dIiIiIiIick6u6BRMlwhvHv5qK+sP5jL5m20siz/CA0NiyCwor+kI/GOH4NESy2mf08FoIMTbpdZ04XCf6tsRPq54uZgbfL0yJwcTHUK96BDqVXPMZrORWVDOnozjHYjVIeKBI0UcLbHw2/4cftufU/N4k9FAK//jXYietAnyoF2w5wndjmdL6xM2DIPBwEND44j2c+Ox77bz655Mbnh3DR/d0Z1gL3W7na+0vFL+M38PPx2b8u/lYubR4XHc0jMChwZY2kBOTmGhiIiIiIiInLNQbxdm/u1S3l6ayGuLE/hhWxo/bEs77Tm+bo6EHe8O9Pl9mnC4jyvBXs5NIiQwGAwEeTkT5OXM4NYBNcfLLL93Ie5OL2BvRnWQmF9qYV9mEfsyi5i79fc/H183x5rw8HiQGBPgjqPDyf8MtD6hfVzdJZSwFq7c8/lGdqcXcPWbq/nw9u50CvO2d2lNUpmlig9XHuCtpfsptVRhMMDYnhE8Orw1Ldyazi7rzZV+m4iIiIiIiMh5MRkNTBoSS58YP/7x/XaSc0t+7wr8wzTh8GMfzTnYcjab6BjmRcew2l2I6fllNdOYdx+bxnwwu5ic4gpWJWazKjG75vEORgMxAe41ayFWT2f2xIZN6xPaUbfIFsy+vy93f7qR+MxCbnxvDa/e2IXLOwbbu7Qmw2azsWh3Js/N201KbikAPaJa8Mzo9rU6d8W+mu9vaBEREREREWlQ3SJbsGjyQGw2W4NPFW7MDIbqqdUh3i4Mafv7moKlFVXsy/zDZirH1kMsLKtkb0YhezMKmb3l9+dxMBqotNq0PqEdhfu48t19vZk0cwvL4o9w/5ebeWxEa+4f1Eo/82eQmFXEsz/tZsW+IwAEejrx5OVtuapziP7sGhmFhSIiIiIiInJB6R/+Z8fF0UTncG86h3vXHLPZbBzOK2VPeiF70wuOrYlYyMGcYiqtNq1P2Ah4OJv5cFx3/jVvD9N/O8hLC+I5cKSY/1zb4YJvYtMclFXCf3+J59M1yVRabTiajNzdP5oJg2O0UUwjpe+KiIiIiIiISCNhMBgIa+FKWAtXhrX7vXOwpKKS1KOlRPu5YW4Cazo2dw4mI1Ouak8rfzem/Lib7zenkpJbwru3dcNHa+4BUFll5dtNqTy/1USh5RAAQ9oE8M8r2xHl52bn6uR0FBaKiIiIiIiINHKujg7EBXrYuwz5k9t6RxHh68bELzez/mAu17y9mo9u70FMwMXb+VlltfHT9jRe+zWBpOxiwECUryvPjG7P4DYBZzxf7E//HSEiIiIiIiIico4Gxvkz6/4+hPu4cCinhGveXs2qhOwzn9jM2Gw2ftmZzqhpK3jwq60kZRfTwtXM1ZFV/DSxj4LCJkRhoYiIiIiIiIjIeYgN9GDO/X3pHtmCwrJKbv9kPV+uO2TvshqEzWZjyd5MrnxjFfd+sZl9mUV4Ojvw6PA4lkzuz2UhNpwcFD81JZqGLCIiIiIiIiJynnzdnfjyr734x/c7mL3lMP83eyf7s4r5vyvaYjI2v01/bDYbqxNzeGVRPFuS8wBwczRxV79o7urfEi8XMxaLxb5Fyjmpc7S7YsUKRo8eTUhI9dbWc+bMOe3jZ82axbBhw/D398fT05PevXuzYMGCc61XRERERERERKRRcnIw8eqNnXl0eBwAH69O4q+fbaSovNLOlV1Y65Nyufn9tfzlo3VsSc7D2WzknoEtWfn3y5g8vDVeLmZ7lyjnoc5hYXFxMZ07d+att946q8evWLGCYcOGMX/+fDZt2sTgwYMZPXo0W7ZsqXOxIiIiIiIiIiKNmcFgYOJlsbw19hKcHIws2ZvF9e/8xuG8UnuXdt62puRx20fruPG9NaxLysXRZOSOPlGseHwwT4xqq52gm4k6T0MeNWoUo0aNOuvHv/baa7Vu/+c//2Hu3Ln8+OOPdO3a9aTnlJeXU15eXnO7oKAAAIvF0ixbWI9fU3O8NpHGQGNMpH5pjInUL40xkfqj8SX1aXhbP768qwf3frmFvRmFXP3mKt4Z24Uu4d72Lq3O9qQXMm1JIov3HgHAwWjg+m6h3D+wJcFezsDJx5HGWONytt8Hg81ms53rixgMBmbPns2YMWPO+hyr1UpUVBSPP/44EydOPOljpkyZwtSpU084PmPGDFxdXc+1XBERERERERGRBpVbDh/sNZFWYsBssHFrjJWufuccxTSojBL4OdXI1pzqiakGbPTwtzEizIqfs52LkzorKSlh7Nix5Ofn4+npecrHNfgGJy+//DJFRUXceOONp3zME088weTJk2tuFxQUEB4ezvDhw097MU2VxWJh0aJFDBs2DLNZ8/pFLjSNMZH6pTEmUr80xkTqj8aXNJQx5ZVM/nY7S+OzmZ5gwiu8FRMGtcRgaJwbnxzKLeHNJfv5YXs61mO55hUdg3hgcCta+rud9fNojDUux2funkmDhoUzZsxg6tSpzJ07l4CAgFM+zsnJCScnpxOOm83mZv3D1dyvT8TeNMZE6pfGmEj90hgTqT8aX1LfWpjNfHh7T56fv4cPVyUxbcl+DuWW8t/rOuFsNtm7vBqH80p5Y3EC325KpepYSjiifSAPD4ujTdC5N29pjDUOZ/s9aLCw8KuvvuLuu+/m22+/ZejQoQ31siIiIiIiIiIidmcyGnjqyna09Hfn6bk7mbM1jZSjpbx3Wzf83E9smGpIWQVlvLU0kZnrU6iosgIwqLU/k4fF0SnM2661ScNrkLBw5syZjB8/nq+++oorrriiIV5SRERERERERKTRGdsrgkhfV+77YhObDh1lzFur+fiOHsQFejR4LTlF5by7fD+frTlEeWV1SNinlS+PDI+jW6RPg9cjjUOdw8KioiISExNrbiclJbF161Z8fHyIiIjgiSee4PDhw3z22WdA9dTj22+/nWnTptGrVy8yMjIAcHFxwcvL6wJdhoiIiIiIiIhI09A3xo9Z9/flrk83cCinhOve/o03b72EgXH+DfL6+SUW3l+5n09WH6SkogqAbpEteGRYHH1i/BqkBmm8jHU9YePGjXTt2pWuXbsCMHnyZLp27crTTz8NQHp6OsnJyTWPf//996msrGTChAkEBwfXfDz44IMX6BJERERERERERJqWmAB35tzfl57RPhSWV3LnJ+v5bM3Ben3NwjILry9OoN+LS3hr6X5KKqroGOrF9Dt78N29vRUUCnAOnYWDBg3CZjv1Ft/Tp0+vdXvZsmV1fQkRERERERERkWavhZsjX9zViydn7+C7Tak8PXcX+7OK+OeV7XAw1bm/65RKKir5bM0h3l2+n7wSCwBtgjyYPCyOYe0CG+2uzGIfDbobsoiIiIiIiIiI/M7RwchL13eilb87L/yyl0/XHOJgTglvjO2Kp/P57SBcZqli5vpk3lq6n+yicgBa+rvx8NA4rugYjNGokFBOpLBQRERERERERMSODAYD9w1qRbSfKw99vZXl+45w/Tu/8dHtPQj3ca3z81VUWvl2UwpvLkkkPb8MgHAfFx4aEsfVXUIuaNeiND8KC0VEREREREREGoGRHYL51tuVuz/bwL7MIsa8tZr3x3U7652JK6uszNmaxrTF+0jJLQUg2MuZSZfFckP3MMwKCeUsKCwUEREREREREWkkOoZ5MXdCP+76dAO70gq45YN1vHR9J67uEnrKc6xWGz/tSOe1Rfs4kF0MgJ+7ExMHt+LmnhE4m00NVb40AwoLRUREREREREQakSAvZ769tzcPfbWVhbszefCrrRw4UsxDQ2NrbUZis9lYsCuT/y3aR3xmIQAtXM3cN6gVt10ahYujQkKpO4WFIiIiIiIiIiKNjKujA+/+pRsvLNjLe8sPMG1xAgeyi3np+k44ORhZtu8Iry7cx47D+QB4ODvwt/4tubNfNO5Oinvk3OmnR0RERERERESkETIaDTwxqi2t/Nx5cvYOftyWRnJuCQ5GA5sOHQXAzdHE+H7R3N2vJV6u57d7sggoLBQRERERERERadRu7BFOuI8r9325iW0peQA4m43c3juKewa2wsfN0b4FSrOisFBEREREREREpJHr3cqX2ff3ZeqPu4j2c+O+ga0I8HS2d1nSDCksFBERERERERFpAqL93Jh+Z097lyHNnNHeBYiIiIiIiIiIiEjjoLBQREREREREREREAIWFIiIiIiIiIiIicozCQhEREREREREREQEUFoqIiIiIiIiIiMgxCgtFREREREREREQEUFgoIiIiIiIiIiIixzjYu4CzYbPZACgoKLBzJfXDYrFQUlJCQUEBZrPZ3uWINDsaYyL1S2NMpH5pjInUH40vkfqlMda4HM/Vjudsp9IkwsLCwkIAwsPD7VyJiIiIiIiIiIhI01VYWIiXl9cp7zfYzhQnNgJWq5W0tDQ8PDwwGAz2LueCKygoIDw8nJSUFDw9Pe1djkizozEmUr80xkTql8aYSP3R+BKpXxpjjYvNZqOwsJCQkBCMxlOvTNgkOguNRiNhYWH2LqPeeXp6avCI1CONMZH6pTEmUr80xkTqj8aXSP3SGGs8TtdReJw2OBERERERERERERFAYaGIiIiIiIiIiIgco7CwEXBycuKZZ57BycnJ3qWINEsaYyL1S2NMpH5pjInUH40vkfqlMdY0NYkNTkRERERERERERKT+qbNQREREREREREREAIWFIiIiIiIiIiIicozCQhEREREREREREQEUFoqIiIiIiIiIiMgxCgtFREREREREREQEUFjYKLz11ltERUXh7OxMr169WL9+vb1LEmkWpkyZgsFgqPXRpk0be5cl0mStWLGC0aNHExISgsFgYM6cObXut9lsPP300wQHB+Pi4sLQoUNJSEiwT7EiTcyZxtcdd9xxwnvayJEj7VOsSBP0/PPP06NHDzw8PAgICGDMmDHEx8fXekxZWRkTJkzA19cXd3d3rrvuOjIzM+1UsUjTcTbja9CgQSe8j9177712qljORGGhnX399ddMnjyZZ555hs2bN9O5c2dGjBhBVlaWvUsTaRbat29Penp6zceqVavsXZJIk1VcXEznzp156623Tnr/iy++yOuvv867777LunXrcHNzY8SIEZSVlTVwpSJNz5nGF8DIkSNrvafNnDmzASsUadqWL1/OhAkTWLt2LYsWLcJisTB8+HCKi4trHvPwww/z448/8u2337J8+XLS0tK49tpr7Vi1SNNwNuML4K9//Wut97EXX3zRThXLmRhsNpvN3kVczHr16kWPHj148803AbBarYSHhzNp0iT+8Y9/2Lk6kaZtypQpzJkzh61bt9q7FJFmx2AwMHv2bMaMGQNUdxWGhITwyCOP8OijjwKQn59PYGAg06dP5+abb7ZjtSJNy5/HF1R3Fubl5Z3QcSgi5+bIkSMEBASwfPlyBgwYQH5+Pv7+/syYMYPrr78egL1799K2bVvWrFnDpZdeaueKRZqOP48vqO4s7NKlC6+99pp9i5Ozos5CO6qoqGDTpk0MHTq05pjRaGTo0KGsWbPGjpWJNB8JCQmEhITQsmVLbr31VpKTk+1dkkizlJSUREZGRq33NC8vL3r16qX3NJELZNmyZQQEBNC6dWvuu+8+cnJy7F2SSJOVn58PgI+PDwCbNm3CYrHUeh9r06YNEREReh8TqaM/j6/jvvzyS/z8/OjQoQNPPPEEJSUl9ihPzoKDvQu4mGVnZ1NVVUVgYGCt44GBgezdu9dOVYk0H7169WL69Om0bt2a9PR0pk6dSv/+/dm5cyceHh72Lk+kWcnIyAA46Xva8ftE5NyNHDmSa6+9lujoaPbv38+TTz7JqFGjWLNmDSaTyd7liTQpVquVhx56iL59+9KhQweg+n3M0dERb2/vWo/V+5hI3ZxsfAGMHTuWyMhIQkJC2L59O3//+9+Jj49n1qxZdqxWTkVhoYg0W6NGjar5ulOnTvTq1YvIyEi++eYb7rrrLjtWJiIiUjd/nMrfsWNHOnXqRKtWrVi2bBlDhgyxY2UiTc+ECRPYuXOn1rIWqQenGl9/+9vfar7u2LEjwcHBDBkyhP3799OqVauGLlPOQNOQ7cjPzw+TyXTCDluZmZkEBQXZqSqR5svb25u4uDgSExPtXYpIs3P8fUvvaSINo2XLlvj5+ek9TaSOJk6cyE8//cTSpUsJCwurOR4UFERFRQV5eXm1Hq/3MZGzd6rxdTK9evUC0PtYI6Ww0I4cHR3p1q0bixcvrjlmtVpZvHgxvXv3tmNlIs1TUVER+/fvJzg42N6liDQ70dHRBAUF1XpPKygoYN26dXpPE6kHqamp5OTk6D1N5CzZbDYmTpzI7NmzWbJkCdHR0bXu79atG2azudb7WHx8PMnJyXofEzmDM42vkzm+CaXexxonTUO2s8mTJ3P77bfTvXt3evbsyWuvvUZxcTF33nmnvUsTafIeffRRRo8eTWRkJGlpaTzzzDOYTCZuueUWe5cm0iQVFRXV+t/fpKQktm7dio+PDxERETz00EP861//IjY2lujoaP75z38SEhJSa0dXETm5040vHx8fpk6dynXXXUdQUBD79+/n8ccfJyYmhhEjRtixapGmY8KECcyYMYO5c+fi4eFRsw6hl5cXLi4ueHl5cddddzF58mR8fHzw9PRk0qRJ9O7dWzshi5zBmcbX/v37mTFjBpdffjm+vr5s376dhx9+mAEDBtCpUyc7Vy8nY7DZbDZ7F3Gxe/PNN3nppZfIyMigS5cuvP766zUtuSJy7m6++WZWrFhBTk4O/v7+9OvXj3//+99aE0PkHC1btozBgwefcPz2229n+vTp2Gw2nnnmGd5//33y8vLo168fb7/9NnFxcXaoVqRpOd34eueddxgzZgxbtmwhLy+PkJAQhg8fznPPPXfCpkIicnIGg+Gkxz/55BPuuOMOAMrKynjkkUeYOXMm5eXljBgxgrffflvTkEXO4EzjKyUlhb/85S/s3LmT4uJiwsPDueaaa3jqqafw9PRs4GrlbCgsFBEREREREREREUBrFoqIiIiIiIiIiMgxCgtFREREREREREQEUFgoIiIiIiIiIiIixygsFBEREREREREREUBhoYiIiIiIiIiIiByjsFBEREREREREREQAhYUiIiIiIiIiIiJyjMJCERERERERERERARQWioiIiIiIiIiIyDEKC0VERERERERERARQWCgiIiIiIiIiIiLH/D8m+PGx2RxK1wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-42554f604de7>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-6a91f2fa5db5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmaromba_only\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         pool = (\n\u001b[0;32m--> 139\u001b[0;31m             MTensor.reshape(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfeat_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-15-933a761e0102>\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# _ibmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     mdot = _ibmd(\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-eceb8dd264eb>\u001b[0m in \u001b[0;36m_ibmd\u001b[0;34m(u, v, idxu, idxv)\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_u\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0midxu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0midxv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0md_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midxu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-60b90be09b9a>\u001b[0m in \u001b[0;36mnormalized\u001b[0;34m(idxu)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0midxu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpre_shape\u001b[0m \u001b[0mx\u001b[0m \u001b[0md_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m   \u001b[0midxu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminmax_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0midxu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0midxu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-60b90be09b9a>\u001b[0m in \u001b[0;36mminmax_normalize\u001b[0;34m(idxu)\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0midxu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpre_shape\u001b[0m \u001b[0mx\u001b[0m \u001b[0md_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0mmin_idxu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0mmax_idxu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784, 1,],\n",
        "        \"samples\": [9, 784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [1, num_classes,],\n",
        "        \"samples\": [9, 784,],\n",
        "        \"is conv\": [False, False,]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.MW.idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 10 # 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.MW.idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    ###\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    _loss = loss.item()\n",
        "    # loss += 1e-1 * torch.cat(model._penalties, dim=0).sum()\n",
        "    ###\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(_loss)\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 1\n",
        "    _batchidx = 0\n",
        "    pool = model.all_pools[_layer]\n",
        "    pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "    display.clear_output(wait=True)\n",
        "    plot_features(pool)\n",
        "    from time import sleep\n",
        "    sleep(3)\n",
        "    #\n",
        "    # pool = model.all_samples[_layer - 1]\n",
        "    # _shape = (\n",
        "    #     config[\"features\"][\"sets\"][_layer - 1],\n",
        "    #     config[\"features\"][\"samples\"][_layer - 1],\n",
        "    # )\n",
        "    # _set = (config[\"features\"][\"sets\"][_layer - 1]) // 2\n",
        "    # pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "    # display.clear_output(wait=True)\n",
        "    # plot_features(pool)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "##\n",
        "# phi = idxu[0] @ idxv[0].T"
      ],
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "1SknOTQ7O9BS",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "Lyzd22RQX-Yg",
        "8_m1YvjxBdj9",
        "Y-K_7fUh2anJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyP52MrIQyKipQNv3YZeOybB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}