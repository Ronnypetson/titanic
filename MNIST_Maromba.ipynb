{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219e4dc3-f71e-4f03-969e-66ba3bbdfc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 17117692.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 338463.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6304648.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 22398627.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 21168589.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 369188.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6097194.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 23858869.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return (\n",
        "  #     cifar10_norm(tr(x))\n",
        "  #     .reshape(channels, img_dim, img_dim)\n",
        "  #     .permute(1, 2, 0)\n",
        "  #     .reshape(-1)\n",
        "  # )\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x)).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "outputs": [],
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "outputs": [],
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "outputs": [],
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 0.01 * ((ch  + offset) /  chs) - 0.05\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx\n",
        "\n",
        "def _cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = (row + offset)\n",
        "        idx[row, col, ch, 1] = (col + offset)\n",
        "        idx[row, col, ch, 2] = (ch  + offset)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "def poly1norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  idxu = (0.5 ** 0.5) * torch.cat([idxu, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "def poly2norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  _idxu = idxu.reshape((-1, d_idx, 1))\n",
        "  middle = (\n",
        "      torch.bmm(_idxu, _idxu.permute(0, 2, 1))\n",
        "      .reshape((*idxu.shape[:-1], d_idx ** 2))\n",
        "  )\n",
        "  idxu = 0.5 * torch.cat([(2.0 ** 0.5) * idxu, middle, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "from collections import defaultdict as dd\n",
        "from itertools import product\n",
        "\n",
        "@lru_cache()\n",
        "def poly_terms(idx_dim, degree):\n",
        "  combs = dd(int)\n",
        "  ranges = (range(idx_dim) for _ in range(degree))\n",
        "  for idxs in product(*ranges):\n",
        "      comb = tuple(sorted(idxs))\n",
        "      combs[comb] += 1\n",
        "  return list(combs.items())\n",
        "\n",
        "\"\"\"\n",
        "sigmoid(8*x - 4)\n",
        "1/(1 + e^4)\n",
        "+ (8 e^4 x)/(1 + e^4)^2\n",
        "+ (32 e^4 (e^4 - 1) x^2)/(1 + e^4)^3\n",
        "+ (256 (e^4 - 4 e^8 + e^12) x^3)/(3 (1 + e^4)^4)\n",
        "+ (512 e^4 (-1 + 11 e^4 - 11 e^8 + e^12) x^4)/(3 (1 + e^4)^5)\n",
        "+ (4096 (e^4 - 26 e^8 + 66 e^12 - 26 e^16 + e^20) x^5)/(15 (1 + e^4)^6)\n",
        "+ O(x^6)\n",
        "(Taylor series)\n",
        "-------------------------\n",
        "0.017986  * x^0\n",
        "0.14130   * x^1\n",
        "0.5448747 * x^2\n",
        "1.3474883 * x^3\n",
        "2.290065  * x^4\n",
        "2.4479883 * x^5\n",
        "\"\"\"\n",
        "\n",
        "def poly_norm(idxu, degree):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  pre_shape = idxu.shape[:-1]\n",
        "  idx_dim = idxu.shape[-1]\n",
        "  idxu = normalized(idxu)\n",
        "  terms = poly_terms(idx_dim, degree)\n",
        "  factors = torch.tensor([term[1] for term in terms]).float().to(idxu.device)\n",
        "  factors = factors ** 0.5\n",
        "  intidx = torch.tensor([list(term[0]) for term in terms]).long().to(idxu.device)\n",
        "  intidx = intidx.reshape(-1)\n",
        "  idxu = idxu.reshape(-1, idx_dim)[:, intidx]\n",
        "  idxu = idxu.reshape(*pre_shape, degree, -1)\n",
        "  idxu = idxu.prod(dim=-2) * factors.reshape(*((1,) * len(pre_shape)), idxu.shape[-1])\n",
        "  return idxu\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _knndot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"k-NN Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  num_neigh = 1\n",
        "  dots = []\n",
        "  q_idxu = idxu.cpu().detach().numpy().reshape(-1, d_idx)\n",
        "  for _pos in range(n):\n",
        "    neigh = NearestNeighbors(n_neighbors=num_neigh, metric=\"cosine\")\n",
        "    neigh.fit(idxv[_pos].cpu().detach().numpy().reshape(-1, d_idx))\n",
        "    n_idxu = neigh.kneighbors(\n",
        "        q_idxu, return_distance=False\n",
        "    ).reshape(-1)\n",
        "    n_idxu = torch.from_numpy(n_idxu).long()\n",
        "    _v = v[_pos].reshape(-1, d_val)[n_idxu].reshape(m, d_u, d_val)\n",
        "    # _dot: M x d_val x d_val\n",
        "    _dot = torch.bmm(_v.permute(0, 2, 1), _v)\n",
        "    # _dot: M x 1 x d_val\n",
        "    _dot = torch.diagonal(_dot, dim1=1, dim2=2).unsqueeze(1)\n",
        "    dots.append(_dot)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.cat(dots, dim=1)\n",
        "  return dot\n",
        "\n",
        "def _icbmd(u, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Conv Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x 1 x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_v == 1\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: M x d_u x N\n",
        "  idxv = (\n",
        "      (idxu.reshape(m * d_u, d_idx))\n",
        "      @ idxv.permute(2, 1, 0).reshape(d_idx, n)\n",
        "  ).reshape(m, d_u, n)\n",
        "  # idxv: M x N x d\n",
        "  idxv = torch.bmm(\n",
        "      u.permute(0, 2, 1),\n",
        "      idxv\n",
        "  ).permute(0, 2, 1)\n",
        "  return idxv\n",
        "\n",
        "def _ibmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  v: N x d_v x d_valv\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu, d_valv = u.shape[-1], v.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxu = poly_norm(idxu, 1) # / (d_u)\n",
        "  # idxv = poly_norm(idxv, 1) # / (d_v)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: N x d_idx x d_valv\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxv: M x d_u x (d_valv * N)\n",
        "  idxv = (\n",
        "      idxu.reshape(m * d_u, d_idx)\n",
        "      @ idxv.permute(1, 2, 0).reshape(d_idx, d_valv * n)\n",
        "  ).reshape(m, d_u, d_valv * n)\n",
        "  # idxv: M x d_valu x (d_valv * N)\n",
        "  idxv = torch.bmm(u.permute(0, 2, 1), idxv)\n",
        "  if d_valv == 1:\n",
        "    # idxv: M x N x d_valu\n",
        "    idxv = idxv.reshape(m, d_valu, n).permute(0, 2, 1)\n",
        "  else:\n",
        "    # idxv: M x N x d_valu or error\n",
        "    idxv = idxv.reshape(m, d_valu, d_valv, n).permute(0, 3, 1, 2)\n",
        "    idxv = torch.diagonal(idxv, dim1=2, dim2=3)\n",
        "  return idxv\n",
        "\n",
        "def _fbmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Fast Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxu: M x d_val x d_idx\n",
        "  # idxv: N x d_idx x d_val\n",
        "  idxu = torch.bmm(u.permute(0, 2, 1), idxu)\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxu: M x N x d_val\n",
        "  idxu = (\n",
        "    (\n",
        "        idxu.reshape(m * d_val, d_idx)\n",
        "        @ (\n",
        "            idxv\n",
        "            .permute(0, 2, 1)\n",
        "            .reshape(n * d_val, d_idx)\n",
        "            .T\n",
        "          )\n",
        "    ).reshape(m, d_val, n, d_val)\n",
        "    .permute(0, 2, 1, 3)\n",
        "  )\n",
        "  idxu = torch.diagonal(idxu, dim1=2, dim2=3)\n",
        "  return idxu\n",
        "\n",
        "def batch_mdot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  if d_idx * (d_u + n) < n * d_u * (d_idx + 1):\n",
        "    return _fbmd(u, v, idxu, idxv)\n",
        "  else:\n",
        "    return _ibmd(u, v, idxu, idxv)\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  ###\n",
        "  # siter = 6\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  #### Tanh seems to work for high-dimensional idx\n",
        "  #### ReLU(x - alpha) / (1.0 - alpha) works for small samples\n",
        "  # alpha = 1.0 - 1.0 / d_v # 0.95\n",
        "  # alpha = min(0.999, alpha)\n",
        "  alpha = 0.97\n",
        "  idxuv = nn.functional.relu((idxuv - alpha) / (1.0 - alpha))\n",
        "  ###\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    ###\n",
        "    # _nsbmd\n",
        "    # _rdot\n",
        "    # _knndot\n",
        "    # _fbmd\n",
        "    # _ibmd, _mbmd\n",
        "    # batch_mdot\n",
        "    ###\n",
        "    mdot = _rdot(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    # _aidx = aidx.mean(dim=-2, keepdim=True)\n",
        "    # _bidx = bidx.mean(dim=-2, keepdim=True)\n",
        "    # onesa = torch.ones(_aidx.shape).to(_aidx.device)\n",
        "    # onesb = torch.ones(_bidx.shape).to(_bidx.device)\n",
        "    # midx = (\n",
        "    #     _nsbmd(_aidx, onesb, _aidx, _bidx)\n",
        "    #     + _nsbmd(onesa, _bidx, _aidx, _bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    _aidx = aidx.mean(dim=-2, keepdim=True)\n",
        "    _bidx = bidx.mean(dim=-2, keepdim=True)\n",
        "    # midx = (\n",
        "    #     _aidx + _bidx.permute(1, 0, 2)\n",
        "    # ) / 2.0\n",
        "    midx = (_aidx + _bidx.norm(dim=-1, keepdim=True).permute(1, 0, 2)) / 2.0\n",
        "    ###\n",
        "    # midx = _icbmd(aidx, aidx, bidx.sum(dim=-2, keepdim=True)) # / aidx.shape[-2]\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  nneigh = min(nneigh, len(xidx))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False,\n",
        "    )\n",
        "    all_hoods = set(tuple(sorted(hood)) for hood in all_hoods)\n",
        "    all_hoods = np.array(list(all_hoods)) # .reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ) # .reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    # self._ones_idx = torch.zeros((1, 1, idx_dim), device=device)\n",
        "    # self.activation = nn.ELU()\n",
        "    self.activation = nn.ReLU()\n",
        "    # self.activation = nn.LeakyReLU()\n",
        "    self._probe = nn.Linear(self._feat_samples[-1], 10).to(device)\n",
        "    self._num_fwd = 0\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _mag = 0.1 # 2.0 # 1000.0 * 0.01\n",
        "    _W_idx = _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    ###\n",
        "    # _W_idx = _W_idx.reshape(-1, idxdim)\n",
        "    # _W_idx[:, 2] = 1.0\n",
        "    # _W_idx = _W_idx.reshape(*shape, idxdim)\n",
        "    ###\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #   _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    # )\n",
        "    # _std = 1.0\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #   _std * torch.randn((*shape, idxdim), device=device)\n",
        "    # )\n",
        "    # _W = torch.ones(shape).float().to(device)\n",
        "    _std = 0.01\n",
        "    # _W = _std * torch.randn(shape, device=device)\n",
        "    # _W = _mag * torch.rand(shape, device=device) - (_mag / 2.0)\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def _reinit_indices(self, pool, params):\n",
        "    \"\"\"\n",
        "    pool: N x mshape\n",
        "    params: param_shape\n",
        "    \"\"\"\n",
        "    idx_dim = pool.idx.shape[-1]\n",
        "    assert params.idx.shape[-1] == idx_dim\n",
        "    pool_idx = pool.idx.reshape(-1, idx_dim)\n",
        "    eps = 1e-6\n",
        "    idx_max = pool_idx.max(dim=0, keepdim=True)[0] + eps\n",
        "    idx_min = pool_idx.min(dim=0, keepdim=True)[0] - eps\n",
        "    idx_itv = idx_max - idx_min\n",
        "    n_samples = len(params.idx.reshape(-1, idx_dim))\n",
        "    sampled_idx = torch.rand((n_samples, idx_dim), device=pool.data.device)\n",
        "    sampled_idx = sampled_idx * idx_itv + idx_min\n",
        "    params.idx = sampled_idx\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = deepcopy(self._config[\"params\"][\"sets\"])\n",
        "    param_samples = deepcopy(self._config[\"params\"][\"samples\"])\n",
        "    feat_sets = deepcopy(self._config[\"features\"][\"sets\"])\n",
        "    feat_samples = deepcopy(self._config[\"features\"][\"samples\"])\n",
        "    ###\n",
        "    self._curr_sets = feat_sets\n",
        "    self._curr_samples = feat_samples\n",
        "    ###\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._num_fwd == 0:\n",
        "        self._reinit_indices(pool, self.MW[wl: wr])\n",
        "      self._num_fwd += 1\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # idx_slice = pool.idx[0]\n",
        "        idx_slice = pool.idx[0, :, :3]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      ###\n",
        "      feat_sets[step] = idxx.shape[0]\n",
        "      feat_samples[step] = idxx.shape[1]\n",
        "      idxx = idxx.reshape(-1)\n",
        "      ###\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      ###\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      maromba_only = True\n",
        "      if maromba_only or (step < n_layers - 1):\n",
        "        pool = (\n",
        "            MTensor.reshape(\n",
        "                pool, (n * feat_sets[step], -1)\n",
        "            )\n",
        "            @ mw\n",
        "        )\n",
        "      else:\n",
        "        pool = self._probe(pool.data.reshape(n, -1))\n",
        "        pool = MTensor(\n",
        "            pool,\n",
        "            torch.zeros((*pool.shape, self._idx_dim)).to(pool.device)\n",
        "        )\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # 500 # 3 # 10\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim, mag=2.0) # 1000.0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_m1YvjxBdj9"
      },
      "source": [
        "### Visualizações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "outputs": [],
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "ca6cd858-e6b4-4054-a53d-e7ef8ec7f56f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"be330e24-a01f-4fe8-8797-4cccfbc701bb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"be330e24-a01f-4fe8-8797-4cccfbc701bb\")) {                    Plotly.newPlot(                        \"be330e24-a01f-4fe8-8797-4cccfbc701bb\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003eval=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.0,0.0,3.634252898621071e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.507856475934659e-10,3.6500824585061764e-10,0.0,0.0,0.0,2.43794318066648e-10,0.0,0.0,0.0,0.0,0.0,0.0,1.2641054869533264e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.509999040891444e-09,0.0,0.0,0.0,0.0,0.0,0.0,5.226997945584344e-09,0.0,0.0,0.0,0.0,4.092763017382595e-09,0.0,0.0,0.0,0.0,3.2896576573904213e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.9157926633983635e-10,0.0,0.0,0.0,0.0,9.329689909520766e-09,0.0,0.0,7.814618951940133e-10,0.0,0.0,0.0,0.0,0.0,8.756946279220301e-10,0.0,8.127783446276737e-10,2.1602097888262506e-10,0.0,0.0,0.0,1.0443442777230416e-09,0.0,0.0,1.1339271743793233e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.044843571193724e-09,0.0,0.0,0.0,0.0,0.0,5.63617263971139e-10,1.922471071225118e-09,0.0,1.271309724160119e-10,0.0,8.855958633091632e-09,6.498602989069013e-09,3.010480198462062e-10,0.0,0.0,0.0,0.0,0.0,4.00235267150606e-09,2.5469117925780438e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.290413802010562e-09,0.0,0.0,0.0,0.0,0.0,0.0,7.66524121953438e-10,0.0,0.0,0.0,8.892944713956297e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0847395870428045e-08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.707490284365349e-11,0.0,0.0,0.0,0.0,5.939632119478233e-10,0.0,0.0,0.0,2.419851652391003e-09,0.0,0.0,0.0,0.0,2.1153832019393803e-09,0.0,0.0,0.0,0.0,2.3102657564777473e-09,0.0,0.0,0.0,0.0,0.0,0.0,1.2997687370841504e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.325141299612369e-09,0.0,0.0,0.0,0.0,4.035876521868431e-09,2.690039302422065e-10,0.0,0.0,8.08419997611054e-12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3.3500119345220014e-10,0.0,0.0,0.0,0.0,0.0,3.217591082460558e-09,0.0,0.0,1.3331288295503896e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.9941759354935584e-10,0.0,0.0,0.0,0.0,7.194037587865409e-10,2.244472607770831e-09,0.0,0.0,5.364482191794195e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.6551118253715913e-09,1.8102822352261683e-08,0.0,5.812828440809881e-09,0.0,4.9827484360776e-09,2.2045254510771883e-09,1.228325635649341e-10,0.0,0.0,0.0,3.367734979775605e-10,6.438505728567634e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3.233783019140901e-09,1.6600095742447252e-09,7.66524121953438e-10,0.0,0.0,0.0,0.0,5.996871887958832e-10,5.27819843387789e-10,0.0,7.814874969369612e-09,0.0,0.0,2.969866796931342e-09,0.0,1.4863008046539505e-10,0.0,0.0,2.5891491173268832e-09,6.438505728567634e-09,0.0,0.0,0.0,1.0780931702925045e-09,1.164924146729307e-11,0.0,0.0,0.0,0.0,6.238848326844959e-11,0.0,0.0,5.060591945493798e-10,0.0,5.237621447662377e-11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.289778754440476e-09,0.0,3.7314373813046586e-11,0.0,0.0,2.5982920259792763e-09,0.0,0.0,0.0,0.0,3.056703223869306e-10,5.838889094444966e-11,5.5035753732113335e-09,2.7328450613595123e-09,2.4497084361030375e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3.991680319614943e-09,0.0,0.0,0.0,0.0,5.454875440236151e-10,0.0,0.0,0.0,0.0,1.4173613394063977e-09,0.0,8.618554758754726e-10,0.0,0.0,0.0,0.0,0.0,2.1039880948592327e-09,0.0,0.0,1.6311021422410477e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7.42143058118927e-09,3.3740185645392273e-10,0.0,0.0,0.0,0.0,0.0,3.863911968160494e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.165746246900028e-10,0.0,0.0,1.4317712349054545e-08,0.0,4.344061999006499e-09,0.0,0.0,0.0,0.0,5.037544825725604e-10,2.118958786212488e-09,0.0,0.0,3.1825680979480353e-10,0.0,0.0,3.4947822413755603e-10,0.0,3.446913865445822e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0878644512990476e-10,0.0,1.2837222396200332e-09,0.0,0.0,0.0,0.0,5.458759222420895e-09,0.0,5.138031111684427e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5.509878664433643e-10,0.0,0.0,0.0,5.718618467653869e-09,0.0,0.0,0.0,0.0,7.024779646869206e-10,6.375026728733246e-09,0.0,2.660422993017164e-09,2.177904967481936e-09,0.0,0.0,5.911764411337117e-09,0.0,0.0,2.94976876258346e-10,4.182682200593035e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.8398729468601687e-11,0.0,1.408190092311301e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5.752199161435101e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.021046980298479e-08,7.1365313658589e-09,0.0,0.0,0.0,0.0,1.903340374198592e-09,0.0,0.0,0.0,0.0,0.0,0.0,1.389104831162058e-09,0.0,0.0,0.0,0.0,0.0,0.0,5.120061596919356e-10,3.1756686169615023e-10,0.0,0.0,3.0393002004025504e-10,0.0,0.0,1.871702792755059e-11,0.0,0.0,0.0,0.0,1.0502656522248799e-09,0.0,0.0,0.0,0.0,1.2172405305932443e-09,0.0,0.0,0.0,0.0,0.0,0.0,2.066140591949761e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3.4894036549104612e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.507856475934659e-10,0.0,0.0,0.0,0.0,0.0,6.51026677012112e-10,4.836645750572188e-09,0.0,0.0,0.0,0.0,7.645970967473659e-09,0.0,3.1392259902673914e-09,0.0,0.0,0.0,0.0,0.0,5.891842569383243e-11,0.0,8.73728200900814e-10,0.0,0.0,0.0,0.0,0.0,1.922500381112968e-09,0.0,0.0,0.0,2.8038757982074003e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.9064112066757843e-08,9.568348779964708e-09,0.0,0.0,0.0,0.0,0.0,0.0,2.11581419051754e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.156194943760738e-09,0.0,1.1339271743793233e-09,3.7050060797128026e-09,0.0,3.20707016499e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.96736818345056e-11,0.0,0.0,2.692523315417361e-09,0.0,0.0,0.0,1.161492568790834e-10,0.0,0.0,0.0,2.377784635854141e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0657797977486894e-09,4.541363729515524e-09,0.0,0.0,0.0,2.4305339962893413e-09,0.0,2.0991011151494376e-09,0.0,1.0447217535514142e-09,1.506136881879172e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.3052599829043174e-09,0.0,0.0,1.0878644512990476e-10,0.0,0.0,1.925678727587865e-09,0.0,6.073251901383969e-10,0.0,0.0,0.0,0.0,0.0,0.0,6.630183957412328e-09,0.0,7.274408853064074e-10,0.0,0.0,8.630512970952964e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5.284070514477435e-09,0.0,0.0,0.0,0.0,0.0],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"x\":[-0.013033830560743809,0.04776861146092415,0.01330245565623045,-0.01986992545425892,-0.017281485721468925,-0.040359705686569214,-0.0005792281590402126,0.005960229784250259,-0.04038742557168007,0.03212372213602066,0.05943470820784569,0.049853865057229996,-0.03970635309815407,-0.014869804494082928,0.05046342313289642,0.038221437484025955,-0.011992202140390873,0.045731376856565475,0.016373122110962868,0.015240395441651344,-0.02606372907757759,0.05551667883992195,0.05346892401576042,-0.008956060744822025,0.06329964101314545,0.010625985451042652,0.04702415317296982,-0.01753941923379898,0.009443291462957859,0.02459372766315937,-0.004483046941459179,-0.015037440694868565,-0.03977496176958084,-0.03877205029129982,-0.02957645058631897,0.06241203099489212,0.0479990653693676,-0.011185497045516968,-0.03536313399672508,0.007131811231374741,0.009843404404819012,0.035681355744600296,0.02921154350042343,0.04196120426058769,0.013015201315283775,0.047714050859212875,0.004970516078174114,0.0018958540167659521,0.01153341680765152,-0.04029221832752228,-0.03114265576004982,0.052765510976314545,-0.021176371723413467,-0.04061756655573845,0.039247527718544006,-0.020444490015506744,-0.015874309465289116,0.009220544248819351,0.03288336843252182,0.030907683074474335,0.014961792156100273,0.04876529052853584,0.055172551423311234,0.023507598787546158,0.04864293709397316,0.007136761210858822,0.04621182009577751,-0.0237832423299551,-0.0031156965997070074,-0.02921455353498459,0.008538173511624336,0.001057966728694737,-0.015911387279629707,0.049286823719739914,0.06340933591127396,-0.02489561401307583,0.01748506911098957,0.06140081211924553,0.059303510934114456,0.0030746946576982737,0.03302103281021118,0.03754763305187225,0.012509364634752274,-0.01774711348116398,0.030027931556105614,-0.028463315218687057,-0.04052514582872391,0.025455573573708534,0.04489196836948395,-0.006714996881783009,0.02127346396446228,-0.016672223806381226,-0.03833385929465294,0.061176981776952744,0.00853705033659935,0.044781431555747986,0.062181588262319565,-0.0007316218689084053,-0.01419521402567625,0.04330235719680786,-0.011905891820788383,0.04662417992949486,-0.025490151718258858,0.0009457694832235575,0.061603158712387085,-0.011307000182569027,-0.01642901450395584,0.054159268736839294,0.030004290863871574,0.04852893948554993,-0.027392681688070297,-0.015097989700734615,0.039343103766441345,0.044270314276218414,0.0626596212387085,0.01628795638680458,0.013071255758404732,0.039302535355091095,0.03784859925508499,0.03713652864098549,-0.03957424312829971,-0.02781197987496853,-0.040760207921266556,-0.04100663214921951,-0.021402105689048767,0.06040649116039276,0.01737978495657444,0.001654244028031826,-0.027907056733965874,-0.04070334881544113,0.026472818106412888,-0.017683805897831917,-0.010541541501879692,-0.01690008118748665,-0.011193777434527874,0.051306575536727905,-0.023022720590233803,0.029786717146635056,-0.030207499861717224,-0.02684926800429821,-0.027725253254175186,-0.026784295216202736,-0.027272731065750122,0.01479782722890377,0.0444500558078289,0.04736296460032463,0.06360483169555664,-0.02026311121881008,0.015584480948746204,0.005154832731932402,0.030980151146650314,0.04907805845141411,0.037897951900959015,-0.013625341467559338,-0.006787021644413471,0.058010634034872055,0.027514437213540077,-0.025719409808516502,0.004194251261651516,0.010359355248510838,-0.04074861481785774,0.0026160175912082195,-0.0398612804710865,0.03414970263838768,0.0409981869161129,-0.040503136813640594,-0.012813412584364414,0.006784779019653797,0.044553980231285095,0.04871141538023949,-0.039911799132823944,-0.02056180313229561,-0.040129367262125015,0.059937261044979095,-0.012624184601008892,-0.007626221515238285,0.008292575366795063,-0.020338447764515877,-0.024288559332489967,0.037060074508190155,-0.04078974947333336,-0.0029642952140420675,0.04277249425649643,-0.03825677931308746,-0.0279147420078516,0.03999628871679306,0.008531170897185802,-0.015006921254098415,0.0630580261349678,0.01281021349132061,0.021398017182946205,0.05578106641769409,0.06328537315130234,0.06281421333551407,-0.03261852636933327,-0.018358374014496803,-0.039874158799648285,0.014727005735039711,-0.01996583864092827,0.012283079326152802,0.037525467574596405,0.03974216431379318,0.043274860829114914,0.013911903835833073,0.045715101063251495,-0.02848774380981922,0.030068624764680862,0.062181632965803146,-0.01612168736755848,0.02929680608212948,-0.030345726758241653,-0.02445913851261139,-0.02065649814903736,0.006605049595236778,-0.006449897773563862,-0.029954131692647934,-0.02519986964762211,0.03739224746823311,-0.01669616438448429,-0.040695540606975555,0.03790866583585739,0.026527918875217438,-0.004240271635353565,-0.01104359608143568,-0.040826909244060516,0.014286119490861893,-0.009092515334486961,-0.0009228978306055069,0.019570980221033096,0.012010440230369568,-0.009641420096158981,0.03239084407687187,0.0630340501666069,0.06325720995664597,-0.025694169104099274,0.044502031058073044,0.028492873534560204,0.0418759286403656,0.04562854394316673,0.028107166290283203,0.031597841531038284,0.05604919418692589,-0.010811222717165947,-0.04100177809596062,-0.03953159600496292,0.01563749648630619,0.004161822143942118,0.03203194588422775,-0.040074534714221954,0.005821025464683771,0.05307278037071228,0.027421588078141212,-0.01665433496236801,-0.03254637122154236,-0.0325208343565464,-0.012460688129067421,-0.027115320786833763,0.03848782926797867,-0.026499317958950996,-0.012246771715581417,0.029453085735440254,-0.0036373536568135023,0.05043994262814522,0.00824503879994154,0.0049103666096925735,-0.025582920759916306,-0.02445138432085514,0.0626664087176323,0.0030423104763031006,-0.0032514494378119707,0.04477387294173241,0.0029204366728663445,0.032896898686885834,0.012201139703392982,-0.00021035410463809967,0.03189804404973984,-0.00661679171025753,-0.013673913665115833,-0.015898067504167557,0.004958180710673332,0.04136189818382263,0.028796127066016197,-0.040229979902505875,-0.0243214201182127,0.03961843624711037,-0.00708573404699564,-0.009284287691116333,0.060302410274744034,0.02693856693804264,0.0028072085697203875,-0.02258492447435856,0.04832352697849274,-0.005610115826129913,0.06322060525417328,-0.040743861347436905,0.008162344805896282,0.06328251212835312,0.018085628747940063,-0.03993238881230354,-0.040529318153858185,-0.02132776938378811,0.03296472132205963,-0.03982393071055412,-0.022391293197870255,-0.040205903351306915,-0.007293437607586384,0.04628661274909973,0.06267551332712173,0.06342193484306335,-0.040184494107961655,0.0157672967761755,0.04780251160264015,-0.018421638756990433,-0.0046708714216947556,0.05678587406873703,0.06248822063207626,0.0030518993735313416,-0.03047015890479088,-0.00976305827498436,-0.007676075212657452,-0.04085388407111168,-0.0005211893003433943,0.06315691024065018,0.012410358525812626,0.02854384109377861,0.05245191976428032,0.04347504302859306,-0.005232873372733593,0.012292913161218166,0.060208193957805634,0.038356371223926544,-0.019193638116121292,-0.03647736832499504,0.03705035522580147,-0.016319043934345245,0.053837213665246964,0.04873818904161453,0.027743911370635033,-0.024915440008044243,-0.035304583609104156,0.059849243611097336,-0.009249947033822536,0.009975607506930828,-0.022273093461990356,-0.006117071956396103,0.06292010098695755,-0.010411789640784264,0.06074202433228493,0.027857312932610512,-0.009294114075601101,0.06190105900168419,-0.0035734286066144705,0.041729483753442764,0.03247340768575668,0.043647173792123795,0.03941089287400246,0.029039883986115456,0.047514691948890686,0.062288958579301834,0.008117377758026123,0.04236665368080139,-0.02059943787753582,0.03526975214481354,0.030807223170995712,0.00316473376005888,0.04710260406136513,-0.0017122162971645594,0.04318910092115402,0.014091955497860909,0.018525980412960052,-0.01596517115831375,-0.006483634002506733,0.0008330581476911902,0.062424104660749435,0.0328684002161026,-0.040815990418195724,0.03166554495692253,0.03763146325945854,-0.02792707458138466,0.012275095097720623,-0.011924504302442074,0.00041405565571039915,0.06122955307364464,0.009505200199782848,-0.023893985897302628,-0.00416933000087738,0.027340440079569817,0.061740241944789886,0.029404416680336,-0.008611857891082764,-0.009147907607257366,0.008820920251309872,0.008970203809440136,-0.027857346460223198,-0.006888740696012974,-0.03301190957427025,0.01097758300602436,0.004645604640245438,-0.01215376053005457,-0.004019933752715588,0.025737909600138664,-0.03462837263941765,0.038734402507543564,-0.0016248270403593779,0.06123947352170944,0.02916124276816845,-0.02068985253572464,-0.031509656459093094,-0.04113180190324783,-0.03505931794643402,-0.0013559600338339806,-0.012559434399008751,-0.013534349389374256,-0.04091431573033333,0.06216072291135788,-0.012173792347311974,-0.029831793159246445,-0.019162509590387344,0.04524914547801018,0.027783462777733803,0.005043978337198496,-0.02759408764541149,0.06014584004878998,-0.028189590200781822,-0.000859301071614027,-0.022255923599004745,0.0624539740383625,0.036597367376089096,-0.038571763783693314,0.0371851809322834,0.03253084048628807,0.046684496104717255,-0.026074130088090897,-0.040847599506378174,0.03751222416758537,-0.026790151372551918,-0.03186393901705742,0.04212310165166855,0.06091683357954025,0.031083323061466217,-0.010273702442646027,-0.039519306272268295,-0.03718659281730652,0.0026703462935984135,0.03592360392212868,-0.008986083790659904,-0.029627665877342224,-0.009355548769235611,0.06253694742918015,0.060380540788173676,-0.03519707918167114,0.012765003368258476,0.009334363043308258,0.016378311440348625,-0.009732458740472794,0.01573341153562069,0.04507618770003319,0.029302475973963737,0.007844185456633568,-0.030696149915456772,-0.03571294620633125,0.04090196639299393,-0.025233205407857895,-0.04015106335282326,0.052846264094114304,0.055634755641222,0.032973967492580414,0.017252041026949883,-0.011154078878462315,0.060501255095005035,-0.0020905386190861464,0.015194760635495186,-0.02269635535776615,0.02839525230228901,0.031367529183626175,-0.040716610848903656,0.031194400042295456,-0.04068680480122566,0.0632103905081749,-0.04055154696106911,0.02938634157180786,-0.040939442813396454,0.0005949488840997219,0.048150818794965744,-0.03193037211894989,-0.024417947977781296,-0.025908006355166435,0.028209149837493896,-0.019904354587197304,-0.039697032421827316,-0.003965212032198906,-0.031390849500894547,-0.0023801999632269144,0.06290768831968307,0.030648045241832733,-0.00018025608733296394,0.01477827224880457,0.06201349198818207,0.021847788244485855,-0.028876258060336113,0.05006590858101845,-0.013128973543643951,-0.0027786691207438707,0.01239106897264719,-0.013635301031172276,0.03980640321969986,0.06361214071512222,0.04262341186404228,0.022902345284819603,-0.04069378599524498,0.05036357417702675,-0.007913465611636639,0.0494522899389267,-0.04094196483492851,-0.020262207835912704,0.03939547389745712,0.03440328687429428,0.062018413096666336,0.027118835598230362,0.003785904264077544,-0.023878978565335274,-0.008730088360607624,0.04520392790436745,-0.024714481085538864,0.04525025561451912,-0.04061185568571091,0.06276234239339828,-0.038409579545259476,0.043086424469947815,0.020679542794823647,-0.0014972123317420483,-0.0018100200686603785,0.04710361361503601,0.028728250414133072,-0.02461446076631546,0.010826250538229942,0.006669268012046814,-0.040454354137182236,0.05158477649092674,0.04567207396030426,0.03200257197022438,-0.0188764538615942,0.03431545943021774,0.02407410368323326,0.062456779181957245,0.028115462511777878,-0.02053394913673401,-0.03968168422579765,-0.004194269888103008,-0.02096174657344818,0.04554711654782295,0.012845633551478386,-0.010353891178965569,-0.00845805648714304,0.030592074617743492,0.04185706004500389,-0.04078437760472298,0.049016743898391724,-0.004600663669407368,-0.03270028531551361,0.06229185312986374,0.029271671548485756,0.06049081310629845,0.015033806674182415,0.03412088006734848,0.0025606707204133272,0.06330883502960205,-0.009727382101118565,0.005504709668457508,-0.02120043896138668,0.03891679272055626,0.005715123377740383,0.0418853722512722,0.047613635659217834,-0.020009493455290794,0.06347345560789108,-0.03977084904909134,-0.02864781767129898,0.0413438156247139,-0.026044582948088646,0.02069859206676483,0.043085962533950806,0.006598961539566517,-0.037052907049655914,0.0612119622528553,0.032669905573129654,0.06342536956071854,-0.013143546879291534,0.060563936829566956,0.03222979977726936,-0.010399376973509789,-0.017878273501992226,-0.04112217575311661,-0.0014617952983826399,0.0025421609170734882,-0.04111797362565994,0.04124878719449043,0.029946111142635345,-0.036419883370399475,0.019683752208948135,0.018789473921060562,0.0020728856325149536,0.016932666301727295,0.06289144605398178,-0.0402030311524868,-0.030608348548412323,0.013768411241471767,0.0298302061855793,-0.01904364489018917,-0.023606088012456894,0.04446703940629959,0.00415438087657094,0.03339555859565735,0.015521377325057983,0.006156619638204575,0.06217716634273529,0.06167322024703026,0.06170986220240593,0.05488729849457741,-0.00859441515058279,-0.020605407655239105,-0.028943412005901337,-0.04083498194813728,0.027473734691739082,0.043473582714796066,-0.00551783200353384,0.011201467365026474,0.0427573025226593,0.003488335758447647,0.06085330620408058,0.03917389735579491,0.01593608595430851,-0.04042898863554001,0.042431771755218506,-0.015692712739109993,-0.03994085267186165,0.059431761503219604,0.01210873294621706,-0.03061043471097946,-0.03638682886958122,-0.039986129850149155,0.006228127516806126,0.06300164014101028,0.0027726071421056986,-0.02568645589053631,0.004241145681589842,-0.025907034054398537,0.009491526521742344,0.041413675993680954,-0.008782479912042618,-0.026977665722370148,0.02918940596282482,-0.024083377793431282,0.06140848249197006,-0.012951978482306004,0.06266168504953384,0.009528450667858124,0.04506372660398483,0.03378390520811081,0.014289932325482368,0.02433514967560768,-0.009267961606383324,0.03494942933320999,0.06391443312168121,0.04824858903884888,-0.04017075523734093,0.05085042119026184,-0.04065163806080818,-0.008542927913367748,0.025990242138504982,-0.03938956558704376,-0.021040430292487144,0.04387350007891655,0.04698057845234871,0.0040585678070783615,-0.0367400124669075,0.04700310155749321,-0.009797581471502781,0.014458565041422844,0.05925077199935913,-0.03105437383055687,-0.03913799300789833,-0.03597255051136017,0.0631922036409378,-0.010848002508282661,0.06079036369919777,-0.007782105356454849,0.026359669864177704,0.0519116036593914,0.04550502821803093,0.03599541634321213,0.06185903400182724,-0.023372311145067215,0.016996553167700768,-0.03976134583353996,0.035017695277929306,-0.002991746412590146,0.04907936975359917,-0.007230706512928009,0.028092171996831894,0.061146385967731476,-0.029892105609178543,-0.013450068421661854,0.01611299254000187,-0.04030664637684822,0.003305039368569851,0.04899941757321358,-0.011011325754225254,0.03862226381897926,0.03718174248933792,0.028806986287236214,0.050322502851486206,-0.02734041027724743,0.0020704101771116257,0.06343154609203339,0.06280456483364105,0.014445336535573006,0.054608575999736786,0.015181598253548145,-0.003421445144340396,0.03883696347475052,0.03249683231115341,-0.03736310452222824,-0.009655973874032497,-0.04049742594361305,-0.035829540342092514,-0.03023967146873474,-0.022378744557499886,-0.04066436365246773,-0.04125300794839859,0.057951804250478745,-0.0072292061522603035,-0.02930278331041336,-0.0203770250082016,-0.015646917745471,0.019243555143475533,0.024054905399680138,0.06289888173341751,-0.028508247807621956,0.02815585397183895],\"y\":[-0.00840879324823618,0.0004247730830684304,0.03633348271250725,0.0624304860830307,0.025919204577803612,0.06118841841816902,0.04856815189123154,0.030359938740730286,-0.004199931398034096,-0.0066723907366395,0.012933622114360332,0.06320769339799881,-0.02724168449640274,-0.006910332478582859,0.004984118975698948,-0.0014840657822787762,0.05336261913180351,-0.005047579295933247,-0.023199189454317093,-0.039403561502695084,-0.026656949892640114,0.006651522591710091,-0.0033940018620342016,-0.001373204868286848,0.033978421241045,0.053147803992033005,0.0357804074883461,0.061243124306201935,-0.03507300838828087,-0.040640827268362045,0.034988220781087875,-0.02155015431344509,-0.027608811855316162,0.009036467410624027,0.031106850132346153,-0.03137356415390968,0.05135439336299896,0.03504420444369316,0.06242908537387848,0.023445745930075645,-0.03403094410896301,0.04206088185310364,0.024986088275909424,0.017784245312213898,0.031345415860414505,0.01851247437298298,0.025365227833390236,0.06209563463926315,0.035260267555713654,0.007145777344703674,0.03324340283870697,-0.03980882838368416,-0.02185804769396782,0.013548613525927067,0.014551580883562565,0.0634428858757019,0.06228484958410263,-0.03553798794746399,0.004182415083050728,0.043607015162706375,0.06190267950296402,0.010317678563296795,0.00609949603676796,-0.04089115187525749,-0.0025605109985917807,0.061796706169843674,-0.01292326394468546,0.04838092252612114,0.022241629660129547,0.031423185020685196,-0.010200805962085724,-0.0010478717740625143,0.02670600637793541,0.03812500461935997,0.032738201320171356,-0.03858572989702225,0.017677970230579376,0.045017309486866,0.053912367671728134,0.022562311962246895,0.05529795214533806,-0.020272215828299522,0.040475450456142426,0.06332900375127792,0.011725280433893204,-0.036711957305669785,-0.03498080000281334,0.015351220965385437,0.03839303180575371,0.05110039561986923,-0.041115060448646545,0.026220742613077164,0.05245678871870041,0.048548873513936996,0.055432334542274475,0.04337600991129875,0.016100671142339706,-0.023020900785923004,0.06254822760820389,-0.008588075637817383,-0.02250627428293228,0.045018140226602554,-0.02498346008360386,-0.019529318436980247,0.015200616791844368,0.02944568172097206,0.04980684444308281,0.0636964812874794,-0.008125855587422848,0.04776516556739807,-0.026554012671113014,0.0631084069609642,-0.029921740293502808,0.008285045623779297,-0.000807915348559618,0.043785564601421356,0.03972836956381798,-0.028747275471687317,0.062421105802059174,0.06254472583532333,0.008417903445661068,0.05139095336198807,0.06048687547445297,0.05978633835911751,-0.038763560354709625,-0.040718596428632736,0.045584697276353836,0.021934133023023605,0.04709819704294205,0.020204991102218628,0.02461729384958744,0.04504813253879547,0.054516132920980453,-0.025601303204894066,-0.00547792948782444,0.06316878646612167,0.031292758882045746,0.02548777498304844,0.048475876450538635,-0.004139061085879803,-0.03866308555006981,-0.005936332978308201,-0.03504647687077522,0.0472276546061039,0.033776186406612396,-0.03991009294986725,-0.012235555797815323,-0.03864086791872978,0.04576433449983597,0.061359953135252,0.04976619407534599,0.03731457516551018,0.06305960565805435,0.0005804573884233832,0.03578444570302963,-0.011010419577360153,0.04567619040608406,0.031840115785598755,0.004841847810894251,0.06269317120313644,-0.017918230965733528,0.023362085223197937,0.024404257535934448,0.007134345360100269,0.01276571024209261,-0.0031994578894227743,0.05341002717614174,-0.03859711438417435,-0.03684467449784279,-0.039056695997714996,0.007755476050078869,-0.038001928478479385,-0.039517130702733994,-0.0300590842962265,0.02975897118449211,0.03348011523485184,0.05880434438586235,0.03659956902265549,0.010541368275880814,0.02374529093503952,0.007960762828588486,-0.019213927909731865,0.0365353524684906,-0.04056397080421448,-0.004475514404475689,-0.0008206937927752733,0.05688240006566048,0.05804775655269623,0.06274009495973587,-0.028325974941253662,0.030289843678474426,-0.005126591771841049,-0.013399343006312847,0.06212245300412178,0.014695562422275543,0.04503723978996277,-0.012046488001942635,0.04174236208200455,-0.038341812789440155,-0.014259214513003826,0.06325393915176392,0.027368927374482155,-0.01613982580602169,0.061216503381729126,-0.001210422022268176,0.06223778426647186,-0.008236049674451351,-0.032660309225320816,0.06274165958166122,-0.0070421127602458,-0.03848925232887268,-0.03762274980545044,0.06344729661941528,-0.03616958484053612,0.03526270017027855,0.059324268251657486,-0.03823499754071236,-0.027154823765158653,0.04579465091228485,0.0492522306740284,-0.031388867646455765,0.017163021489977837,0.009924190118908882,0.04744717851281166,0.043787214905023575,0.06249186769127846,0.04929722100496292,-0.040461018681526184,0.0302402526140213,0.01164760161191225,-0.0005245404317975044,0.0023533643689006567,0.06282965838909149,0.062368959188461304,0.05454534664750099,0.015181043185293674,-0.011444572359323502,-0.03340233862400055,-0.0014209903310984373,0.062147289514541626,0.04341074451804161,0.06275467574596405,-0.006583470851182938,0.04457001015543938,-0.016047434881329536,0.043543875217437744,-0.014439369551837444,-0.004463134333491325,-0.015044440515339375,0.061577700078487396,0.06340722739696503,-0.04060986638069153,0.025402726605534554,0.03251759335398674,-0.039545074105262756,0.02869846671819687,0.03174887225031853,-0.030396413058042526,0.01739974319934845,-0.00851275585591793,-0.04011823236942291,0.014192230999469757,-0.0015062908641994,-0.03510892018675804,-0.03771026432514191,-0.02530587464570999,-0.025022830814123154,-0.004824968054890633,0.05100661888718605,-0.04092607647180557,-0.006551641039550304,0.022421831265091896,0.055273301899433136,0.06168804690241814,0.035944849252700806,-0.03582659363746643,0.03586741164326668,0.03899271413683891,0.06273149698972702,0.020867936313152313,-0.004181164316833019,-0.007986006326973438,0.007281981408596039,-0.025244588032364845,0.06314332038164139,0.05826466530561447,-0.0019264828879386187,0.04855289310216904,-0.040642786771059036,-0.03907685726881027,0.062482986599206924,0.0011955468216910958,-0.022672688588500023,0.033094123005867004,0.04168923944234848,0.008130192756652832,0.02822316624224186,-0.009310939349234104,-0.027011308819055557,-0.019785234704613686,-0.03876982256770134,0.043546732515096664,0.0538870170712471,-0.036500539630651474,0.0004636638332158327,0.058325495570898056,0.010122223757207394,-0.030430488288402557,-0.0038691784720867872,0.03815315663814545,-0.02461409755051136,0.01263018511235714,-0.038606129586696625,0.05333556979894638,-0.005308136343955994,-0.024459121748805046,0.06258472055196762,0.05276283621788025,-0.0008987865876406431,0.04531664401292801,-0.037922006100416183,-0.020254528149962425,-0.004681840538978577,0.016396984457969666,-0.03837443143129349,0.050972070544958115,0.0385560616850853,0.009377097710967064,0.017368052154779434,0.013518042862415314,0.06290461868047714,0.06262296438217163,0.011657807976007462,0.011835409328341484,0.06225597485899925,0.06243383511900902,0.015122851356863976,0.04574491083621979,-0.025475773960351944,0.05574459955096245,8.982373401522636e-05,0.0041015734896063805,0.06280013173818588,-0.023696884512901306,0.00946199893951416,0.004644441418349743,0.037714771926403046,0.04453948140144348,0.06223053112626076,0.035500310361385345,-0.026498567312955856,0.013783089816570282,-0.01920434460043907,0.06306938081979752,-0.039926473051309586,-0.02896822616457939,-0.03909453749656677,0.0007219953695312142,0.03964146599173546,0.024752812460064888,-0.03835853561758995,0.023648427799344063,0.061582427471876144,0.011921272613108158,0.061950985342264175,0.018599146977066994,-0.025238851085305214,-0.01589948683977127,0.04393193498253822,0.0628984197974205,0.04994707554578781,0.03838886693120003,0.05563744902610779,-0.023890580981969833,0.00392402708530426,-0.008238025940954685,0.006156651768833399,0.062206752598285675,-0.025800906121730804,0.05976233258843422,-0.00827315915375948,-0.04001038148999214,0.04490107670426369,0.009450085461139679,-0.023727169260382652,0.05440029129385948,-0.013816415332257748,-0.03982407599687576,0.06274230778217316,0.04975105822086334,-0.013024303130805492,-0.011920558288693428,0.035535458475351334,0.04836401343345642,0.06169140711426735,-0.0396309569478035,-0.015054901130497456,0.0039589679799973965,0.028408316895365715,0.0516250841319561,-0.004813971929252148,0.05949968844652176,0.013992521911859512,0.02272665686905384,0.04915332421660423,-0.00703070405870676,0.05011153593659401,0.04096512496471405,0.0464722216129303,-0.004224744625389576,0.04784470051527023,0.04302597790956497,-0.013938522897660732,-0.0172849390655756,0.058114804327487946,-0.006646253168582916,-0.0383133664727211,-0.023291513323783875,0.03464876487851143,-0.01221828255802393,0.05256105959415436,-0.02695346623659134,0.05992276594042778,-0.0045656561851501465,-0.023194510489702225,0.023029934614896774,0.058886997401714325,-0.028248336166143417,-0.011792540550231934,0.009301763959228992,0.054809629917144775,-0.0010769357904791832,0.04735951870679855,0.06038904935121536,-0.027076182886958122,0.026822529733181,0.05134292319417,0.028587868437170982,0.044659268110990524,0.048528414219617844,0.05259852111339569,-0.039684828370809555,0.029172958806157112,0.061744656413793564,-0.0030700017232447863,-0.04137016087770462,-0.028689583763480186,0.04315032809972763,-0.031276315450668335,-0.020946238189935684,0.030472468584775925,0.039477232843637466,0.028874799609184265,0.06259196996688843,-0.002480289665982127,-0.024817919358611107,-0.006097756326198578,-0.04027196019887924,0.06271021068096161,-0.035910505801439285,-0.029405295848846436,0.01131688803434372,0.061776790767908096,-0.008488019928336143,0.016147734597325325,-0.005173899233341217,0.005118108820170164,-0.022871414199471474,0.035119254142045975,0.05991838499903679,-0.04075811058282852,0.04549402743577957,-0.02393643744289875,-0.04026908054947853,-0.01788659207522869,0.06040123105049133,-0.006646396592259407,0.039967700839042664,-0.0027475066017359495,0.041578423231840134,-0.010479913093149662,-0.03846197947859764,0.02114352211356163,0.009632205590605736,0.0386575311422348,-0.03746078535914421,0.04752739146351814,0.04582894220948219,0.05078791081905365,0.05401857942342758,-0.022176004946231842,0.060473427176475525,0.01210576482117176,-0.01579766906797886,-0.03028201311826706,0.013272307813167572,-0.018001161515712738,0.06287167966365814,0.044839780777692795,0.04963640868663788,0.04900757968425751,0.0009160742629319429,0.04553849622607231,-0.037708085030317307,0.02738836221396923,0.010921735316514969,-0.010693230666220188,-0.03167251497507095,-0.01253177784383297,-0.009152974002063274,0.06222213804721832,0.00628314632922411,0.03782659024000168,0.01026154775172472,0.02670464850962162,0.02738967165350914,0.04218823090195656,-0.0016071673016995192,0.01797439530491829,0.006486521102488041,0.031006012111902237,0.05303983390331268,0.024728838354349136,-0.002595137106254697,-0.03438691422343254,0.04939709231257439,-0.0006386826280504465,-0.03120439127087593,0.04477807506918907,-0.041039444506168365,0.01841065287590027,-0.040635958313941956,0.01152251847088337,-0.034350693225860596,0.062405966222286224,0.03783471882343292,0.027098428457975388,-0.012050473131239414,0.0018364961724728346,0.039076320827007294,-0.0059989746659994125,0.04588095098733902,0.057302601635456085,-0.04079952836036682,0.06321629136800766,-0.034876804798841476,0.023929784074425697,0.042483095079660416,-0.022359134629368782,0.0631915032863617,0.025632359087467194,0.06247369945049286,-0.004387730732560158,0.049923233687877655,0.05426015332341194,0.04375392198562622,0.046463124454021454,-0.003096829866990447,0.05358467623591423,0.03850783035159111,-0.032678063958883286,0.0625901147723198,0.04939817264676094,0.04533766955137253,0.005176509264856577,0.02309546433389187,0.061736077070236206,0.039384353905916214,0.00886210985481739,-0.03864660486578941,-0.03018840029835701,0.030243434011936188,0.012109686620533466,0.03399995341897011,0.027609553188085556,-0.01269849669188261,-0.027428116649389267,-0.030226893723011017,0.017286278307437897,0.06267258524894714,0.046718768775463104,-0.0379069447517395,0.05433858931064606,-0.02796548418700695,0.06098703294992447,0.053443845361471176,0.028511105105280876,0.05320713296532631,0.05506358668208122,-0.023388782516121864,0.03787185996770859,0.02514788508415222,0.047093961387872696,-0.040694061666727066,-0.0073509179055690765,0.0476103276014328,0.0431961715221405,-0.009465452283620834,-0.02751826122403145,0.018416116014122963,0.0630146935582161,0.06222200766205788,0.06250972300767899,-0.03323334828019142,0.012929306365549564,0.014171812683343887,0.03787187859416008,0.06201907992362976,-0.038506682962179184,0.033851295709609985,0.008575926534831524,0.024160994216799736,0.059776194393634796,-0.03953905776143074,0.005802967585623264,0.017132854089140892,-0.02805837243795395,-0.028277894482016563,-0.013641518540680408,0.03462005406618118,-0.03825581818819046,0.04599497839808464,0.06029077246785164,-0.021629557013511658,-0.015853842720389366,0.03705822676420212,-0.0318591445684433,-0.016403665766119957,-0.012554618529975414,-0.019767247140407562,0.06307744234800339,-0.024762218818068504,0.04589458927512169,-0.00955970212817192,0.040083304047584534,0.00874701701104641,0.05415428429841995,0.04019423574209213,0.043995410203933716,0.062137503176927567,0.043513309210538864,-0.010467018000781536,0.0012541631003841758,0.060400597751140594,-0.004715337418019772,0.003274342743679881,0.06250961124897003,-0.035247303545475006,-0.03893828019499779,0.049400392919778824,-0.0039725229144096375,-0.010596475563943386,-0.024822833016514778,0.017368720844388008,0.0325910858809948,-0.03398223966360092,-0.037797536700963974,0.01090872474014759,0.04241393879055977,-0.02638450264930725,-0.006120279431343079,0.0029399306513369083,0.06144729629158974,-0.00892298948019743,0.017554327845573425,-0.006485366262495518,0.06307794898748398,-0.032569464296102524,0.0021217556204646826,0.0168963260948658,0.03420119360089302,0.023427894338965416,0.03868813067674637,0.011548747308552265,0.06272980570793152,0.04173245280981064,0.04538402333855629,-0.0008965663146227598,0.050296541303396225,0.06328397989273071,-0.02797003835439682,-0.028640499338507652,0.05531207099556923,0.027627693489193916,0.03166375681757927,-0.0027792437467724085,0.006708451546728611,0.049465011805295944,0.01583867333829403,-0.00151694449596107,0.008626403287053108,-0.03967706486582756,0.06267888098955154,0.02927563525736332,-0.029107481241226196,0.057824503630399704,0.05211588740348816,0.036558058112859726,0.007425194606184959,-0.01215299777686596,0.014440097846090794,0.0488094724714756,0.06015229970216751,-0.02364303171634674,0.04179605096578598,-0.012880293652415276,0.015277816914021969,-0.006994846276938915,0.06284685432910919,0.008889560587704182,-0.005951979197561741,0.05495065823197365,0.02657310664653778,-0.008534565567970276,0.031627755612134933,-0.033430881798267365,-0.01316710002720356,-0.002317900536581874,0.06213974207639694,0.02228953130543232,-0.04010143503546715,-0.04090080410242081,-0.010931328870356083,0.04300146922469139,0.011964024975895882,0.062226198613643646,0.05282239615917206,0.06084362044930458,-0.030612949281930923,0.057463906705379486,-0.03246968239545822,0.058117903769016266,-0.028134774416685104,0.05064592882990837,-0.0038477901834994555,0.06286506354808807,-0.006161695346236229,0.004789311438798904,0.062100525945425034,-0.04006033390760422],\"z\":[0.006342090666294098,0.006509134545922279,0.006744640879333019,0.006436913274228573,0.006579388864338398,0.006549455225467682,0.0065567754209041595,0.006592579185962677,0.006414036266505718,0.006576617248356342,0.006469196639955044,0.006514382548630238,0.0068180616945028305,0.0065109096467494965,0.006804749369621277,0.006561201997101307,0.006565418094396591,0.006433169357478619,0.006717405281960964,0.0066987089812755585,0.006485098972916603,0.006414922885596752,0.006335197016596794,0.006798367947340012,0.006502815522253513,0.006412583403289318,0.006370938383042812,0.006602130830287933,0.006679966114461422,0.0066093215718865395,0.0064580366015434265,0.006706110201776028,0.006714005023241043,0.006872513331472874,0.006421295925974846,0.006667874753475189,0.006414366886019707,0.006493351422250271,0.006954108364880085,0.006638903170824051,0.006586343981325626,0.006430092267692089,0.006663593463599682,0.006645028479397297,0.006592876277863979,0.006780775263905525,0.006569667719304562,0.0066717518493533134,0.00659459363669157,0.006453333422541618,0.0065786950290203094,0.00646629836410284,0.006823315285146236,0.006755285896360874,0.00649418868124485,0.006719433702528477,0.006619923748075962,0.006538870744407177,0.006566950120031834,0.006449095904827118,0.006562485359609127,0.006681323051452637,0.006336729973554611,0.0064633311703801155,0.0065277256071567535,0.006540767848491669,0.006490672938525677,0.00645995419472456,0.006527896039187908,0.006456187926232815,0.006814371794462204,0.006489882245659828,0.006668071262538433,0.006793925538659096,0.006550136022269726,0.006432925350964069,0.006644386798143387,0.006568784825503826,0.006461934186518192,0.006494925357401371,0.006542082875967026,0.006622261367738247,0.006399356760084629,0.006850793957710266,0.0065981484949588776,0.006454378366470337,0.006511854939162731,0.006379842758178711,0.006438851356506348,0.006533754989504814,0.0063471561297774315,0.006600761786103249,0.006596083752810955,0.006718512624502182,0.006358935497701168,0.006495959125459194,0.006663627922534943,0.006486926227807999,0.006718812510371208,0.0062776291742920876,0.0065307822078466415,0.006712821312248707,0.006578408181667328,0.006510878913104534,0.0066491058096289635,0.006615271791815758,0.006629125215113163,0.006785206496715546,0.006390790455043316,0.006621329113841057,0.006772969849407673,0.006846629083156586,0.0066410452127456665,0.006455607712268829,0.006695137359201908,0.00666668638586998,0.006433065980672836,0.0067743705585598946,0.006564469076693058,0.006634724326431751,0.006835460662841797,0.006496940739452839,0.0065244585275650024,0.006556745618581772,0.006550378166139126,0.006304256618022919,0.0067136334255337715,0.006647538393735886,0.00661642849445343,0.0064118485897779465,0.006740309298038483,0.006452640518546104,0.006554263643920422,0.006645414046943188,0.006379434838891029,0.00656010489910841,0.006859428249299526,0.006669250316917896,0.006518416106700897,0.0065142009407281876,0.0062842098996043205,0.006460950709879398,0.006819164380431175,0.006564117036759853,0.006277109496295452,0.006391002796590328,0.006616010330617428,0.006469846703112125,0.0066291773691773415,0.0065612103790044785,0.006652970798313618,0.006750507280230522,0.006704658269882202,0.0065428512170910835,0.0066502951085567474,0.006268847733736038,0.006387988105416298,0.006629312410950661,0.006457074545323849,0.006860402412712574,0.006388918496668339,0.006582802161574364,0.006539014168083668,0.006581729277968407,0.006435244344174862,0.00641581229865551,0.006385681219398975,0.006544734351336956,0.00690053403377533,0.006335262209177017,0.006712186150252819,0.006669739261269569,0.006410012952983379,0.006269817240536213,0.006524387747049332,0.006541364826261997,0.006220734678208828,0.006507801823318005,0.006551486440002918,0.006571020931005478,0.0063724517822265625,0.00656447559595108,0.006452774628996849,0.006158080883324146,0.006597741506993771,0.006691800430417061,0.006654910743236542,0.006307195872068405,0.006710143759846687,0.006509088911116123,0.006635010242462158,0.006330425851047039,0.006535378284752369,0.006556701846420765,0.006818694993853569,0.006453227251768112,0.0066716307774186134,0.006729321554303169,0.006576514802873135,0.00651753693819046,0.006665670312941074,0.006488197483122349,0.006621306762099266,0.006664644926786423,0.006614387966692448,0.0065228985622525215,0.006475792266428471,0.006540889851748943,0.006760391406714916,0.00649624690413475,0.006490589119493961,0.006367783062160015,0.006716528907418251,0.006560713052749634,0.006532724015414715,0.006727868691086769,0.006390715949237347,0.00668860599398613,0.0066617876291275024,0.006655140779912472,0.00656125508248806,0.006572652608156204,0.006519392132759094,0.006361719220876694,0.006248592399060726,0.006764563731849194,0.006537649780511856,0.00650845468044281,0.0066474247723817825,0.00663988571614027,0.006572296842932701,0.006614093668758869,0.00670000072568655,0.00670417957007885,0.006760391406714916,0.006583987735211849,0.006521331146359444,0.00644390843808651,0.006615092046558857,0.006519385613501072,0.006496249698102474,0.006463047116994858,0.006541530601680279,0.006217751652002335,0.00673845037817955,0.006473219022154808,0.006470574997365475,0.006705297157168388,0.006544741801917553,0.006677404046058655,0.006574970670044422,0.006471709348261356,0.006535978056490421,0.006607905961573124,0.006409891881048679,0.006701663136482239,0.006618699058890343,0.006617468781769276,0.006406733766198158,0.006394285708665848,0.006628288887441158,0.006410412490367889,0.006456305272877216,0.006575331091880798,0.00655723363161087,0.006650980561971664,0.006754136644303799,0.006551036611199379,0.006440852768719196,0.006469455547630787,0.006449352018535137,0.006538162007927895,0.006582528352737427,0.006572108715772629,0.00681070052087307,0.006810483522713184,0.006648292765021324,0.006312861107289791,0.006726299412548542,0.006568814627826214,0.006426935084164143,0.0064847106114029884,0.006502017378807068,0.006681391969323158,0.006771707907319069,0.006815209053456783,0.006752603687345982,0.006673598662018776,0.006436238065361977,0.006462186574935913,0.0064166635274887085,0.006609346717596054,0.0065366001799702644,0.006410279311239719,0.006250839680433273,0.006750857457518578,0.006622628308832645,0.006578980013728142,0.006695391610264778,0.0065708523616194725,0.006536683067679405,0.006457701325416565,0.006621494889259338,0.006876046769320965,0.0065272292122244835,0.006868788972496986,0.006538303568959236,0.00675378181040287,0.006681765429675579,0.006570612080395222,0.006467018276453018,0.006400761194527149,0.006604552268981934,0.006639045663177967,0.006193534005433321,0.00687052309513092,0.006704326719045639,0.006624067202210426,0.006540220230817795,0.006601739674806595,0.006339590065181255,0.006582536734640598,0.006703987717628479,0.006679263897240162,0.0067473407834768295,0.006452127359807491,0.006356162950396538,0.006470628082752228,0.006681232713162899,0.006665515713393688,0.0066496990621089935,0.006508214399218559,0.006886626593768597,0.006671535782516003,0.006686024367809296,0.006727032363414764,0.006780700758099556,0.006442931480705738,0.006629330106079578,0.006738482043147087,0.006687695160508156,0.006587152369320393,0.006852250546216965,0.0068236710503697395,0.006530268117785454,0.006803414784371853,0.006474786438047886,0.006563260219991207,0.006572918966412544,0.006545283831655979,0.0066388873383402824,0.0064398907124996185,0.006665918976068497,0.006909973919391632,0.006308848969638348,0.006724406033754349,0.006473308429121971,0.006475668400526047,0.006602086126804352,0.006671445444226265,0.0064195916056632996,0.006419043056666851,0.006380301900207996,0.006670134142041206,0.006409670226275921,0.00679855328053236,0.006447874009609222,0.006581478752195835,0.006528298370540142,0.006610052660107613,0.006631256081163883,0.006804413162171841,0.0066793542355299,0.00680703017860651,0.00654968898743391,0.006515919230878353,0.006485870108008385,0.006519823335111141,0.006583087146282196,0.00663840863853693,0.006463944911956787,0.006437432952225208,0.006571715697646141,0.006876599043607712,0.006780631840229034,0.006761801429092884,0.006395409815013409,0.006755081936717033,0.006649023853242397,0.006390866823494434,0.006360800936818123,0.006720500998198986,0.006649327464401722,0.006411148235201836,0.006682918407022953,0.006414264440536499,0.0066496143117547035,0.006582333706319332,0.006576860323548317,0.006670454517006874,0.006512913852930069,0.006845797412097454,0.006495462730526924,0.006500815972685814,0.0067138671875,0.006509952247142792,0.006752961315214634,0.006598916836082935,0.006443362683057785,0.006629584357142448,0.0066376375034451485,0.0066695138812065125,0.006555765867233276,0.006361856125295162,0.0064979176968336105,0.0065660132095217705,0.006481314077973366,0.006482700817286968,0.0063711898401379585,0.006372253410518169,0.006254903972148895,0.006637665443122387,0.006321805529296398,0.006545619107782841,0.006446512416005135,0.006264430470764637,0.006557300686836243,0.0065238457173109055,0.006806926801800728,0.0064710769802331924,0.006545625627040863,0.006665201857686043,0.006677065975964069,0.006536182947456837,0.006650127470493317,0.00630233995616436,0.006418769247829914,0.0063820891082286835,0.006563887000083923,0.006722205318510532,0.006325306370854378,0.006377294659614563,0.006376486271619797,0.006479569710791111,0.006555219180881977,0.006323853507637978,0.006442629732191563,0.0066652679815888405,0.006654891185462475,0.006391194649040699,0.006364724598824978,0.006402385421097279,0.006627683527767658,0.006623336113989353,0.00664430670440197,0.006481359712779522,0.0064577264711260796,0.006578210741281509,0.0068488651886582375,0.006620530039072037,0.006710476242005825,0.006451551802456379,0.006628477014601231,0.006679030135273933,0.006775246933102608,0.006329047493636608,0.006427908316254616,0.006714492104947567,0.006302013993263245,0.0063215019181370735,0.00641095545142889,0.0066206688061356544,0.006740277633070946,0.00653215404599905,0.006541505455970764,0.0065596746280789375,0.006758770905435085,0.006246916018426418,0.006753452122211456,0.006318640895187855,0.0064778514206409454,0.006281358189880848,0.006564232520759106,0.0064848642796278,0.006640068255364895,0.006319099105894566,0.006599600426852703,0.006423621438443661,0.006596152670681477,0.006636578589677811,0.00650510098785162,0.006688208319246769,0.006386150605976582,0.006640687584877014,0.006601538509130478,0.0067879799753427505,0.006782883778214455,0.006581353023648262,0.006579564884305,0.0065559083595871925,0.006552194245159626,0.006554669700562954,0.0066352784633636475,0.006650022231042385,0.006716608069837093,0.006552430801093578,0.006521481089293957,0.006906379945576191,0.0065180473029613495,0.006625823676586151,0.006508246064186096,0.006639922969043255,0.006667744368314743,0.006374240852892399,0.006760867312550545,0.006474493071436882,0.00634387694299221,0.006521411240100861,0.006628497503697872,0.006356451660394669,0.006724249571561813,0.006518610753118992,0.006672734394669533,0.00653864536434412,0.006819451227784157,0.0066264932975173,0.006694433279335499,0.0065513839945197105,0.006640397012233734,0.006265085190534592,0.006637617014348507,0.006454175338149071,0.006473466753959656,0.006500910967588425,0.00668229628354311,0.006514357402920723,0.006562161259353161,0.0065155671909451485,0.006573865190148354,0.006410497240722179,0.006740223616361618,0.0065712640061974525,0.006376737728714943,0.006523597985506058,0.006773635745048523,0.006533805280923843,0.006521275267004967,0.0066354237496852875,0.0065056877210736275,0.006685960106551647,0.00678168423473835,0.006793292239308357,0.006548759527504444,0.006383918225765228,0.006457793526351452,0.006784308701753616,0.006679845973849297,0.00645988155156374,0.006711550056934357,0.006569722667336464,0.006558088585734367,0.006575728766620159,0.00676743034273386,0.0065906113013625145,0.006670024245977402,0.00654582679271698,0.006688866764307022,0.006520782597362995,0.00674331933259964,0.006556818261742592,0.006578341126441956,0.006441625766456127,0.006426817737519741,0.0066549889743328094,0.006802309304475784,0.006530961953103542,0.006742621771991253,0.006418166682124138,0.006569604389369488,0.006552213802933693,0.006695707328617573,0.006501255556941032,0.006224448326975107,0.006816789507865906,0.006381392478942871,0.0064445845782756805,0.006646603345870972,0.006313258782029152,0.006381151266396046,0.006651819683611393,0.006480309180915356,0.006565894931554794,0.006492425687611103,0.006416598334908485,0.0064767953008413315,0.006402529776096344,0.006789187900722027,0.006495656445622444,0.006817099638283253,0.006560405716300011,0.0066232336685061455,0.0067301345989108086,0.006571941077709198,0.006745040416717529,0.006712258793413639,0.006691337563097477,0.006544627249240875,0.006409609690308571,0.0065696705132722855,0.006687747314572334,0.0064020222052931786,0.006587141193449497,0.006519070826470852,0.006663801148533821,0.006559324450790882,0.006658582948148251,0.006571059115231037,0.006536201573908329,0.0061890967190265656,0.006636424921452999,0.006631265394389629,0.006625579670071602,0.006541017442941666,0.006640714593231678,0.006585787981748581,0.00676207710057497,0.006685955449938774,0.006660342216491699,0.006490614265203476,0.006469422951340675,0.006805846467614174,0.0064842430874705315,0.0067505016922950745,0.006660904735326767,0.006466497667133808,0.006764864549040794,0.006500932388007641,0.006393712945282459,0.006413794122636318,0.006861303001642227,0.006523537449538708,0.006656092591583729,0.006781764328479767,0.006274744868278503,0.006540358066558838,0.00656367652118206,0.006515746936202049,0.006681507453322411,0.00649070180952549,0.0065446821972727776,0.006544227711856365,0.006480704061686993,0.006630079820752144,0.006676414981484413,0.006327492184937,0.006730254739522934,0.0064954208210110664,0.006406226195394993,0.006326158531010151,0.006454530172049999,0.00650409609079361,0.006656402722001076,0.00634831003844738,0.00675999466329813,0.006667717359960079,0.006650096736848354,0.006505013443529606,0.006313295103609562,0.006805030629038811,0.006528712809085846,0.0064149294048547745,0.006418969482183456,0.006387188099324703,0.006426209583878517,0.006747509352862835,0.006638272665441036,0.006630671210587025,0.006455175578594208,0.006792331114411354,0.006729731336236,0.0064101023599505424,0.006773863919079304,0.0068340059369802475,0.006560950540006161,0.0064794886857271194,0.006584438495337963,0.006550824269652367,0.006512594409286976,0.006664954125881195,0.006610996089875698,0.006654584780335426,0.006805160082876682,0.006470796652138233,0.006686351262032986,0.006612889468669891,0.006519921123981476,0.006693181581795216,0.0065772878006100655,0.0066452305763959885,0.006467391736805439,0.0065896399319171906,0.006620327010750771,0.006684187799692154,0.006714479997754097,0.006396948359906673,0.006472661159932613,0.0067368969321250916,0.006538921035826206,0.006750245578587055,0.006508976221084595,0.006518534384667873,0.006251834332942963,0.006289448589086533,0.006643456406891346,0.0065458109602332115,0.006745082326233387,0.006576252169907093,0.006453299894928932,0.0066043175756931305,0.006509202532470226,0.006419920362532139,0.006428305990993977,0.006740120239555836,0.006509517319500446,0.006772337481379509,0.006901177577674389,0.006673306226730347,0.00629215594381094,0.006364187225699425,0.006321952678263187,0.006222867406904697,0.006818709895014763,0.006410003639757633,0.006555723026394844,0.006475550122559071,0.00652310810983181,0.006559130735695362,0.006802843883633614,0.0064431969076395035,0.006622678600251675],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"val\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('be330e24-a01f-4fe8-8797-4cccfbc701bb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-28ae263c7bfb>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-34a20f380e0e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmaromba_only\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         pool = (\n\u001b[0;32m--> 171\u001b[0;31m             MTensor.reshape(\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfeat_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-25-29f8b7222352>\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# batch_mdot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     mdot = _rdot(\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-e0503664c9ec>\u001b[0m in \u001b[0;36m_rdot\u001b[0;34m(u, v, *args)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_d_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0md_u\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nsbmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0m_d_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0md_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   dot = (\n",
            "\u001b[0;32m<ipython-input-13-e0503664c9ec>\u001b[0m in \u001b[0;36m_nsbmd\u001b[0;34m(u, v, idxu, idxv, bias)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;31m# alpha = min(0.999, alpha)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m   \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.97\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m   \u001b[0midxuv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxuv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0midxuv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midxuv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m     r\"\"\"relu(input, inplace=False) -> Tensor\n\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = True\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784, 784, 784, 784, 1,],\n",
        "        \"samples\": [9, 18, 36, 54, 784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [2, 4, 6, 1, num_classes,],\n",
        "        \"samples\": [9, 9, 9, 9, 784,],\n",
        "        \"is conv\": [False, False, False, False, False]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.MW.idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 10 # 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.MW.idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    ###\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    _loss = loss.item()\n",
        "    # loss += 1e-1 * torch.cat(model._penalties, dim=0).sum()\n",
        "    ###\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(_loss)\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 3\n",
        "    _batchidx = 0\n",
        "    # pool = model.all_pools[_layer]\n",
        "    # pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "    # display.clear_output(wait=True)\n",
        "    # plot_features(pool)\n",
        "    # from time import sleep\n",
        "    # sleep(3)\n",
        "    #\n",
        "    pool = model.all_samples[_layer - 1]\n",
        "    _shape = (\n",
        "        model._curr_sets[_layer - 1],\n",
        "        model._curr_samples[_layer - 1],\n",
        "    )\n",
        "    _set = (model._curr_sets[_layer - 1]) // 2\n",
        "    pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "    display.clear_output(wait=True)\n",
        "    plot_features(pool)\n",
        "    from time import sleep\n",
        "    sleep(3)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "outputs": [],
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "##\n",
        "# phi = idxu[0] @ idxv[0].T\n",
        "# import seaborn as sns\n",
        "# sns.heatmap(phi.cpu().detach().numpy()); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "ilOucSYLd2zy",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "1SknOTQ7O9BS",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "8_m1YvjxBdj9",
        "Y-K_7fUh2anJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyObDcYuLf7dz368agpQS+0I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}