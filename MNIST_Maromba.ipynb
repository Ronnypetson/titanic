{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6406a996-0039-41c8-a610-92b0db7a836d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 117182285.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 4488248.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 55495800.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 24933345.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 113592252.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 5777248.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 63391447.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 7886149.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ],
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0):\n",
        "  idx = np.zeros((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = int(np.log((d_u + d_v) // 2)) * 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    ###\n",
        "    mdot = _nsbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # ###\n",
        "    midx = (\n",
        "        _nsbmd(aidx, onesb, aidx, bidx)\n",
        "        + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    # midx = _nsbmd(aidx, bidx, aidx, bidx)\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _rdot(aidx, onesb, aidx, bidx)\n",
        "    #     + _rdot(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "# def idx2d(\n",
        "#     channels: int,\n",
        "#     rows: int,\n",
        "#     cols: int,\n",
        "#     w: int,\n",
        "#     h: int,\n",
        "#     stride: int=2,\n",
        "#     dilation: int=1,\n",
        "#     device=\"cpu\"\n",
        "#   ):\n",
        "#   idx = []\n",
        "#   dilh = 1 + dilation * (h - 1)\n",
        "#   dilw = 1 + dilation * (w - 1)\n",
        "#   for row in range(0, rows - (dilh - 1), stride):\n",
        "#     for col in range(0, cols - (dilw - 1), stride):\n",
        "#       for ch in range(channels):\n",
        "#         for drow in range(0, dilh, dilation):\n",
        "#           for dcol in range(0, dilw, dilation):\n",
        "#             idx.append(\n",
        "#                 cols * rows * ch\n",
        "#                 + cols * (row + drow)\n",
        "#                 + (col + dcol)\n",
        "#             )\n",
        "#   idx = torch.tensor(idx).long().to(device)\n",
        "#   return idx\n",
        "\n",
        "# def unsort(idxs):\n",
        "#   ridxs = [0 for _ in idxs]\n",
        "#   for i, idx in enumerate(idxs):\n",
        "#     ridxs[idx] = i\n",
        "#   ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "#   return ridxs\n",
        "\n",
        "# def get_perms(tmp_idx):\n",
        "#   idxs, _idxs = [], []\n",
        "#   for dim in range(tmp_idx.shape[-1]):\n",
        "#     ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "#     idxs.append(ordering.cpu().detach())\n",
        "#     _idxs.append(unsort(ordering).cpu().detach())\n",
        "#   return idxs, _idxs\n",
        "\n",
        "# def resort(k, src, tgt):\n",
        "#   assert src == 0 or tgt == 0\n",
        "#   global idxs, _idxs\n",
        "#   if tgt == 0:\n",
        "#     return idxs[src][k]\n",
        "#   return _idxs[tgt][k]\n",
        "\n",
        "# def hoods(dims, k0, w, _min=0, _max=None):\n",
        "#   assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "#   if len(dims) == 0:\n",
        "#     return [k0] # [k0.item()]\n",
        "#   _hoods = []\n",
        "#   global idxs, _idxs\n",
        "#   _k0d = resort(k0, 0, dims[-1]) #, idxs, _idxs)\n",
        "#   for _w in range(-(w[-1] // 2), (w[-1] // 2) + (w[-1] % 2)):\n",
        "#     # k0d = min(_max, max(_min, _k0d + _w))\n",
        "#     k0d = torch.clip(_k0d + _w, min=_min, max=_max)\n",
        "#     _hoods += hoods(\n",
        "#         dims[:-1],\n",
        "#         resort(\n",
        "#             k0d,\n",
        "#             dims[-1], 0,\n",
        "#             # idxs, _idxs\n",
        "#         ),\n",
        "#         w[:-1],\n",
        "#         # idxs, _idxs,\n",
        "#         _min, _max\n",
        "#     )\n",
        "#   return _hoods\n",
        "\n",
        "# idxs, _idxs = None, None\n",
        "\n",
        "# def _idxhood(xidx, ws, stride):\n",
        "#   \"\"\"\n",
        "#   xidx: in_dim x idx_dim\n",
        "#   \"\"\"\n",
        "#   dims = tuple(range(xidx.shape[-1]))\n",
        "#   global idxs, _idxs\n",
        "#   idxs, _idxs = get_perms(xidx)\n",
        "#   pivots = torch.tensor([piv for piv in range(0, len(xidx), stride)]).long()\n",
        "#   all_hoods = hoods(dims, pivots, ws, 0, len(xidx) - 1)\n",
        "#   # all_hoods = torch.tensor(all_hoods).long().T.reshape(-1)\n",
        "#   all_hoods = torch.cat(all_hoods, dim=0).reshape(len(all_hoods), -1).T\n",
        "#   all_hoods = all_hoods.reshape(-1)\n",
        "#   # Pdb().set_trace()\n",
        "#   return all_hoods\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    _std = 0.01\n",
        "    self._ones_idx = nn.Parameter(\n",
        "        _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    )\n",
        "    self.activation = nn.ELU()\n",
        "    # self.activation = nn.ReLU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    # _W = nn.Parameter(\n",
        "    #     2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    # )\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _std = 0.01\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        _std * torch.randn((*shape, idxdim), device=device)\n",
        "    )\n",
        "    # _W_idx = _std * torch.randn((*shape, idxdim), device=device)\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        # indices=torch.zeros(n, 1, idx_dim).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      pool = (\n",
        "          self._put_one(MTensor.reshape(\n",
        "              pool, (n * feat_sets[step], -1)\n",
        "          ))\n",
        "          @ mw\n",
        "      )\n",
        "      # pool = (\n",
        "      #     MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     )\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      # pool = (\n",
        "      #     MTensor.reshape(pool, (n * feat_sets[step], -1))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      self.all_pools.append(pool[:4])\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim) ### offset=0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "HNheVxvNNK30",
        "outputId": "a715741a-0caa-4df5-e31c-dff9c944cde0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e5120073ada2>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# model = MModule(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# model = MModule2(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   model = MModule3(\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0midx_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MModule3' is not defined"
          ]
        }
      ],
      "source": [
        "hidden_dim = 50\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    (2, 3, 3),\n",
        "    (2, 3, 3),\n",
        "    # (2, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    hidden_dim,\n",
        "]\n",
        "\n",
        "sets = [samp[0] for samp in samples[1:-1]] + [1, num_classes]\n",
        "_samples = [int(np.prod(samp)) for samp in samples]\n",
        "conv_params = int(np.array(_samples[:-1]).dot(np.array(sets[:-1])))\n",
        "# conv_params = int(np.prod(np.array(samples[:-1])))\n",
        "n_params = int(np.array(_samples).dot(np.array(sets)))\n",
        "# n_params = conv_params + hidden_dim * num_classes\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  # model = MModule2(\n",
        "  model = MModule3(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "64be4bb4-c91b-4b50-bc50-010b4059126e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784,    784,     784,     784,    1,],\n",
        "        \"samples\": [9,      36,      36,      1,      784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [4,      4,       4,       1,      num_classes,],\n",
        "        \"samples\": [(9, 1), (36, 1), (36, 1), (4, 1), (32, 1),],\n",
        "        \"is conv\": [False,  False,   False,   False,  False]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  # widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    metric_cols = [\"train loss\"]\n",
        "  group_cols = [\"epoch\"] + metric_cols\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    .reset_index()\n",
        "    .sort_values(\"epoch\", ascending=True)\n",
        "    .tail(30)[[\"train loss\"]]\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "ilOucSYLd2zy",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "Lyzd22RQX-Yg"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPua23ChKRbw82SR4gaG4c1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}