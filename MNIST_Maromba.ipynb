{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea294bd-c74a-418d-c3e6-c63ce729b7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 20794562.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 338560.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6119616.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 22214276.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 20247182.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 342019.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6069982.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 15556395.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return (\n",
        "  #     cifar10_norm(tr(x))\n",
        "  #     .reshape(channels, img_dim, img_dim)\n",
        "  #     .permute(1, 2, 0)\n",
        "  #     .reshape(-1)\n",
        "  # )\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x)).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "outputs": [],
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "outputs": [],
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "outputs": [],
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 0.01 * ((ch  + offset) /  chs) - 0.05\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx\n",
        "\n",
        "def _cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = (row + offset)\n",
        "        idx[row, col, ch, 1] = (col + offset)\n",
        "        idx[row, col, ch, 2] = (ch  + offset)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "def poly1norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  idxu = (0.5 ** 0.5) * torch.cat([idxu, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "def poly2norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  _idxu = idxu.reshape((-1, d_idx, 1))\n",
        "  middle = (\n",
        "      torch.bmm(_idxu, _idxu.permute(0, 2, 1))\n",
        "      .reshape((*idxu.shape[:-1], d_idx ** 2))\n",
        "  )\n",
        "  idxu = 0.5 * torch.cat([(2.0 ** 0.5) * idxu, middle, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "from collections import defaultdict as dd\n",
        "from itertools import product\n",
        "\n",
        "@lru_cache()\n",
        "def poly_terms(idx_dim, degree):\n",
        "  combs = dd(int)\n",
        "  ranges = (range(idx_dim) for _ in range(degree))\n",
        "  for idxs in product(*ranges):\n",
        "      comb = tuple(sorted(idxs))\n",
        "      combs[comb] += 1\n",
        "  return list(combs.items())\n",
        "\n",
        "\"\"\"\n",
        "sigmoid(8*x - 4)\n",
        "1/(1 + e^4)\n",
        "+ (8 e^4 x)/(1 + e^4)^2\n",
        "+ (32 e^4 (e^4 - 1) x^2)/(1 + e^4)^3\n",
        "+ (256 (e^4 - 4 e^8 + e^12) x^3)/(3 (1 + e^4)^4)\n",
        "+ (512 e^4 (-1 + 11 e^4 - 11 e^8 + e^12) x^4)/(3 (1 + e^4)^5)\n",
        "+ (4096 (e^4 - 26 e^8 + 66 e^12 - 26 e^16 + e^20) x^5)/(15 (1 + e^4)^6)\n",
        "+ O(x^6)\n",
        "(Taylor series)\n",
        "-------------------------\n",
        "0.017986  * x^0\n",
        "0.14130   * x^1\n",
        "0.5448747 * x^2\n",
        "1.3474883 * x^3\n",
        "2.290065  * x^4\n",
        "2.4479883 * x^5\n",
        "\"\"\"\n",
        "\n",
        "def poly_norm(idxu, degree):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  pre_shape = idxu.shape[:-1]\n",
        "  idx_dim = idxu.shape[-1]\n",
        "  idxu = normalized(idxu)\n",
        "  terms = poly_terms(idx_dim, degree)\n",
        "  factors = torch.tensor([term[1] for term in terms]).float().to(idxu.device)\n",
        "  factors = factors ** 0.5\n",
        "  intidx = torch.tensor([list(term[0]) for term in terms]).long().to(idxu.device)\n",
        "  intidx = intidx.reshape(-1)\n",
        "  idxu = idxu.reshape(-1, idx_dim)[:, intidx]\n",
        "  idxu = idxu.reshape(*pre_shape, degree, -1)\n",
        "  idxu = idxu.prod(dim=-2) * factors.reshape(*((1,) * len(pre_shape)), idxu.shape[-1])\n",
        "  return idxu\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _knndot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"k-NN Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  num_neigh = 1\n",
        "  dots = []\n",
        "  q_idxu = idxu.cpu().detach().numpy().reshape(-1, d_idx)\n",
        "  for _pos in range(n):\n",
        "    neigh = NearestNeighbors(n_neighbors=num_neigh, metric=\"cosine\")\n",
        "    neigh.fit(idxv[_pos].cpu().detach().numpy().reshape(-1, d_idx))\n",
        "    n_idxu = neigh.kneighbors(\n",
        "        q_idxu, return_distance=False\n",
        "    ).reshape(-1)\n",
        "    n_idxu = torch.from_numpy(n_idxu).long()\n",
        "    _v = v[_pos].reshape(-1, d_val)[n_idxu].reshape(m, d_u, d_val)\n",
        "    # _dot: M x d_val x d_val\n",
        "    _dot = torch.bmm(_v.permute(0, 2, 1), _v)\n",
        "    # _dot: M x 1 x d_val\n",
        "    _dot = torch.diagonal(_dot, dim1=1, dim2=2).unsqueeze(1)\n",
        "    dots.append(_dot)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.cat(dots, dim=1)\n",
        "  return dot\n",
        "\n",
        "def _icbmd(u, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Conv Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x 1 x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_v == 1\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: M x d_u x N\n",
        "  idxv = (\n",
        "      (idxu.reshape(m * d_u, d_idx))\n",
        "      @ idxv.permute(2, 1, 0).reshape(d_idx, n)\n",
        "  ).reshape(m, d_u, n)\n",
        "  # idxv: M x N x d\n",
        "  idxv = torch.bmm(\n",
        "      u.permute(0, 2, 1),\n",
        "      idxv\n",
        "  ).permute(0, 2, 1)\n",
        "  return idxv\n",
        "\n",
        "def _ibmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  v: N x d_v x d_valv\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu, d_valv = u.shape[-1], v.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxu = poly_norm(idxu, 1) # / (d_u)\n",
        "  # idxv = poly_norm(idxv, 1) # / (d_v)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: N x d_idx x d_valv\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxv: M x d_u x (d_valv * N)\n",
        "  idxv = (\n",
        "      idxu.reshape(m * d_u, d_idx)\n",
        "      @ idxv.permute(1, 2, 0).reshape(d_idx, d_valv * n)\n",
        "  ).reshape(m, d_u, d_valv * n)\n",
        "  # idxv: M x d_valu x (d_valv * N)\n",
        "  idxv = torch.bmm(u.permute(0, 2, 1), idxv)\n",
        "  if d_valv == 1:\n",
        "    # idxv: M x N x d_valu\n",
        "    idxv = idxv.reshape(m, d_valu, n).permute(0, 2, 1)\n",
        "  else:\n",
        "    # idxv: M x N x d_valu or error\n",
        "    idxv = idxv.reshape(m, d_valu, d_valv, n).permute(0, 3, 1, 2)\n",
        "    idxv = torch.diagonal(idxv, dim1=2, dim2=3)\n",
        "  return idxv\n",
        "\n",
        "def _fbmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Fast Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxu: M x d_val x d_idx\n",
        "  # idxv: N x d_idx x d_val\n",
        "  idxu = torch.bmm(u.permute(0, 2, 1), idxu)\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxu: M x N x d_val\n",
        "  idxu = (\n",
        "    (\n",
        "        idxu.reshape(m * d_val, d_idx)\n",
        "        @ (\n",
        "            idxv\n",
        "            .permute(0, 2, 1)\n",
        "            .reshape(n * d_val, d_idx)\n",
        "            .T\n",
        "          )\n",
        "    ).reshape(m, d_val, n, d_val)\n",
        "    .permute(0, 2, 1, 3)\n",
        "  )\n",
        "  idxu = torch.diagonal(idxu, dim1=2, dim2=3)\n",
        "  return idxu\n",
        "\n",
        "def batch_mdot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  if d_idx * (d_u + n) < n * d_u * (d_idx + 1):\n",
        "    return _fbmd(u, v, idxu, idxv)\n",
        "  else:\n",
        "    return _ibmd(u, v, idxu, idxv)\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  ###\n",
        "  # siter = 6\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  #### Tanh seems to work for high-dimensional idx\n",
        "  #### ReLU(x - alpha) / (1.0 - alpha) works for small samples\n",
        "  # alpha = 1.0 - 1.0 / d_v # 0.95\n",
        "  # alpha = min(0.999, alpha)\n",
        "  alpha = 0.97\n",
        "  idxuv = nn.functional.relu((idxuv - alpha) / (1.0 - alpha))\n",
        "  ###\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    ###\n",
        "    # _nsbmd\n",
        "    # _rdot\n",
        "    # _knndot\n",
        "    # _fbmd\n",
        "    # _ibmd, _mbmd\n",
        "    # batch_mdot\n",
        "    ###\n",
        "    mdot = _rdot(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    # _aidx = aidx.mean(dim=-2, keepdim=True)\n",
        "    # _bidx = bidx.mean(dim=-2, keepdim=True)\n",
        "    # onesa = torch.ones(_aidx.shape).to(_aidx.device)\n",
        "    # onesb = torch.ones(_bidx.shape).to(_bidx.device)\n",
        "    # midx = (\n",
        "    #     _nsbmd(_aidx, onesb, _aidx, _bidx)\n",
        "    #     + _nsbmd(onesa, _bidx, _aidx, _bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    _aidx = aidx.mean(dim=-2, keepdim=True)\n",
        "    _bidx = bidx.mean(dim=-2, keepdim=True)\n",
        "    _bnorm = _bidx.norm(dim=-1)\n",
        "    _bidx *= 0.0\n",
        "    _bidx[:, :, 2] = _bnorm\n",
        "    _aidx[:, :, 2] = 0.0\n",
        "    # midx = (\n",
        "    #     _aidx + _bidx.permute(1, 0, 2)\n",
        "    # ) / 2.0\n",
        "    # midx = (_aidx + _bidx.permute(1, 0, 2))\n",
        "    __bidx = (\n",
        "        torch.arange(1, _bidx.shape[0] + 1)\n",
        "        .to(_bidx.device)\n",
        "        .reshape(1, _bidx.shape[0], 1)\n",
        "        / (_bidx.shape[0])\n",
        "    )\n",
        "    midx = _aidx + 1e-3 * __bidx\n",
        "    ###\n",
        "    # midx = _icbmd(aidx, aidx, bidx.sum(dim=-2, keepdim=True)) # / aidx.shape[-2]\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  nneigh = min(nneigh, len(xidx))\n",
        "  neigh = NearestNeighbors(\n",
        "      n_neighbors=nneigh,\n",
        "      algorithm=\"brute\",\n",
        "      # metric=\"minkowski\",\n",
        "      # p=1,\n",
        "  )\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    num_sets = min(num_sets, len(xidx))\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False,\n",
        "    )\n",
        "    all_hoods = set(tuple(sorted(hood)) for hood in all_hoods)\n",
        "    all_hoods = np.array(list(all_hoods))\n",
        "    ###\n",
        "    hood_means = xidx[all_hoods.reshape(-1)]\n",
        "    hood_means = hood_means.reshape(len(all_hoods), nneigh, xidx.shape[-1])\n",
        "    hood_mins = hood_means.min(axis=1)[:, None, :]\n",
        "    hood_maxes = hood_means.max(axis=1)[:, None, :]\n",
        "    hood_norm = (hood_means - hood_mins) / (hood_maxes - hood_mins + 1e-6)\n",
        "    hood_norm_ = hood_norm.mean(axis=1)\n",
        "    hood_consensus = np.median(hood_norm_, axis=0)\n",
        "    hood_filter = (np.linalg.norm(hood_norm_ - hood_consensus[None, :], axis=1) < 1e-4)\n",
        "    all_hoods = all_hoods[hood_filter]\n",
        "    ###\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ) # .reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    # self._ones_idx = torch.zeros((1, 1, idx_dim), device=device)\n",
        "    # self.activation = nn.ELU()\n",
        "    self.activation = nn.ReLU()\n",
        "    # self.activation = nn.LeakyReLU()\n",
        "    self._probe = nn.Linear(self._feat_samples[-1], 10).to(device)\n",
        "    self._num_fwd = 0\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _mag = 0.1 # 2.0 # 1000.0 * 0.01\n",
        "    _W_idx = _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    ###\n",
        "    # _W_idx = _W_idx.reshape(-1, idxdim)\n",
        "    # _W_idx[:, 2] = 1.0\n",
        "    # _W_idx = _W_idx.reshape(*shape, idxdim)\n",
        "    ###\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #   _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    # )\n",
        "    # _std = 1.0\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #   _std * torch.randn((*shape, idxdim), device=device)\n",
        "    # )\n",
        "    # _W = torch.ones(shape).float().to(device)\n",
        "    _std = 0.01\n",
        "    # _W = _std * torch.randn(shape, device=device)\n",
        "    # _W = _mag * torch.rand(shape, device=device) - (_mag / 2.0)\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def _reinit_indices(self, pool, params):\n",
        "    \"\"\"\n",
        "    pool: N x mshape\n",
        "    params: param_shape\n",
        "    \"\"\"\n",
        "    idx_dim = pool.idx.shape[-1]\n",
        "    assert params.idx.shape[-1] == idx_dim\n",
        "    pool_idx = pool.idx.reshape(-1, idx_dim)\n",
        "    eps = 1e-6\n",
        "    idx_max = pool_idx.max(dim=0, keepdim=True)[0] + eps\n",
        "    idx_min = pool_idx.min(dim=0, keepdim=True)[0] - eps\n",
        "    idx_itv = idx_max - idx_min\n",
        "    n_samples = len(params.idx.reshape(-1, idx_dim))\n",
        "    sampled_idx = torch.rand((n_samples, idx_dim), device=pool.data.device)\n",
        "    sampled_idx = sampled_idx * idx_itv + idx_min\n",
        "    params.idx = sampled_idx\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = deepcopy(self._config[\"params\"][\"sets\"])\n",
        "    param_samples = deepcopy(self._config[\"params\"][\"samples\"])\n",
        "    feat_sets = deepcopy(self._config[\"features\"][\"sets\"])\n",
        "    feat_samples = deepcopy(self._config[\"features\"][\"samples\"])\n",
        "    ###\n",
        "    # self._curr_sets = feat_sets\n",
        "    # self._curr_samples = feat_samples\n",
        "    ###\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._num_fwd == 0:\n",
        "        self._reinit_indices(pool, self.MW[wl: wr])\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # idx_slice = pool.idx[0]\n",
        "        idx_slice = pool.idx[0, :, :3]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      ###\n",
        "      feat_sets[step] = idxx.shape[0]\n",
        "      feat_samples[step] = idxx.shape[1]\n",
        "      idxx = idxx.reshape(-1)\n",
        "      ###\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      ###\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      maromba_only = True\n",
        "      if maromba_only or (step < n_layers - 1):\n",
        "        pool = (\n",
        "            MTensor.reshape(\n",
        "                pool, (n * feat_sets[step], -1)\n",
        "            )\n",
        "            @ mw\n",
        "        )\n",
        "      else:\n",
        "        pool = self._probe(pool.data.reshape(n, -1))\n",
        "        pool = MTensor(\n",
        "            pool,\n",
        "            torch.zeros((*pool.shape, self._idx_dim)).to(pool.device)\n",
        "        )\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    self._num_fwd += 1\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # 500 # 3 # 10\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim, mag=2.0) # 1000.0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_m1YvjxBdj9"
      },
      "source": [
        "### Visualizações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "outputs": [],
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "0bd6c378-e2a9-4d41-80cb-c4449ab3755c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABSUAAAESCAYAAAALwbDgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhXUlEQVR4nO3deVxVdf7H8fe9l8u+CCogirtpbllqppZaIWqWMuW0S1bmWJiaTYu/KZdswsy0ZRxzdNI2szE1ywzFBYjSLJPcyjQ1VzA1QRbhwj2/P5CbV0G4plyB1/Px4BHnnO/3nM+5fubM9eP3fL8mwzAMAQAAAAAAAEAlMbs7AAAAAAAAAAA1C0VJAAAAAAAAAJWKoiQAAAAAAACASkVREgAAAAAAAECloigJAAAAAAAAoFJRlAQAAAAAAABQqShKAgAAAAAAAKhUHu4O4HJit9t16NAhBQQEyGQyuTscAAAAAAAAoEoxDEMnT55URESEzOayx0NSlDzDoUOHFBkZ6e4wAAAAAAAAgCpt//79atCgQZnHKUqeISAgQFLxhxYYGOjmaC4+m82mlStXKjo6Wlar1d3hoAogZ+AqcgauImfgKnIGriJn4CpyBq4iZ+Cq6p4zWVlZioyMdNTZykJR8gwlr2wHBgZW26Kkr6+vAgMDq2XS4+IjZ+AqcgauImfgKnIGriJn4CpyBq4iZ+CqmpIz5U2NyEI3AAAAAAAAACoVRUkAAAAAAAAAlYqiJAAAAAAAAIBKxZySAAAAAAAAqHR2u10FBQXuDqPS2Ww2eXh46NSpUyoqKnJ3OC6zWq2yWCx/+jwUJQEAAAAAAFCpCgoKtGfPHtntdneHUukMw1B4eLj2799f7mIwl6tatWopPDz8T8XvUlEyPj5eixcv1k8//SQfHx9169ZNL7/8slq2bFlmn8WLF+ull17Srl27ZLPZ1KJFCz355JMaPHiwo41hGBo/frxmz56tEydOqHv37po5c6ZatGghSdq7d68mTZqkNWvWKD09XREREbr//vv1j3/8Q56eno42TZo0Oef669at03XXXefKbQIAAAAAAOASMQxDhw8flsViUWRkpMzmmjW7oN1uV3Z2tvz9/avcvRuGodzcXB05ckSSVK9evQs+l0tFyeTkZMXFxalz584qLCzU//3f/yk6Olrbt2+Xn59fqX1CQkL0j3/8Q61atZKnp6eWLVumBx98UKGhoerTp48kacqUKXrjjTf0zjvvqEmTJnr++efVp08fbd++Xd7e3vrpp59kt9s1a9YsNW/eXFu3btUjjzyinJwcTZ061el6q1atUps2bRzbtWvXdvUzqba2H87SjhMmBf1yTB4WD51ZzD6nru107I+NswvgZ26eWR0/37mdz3EB5y7zXOePtawYyupT0XNfyP2d2+fi3d85ff7EuW02mzILpCMn82X1KDrnJBX/TFyPQWX8WVTqZ3cR76+q/usXAAAAAFxshYWFys3NVUREhHx9fd0dTqUreW3d29u7yhUlJcnHx0eSdOTIEYWGhl7wq9wuFSUTEhKctufNm6fQ0FBt3LhRPXr0KLVPr169nLZHjRqld955R6mpqerTp48Mw9Brr72m5557TgMHDpQkvfvuuwoLC9Mnn3yiu+++W3379lXfvn0d52jatKl27NihmTNnnlOUrF27tsLDw125rRpj2qpdSv7Zon//uNHdoaBK8dC4jcnuDqJa+9MFz7N7lXG+i110Les6hTaLJvywVhazSSaTSRaTSWaTZDabZD7rd4vJJJNJxb+bS2lnMjmOndPu9DGzuYx25zt2+neLqZSYzjqHyaTT1zx/7Oe0K++6Z7W9oHOc9RmUFjsFcQAAAFxuSuZRLHn7FVVPSTHZZrNVTlHybJmZmZKKR0NWhGEYWrNmjXbs2KGXX35ZkrRnzx6lp6crKirK0S4oKEhdunTRunXrdPfdd5d57dKuO2DAAJ06dUpXXHGFnn76aQ0YMKDMePLz85Wfn+/YzsrKklT8gdpstgrdU1VSP8hLEb6GAgL8dWYJwTCc2xkySj12ZrOz++gC+lTkOmd3Kut8zvvL7qML6ON8ndJjPltF+1TkOjpvH6OM/RXr49SmtD6GZBh2p4rV+fMAF6LM/D/7YNlnuIjRXAwm5eZWv2doVVVS3HQueJ5R9DSfW4A1nT5evM8ki7nkHH/87nwO5/Z/FG+d951dqDaZTTIZhg4fMuurT7bKw2I+f/vT1z933/kK2irlfs7oe1a8Z95PWcXuPz7LM85x9ufiKF6XXP/8sVM8rriS72jV8bsaLg1yBq4iZ+AqcsZ1NptNhmHIMIwaO6dkyX+r6v2X/PmVVpSs6P8WLrgoabfbNXr0aHXv3l1t27Y9b9vMzEzVr19f+fn5slgs+ve//63evXtLktLT0yVJYWFhTn3CwsIcx862a9cuvfnmm06jJP39/fXqq6+qe/fuMpvNWrRokWJiYvTJJ5+UWZiMj4/XxIkTz9m/cuXKajl8uIuH1OUqScp0dyioAc5baFMZxy6gT1k1u4txzbLOcd6CdAX2X1D/CvY5731fyGdVgT+Tcz43o3ifYUj2s/5rSLI7jpv+2F9mm9L3Ox2vUB+T8/4KXK/M6573es7XcbQ5o2+593NGjIbKjtk4d+KNUtkNyX76D9JWdLkVsEuYte7IIXcH4Vam03+iJpNkPv1fx+9nb5/ZRsWF5zP/W1xALWWfo49R5jnK61tmn1JiNMko/Rwl+0rOUYH7ObOtSZKXRcr4NFH+HpKPR/ExoDyJiYnuDgFVDDkDV5EzFefh4aHw8HBlZ2fXyNW3S5w8edLdIVywgoIC5eXlKSUlRYWFhU7HcnNzK3QOk1HWsKlyPProo/riiy+UmpqqBg0anLet3W7X7t27lZ2drdWrV2vSpEn65JNP1KtXL3399dfq3r27Dh065DQ55p133imTyaSPPvrI6VwHDx5Uz5491atXL82ZM+e8142NjdWePXv05Zdflnq8tJGSkZGROnr0qAIDA8v7CKocm82mxMRE9e7dW1ar1d3hoAogZ+AqcqbyGIYhuyEV2Y0/fj/9r5VF9uJCpGEYKjpdlLTbDUeBsnj7j/Z/nKd4X3Hf4n2O9mef5+zzlRNLaecoshsqLCrSzp071aRpM5nMZhXZVco5jNNFXeN0fGdd3+7c/sxYStqXxHLuvnM/l5Lfy4rFON2+yOlzKi2+4t9xaVnMJoX4WlXbz1Mhp39q+3s6tmuf/gnx91SIr6f8vSyMTK1h+P8muIqcgavIGdedOnVK+/fvV+PGjeXt7e3ucCqdYRg6efKkAgICquz3klOnTmnv3r2KjIw8588wKytLderUUWZm5nnraxc0UnLEiBFatmyZUlJSyi1ISpLZbFbz5s0lSR06dNCPP/6o+Ph49erVyzH/Y0ZGhlNRMiMjQx06dHA6z6FDh3TjjTeqW7du+s9//lPudbt06XLef6nw8vKSl5fXOfutVmu1fpBU9/vDxUfOwFXkDCrKZrNped7PuiXqimqbMyUFypIipv3MYqj9rILtGYXPovMcs59dULVXsN1ZRdOzi6znxHR27PYy2p2OwdV7vJD4iorsOnI8U6dkVdapQhXZDf2WXaDfsis2ysLTw6w6fp6q7e/lKGDW8fdyFDHr+HsVFzVP7/O2XtgcSbj88P9NcBU5A1eRMxVXVFRUPMWN2VwlF3r5s0pe2W7WrJlGjx6t0aNHX/C5Gjdu/KfPcSHMZrNMJlOpeV/R/x24VJQ0DEOPP/64lixZoqSkJDVp0sSV7g52u90xQrFJkyYKDw/X6tWrHUXIrKwsffPNN3r00UcdfQ4ePKgbb7xRHTt21Ny5cyuUtGlpaX9qaXIAAIA/y2w2ySzTn5vIGw42m03Lly/XLbf0kWGy6PfcAh3Nztex7AIdyyn5b4GOnd53NKdAx0/vzy0oUkGhXYcyT+lQ5qkKXc/P01JcoPT3VG2/4kJlSdGyjn/JaMzi34P9PGW11Ly/WAEAUFP06tVLHTp00GuvvXZRzvfNN98oICDgopyrKnLp+3FcXJzmz5+vpUuXKiAgwDHnY1BQkGM58NjYWNWvX1/x8fGSiudt7NSpk5o1a6b8/HwtX75c7733nmbOnCmpeGL30aNH68UXX1SLFi3UpEkTPf/884qIiFBMTIyk4oJkr1691KhRI02dOlW//fabI6aSkZbvvPOOPD09dfXVV0uSFi9erLfffrvcV7wBAABQNXl6mBUW6K2wwIq99pVbUKhj2QU6nlNcwDyaXXB6+48C5rHs/OLj2QUqKLIrp6BIOcdzte94xeZGCvKxFo++9CsuZIb4/VHArO3ndXo0ZvG+Wj5WmZkQEwCAasUwDBUVFcnDo/ySW926dWvkSNESLhUlSwqJvXr1cto/d+5cDRkyRJK0b98+pw80JydHjz32mA4cOCAfHx+1atVK77//vu666y5Hm6efflo5OTkaNmyYTpw4oeuvv14JCQmOd9ITExO1a9cu7dq165zXxc+cEnPSpEn69ddf5eHhoVatWumjjz7SoEGDXLlFAAAAVFO+nh7yDfFQZEj5CxoahqGT+YWOomVJAfNYdn7xSMwzRmMeyykuZNoNKTPPpsw8m3b/llPuNcwmOUZanvnKeO3ThcySuTFLfg/w8qiy804BAHA+hmEoz1bklmv7WCs23/SQIUOUnJys5ORkvf7665KkPXv2aO/evbrxxhu1fPlyPffcc9qyZYtWrlypyMhIjRkzRuvXr1dOTo6uvPJKxcfHKyoqynHOpk2bOr16bTKZNHv2bH3++edasWKF6tevr1dffbXMBZxLs2/fPj3++ONavXq1zGaz+vbtqzfffNOxwPQPP/yg0aNH67vvvpPJZFKLFi00a9YsderUSb/++qtGjBih1NRUFRQUqHHjxnrllVd0yy23uPCJVpzLr2+XJykpyWn7xRdf1IsvvnjePiaTSS+88IJeeOGFUo8PGTLEUfQsywMPPKAHHnig3PgAAACA8phMJgV6WxXobVWTOn7ltrfbDZ3Is+lYdnEB03k05h+jL4+eHpWZmWeT3ZCOZhfoaHaBlFF+TJ4W8x8L+fh7qY7fHyMxi+fGPHM0ppd8PJkPEwBQNeTZitR63Aq3XHv7C33k61l+eez111/Xzz//rLZt2zrqV3Xr1tXevXslSc8++6ymTp2qpk2bKjg4WPv379ctt9yif/7zn/Ly8tK7776r2267TTt27Djv+iwTJ07UlClT9Morr+jNN9/Ufffdp19//VUhISHlxmi32zVw4ED5+/srOTlZhYWFiouL01133eWo19133326+uqrNXPmTFksFqWlpTnmgIyLi1NBQYFSUlLk5+en7du3y9/fv9zrXiimNwIAAAD+JLPZ5Fj9u0VY+e1tRXb9nlNckCwZaVlSwHTMi1kyR2Z2vnIKilRQZFd61imlZ1VsPkxfT8vpV8i9Ti/uc8ZoTP8zRmieLmR6etTc18cAAChPUFCQPD095evr65hK8EwvvPCCevfu7dgOCQnRVVdd5dieNGmSlixZok8//VSPPfZYmdcZMmSI7rnnHknSSy+9pDfeeEMbNmxQ3759y41x9erV2rJli/bs2aPIyEhJ0rvvvqs2bdro22+/VefOnbVv3z499dRTatWqlSSpRYsWjv779u3THXfcoXbt2kkqHsl5KVGUBAAAACqZ1WJWaKC3Qis4H+YpW9FZr4z/8Sr50TNGYh7LztfRnAIVFNqVW1Ck3ON52n88r0LXCPT2UJ0zViUvfTRm8fFgX09ZmA8TAHCR+Fgt2v5CH7dd+2Lo1KmT03Z2drYmTJigzz//XIcPH1ZhYaHy8vK0b9++856nffv2jt/9/PwUGBioI0eOVCiGH3/8UZGRkY6CpCS1bt1atWrV0o8//qjOnTtrzJgxGjp0qN577z1FRUXpr3/9q5o1ayZJGjlypB599FGtXLlSUVFRuuOOO5ziudgoSgIAAACXOW+rRfVr+ah+LZ9y2xqGoZyCIser5CXFy+M5pa9UfjynQEV2Q1mnCpV1qlC7j5Y/H6bJJIX4ejov5nP6v2cu5lP79JyZgT7MhwkAKJvJZKrQK9SXMz8/5+le/v73vysxMVFTp05V8+bN5ePjo0GDBqmgoOC85yl5lbqEyWSS3W6/aHFOmDBB9957rz7//HN98cUXGj9+vBYsWKC//OUvGjp0qPr06aPPP/9cK1euVHx8vF599VU9/vjjF+36Z6raf+IAAAAAnJhMJvl7ecjfy0ONaldsPszMPJvT6Ms//vvH3JjHT+//Pdcmw5BjwZ+KsFpMzov6nL2Yj98fIzFr+3tW+b+YAgCqJ09PTxUVVWxBnq+++kpDhgzRX/7yF0nFIydL5p+8VK688krt379f+/fvd4yW3L59u06cOKHWrVs72l1xxRW64oor9MQTT+iee+7R3LlzHXFGRkZq+PDhGj58uMaOHavZs2dTlAQAAABw8ZnNJgX7eSrYz1PNQ8ufzL6wyK7juQV/LN5zevRlWYv7nMwvlK3IUEZWvjKy8isUk7fVrNp+Xo4RlyWvlNc5XbwsWcyn5HcvDxb1AQBceo0bN9Y333yjvXv3yt/f/7yLz7Ro0UKLFy/WbbfdJpPJpOeff/6ijngsTVRUlNq1a6f77rtPr732mgoLC/XYY4+pZ8+e6tSpk/Ly8vTUU09p0KBBatKkiQ4cOKBvv/1Wd9xxhyRp9OjR6tevn6644gr9/vvvWrt2ra688spLFi9FSQAAAAAV5mExKzTAW6EBFZ8P8/gZoy7Pfn38zFGZR7PzlV9o1ymbXQdP5OngiYrNhxng5VHmQj61vC3amWlSs/STCqvlp2BfqzwsLOoDAHDd3//+dz3wwANq3bq18vLytGfPnjLbTps2TQ899JC6deumOnXq6JlnnlFWVtYljc9kMmnp0qV6/PHH1aNHD5nNZvXt21dvvvmmJMlisejYsWOKjY1VRkaG6tSpo9tvv10TJ06UJBUVFSkuLk4HDhxQYGCg+vbtq+nTp1+yeClKAgAAALhkvK0WRdTyUUQF58PMLSgqLlDm5Ot49pmjLwt0PKdkcZ8/RmMW2g2dzC/UyfxC7T2WW8aZLfr39nWSiufDrOVjdRQwz7e4Tx1/TwV6W2VmUR8AgIpfe163bp3TvsaNG8swjHPaNm7cWGvWrHHaFxcXJ0mOEZO7d++W2fzHP5SVdp4TJ06cN6azXwlv2LChli5dWmpbT09Pffjhh2Weq6R4WVkoSgIAAAC4LJhMJvl5ecjPy0MNa/uW294wDGXlFepoTr6jaFlSwDxWUsA8eUq/ph9XvslTJ/KK58P8Pdem33Nt2lWBmDxOv95e+4xXxsucG9PfS36eFhb1AQCgAihKAgAAAKiSTCaTgnytCvK1qlnd0tvYbDYtX75ct9xyo8wWD/2ee7pomZ2vozkFOp597ujLY6dXKj95qlCFdkO/nczXbyfzJZ0sNyYvD7Pz6MvTc2OGnFHArOPnpZDThUxvK/NhAgBqJoqSAAAAAGoEi9mkOv5equPvJSmg3Pb5hUX6PcdWvJhPzh9Fy5ICZskK5Mey83U0O1+nbHblF7o2H6b/6fkwS1YnL17cx1MhJb+fMSoz2M9TVubDBABUExQlAQAAAKAUXh4WhQdZFB5UsUV9cgsKnRfwOWsxn6NnrEp+LCdftiJD2fmFys4v1K9lzofprJavtfhV8ZJipVPh8vRIzNO/B/kwHyYA4PJFURIAAAAALgJfTw/5hngoMqSC82GeKnQefemYG7O4gFlSvDyeU7zPbkgncm06kWvTL7/llHsNi9mkYF9Pp9GXxXNjFr9KHuLn6TQa09/Lg/kwAVSq0hZ2QdVQsljPn0FREgAAAAAqmclkUpCPVUE+VjUtYz7MMxXZDZ3ILRl5+UcB0/Ea+Zn7cgqUmWdTkd3Q0dOvlleEp8XsPPryjFXJa/udOyrTx5P5MAFcGKvVKpPJpN9++01169atcf8gYrfbVVBQoFOnTjmtvl0VGIahgoIC/fbbbzKbzfL09Lzgc1GUBAAAAIDLnMVsOr1QjpcUVn77gkK7fs91fmW8ZG7M46cLmCWjM49nFyinoEgFRXYdzjylw5mnKhSTr6el9MV8Tq9UXrLYTx1/LwX7esrTo2r9xRvApWOxWNSgQQMdOHBAe/fudXc4lc4wDOXl5cnHx6fKFmR9fX3VsGHDP1VUpSgJAAAAANWMp4dZYYHeCgus2HyYeQVFZ4y0zC99bkzH6MwCFRTZlVtQpNzjedp/vGKL+gR6e6iO/x8jLUP8PVXnjFXJQ04XM2v7eaqWr6cszIcJVGv+/v5q0aKFbDabu0OpdDabTSkpKerRo4esVqu7w3GZxWKRh8efn/KDoiQAAAAA1HA+nhY18PRVg+CKzYeZnV/oKGAePT0PZvEq5MUFzOOnC5jFx/JlN6SsU4XKOlWo3UfLnw/TbJKCfT3PWsDnj9GXZ4/ODPRmPkygKrJYLLJYat5UEBaLRYWFhfL29q6SRcmLhaIkAAAAAKDCTCaTArytCvC2qnEdv3Lb2+2GMvNsf7wyfrpQebS0UZk5BTqRa5Pd0OnRmQWSssu9htViKh59ecYr47X9PE+PxvQ6Z25MX0/+KgwA7saTGAAAAABwyZjNJgX7eSrYz1PNQ8tvbysqng+z5FXxs18rP3rGquTHsguUnV8oW5Gh9KxTSs+q2HyYPtaS+TDPLFaefnXcx6Lciq0NBAD4EyhKAgAAAAAuG1aLWaEB3goNqNh8mKdsRY4FfI6esSr58ZwCp9GYx3MK9Ft2vgoK7cqzFenA73k68Hvp82F6mi0qrLdPD3ZvKjNzWwLAJUFREgAAAABQZXlbLapfy0f1a/mU29YwDOUUFDleFS8pYDp+z8nXjsNZ+ikjW5M+/0lfbM3Q5Dvaq3mofyXcCQDULBQlAQAAAAA1gslkkr+Xh/y9PNSodunzYebnF+gf8xL0xUFPfffr77rl9S81KqqFhvVoKqvFXMkRA0D1xRMVAAAAAIDTzGaTbgg39Pnj3dTziroqKLLrlRU7NPBfX2nrwUx3hwcA1YZLRcn4+Hh17txZAQEBCg0NVUxMjHbs2HHePosXL1anTp1Uq1Yt+fn5qUOHDnrvvfec2hiGoXHjxqlevXry8fFRVFSUdu7c6dTm+PHjuu+++xQYGKhatWrp4YcfVna28ypsmzdv1g033CBvb29FRkZqypQprtweAAAAAACSpPq1fDTvwc6adudVquVr1fbDWRo44yu9nPCTTtmK3B0eAFR5LhUlk5OTFRcXp/Xr1ysxMVE2m03R0dHKyckps09ISIj+8Y9/aN26ddq8ebMefPBBPfjgg1qxYoWjzZQpU/TGG2/orbfe0jfffCM/Pz/16dNHp079sXLafffdp23btikxMVHLli1TSkqKhg0b5jielZWl6OhoNWrUSBs3btQrr7yiCRMm6D//+Y8rtwgAAAAAgKTi171vv6aBEp/oqf7t66nIbmhm0i+65fUv9e3e4+4ODwCqNJfmlExISHDanjdvnkJDQ7Vx40b16NGj1D69evVy2h41apTeeecdpaamqk+fPjIMQ6+99pqee+45DRw4UJL07rvvKiwsTJ988onuvvtu/fjjj0pISNC3336rTp06SZLefPNN3XLLLZo6daoiIiL0wQcfqKCgQG+//bY8PT3Vpk0bpaWladq0aU7FyzPl5+crPz/fsZ2VlSVJstlsstlsrnw0VULJPVXHe8OlQc7AVeQMXEXOwFXkDFxFzsBVpeVMLW+zXvtrO/VvE6bxn23X7qM5+utb63R/l0g92buF/L1YrqEm4zkDV1X3nKnofZkMwzAu9CK7du1SixYttGXLFrVt27bc9oZhaM2aNRowYIA++eQT9e7dW7t371azZs20adMmdejQwdG2Z8+e6tChg15//XW9/fbbevLJJ/X77787jhcWFsrb21sLFy7UX/7yF8XGxiorK0uffPKJo83atWt100036fjx4woODj4nngkTJmjixInn7J8/f758fX1d+zAAAAAAANVebqG09Fez1h8pfvEw2NPQXU3tujL4gv9qDQDVSm5uru69915lZmYqMDCwzHYX/M85drtdo0ePVvfu3cstSGZmZqp+/frKz8+XxWLRv//9b/Xu3VuSlJ6eLkkKCwtz6hMWFuY4lp6ertDQUOfAPTwUEhLi1KZJkybnnKPkWGlFybFjx2rMmDGO7aysLEVGRio6Ovq8H1pVZbPZlJiYqN69e8tqtbo7HFQB5AxcRc7AVeQMXEXOwFXkDFxVkZwZJOmrX47puU+26cCJU3rrJ4v+0qGexvZrqWBfz8oNGG7Hcwauqu45U/ImcnkuuCgZFxenrVu3KjU1tdy2AQEBSktLU3Z2tlavXq0xY8aoadOm57zaXdm8vLzk5eV1zn6r1Votk6JEdb8/XHzkDFxFzsBV5AxcRc7AVeQMXFVezvRqFa6VY+po6oqfNffrPVqSdlhf7jqmFwa2Vb+24TKZTJUYLS4HPGfgquqaMxW9J5cWuikxYsQILVu2TGvXrlWDBg3Kv4jZrObNm6tDhw568sknNWjQIMXHx0uSwsPDJUkZGRlOfTIyMhzHwsPDdeTIEafjhYWFOn78uFOb0s5x5jUAAAAAALhYfD09NO621vp4eDc1D/XX0ewCPfbB9xr+/kYdyTpV/gkAoAZzqShpGIZGjBihJUuWaM2aNee8Ll1RdrvdscBMkyZNFB4ertWrVzuOZ2Vl6ZtvvlHXrl0lSV27dtWJEye0ceNGR5s1a9bIbrerS5cujjYpKSlOk2kmJiaqZcuWpb66DQAAAADAxdCxUbA+H3m9Rt7UXB5mk1Zsy1DUtGT977v9+hPLOABAteZSUTIuLk7vv/++5s+fr4CAAKWnpys9PV15eXmONrGxsRo7dqxjOz4+XomJidq9e7d+/PFHvfrqq3rvvfd0//33S5JMJpNGjx6tF198UZ9++qm2bNmi2NhYRUREKCYmRpJ05ZVXqm/fvnrkkUe0YcMGffXVVxoxYoTuvvtuRURESJLuvfdeeXp66uGHH9a2bdv00Ucf6fXXX3eaMxIAAAAAgEvBy8OiMdEt9emI69WufpCyThXq6Y83a/B/N2j/8Vx3hwcAlx2X5pScOXOmJJ0zF+TcuXM1ZMgQSdK+fftkNv9R68zJydFjjz2mAwcOyMfHR61atdL777+vu+66y9Hm6aefVk5OjoYNG6YTJ07o+uuvV0JCgry9vR1tPvjgA40YMUI333yzzGaz7rjjDr3xxhuO40FBQVq5cqXi4uLUsWNH1alTR+PGjdOwYcNcuUUAAAAAAC5Y64hALXmsm/6bukfTEn9W6q6jip6eoqf7tlRs18aymJlrEgAkF4uSFRl2npSU5LT94osv6sUXXzxvH5PJpBdeeEEvvPBCmW1CQkI0f/78856nffv2+vLLL8uNEQAAAACAS8XDYtbfejZT79ZhenbxFm3Yc1wTP9uuz344pCmD2qt5aIC7QwQAt7ughW4AAAAAAMD5Na3rrwWPXKcXY9rK38tD3+87oVteT9Wbq3fKVmR3d3gA4FYUJQEAAAAAuETMZpPuv66RVj7RQze2rKuCIrteTfxZt72Zqi0HMt0dHgC4DUVJAAAAAAAusYhaPnp7SGe9dlcHBfta9VP6SQ2ckar4L37UKVuRu8MDgEpHURIAAAAAgEpgMpkUc3V9JY7pqduuipDdkGYl71a/17/UN7uPuTs8AKhUFCUBAAAAAKhEdfy99OY9V2t2bCeFBXppz9Ec3fWf9Xruky06ecrm7vAAoFJQlAQAAAAAwA16tw7Tyid66p5rIyVJ76/fpz7TU7T2pyNujgwALj2KkgAAAAAAuEmQj1Xxt7fX/KFd1DDEV4cyT+nBed/qiY/SdDynwN3hAcAlQ1ESAAAAAAA369a8jhJG36Ch1zeR2SQt2XRQvacla9nmQzIMw93hAcBFR1ESAAAAAIDLgK+nh567tbUWPdpNLUL9dSynQCPmb9Kw9zYqI+uUu8MDgIuKoiQAAAAAAJeRqxsGa9nI6zXq5hbyMJuUuD1DUdOS9dG3+xg1CaDaoCgJAAAAAMBlxsvDoid6X6FlI69X+wZBOnmqUM8s2qL75nyjfcdy3R0eAPxpFCUBAAAAALhMtQoP1OJHu+kft1wpb6tZX/9yTH1eS9GcL3eryM6oSQBVF0VJAAAAAAAuYx4Wsx7p0VQJo3rouqYhyrMV6cXPf9QdM7/Wzxkn3R0eAFwQipIAAAAAAFQBjev4af7Q6/TSX9opwMtDaftPqP8bX+r1VTtVUGh3d3gA4BKKkgAAAAAAVBFms0n3dmmolWN66OZWobIVGZq+6mcN+Feqfth/wt3hAUCFUZQEAAAAAKCKqRfkozkPdNLrd3dQiJ+nfko/qb/8+yu9tPxH5RUUuTs8ACgXRUkAAAAAAKogk8mkgR3qK/GJHhrYIUJ2Q/pPym71ez1F63455u7wAOC8KEoCAAAAAFCF1fb30ut3X605sZ0UHuitvcdydc/s9fq/JVuUdcrm7vAAoFQUJQEAAAAAqAaiWodp5ZgeurdLQ0nS/G/2KXpaitb8lOHmyADgXBQlAQAAAACoJgK9rXrpL+00/5EualTbV+lZp/TQvO80asEmHcvOd3d4AOBAURIAAAAAgGqmW7M6ShjVQ8N6NJXZJC1NO6Te01P06Q+HZBiGu8MDANeKkvHx8ercubMCAgIUGhqqmJgY7dix47x9Zs+erRtuuEHBwcEKDg5WVFSUNmzY4NQmIyNDQ4YMUUREhHx9fdW3b1/t3LnTcXzv3r0ymUyl/ixcuNDRrrTjCxYscOUWAQAAAACoFnw8Lfq/W67Ukse6q1V4gI7nFGjkh5v0yLvfKT3zlLvDA1DDuVSUTE5OVlxcnNavX6/ExETZbDZFR0crJyenzD5JSUm65557tHbtWq1bt06RkZGKjo7WwYMHJUmGYSgmJka7d+/W0qVLtWnTJjVq1EhRUVGO80ZGRurw4cNOPxMnTpS/v7/69evndL25c+c6tYuJiXHxIwEAAAAAoPq4KrKWPh1xvZ6IukJWi0mrfjyi3tOS9eGGfYyaBOA2Hq40TkhIcNqeN2+eQkNDtXHjRvXo0aPUPh988IHT9pw5c7Ro0SKtXr1asbGx2rlzp9avX6+tW7eqTZs2kqSZM2cqPDxcH374oYYOHSqLxaLw8HCn8yxZskR33nmn/P39nfbXqlXrnLYAAAAAANRknh5mjYpqoX7twvX0x5uVtv+Exi7eok/TDin+9nZqXMfP3SECqGFcKkqeLTMzU5IUEhJS4T65ubmy2WyOPvn5xRPtent7O9qYzWZ5eXkpNTVVQ4cOPeccGzduVFpammbMmHHOsbi4OA0dOlRNmzbV8OHD9eCDD8pkMpUaS35+vuP6kpSVlSVJstlsstlsFb6nqqLknqrjveHSIGfgKnIGriJn4CpyBq4iZ+Cq6p4zTUK8tWBoZ727fp+mrdqpdbuPqe/rKRp9c3MN6dpIFnPpf39G2ap7zuDiq+45U9H7MhkXOFbbbrdrwIABOnHihFJTUyvc77HHHtOKFSu0bds2eXt7y2azqXnz5urSpYtmzZolPz8/TZ8+Xc8++6yio6O1YsWKUs+RlJSk7du3O+2fNGmSbrrpJvn6+mrlypUaP368pkyZopEjR5Yay4QJEzRx4sRz9s+fP1++vr4VvicAAAAAAKqao6ekBb+YtTOreGa3hn6G7mlepAj+OgzgT8jNzdW9996rzMxMBQYGltnugouSjz76qL744gulpqaqQYMGFeozefJkTZkyRUlJSWrfvr1j/8aNG/Xwww/rhx9+kMViUVRUlMxmswzD0BdffOF0jry8PNWrV0/PP/+8nnzyyfNeb9y4cZo7d672799f6vHSRkpGRkbq6NGj5/3QqiqbzabExET17t1bVqvV3eGgCiBn4CpyBq4iZ+AqcgauImfgqpqWM4ZhaOHGg4pP+FnZ+YWyWkwa3qOJhvdoKk8Pl5ahqLFqWs7gz6vuOZOVlaU6deqUW5S8oNe3R4wYoWXLliklJaXCBcmpU6dq8uTJWrVqlVNBUpI6duyotLQ0ZWZmqqCgQHXr1lWXLl3UqVOnc87z8ccfKzc3V7GxseVes0uXLpo0aZLy8/Pl5eV1znEvL69S91ut1mqZFCWq+/3h4iNn4CpyBq4iZ+AqcgauImfgqpqUM/d1baKbW9fTc59s1aofM/Tm2t1asf2Ipgy6Sh0ia7k7vCqjJuUMLo7qmjMVvSeX/tnDMAyNGDFCS5Ys0Zo1a9SkSZMK9ZsyZYomTZqkhISEUguNJYKCglS3bl3t3LlT3333nQYOHHhOm//+978aMGCA6tatW+5109LSFBwcXGrhEQAAAAAAFAsP8tbs2I56856rVdvPUz9nZOv2f3+lF5dtV15BkbvDA1ANuTRSMi4uTvPnz9fSpUsVEBCg9PR0ScXFRB8fH0lSbGys6tevr/j4eEnSyy+/rHHjxmn+/Plq3Lixo4+/v79j5eyFCxeqbt26atiwobZs2aJRo0YpJiZG0dHRTtfftWuXUlJStHz58nNi++yzz5SRkaHrrrtO3t7eSkxM1EsvvaS///3vLn4kAAAAAADUPCaTSbddFaHuzeto0rLtWrLpoOak7tHK7RmafEc7dWtWx90hAqhGXBopOXPmTGVmZqpXr16qV6+e4+ejjz5ytNm3b58OHz7s1KegoECDBg1y6jN16lRHm8OHD2vw4MFq1aqVRo4cqcGDB+vDDz885/pvv/22GjRocE6xUioeGjpjxgx17dpVHTp00KxZszRt2jSNHz/elVsEAAAAAKBGC/Hz1PS7OujtIZ1UL8hb+47n6t7Z32js4s3KOlU9VwsGUPlcGilZkTVxkpKSnLb37t1bbp+RI0eWuUL2mV566SW99NJLpR7r27ev+vbtW+45AAAAAABA+W5qFaaVT4To5YSf9P76ffpww36t+emI/hnTTlGtw9wdHoAqjqW0AAAAAABAqQK8rXoxpp0WDLtOTer4KSMrX0Pf/U6Pf7hJx7Lz3R0egCqMoiQAAAAAADiv65rW1hejbtDfejaV2SR99sMhRU1L1tK0gxV6qxIAzkZREgAAAAAAlMvbatHYflfqk7juahUeoN9zbRq1IE0Pv/OdDp3Ic3d4AKoYipIAAAAAAKDC2jeopc8ev15P9r5Cnhaz1vx0RNHTU/T++l9ltzNqEkDFUJQEAAAAAAAusVrMevzmFvp85PW6umEtZecX6rlPtuqe2eu152iOu8MDUAVQlAQAAAAAABekRViAPh7eTeNubS0fq0Xf7Dmuvq+laFbyLyossrs7PACXMYqSAAAAAADgglnMJj10fROtfKKHrm9eR/mFdsV/8ZNun/m1fjyc5e7wAFymKEoCAAAAAIA/LTLEV+89fK2m3NFeAd4e2nwgU7e9mappK3cov7DI3eEBuMxQlAQAAAAAABeFyWTSnZ0jtWpMT0W3DlOh3dAba3bp1jdS9f2+390dHoDLCEVJAAAAAABwUYUFemvW4I6ace81quPvqZ1HsnXHzK/1wmfblVtQ6O7wAFwGKEoCAAAAAICLzmQyqX/7ekp8oqduv6a+DEN6+6s96vNair7addTd4QFwM4qSAAAAAADgkgn289S0Ozto3oOdVb+Wj/Yfz9N9c77RMx9vVmaezd3hAXATipIAAAAAAOCS69UyVCue6KHYro0kSR99t1+9pyVr5bZ0N0cGwB0oSgIAAAAAgErh7+WhFwa21f/+1lVN6/jpyMl8DXtvo+Lmf6/fTua7OzwAlYiiJAAAAAAAqFTXNgnR8lE36NFezWQxm/T55sPqPT1Zi78/IMMw3B0egEpAURIAAAAAAFQ6b6tFz/RtpaVx3dW6XqBO5No05n8/6MF53+rgiTx3hwfgEqMoCQAAAAAA3KZt/SAtHdFdT/VpKU+LWUk7flP0tGS9t26v7HZGTQLVFUVJAAAAAADgVlaLWXE3NtfyUTeoY6Ng5RQU6fml23T3f9Zr92/Z7g4PwCVAURIAAAAAAFwWmof6a+HfumrCba3l62nRhr3H1ff1LzUz6RcVFtndHR6Ai4iiJAAAAAAAuGyYzSYN6d5EK0b30A0t6qig0K6XE35SzL+/0vZDWe4OD8BFQlESAAAAAABcdiJDfPXuQ9fqlUHtFejtoa0HszTgX6maumKHTtmK3B0egD+JoiQAAAAAALgsmUwm/bVTpFY92VN924Sr0G7oX2t3qf8bX2rjr8fdHR6AP8GlomR8fLw6d+6sgIAAhYaGKiYmRjt27Dhvn9mzZ+uGG25QcHCwgoODFRUVpQ0bNji1ycjI0JAhQxQRESFfX1/17dtXO3fudGrTq1cvmUwmp5/hw4c7tdm3b5/69+8vX19fhYaG6qmnnlJhYaErtwgAAAAAAC4zoQHeemtwR8287xrV8ffSL7/laNBb6zTh023Kyefv/UBV5FJRMjk5WXFxcVq/fr0SExNls9kUHR2tnJycMvskJSXpnnvu0dq1a7Vu3TpFRkYqOjpaBw8elCQZhqGYmBjt3r1bS5cu1aZNm9SoUSNFRUWdc95HHnlEhw8fdvxMmTLFcayoqEj9+/dXQUGBvv76a73zzjuaN2+exo0b58otAgAAAACAy1S/dvW0akwPDerYQIYhzft6r/q8lqIvd/7m7tAAuMjDlcYJCQlO2/PmzVNoaKg2btyoHj16lNrngw8+cNqeM2eOFi1apNWrVys2NlY7d+7U+vXrtXXrVrVp00aSNHPmTIWHh+vDDz/U0KFDHX19fX0VHh5e6nVWrlyp7du3a9WqVQoLC1OHDh00adIkPfPMM5owYYI8PT1duVUAAAAAAHAZquXrqal/vUoDrorQ2MVbdOD3PA3+7wb9tWMDPde/tYJ8re4OEUAFuFSUPFtmZqYkKSQkpMJ9cnNzZbPZHH3y8/MlSd7e3o42ZrNZXl5eSk1NdSpKfvDBB3r//fcVHh6u2267Tc8//7x8fX0lSevWrVO7du0UFhbmaN+nTx89+uij2rZtm66++upzYsnPz3dcX5KysopX8bLZbLLZbBW+p6qi5J6q473h0iBn4CpyBq4iZ+AqcgauImfgKnKm6ujapJY+H9FVr67apfe/2aeFGw8oaccRjb/1SvVpE1b+CS4Scgauqu45U9H7MhmGYVzIBex2uwYMGKATJ04oNTW1wv0ee+wxrVixQtu2bZO3t7dsNpuaN2+uLl26aNasWfLz89P06dP17LPPKjo6WitWrJAk/ec//1GjRo0UERGhzZs365lnntG1116rxYsXS5KGDRumX3/91dFeKi6A+vn5afny5erXr985sUyYMEETJ048Z//8+fMdxU4AAAAAAHB5250lffiLRUdOmSRJV4XYNaiJXYG8NAlUutzcXN17773KzMxUYGBgme0ueKRkXFyctm7d6lJBcvLkyVqwYIGSkpIcIyOtVqsWL16shx9+WCEhIbJYLIqKilK/fv10Zr102LBhjt/btWunevXq6eabb9Yvv/yiZs2aXdA9jB07VmPGjHFsZ2VlOea8PN+HVlXZbDYlJiaqd+/esloZzo7ykTNwFTkDV5EzcBU5A1eRM3AVOVN1PWIr0oyk3fpP6l79cNysvXme+r9+LfWXDhEymUyX7LrkDFxV3XOm5E3k8lxQUXLEiBFatmyZUlJS1KBBgwr1mTp1qiZPnqxVq1apffv2Tsc6duyotLQ0ZWZmqqCgQHXr1lWXLl3UqVOnMs/XpUsXSdKuXbvUrFkzhYeHl7qqt6Qy56H08vKSl5fXOfutVmu1TIoS1f3+cPGRM3AVOQNXkTNwFTkDV5EzcBU5U/VYrVY9c0tr3dqhvp7+eLO2HcrSM4u36fOtR/TSX9qqQfClfSOSnIGrqmvOVPSeXFp92zAMjRgxQkuWLNGaNWvUpEmTCvWbMmWKJk2apISEhPMWGoOCglS3bl3t3LlT3333nQYOHFhm27S0NElSvXr1JEldu3bVli1bdOTIEUebxMREBQYGqnXr1hWKEwAAAAAAVG1tIoL0SVx3Pd23pTw9zEr5+TdFT0/RO1/vld1+QTPYAbgEXCpKxsXF6f3339f8+fMVEBCg9PR0paenKy8vz9EmNjZWY8eOdWy//PLLev755/X222+rcePGjj7Z2dmONgsXLlRSUpJ2796tpUuXqnfv3oqJiVF0dLQk6ZdfftGkSZO0ceNG7d27V59++qliY2PVo0cPx6jL6OhotW7dWoMHD9YPP/ygFStW6LnnnlNcXFypoyEBAAAAAED1ZLWY9Viv5vpi1A3q3DhYuQVFGv/pNt05a51++S27/BMAuORcKkrOnDlTmZmZ6tWrl+rVq+f4+eijjxxt9u3bp8OHDzv1KSgo0KBBg5z6TJ061dHm8OHDGjx4sFq1aqWRI0dq8ODB+vDDDx3HPT09tWrVKkVHR6tVq1Z68skndccdd+izzz5ztLFYLFq2bJksFou6du2q+++/X7GxsXrhhRcu6IMBAAAAAABVW7O6/vpoWFe9MLCN/Dwt+u7X39Xv9S81Y+0u2Yrs7g4PqNFcmlOyIgt1JyUlOW3v3bu33D4jR47UyJEjyzweGRmp5OTkcs/TqFEjLV++vNx2AAAAAACgZjCbTYrt2lg3tQrVP5ZsVfLPv+mVFTu0fMthvXxHe7WtH+TuEIEayaWRkgAAAAAAAFVRg2BfzXuws6bdeZVq+Vq17VCWBs74SlMSftIpW5G7wwNqHIqSAAAAAACgRjCZTLr9mgZKfKKn+rerpyK7oX8n/aJb3vhS3+097u7wgBqFoiQAAAAAAKhR6gZ4acZ91+it+zuqboCXdv+Wo7/OWqfxS7cqO7/Q3eEBNQJFSQAAAAAAUCP1bRuuVU/01J2dGsgwpHfW/ao+01OU/PNv7g4NqPYoSgIAAAAAgBoryNeqKYOu0vsPd1GDYB8dPJGnB97eoDH/S9OJ3AJ3hwdUWxQlAQAAAABAjXd9izpaMbqHHuzeWCaTtPj7g4qalqzlWw67OzSgWqIoCQAAAAAAIMnPy0Pjb2ujj4d3U/NQfx3NLtBjH3yv4e9t1JGsU+4OD6hWKEoCAAAAAACcoWOjYH0+8no9flNzeZhNStiWrqhpyfrfd/tlGIa7wwOqBYqSAAAAAAAAZ/HysOjJ6Jb6dMT1alc/SFmnCvX0x5sV+/YG7T+e6+7wgCqPoiQAAAAAAEAZWkcEaslj3fRsv1by8jDry51H1ee1FM39ao+K7IyaBC4URUkAAAAAAIDz8LCYNbxnM30x6gZd2yREuQVFmvjZdt05a512Hcl2d3hAlURREgAAAAAAoAKa1vXXgkeu04sxbeXv5aGNv/6uAf9ep5UHTLIV2d0dHlClUJQEAAAAAACoILPZpPuva6SVT/RQr5Z1ZSsy9Pl+i25/6xttPZjp7vCAKoOiJAAAAAAAgIsiavlo7pDOmjqonfw8DP2UflIDZ3ylyV/8pFO2IneHB1z2KEoCAAAAAABcAJPJpIFX1dPYDkXq3zZcRXZDbyX/olte/1Ib9hx3d3jAZY2iJAAAAAAAwJ8QYJVeu6u9/jO4o0IDvLT7aI7unLVOz3+yVSdP2dwdHnBZoigJAAAAAABwEUS3CVfimJ66u3OkJOm99b+qz/QUrd1xxM2RAZcfipIAAAAAAAAXSZCPVZPvaK8PhnZRZIiPDmWe0oNzv9WYj9L0e06Bu8MDLhsUJQEAAAAAAC6y7s3raMXoHnr4+iYymaTFmw4qalqylm0+JMMw3B0e4HYUJQEAAAAAAC4BX08PPX9ray16tJtahPrrWE6BRszfpL+9t1EZWafcHR7gVhQlAQAAAAAALqFrGgZr2cjrNfLmFvIwm7Rye4aipiXro2/3MWoSNRZFSQAAAAAAgEvMy8OiMb2v0GePX6/2DYJ08lShnlm0Rff/9xvtO5br7vCASudSUTI+Pl6dO3dWQECAQkNDFRMTox07dpy3z+zZs3XDDTcoODhYwcHBioqK0oYNG5zaZGRkaMiQIYqIiJCvr6/69u2rnTt3Oo4fP35cjz/+uFq2bCkfHx81bNhQI0eOVGZmptN5TCbTOT8LFixw5RYBAAAAAAAumSvrBWrxo930j1uulJeHWV/tOqY+r6Xov6l7VGRn1CRqDpeKksnJyYqLi9P69euVmJgom82m6Oho5eTklNknKSlJ99xzj9auXat169YpMjJS0dHROnjwoCTJMAzFxMRo9+7dWrp0qTZt2qRGjRopKirKcd5Dhw7p0KFDmjp1qrZu3ap58+YpISFBDz/88DnXmzt3rg4fPuz4iYmJceUWAQAAAAAALikPi1mP9GiqFaN7qEuTEOXZijRp2XYNeutr7cw46e7wgErh4UrjhIQEp+158+YpNDRUGzduVI8ePUrt88EHHzhtz5kzR4sWLdLq1asVGxurnTt3av369dq6davatGkjSZo5c6bCw8P14YcfaujQoWrbtq0WLVrkOEezZs30z3/+U/fff78KCwvl4fHHbdSqVUvh4eEVup/8/Hzl5+c7trOysiRJNptNNputQueoSkruqTreGy4NcgauImfgKnIGriJn4CpyBq4iZ+CqP5Mz9YM89e6QjvrfxoOavGKHNu07oVve+FKP9WyqYTc0kacHs+5VR9X9OVPR+zIZf2JG1V27dqlFixbasmWL2rZtW6E+J0+eVGhoqBYuXKhbb71VW7ZsUfv27bVr1y41a9bM0S4yMlI333yz5s2bV+p55syZo7Fjx+q3337742ZMJkVERCg/P19NmzbV8OHD9eCDD8pkMpV6jgkTJmjixInn7J8/f758fX0rdD8AAAAAAAB/1ol86aPdZm0/UVyIjPA1dE+zIjX0d3NggItyc3N17733KjMzU4GBgWW2u+CipN1u14ABA3TixAmlpqZWuN9jjz2mFStWaNu2bfL29pbNZlPz5s3VpUsXzZo1S35+fpo+fbqeffZZRUdHa8WKFeec4+jRo+rYsaPuv/9+/fOf/3TsnzRpkm666Sb5+vpq5cqVGj9+vKZMmaKRI0eWGktpIyUjIyN19OjR835oVZXNZlNiYqJ69+4tq9Xq7nBQBZAzcBU5A1eRM3AVOQNXkTNwFTkDV13MnDEMQ8u2pGvS5z/p91ybzCbpoe6NNfLGZvLxtFykiOFu1f05k5WVpTp16pRblHTp9e0zxcXFaevWrS4VJCdPnqwFCxYoKSlJ3t7ekiSr1arFixfr4YcfVkhIiCwWi6KiotSvXz+VVi/NyspS//791bp1a02YMMHp2PPPP+/4/eqrr1ZOTo5eeeWVMouSXl5e8vLyOme/1WqtlklRorrfHy4+cgauImfgKnIGriJn4CpyBq4iZ+Cqi5Uzt3dsqJ4twzTxs+369IdDmpO6V6t+PKLJd7TXdU1rX4RIcbmors+Zit7TBU1OMGLECC1btkxr165VgwYNKtRn6tSpmjx5slauXKn27ds7HevYsaPS0tJ04sQJHT58WAkJCTp27JiaNm3q1O7kyZPq27evAgICtGTJknJvskuXLjpw4IDTaEgAAAAAAIDLWW1/L71xz9WaE9tJ4YHe2nssV3f/Z73+sWSLTp6qnvMQouZxqShpGIZGjBihJUuWaM2aNWrSpEmF+k2ZMkWTJk1SQkKCOnXqVGa7oKAg1a1bVzt37tR3332ngQMHOo5lZWUpOjpanp6e+vTTTx0jLc8nLS1NwcHBpY6GBAAAAAAAuJxFtQ7TyjE9dM+1DSVJH3yzT9HTU7Tmpww3Rwb8eS69vh0XF6f58+dr6dKlCggIUHp6uqTiYqKPj48kKTY2VvXr11d8fLwk6eWXX9a4ceM0f/58NW7c2NHH399f/v7Fs7UuXLhQdevWVcOGDbVlyxaNGjVKMTExio6OlvRHQTI3N1fvv/++srKyHCtl161bVxaLRZ999pkyMjJ03XXXydvbW4mJiXrppZf097///SJ8TAAAAAAAAJUv0Nuq+Nvb6bar6mns4i369ViuHpr3nWI6RGjcbW0U4ufp7hCBC+JSUXLmzJmSpF69ejntnzt3roYMGSJJ2rdvn8xms1OfgoICDRo0yKnP+PHjHXNCHj58WGPGjFFGRobq1aun2NhYp/khv//+e33zzTeSpObNmzudZ8+ePWrcuLGsVqtmzJihJ554QoZhqHnz5po2bZoeeeQRV24RAAAAAADgstOtWR0ljOqhaYk79N/UPfok7ZBSdh7VhAFtdFv7ejKZTO4OEXCJS0XJiizUnZSU5LS9d+/ecvuMHDmyzMVopOIiaHnX7tu3r/r27VvutQAAAAAAAKoiH0+L/tG/tfq3j9AzH2/WjoyTGvnhJn2adkgvxrRVeFD5U90Bl4sLWugGAAAAAAAA7tEhspY+e/x6PRF1hawWk1b9mKHe05L14YZ9FRpQBlwOKEoCAAAAAABUMZ4eZo2KaqFlj9+gqyJr6WR+ocYu3qJ7Z3+jX4/luDs8oFwUJQEAAAAAAKqoluEBWvxoNz3X/0p5W81at/uY+ryWojlf7laRnVGTuHxRlAQAAAAAAKjCLGaTht7QVCtG91DXprV1ymbXi5//qNtnfq0d6SfdHR5QKoqSAAAAAAAA1UCj2n6a/0gXTb69nQK8PPTD/hO69c0v9dqqn1VQaHd3eIATipIAAAAAAADVhMlk0t3XNlTimJ6KujJUtiJDr63aqdveTFXa/hPuDg9woCgJAAAAAABQzYQHeWt2bCe9ec/Vqu3nqR0ZJ3X7v7/SPz/frryCIneHB1CUBAAAAAAAqI5MJpNuuypCiWN6KqZDhOyGNPvLPerzWoq+/uWou8NDDUdREgAAAAAAoBoL8fPUa3dfrbeHdFK9IG/tO56re2d/o7GLtyjrlM3d4aGGoigJAAAAAABQA9zUKkwrn+ih+7o0lCR9uGGfek9L1qrtGW6ODDURRUkAAAAAAIAaIsDbqn/+pZ0WDLtOjWv7KiMrX0Pf/U4jP9ykY9n57g4PNQhFSQAAAAAAgBrmuqa1lTC6h/7Ws6nMJunTHw4palqylqYdlGEY7g4PNQBFSQAAAAAAgBrI22rR2H5X6pO47moVHqDfc20atSBNQ9/5Tocz89wdHqo5ipIAAAAAAAA1WPsGtfTpiOv1ZO8r5Gkxa/VPR9R7Woo++OZX2e2MmsSlQVESAAAAAACghvP0MOvxm1vo85HX6+qGtZSdX6h/LNmqe+es196jOe4OD9UQRUkAAAAAAABIklqEBejj4d007tbW8rFatH73cfV5LUX/SflFhUV2d4eHaoSiJAAAAAAAABwsZpMeur6JVozuoe7Nayu/0K6Xlv+kO2Z+rZ/Ss9wdHqoJipIAAAAAAAA4R8Pavnr/4S6ackd7BXh76IcDmbr1jVRNS/xZ+YVF7g4PVRxFSQAAAAAAAJTKZDLpzs6RWjWmp3q3DlOh3dAbq3fq1jdS9f2+390dHqowipIAAAAAAAA4r7BAb/1ncEfNuPca1fH31M4j2bpj5teatGy7cgsK3R0eqiCKkgAAAAAAACiXyWRS//b1lPhET91+dX0ZhvTf1D3q81qKvtp11N3hoYpxqSgZHx+vzp07KyAgQKGhoYqJidGOHTvO22f27Nm64YYbFBwcrODgYEVFRWnDhg1ObTIyMjRkyBBFRETI19dXffv21c6dO53anDp1SnFxcapdu7b8/f11xx13KCMjw6nNvn371L9/f/n6+io0NFRPPfWUCgup1gMAAAAAAFwswX6emnZXB819sLMigry1/3ie7pvzjZ5dtFmZeTZ3h4cqwqWiZHJysuLi4rR+/XolJibKZrMpOjpaOTk5ZfZJSkrSPffco7Vr12rdunWKjIxUdHS0Dh48KEkyDEMxMTHavXu3li5dqk2bNqlRo0aKiopyOu8TTzyhzz77TAsXLlRycrIOHTqk22+/3XG8qKhI/fv3V0FBgb7++mu98847mjdvnsaNG+fqZwIAAAAAAIBy3NgyVCvH9FRs10aSpAXf7lfvaclauS3dzZGhKvBwpXFCQoLT9rx58xQaGqqNGzeqR48epfb54IMPnLbnzJmjRYsWafXq1YqNjdXOnTu1fv16bd26VW3atJEkzZw5U+Hh4frwww81dOhQZWZm6r///a/mz5+vm266SZI0d+5cXXnllVq/fr2uu+46rVy5Utu3b9eqVasUFhamDh06aNKkSXrmmWc0YcIEeXp6unKrAAAAAAAAKIe/l4deGNhWt7aP0DOLNmvP0RwNe2+jbm1fTxMGtFEdfy93h4jLlEtFybNlZmZKkkJCQircJzc3VzabzdEnPz9fkuTt7e1oYzab5eXlpdTUVA0dOlQbN26UzWZTVFSUo02rVq3UsGFDrVu3Ttddd53WrVundu3aKSwszNGmT58+evTRR7Vt2zZdffXV58SSn5/vuL4kZWVlSZJsNptstuo33LjknqrjveHSIGfgKnIGriJn4CpyBq4iZ+AqcgauImeKXd0gQJ8+dp3+tXa35ny1V8s2H1bqzqN67paWGnBVPZlMJneHeNmo7jlT0fu64KKk3W7X6NGj1b17d7Vt27bC/Z555hlFREQ4CowlxcWxY8dq1qxZ8vPz0/Tp03XgwAEdPnxYkpSeni5PT0/VqlXL6VxhYWFKT093tDmzIFlyvORYaeLj4zVx4sRz9q9cuVK+vr4VvqeqJjEx0d0hoIohZ+AqcgauImfgKnIGriJn4CpyBq4iZ4q1lvREG+nDXyw6mGvT3xdt1durN+vOpnYFM2jSSXXNmdzc3Aq1u+CiZFxcnLZu3arU1NQK95k8ebIWLFigpKQkx8hIq9WqxYsX6+GHH1ZISIgsFouioqLUr18/GYZxoeFVyNixYzVmzBjHdlZWlmPOy8DAwEt6bXew2WxKTExU7969ZbVa3R0OqgByBq4iZ+AqcgauImfgKnIGriJn4CpypnQPFdk1J3Wv3lz7i7afMOuVbVY9FX2F7unUQGZzzR41Wd1zpuRN5PJcUFFyxIgRWrZsmVJSUtSgQYMK9Zk6daomT56sVatWqX379k7HOnbsqLS0NGVmZqqgoEB169ZVly5d1KlTJ0lSeHi4CgoKdOLECafRkhkZGQoPD3e0KW1V75JjpfHy8pKX17lleqvVWi2TokR1vz9cfOQMXEXOwFXkDFxFzsBV5AxcRc7AVeSMM6tVGhnVUre0j9DTH2/W9/tOaMJnP2r51gxNvr2dmtb1d3eIblddc6ai9+TS6tuGYWjEiBFasmSJ1qxZoyZNmlSo35QpUzRp0iQlJCQ4Co2lCQoKUt26dbVz50599913GjhwoKTioqXVatXq1asdbXfs2KF9+/apa9eukqSuXbtqy5YtOnLkiKNNYmKiAgMD1bp1a1duEwAAAAAAABdB89AALRzeTRNuay1fT4s27Dmufq9/qbeSf1Fhkd3d4cGNXBopGRcXp/nz52vp0qUKCAhwzNUYFBQkHx8fSVJsbKzq16+v+Ph4SdLLL7+scePGaf78+WrcuLGjj7+/v/z9i6viCxcuVN26ddWwYUNt2bJFo0aNUkxMjKKjox3nf/jhhzVmzBiFhIQoMDBQjz/+uLp27arrrrtOkhQdHa3WrVtr8ODBmjJlitLT0/Xcc88pLi6u1NGQAAAAAAAAuPQsZpOGdG+im68M0/8t2aIvdx7V5C9+0rLNhzTljqvUOqL6TaGH8rk0UnLmzJnKzMxUr169VK9ePcfPRx995Gizb98+xwI1JX0KCgo0aNAgpz5Tp051tDl8+LAGDx6sVq1aaeTIkRo8eLA+/PBDp2tPnz5dt956q+644w716NFD4eHhWrx4seO4xWLRsmXLZLFY1LVrV91///2KjY3VCy+84PKHAgAAAAAAgIsrMsRX7z50rV4Z1F6B3h7aejBLA/6VqldX7lB+YZG7w0Mlc2mkZEUWnklKSnLa3rt3b7l9Ro4cqZEjR563jbe3t2bMmKEZM2aU2aZRo0Zavnx5udcDAAAAAABA5TOZTPprp0j1vKKuxi3dpoRt6XpzzS59sTVdL9/RXh0bBbs7RFQSl0ZKAgAAAAAAAH9WaKC33hrcUTPvu0Z1/L2060i2Br31tSZ+tk05+YXuDg+VgKIkAAAAAAAA3KJfu3paNaaH7rimgQxDmvvVXvV5LUVf7vzN3aHhEqMoCQAAAAAAALep5eupV++8Su88dK3q1/LRgd/zNPi/G/T0xz8oM9fm7vBwiVCUBAAAAAAAgNv1vKKuVjzRQw90bSSTSfrfdwcUNT1ZCVvT3R0aLgGKkgAAAAAAALgs+Ht5aOLAtvrf37qqaV0//XYyX8Pf36i4D77Xbyfz3R0eLiKKkgAAAAAAALisdG4couUjb9BjvZrJYjbp8y2HFTUtWYs2HpBhGO4ODxcBRUkAAAAAAABcdrytFj3dt5WWxnVX63qBysyz6cmFP2jI3G914Pdcd4eHP4miJAAAAAAAAC5bbesHaemI7nqqT0t5epiV/PNv6jM9Re+u2yu7nVGTVRVFSQAAAAAAAFzWrBaz4m5sruUjb1CnRsHKKSjSuKXbdNd/1umX37LdHR4uAEVJAAAAAAAAVAnNQ/31v7911cQBbeTradG3e39Xv9e/1L+TdslWZHd3eHABRUkAAAAAAABUGWazSQ90a6yVT/RQjyvqqqDQrikJOxQz4yttPZjp7vBQQRQlAQAAAAAAUOU0CPbVOw921qt/vUpBPlZtO5SlgTO+0isrftIpW5G7w0M5KEoCAAAAAACgSjKZTLqjYwOtGtNTt7QLV5Hd0Iy1v+iWN77Ud3uPuzs8nAdFSQAAAAAAAFRpdQO89O/7Ouqt+69R3QAv7f4tR3+dtU4TPt2mnPxCd4eHUlCUBAAAAAAAQLXQt209rXqip/7asYEMQ5r39V5FT09Rys+/uTs0nIWiJAAAAAAAAKqNIF+rXvnrVXrv4WvVINhHB0/kKfbtDfr7wh90IrfA3eHhNIqSAAAAAAAAqHZuaFFXK0b30JBujWUySR9vPKCoaSn6Ysthd4cGUZQEAAAAAABANeXn5aEJA9ro4+Fd1ayun45m5+vRD77Xo+9v1JGTp9wdXo1GURIAAAAAAADVWsdGIfp85A0acWNzeZhN+mJrunpPS9HC7/bLMAx3h1cjUZQEAAAAAABAtedttejvfVpq6Yjuals/UJl5Nj318WbFvr1B+4/nuju8GoeiJAAAAAAAAGqMNhFB+uSx7nq2Xyt5eZj15c6j6vNaiuZ9tUd2O6MmKwtFSQAAAAAAANQoHhazhvdspi9G3aBrG4cot6BIEz7brr/OWqddR066O7wawaWiZHx8vDp37qyAgACFhoYqJiZGO3bsOG+f2bNn64YbblBwcLCCg4MVFRWlDRs2OLXJzs7WiBEj1KBBA/n4+Kh169Z66623HMf37t0rk8lU6s/ChQsd7Uo7vmDBAlduEQAAAAAAADVE07r+WjDsOk2KaSs/T4s2/vq7bnk9VTPW7pKtyO7u8Ko1l4qSycnJiouL0/r165WYmCibzabo6Gjl5OSU2ScpKUn33HOP1q5dq3Xr1ikyMlLR0dE6ePCgo82YMWOUkJCg999/Xz/++KNGjx6tESNG6NNPP5UkRUZG6vDhw04/EydOlL+/v/r16+d0vblz5zq1i4mJceUWAQAAAAAAUIOYzSYNvq6RVo7pqV4t66qgyK5XVuzQwH99pa0HM90dXrXl4UrjhIQEp+158+YpNDRUGzduVI8ePUrt88EHHzhtz5kzR4sWLdLq1asVGxsrSfr666/1wAMPqFevXpKkYcOGadasWdqwYYMGDBggi8Wi8PBwp/MsWbJEd955p/z9/Z3216pV65y2AAAAAAAAwPnUr+WjuUM665O0g5r42XZtP5ylgTO+0rAeTTXq5hbytlrcHWK14lJR8myZmcXV4pCQkAr3yc3Nlc1mc+rTrVs3ffrpp3rooYcUERGhpKQk/fzzz5o+fXqp59i4caPS0tI0Y8aMc47FxcVp6NChatq0qYYPH64HH3xQJpOp1PPk5+crPz/fsZ2VlSVJstlsstlsFb6nqqLknqrjveHSIGfgKnIGriJn4CpyBq4iZ+AqcgauImeqn1vbhqlr41p64fOftHxrhmYm/aKELYf10l/aqFOj4D99/uqeMxW9L5NhGBe0rJDdbteAAQN04sQJpaamVrjfY489phUrVmjbtm3y9vaWVFwcHDZsmN599115eHjIbDZr9uzZjpGUpZ0jKSlJ27dvd9o/adIk3XTTTfL19dXKlSs1fvx4TZkyRSNHjiz1PBMmTNDEiRPP2T9//nz5+vpW+J4AAAAAAABQ/Ww+btLC3WZl2YoHvN0QZtetjezyZtBkmXJzc3XvvfcqMzNTgYGBZba74KLko48+qi+++EKpqalq0KBBhfpMnjxZU6ZMUVJSktq3b+/YP3XqVM2ePVtTp05Vo0aNlJKSorFjx2rJkiWKiopyOkdeXp7q1aun559/Xk8++eR5rzdu3DjNnTtX+/fvL/V4aSMlIyMjdfTo0fN+aFWVzWZTYmKievfuLavV6u5wUAWQM3AVOQNXkTNwFTkDV5EzcBU5A1eRM9VfVp5Nk1f8rIUbi9dHiQjy1qSBrdWjRZ0LOl91z5msrCzVqVOn3KLkBb2+PWLECC1btkwpKSkVLkhOnTpVkydP1qpVq5wKknl5efq///s/LVmyRP3795cktW/fXmlpaZo6deo5RcmPP/5Yubm5ZY6iPFOXLl00adIk5efny8vL65zjXl5epe63Wq3VMilKVPf7w8VHzsBV5AxcRc7AVeQMXEXOwFXkDFxFzlRfta1WvfLXDoq5uoGeXbxZ+4/n6eF3v9ft19TX8/1bK9jP84LOW11zpqL35NLq24ZhaMSIEVqyZInWrFmjJk2aVKjflClTNGnSJCUkJKhTp05Ox0rmbzSbnUOxWCyy289dev2///2vBgwYoLp165Z73bS0NAUHB5daeAQAAAAAAAAqqnvzOloxuoce6t5EJpO0+PuD6j09WZ9vPqwLfBG5RnNppGRcXJzmz5+vpUuXKiAgQOnp6ZKkoKAg+fj4SJJiY2NVv359xcfHS5JefvlljRs3TvPnz1fjxo0dffz9/eXv76/AwED17NlTTz31lHx8fNSoUSMlJyfr3Xff1bRp05yuv2vXLqWkpGj58uXnxPbZZ58pIyND1113nby9vZWYmKiXXnpJf//7313/VAAAAAAAAICz+Hp6aNxtrXXrVfX0zMebtfNItuLmf6/o1mF6MaatQgO93R1ileHSSMmZM2cqMzNTvXr1Ur169Rw/H330kaPNvn37dPjwYac+BQUFGjRokFOfqVOnOtosWLBAnTt31n333afWrVtr8uTJ+uc//6nhw4c7Xf/tt99WgwYNFB0dfU5sVqtVM2bMUNeuXdWhQwfNmjVL06ZN0/jx4125RQAAAAAAAOC8rmkYrGUjr9fIm1vIw2zSyu0Zunlasv737X5GTVaQSyMlK/KhJiUlOW3v3bu33D7h4eGaO3duue1eeuklvfTSS6Ue69u3r/r27VvuOQAAAAAAAIA/y8vDojG9r1C/tuF6ZtFmbT6QqacXbdanPxxS/O3tFBni6+4QL2sujZQEAAAAAAAA8Icr6wVq8aPd9H+3tJKXh1mpu44qenqK3k7doyI7oybLQlESAAAAAAAA+BM8LGYN69FMK0b3UJcmIcqzFemFZdv117e+1s6Mk+4O77JEURIAAAAAAAC4CBrX8dOHj1ynf/6lrfy9PPT9vhPq/0aq3ly9U7Yiu7vDu6xQlAQAAAAAAAAuErPZpPu6NFLimB66qVWoCorsejXxZ932Zqq2HMh0d3iXDYqSAAAAAAAAwEVWL8hH/32gk16/u4OCfa36Kf2kBs5I1ZQVP6ugyN3RuR9FSQAAAAAAAOASMJlMGtihvlaN6anbroqQ3ZBmp+7Vv7ZbZBg1exEcipIAAAAAAADAJVTb30tv3nO1Zsd2UliAl7qF2WUymdwdllt5uDsAAAAAAAAAoCbo3TpMnRoGKnnVSneH4naMlAQAAAAAAAAqib+Xh2r4IElJFCUBAAAAAAAAVDKKkgAAAAAAAAAqFUVJAAAAAAAAAJWKoiQAAAAAAACASkVREgAAAAAAAECloigJAAAAAAAAoFJ5uDuAy4lhGJKkrKwsN0dyadhsNuXm5iorK0tWq9Xd4aAKIGfgKnIGriJn4CpyBq4iZ+AqcgauImfgquqeMyV1tZI6W1koSp7h5MmTkqTIyEg3RwIAAAAAAABUXSdPnlRQUFCZx01GeWXLGsRut+vQoUMKCAiQyWRydzgXXVZWliIjI7V//34FBga6OxxUAeQMXEXOwFXkDFxFzsBV5AxcRc7AVeQMXFXdc8YwDJ08eVIREREym8ueOZKRkmcwm81q0KCBu8O45AIDA6tl0uPSIWfgKnIGriJn4CpyBq4iZ+AqcgauImfgquqcM+cbIVmChW4AAAAAAAAAVCqKkgAAAAAAAAAqFUXJGsTLy0vjx4+Xl5eXu0NBFUHOwFXkDFxFzsBV5AxcRc7AVeQMXEXOwFXkTDEWugEAAAAAAABQqRgpCQAAAAAAAKBSUZQEAAAAAAAAUKkoSgIAAAAAAACoVBQlAQAAAAAAAFQqipIAAAAAAAAAKhVFyWpmxowZaty4sby9vdWlSxdt2LDhvO0XLlyoVq1aydvbW+3atdPy5csrKVJcLlzJmXnz5slkMjn9eHt7V2K0cLeUlBTddtttioiIkMlk0ieffFJun6SkJF1zzTXy8vJS8+bNNW/evEseJy4fruZMUlLSOc8Zk8mk9PT0ygkYbhUfH6/OnTsrICBAoaGhiomJ0Y4dO8rtx/eZmutCcobvMzXbzJkz1b59ewUGBiowMFBdu3bVF198cd4+PGNqNldzhmcMzjR58mSZTCaNHj36vO1q6nOGomQ18tFHH2nMmDEaP368vv/+e1111VXq06ePjhw5Umr7r7/+Wvfcc48efvhhbdq0STExMYqJidHWrVsrOXK4i6s5I0mBgYE6fPiw4+fXX3+txIjhbjk5Obrqqqs0Y8aMCrXfs2eP+vfvrxtvvFFpaWkaPXq0hg4dqhUrVlziSHG5cDVnSuzYscPpWRMaGnqJIsTlJDk5WXFxcVq/fr0SExNls9kUHR2tnJycMvvwfaZmu5Cckfg+U5M1aNBAkydP1saNG/Xdd9/ppptu0sCBA7Vt27ZS2/OMgas5I/GMQbFvv/1Ws2bNUvv27c/brkY/ZwxUG9dee60RFxfn2C4qKjIiIiKM+Pj4UtvfeeedRv/+/Z32denSxfjb3/52SePE5cPVnJk7d64RFBRUSdHhcifJWLJkyXnbPP3000abNm2c9t11111Gnz59LmFkuFxVJGfWrl1rSDJ+//33SokJl7cjR44Ykozk5OQy2/B9BmeqSM7wfQZnCw4ONubMmVPqMZ4xKM35coZnDAzDME6ePGm0aNHCSExMNHr27GmMGjWqzLY1+TnDSMlqoqCgQBs3blRUVJRjn9lsVlRUlNatW1dqn3Xr1jm1l6Q+ffqU2R7Vy4XkjCRlZ2erUaNGioyMLPdfCAGeM7hQHTp0UL169dS7d2999dVX7g4HbpKZmSlJCgkJKbMNzxmcqSI5I/F9BsWKioq0YMEC5eTkqGvXrqW24RmDM1UkZySeMZDi4uLUv3//c54fpanJzxmKktXE0aNHVVRUpLCwMKf9YWFhZc7DlZ6e7lJ7VC8XkjMtW7bU22+/raVLl+r999+X3W5Xt27ddODAgcoIGVVQWc+ZrKws5eXluSkqXM7q1aunt956S4sWLdKiRYsUGRmpXr166fvvv3d3aKhkdrtdo0ePVvfu3dW2bdsy2/F9BiUqmjN8n8GWLVvk7+8vLy8vDR8+XEuWLFHr1q1LbcszBpJrOcMzBgsWLND333+v+Pj4CrWvyc8ZD3cHAKDq6Nq1q9O/CHbr1k1XXnmlZs2apUmTJrkxMgDVRcuWLdWyZUvHdrdu3fTLL79o+vTpeu+999wYGSpbXFyctm7dqtTUVHeHgiqiojnD9xm0bNlSaWlpyszM1Mcff6wHHnhAycnJZRaZAFdyhmdMzbZ//36NGjVKiYmJLHBUARQlq4k6derIYrEoIyPDaX9GRobCw8NL7RMeHu5Se1QvF5IzZ7Narbr66qu1a9euSxEiqoGynjOBgYHy8fFxU1Soaq699loKUzXMiBEjtGzZMqWkpKhBgwbnbcv3GUiu5czZ+D5T83h6eqp58+aSpI4dO+rbb7/V66+/rlmzZp3TlmcMJNdy5mw8Y2qWjRs36siRI7rmmmsc+4qKipSSkqJ//etfys/Pl8VicepTk58zvL5dTXh6eqpjx45avXq1Y5/dbtfq1avLnOuia9euTu0lKTEx8bxzY6D6uJCcOVtRUZG2bNmievXqXaowUcXxnMHFkJaWxnOmhjAMQyNGjNCSJUu0Zs0aNWnSpNw+PGdqtgvJmbPxfQZ2u135+fmlHuMZg9KcL2fOxjOmZrn55pu1ZcsWpaWlOX46deqk++67T2lpaecUJKUa/pxx90o7uHgWLFhgeHl5GfPmzTO2b99uDBs2zKhVq5aRnp5uGIZhDB482Hj22Wcd7b/66ivDw8PDmDp1qvHjjz8a48ePN6xWq7FlyxZ33QIqmas5M3HiRGPFihXGL7/8YmzcuNG4++67DW9vb2Pbtm3uugVUspMnTxqbNm0yNm3aZEgypk2bZmzatMn49ddfDcMwjGeffdYYPHiwo/3u3bsNX19f46mnnjJ+/PFHY8aMGYbFYjESEhLcdQuoZK7mzPTp041PPvnE2Llzp7FlyxZj1KhRhtlsNlatWuWuW0AlevTRR42goCAjKSnJOHz4sOMnNzfX0YbvMzjTheQM32dqtmeffdZITk429uzZY2zevNl49tlnDZPJZKxcudIwDJ4xOJerOcMzBmc7e/VtnjN/oChZzbz55ptGw4YNDU9PT+Paa6811q9f7zjWs2dP44EHHnBq/7///c+44oorDE9PT6NNmzbG559/XskRw91cyZnRo0c72oaFhRm33HKL8f3337sharjL2rVrDUnn/JTkyQMPPGD07NnznD4dOnQwPD09jaZNmxpz586t9LjhPq7mzMsvv2w0a9bM8Pb2NkJCQoxevXoZa9ascU/wqHSl5Yokp+cG32dwpgvJGb7P1GwPPfSQ0ahRI8PT09OoW7eucfPNNzuKS4bBMwbncjVneMbgbGcXJXnO/MFkGIZReeMyAQAAAAAAANR0zCkJAAAAAAAAoFJRlAQAAAAAAABQqShKAgAAAAAAAKhUFCUBAAAAAAAAVCqKkgAAAAAAAAAqFUVJAAAAAAAAAJWKoiQAAAAAAACASkVREgAAAAAAAECloigJAAAAAAAAoFJRlAQAAAAAAABQqShKAgAAAAAAAKhU/w/qA8l7yI9pywAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784, 2*784, 4*784, 1,],\n",
        "        \"samples\": [9, 18, 36, 6*784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [2, 4, 6, num_classes,],\n",
        "        \"samples\": [9, 9, 9, 784,],\n",
        "        \"is conv\": [False, False, False, False]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.MW.idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 10 # 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.MW.idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    ###\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    _loss = loss.item()\n",
        "    # loss += 1e-1 * torch.cat(model._penalties, dim=0).sum()\n",
        "    ###\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(_loss)\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 3\n",
        "    _batchidx = 0\n",
        "    feat_map = True\n",
        "    if feat_map:\n",
        "      pool = model.all_pools[_layer]\n",
        "      pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "      display.clear_output(wait=True)\n",
        "      plot_features(pool)\n",
        "    else:\n",
        "      pool = model.all_samples[_layer - 1]\n",
        "      _shape = (\n",
        "          model._curr_sets[_layer - 1],\n",
        "          model._curr_samples[_layer - 1],\n",
        "      )\n",
        "      _set = (model._curr_sets[_layer - 1]) // 2\n",
        "      pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "      display.clear_output(wait=True)\n",
        "      plot_features(pool)\n",
        "    from time import sleep\n",
        "    sleep(3)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "outputs": [],
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "##\n",
        "# phi = idxu[0] @ idxv[0].T\n",
        "# import seaborn as sns\n",
        "# sns.heatmap(phi.cpu().detach().numpy()); plt.show()\n",
        "##\n",
        "# iidx = xidx[(all_hoods[hood_filter]).reshape(-1)].reshape(sum(hood_filter), -1, 3)\n",
        "# iidx_ = iidx.mean(axis=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "ilOucSYLd2zy",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "kTfYY3SQXNJF",
        "vCh8kNiFl15G",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "8_m1YvjxBdj9"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMw89vO/RtY4crNT8pIHIsd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}