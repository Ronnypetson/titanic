{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd60e99a-3051-4142-bf59-e7a287322a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms import Normalize\n",
        "\n",
        "tr = ToTensor()\n",
        "cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "\n",
        "channels = 3\n",
        "img_dim = 32\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  return tr(x).reshape(-1)\n",
        "  # return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "# SOURCE_DATASET = FashionMNIST\n",
        "SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0):\n",
        "  idx = np.zeros((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _sgbmd(u, v, idxu, idxv, sim=None, f=None, normalize=True) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Slow General Batch Maromba Dot\"\n",
        "  Slower, more general, implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  sim: index similarity function\n",
        "  f: value function\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  sim = Pairwise(sim)\n",
        "  f = Pairwise(f)\n",
        "  ###\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  ###\n",
        "  # sims: (M * N) x 1 x (d_u * d_v)\n",
        "  # vals: (M * N) x (d_u * d_v) x d_val\n",
        "  sims = sim(idxu, idxv).reshape(m * n, 1, d_u * d_v) ###\n",
        "  norm = 1.0\n",
        "  if normalize:\n",
        "    # norm: (M * N) x 1\n",
        "    norm = sims.sum(dim=-1)\n",
        "  vals = f(u, v)\n",
        "  vals = vals.reshape(m * n, d_u * d_v, d_val)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.bmm(sims, vals).squeeze(1)\n",
        "  eps = 1e-8\n",
        "  dot = (dot / (norm + eps)).reshape(m, n, d_val)\n",
        "  return dot\n",
        "\n",
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = int(np.log((d_u + d_v) // 2)) * 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    ###\n",
        "    # mdot = _nsbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = _rdot(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, onesb, aidx, bidx)\n",
        "    #     + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    # midx = _nsbmd(aidx, bidx, aidx, bidx)\n",
        "    ###\n",
        "    midx = (\n",
        "        _rdot(aidx, onesb, aidx, bidx)\n",
        "        + _rdot(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "def idx2d(\n",
        "    channels: int,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    stride: int=2,\n",
        "    dilation: int=1,\n",
        "    device=\"cpu\"\n",
        "  ):\n",
        "  idx = []\n",
        "  dilh = 1 + dilation * (h - 1)\n",
        "  dilw = 1 + dilation * (w - 1)\n",
        "  for row in range(0, rows - (dilh - 1), stride):\n",
        "    for col in range(0, cols - (dilw - 1), stride):\n",
        "      for ch in range(channels):\n",
        "        for drow in range(0, dilh, dilation):\n",
        "          for dcol in range(0, dilw, dilation):\n",
        "            idx.append(\n",
        "                cols * rows * ch\n",
        "                + cols * (row + drow)\n",
        "                + (col + dcol)\n",
        "            )\n",
        "  idx = torch.tensor(idx).long().to(device)\n",
        "  return idx\n",
        "\n",
        "def unsort(idxs):\n",
        "  ridxs = [0 for _ in idxs]\n",
        "  for i, idx in enumerate(idxs):\n",
        "    ridxs[idx] = i\n",
        "  ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "  return ridxs\n",
        "\n",
        "def get_perms(tmp_idx):\n",
        "  idxs, _idxs = [], []\n",
        "  for dim in range(tmp_idx.shape[-1]):\n",
        "    ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "    idxs.append(ordering.cpu().detach())\n",
        "    _idxs.append(unsort(ordering).cpu().detach())\n",
        "  return idxs, _idxs\n",
        "\n",
        "def resort(k, src, tgt):\n",
        "  assert src == 0 or tgt == 0\n",
        "  global idxs, _idxs\n",
        "  if tgt == 0:\n",
        "    return idxs[src][k]\n",
        "  return _idxs[tgt][k]\n",
        "\n",
        "def hoods(dims, k0, w, _min=0, _max=None):\n",
        "  assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "  if len(dims) == 0:\n",
        "    return [k0] # [k0.item()]\n",
        "  _hoods = []\n",
        "  global idxs, _idxs\n",
        "  _k0d = resort(k0, 0, dims[-1]) #, idxs, _idxs)\n",
        "  for _w in range(-(w[-1] // 2), (w[-1] // 2) + (w[-1] % 2)):\n",
        "    # k0d = min(_max, max(_min, _k0d + _w))\n",
        "    k0d = torch.clip(_k0d + _w, min=_min, max=_max)\n",
        "    _hoods += hoods(\n",
        "        dims[:-1],\n",
        "        resort(\n",
        "            k0d,\n",
        "            dims[-1], 0,\n",
        "            # idxs, _idxs\n",
        "        ),\n",
        "        w[:-1],\n",
        "        # idxs, _idxs,\n",
        "        _min, _max\n",
        "    )\n",
        "  return _hoods\n",
        "\n",
        "idxs, _idxs = None, None\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array(range(len(xidx))).reshape(-1, 1)\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods\n",
        "\n",
        "def _idxhood(xidx, ws, stride):\n",
        "  \"\"\"\n",
        "  xidx: in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  dims = tuple(range(xidx.shape[-1]))\n",
        "  global idxs, _idxs\n",
        "  idxs, _idxs = get_perms(xidx)\n",
        "  pivots = torch.tensor([piv for piv in range(0, len(xidx), stride)]).long()\n",
        "  all_hoods = hoods(dims, pivots, ws, 0, len(xidx) - 1)\n",
        "  # all_hoods = torch.tensor(all_hoods).long().T.reshape(-1)\n",
        "  all_hoods = torch.cat(all_hoods, dim=0).reshape(len(all_hoods), -1).T\n",
        "  all_hoods = all_hoods.reshape(-1)\n",
        "  # Pdb().set_trace()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    self.activation = nn.ELU()\n",
        "    # self.activation = nn.ReLU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      ###\n",
        "      if step < n_layers - 1:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          # sample=True,\n",
        "          sample=False,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      pool = MTensor.reshape(pool, (n * feat_sets[step], -1)) @ mw\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      self.all_pools.append(pool[:4])\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim) ### offset=0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "HNheVxvNNK30",
        "outputId": "a715741a-0caa-4df5-e31c-dff9c944cde0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e5120073ada2>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# model = MModule(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# model = MModule2(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   model = MModule3(\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0midx_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MModule3' is not defined"
          ]
        }
      ],
      "source": [
        "hidden_dim = 50\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    (2, 3, 3),\n",
        "    (2, 3, 3),\n",
        "    # (2, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    hidden_dim,\n",
        "]\n",
        "\n",
        "sets = [samp[0] for samp in samples[1:-1]] + [1, num_classes]\n",
        "_samples = [int(np.prod(samp)) for samp in samples]\n",
        "conv_params = int(np.array(_samples[:-1]).dot(np.array(sets[:-1])))\n",
        "# conv_params = int(np.prod(np.array(samples[:-1])))\n",
        "n_params = int(np.array(_samples).dot(np.array(sets)))\n",
        "# n_params = conv_params + hidden_dim * num_classes\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  # model = MModule2(\n",
        "  model = MModule3(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "xGn5VTZPw-1K",
        "outputId": "e74e5f55-85f0-476d-abae-aef76c041700"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [1024,   1024,    1024,    1024,    1,],\n",
        "        \"samples\": [9,      9,       9,       1,       1024,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [16,     32,      64,      1,       num_classes,],\n",
        "        \"samples\": [(9, 3), (9, 16), (9, 32), (1, 32), (1024, 1),],\n",
        "    },\n",
        "}\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1,],\n",
        "#         \"samples\": [1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [num_classes,],\n",
        "#         \"samples\": [(200, 1),],\n",
        "#     },\n",
        "# }\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  # widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "_T9hF3Uoi3tF",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "Lyzd22RQX-Yg"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOEeqpRKy0fNC63DwhWjzlf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}