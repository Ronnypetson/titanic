{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dc7a51-cfa0-4200-d1d4-318148085a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11759997.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 211402.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3953686.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 23093344.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11446936.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 206581.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3947621.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 21898861.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 32 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ],
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0):\n",
        "  idx = np.zeros((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = int(np.log((d_u + d_v) // 2)) * 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    ###\n",
        "    mdot = _nsbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # ###\n",
        "    midx = (\n",
        "        _nsbmd(aidx, onesb, aidx, bidx)\n",
        "        + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    # midx = _nsbmd(aidx, bidx, aidx, bidx)\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _rdot(aidx, onesb, aidx, bidx)\n",
        "    #     + _rdot(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  xidx = xidx / np.linalg.norm(xidx, axis=-1)[:, None]\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    self.activation = nn.ELU()\n",
        "    # self.activation = nn.ReLU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    # _W = nn.Parameter(\n",
        "    #     2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    # )\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _std = 0.005\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        _std * torch.randn((*shape, idxdim), device=device)\n",
        "    )\n",
        "    # _W_idx = _std * torch.randn((*shape, idxdim), device=device)\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        # indices=torch.zeros(n, 1, idx_dim).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      pool = (\n",
        "          MTensor.reshape(\n",
        "              pool, (n * feat_sets[step], -1)\n",
        "          )\n",
        "          @ mw\n",
        "      )\n",
        "      ###\n",
        "      # pool = (\n",
        "      #     MTensor.reshape(pool, (n * feat_sets[step], -1))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim) ### offset=0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizações"
      ],
      "metadata": {
        "id": "8_m1YvjxBdj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ],
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "8f3561af-61a3-439c-b98a-bd9b3745223c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784,   784,   1,],\n",
        "        \"samples\": [9,     18,    2*784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [4,     4,     num_classes,],\n",
        "        \"samples\": [9,     18,    100,],\n",
        "        \"is conv\": [False, False, False]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-2)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 2\n",
        "    _batchidx = 0\n",
        "    # pool = model.all_pools[_layer]\n",
        "    # pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "    # display.clear_output(wait=True)\n",
        "    # plot_features(pool)\n",
        "    pool = model.all_samples[_layer - 1]\n",
        "    _shape = (\n",
        "        config[\"features\"][\"sets\"][_layer - 1],\n",
        "        config[\"features\"][\"samples\"][_layer - 1],\n",
        "    )\n",
        "    _set = (config[\"features\"][\"sets\"][_layer - 1]) // 2\n",
        "    pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "    display.clear_output(wait=True)\n",
        "    plot_features(pool)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ],
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "e0TdCxX0Jzn0",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "Lyzd22RQX-Yg",
        "Y-K_7fUh2anJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOuqqhaQBnevFd0U+Q7MRFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}