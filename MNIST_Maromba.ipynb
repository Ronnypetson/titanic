{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3eeb64-93ff-4704-c064-ec42aa1ab336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to MNIST_root/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:14<00:00, 11621145.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/cifar-10-python.tar.gz to MNIST_root/\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to MNIST_root_test/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12209587.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/cifar-10-python.tar.gz to MNIST_root_test/\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 3\n",
        "img_dim = 32\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  return transform(x).reshape(-1)\n",
        "  # return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 4 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "# SOURCE_DATASET = FashionMNIST\n",
        "SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\n",
        "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "#         self.fc2 = nn.Linear(120, 84)\n",
        "#         self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(F.relu(self.conv1(x)))\n",
        "#         x = self.pool(F.relu(self.conv2(x)))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = self.fc3(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ],
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0):\n",
        "  idx = np.zeros((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _sgbmd(u, v, idxu, idxv, sim=None, f=None, normalize=True) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Slow General Batch Maromba Dot\"\n",
        "  Slower, more general, implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  sim: index similarity function\n",
        "  f: value function\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  sim = Pairwise(sim)\n",
        "  f = Pairwise(f)\n",
        "  ###\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  ###\n",
        "  # sims: (M * N) x 1 x (d_u * d_v)\n",
        "  # vals: (M * N) x (d_u * d_v) x d_val\n",
        "  sims = sim(idxu, idxv).reshape(m * n, 1, d_u * d_v) ###\n",
        "  norm = 1.0\n",
        "  if normalize:\n",
        "    # norm: (M * N) x 1\n",
        "    norm = sims.sum(dim=-1)\n",
        "  vals = f(u, v)\n",
        "  vals = vals.reshape(m * n, d_u * d_v, d_val)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.bmm(sims, vals).squeeze(1)\n",
        "  eps = 1e-8\n",
        "  dot = (dot / (norm + eps)).reshape(m, n, d_val)\n",
        "  return dot\n",
        "\n",
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = int(np.log((d_u + d_v) // 2)) * 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    ###\n",
        "    # mdot = _nsbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = _rdot(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, onesb, aidx, bidx)\n",
        "    #     + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    # midx = _nsbmd(aidx, bidx, aidx, bidx)\n",
        "    ###\n",
        "    midx = (\n",
        "        _rdot(aidx, onesb, aidx, bidx)\n",
        "        + _rdot(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "def idx2d(\n",
        "    channels: int,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    stride: int=2,\n",
        "    dilation: int=1,\n",
        "    device=\"cpu\"\n",
        "  ):\n",
        "  idx = []\n",
        "  dilh = 1 + dilation * (h - 1)\n",
        "  dilw = 1 + dilation * (w - 1)\n",
        "  for row in range(0, rows - (dilh - 1), stride):\n",
        "    for col in range(0, cols - (dilw - 1), stride):\n",
        "      for ch in range(channels):\n",
        "        for drow in range(0, dilh, dilation):\n",
        "          for dcol in range(0, dilw, dilation):\n",
        "            idx.append(\n",
        "                cols * rows * ch\n",
        "                + cols * (row + drow)\n",
        "                + (col + dcol)\n",
        "            )\n",
        "  idx = torch.tensor(idx).long().to(device)\n",
        "  return idx\n",
        "\n",
        "def unsort(idxs):\n",
        "  ridxs = [0 for _ in idxs]\n",
        "  for i, idx in enumerate(idxs):\n",
        "    ridxs[idx] = i\n",
        "  ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "  return ridxs\n",
        "\n",
        "def get_perms(tmp_idx):\n",
        "  idxs, _idxs = [], []\n",
        "  for dim in range(tmp_idx.shape[-1]):\n",
        "    ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "    idxs.append(ordering.cpu().detach())\n",
        "    _idxs.append(unsort(ordering).cpu().detach())\n",
        "  return idxs, _idxs\n",
        "\n",
        "def resort(k, src, tgt):\n",
        "  assert src == 0 or tgt == 0\n",
        "  global idxs, _idxs\n",
        "  if tgt == 0:\n",
        "    return idxs[src][k]\n",
        "  return _idxs[tgt][k]\n",
        "\n",
        "def hoods(dims, k0, w, _min=0, _max=None):\n",
        "  assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "  if len(dims) == 0:\n",
        "    return [k0] # [k0.item()]\n",
        "  _hoods = []\n",
        "  global idxs, _idxs\n",
        "  _k0d = resort(k0, 0, dims[-1]) #, idxs, _idxs)\n",
        "  for _w in range(-(w[-1] // 2), (w[-1] // 2) + (w[-1] % 2)):\n",
        "    # k0d = min(_max, max(_min, _k0d + _w))\n",
        "    k0d = torch.clip(_k0d + _w, min=_min, max=_max)\n",
        "    _hoods += hoods(\n",
        "        dims[:-1],\n",
        "        resort(\n",
        "            k0d,\n",
        "            dims[-1], 0,\n",
        "            # idxs, _idxs\n",
        "        ),\n",
        "        w[:-1],\n",
        "        # idxs, _idxs,\n",
        "        _min, _max\n",
        "    )\n",
        "  return _hoods\n",
        "\n",
        "idxs, _idxs = None, None\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods\n",
        "\n",
        "def _idxhood(xidx, ws, stride):\n",
        "  \"\"\"\n",
        "  xidx: in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  dims = tuple(range(xidx.shape[-1]))\n",
        "  global idxs, _idxs\n",
        "  idxs, _idxs = get_perms(xidx)\n",
        "  pivots = torch.tensor([piv for piv in range(0, len(xidx), stride)]).long()\n",
        "  all_hoods = hoods(dims, pivots, ws, 0, len(xidx) - 1)\n",
        "  # all_hoods = torch.tensor(all_hoods).long().T.reshape(-1)\n",
        "  all_hoods = torch.cat(all_hoods, dim=0).reshape(len(all_hoods), -1).T\n",
        "  all_hoods = all_hoods.reshape(-1)\n",
        "  # Pdb().set_trace()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # self.activation = nn.ELU()\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=torch.zeros(n, 1, idx_dim).to(device),\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          # sample=True,\n",
        "          sample=False,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      pool = (\n",
        "          self._put_one(MTensor.reshape(\n",
        "              pool, (n * feat_sets[step], -1)\n",
        "          ))\n",
        "          @ mw\n",
        "      )\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      self.all_pools.append(pool[:4])\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim) ### offset=0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "HNheVxvNNK30",
        "outputId": "a715741a-0caa-4df5-e31c-dff9c944cde0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e5120073ada2>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# model = MModule(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# model = MModule2(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   model = MModule3(\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0midx_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MModule3' is not defined"
          ]
        }
      ],
      "source": [
        "hidden_dim = 50\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    (2, 3, 3),\n",
        "    (2, 3, 3),\n",
        "    # (2, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    # (1, 3, 3),\n",
        "    hidden_dim,\n",
        "]\n",
        "\n",
        "sets = [samp[0] for samp in samples[1:-1]] + [1, num_classes]\n",
        "_samples = [int(np.prod(samp)) for samp in samples]\n",
        "conv_params = int(np.array(_samples[:-1]).dot(np.array(sets[:-1])))\n",
        "# conv_params = int(np.prod(np.array(samples[:-1])))\n",
        "n_params = int(np.array(_samples).dot(np.array(sets)))\n",
        "# n_params = conv_params + hidden_dim * num_classes\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  # model = MModule2(\n",
        "  model = MModule3(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "xGn5VTZPw-1K",
        "outputId": "430ca98b-7331-421b-d489-7ec5d6f518d7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = False\n",
        "valid_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [1024,    1024,     1024,    1,         1,        1,],\n",
        "        \"samples\": [25,      25,       1,       1024,      200,      100,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [6,       16,       1,       200,       100,      num_classes,],\n",
        "        \"samples\": [(76, 1), (151, 1), (1, 17), (1025, 1), (201, 1), (101, 1),],\n",
        "        \"is conv\": [True,    True,    True,    False,     False,    False,]\n",
        "    },\n",
        "}\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1,],\n",
        "#         \"samples\": [1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [num_classes,],\n",
        "#         \"samples\": [(200, 1),],\n",
        "#     },\n",
        "# }\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  # widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "ilOucSYLd2zy",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "_T9hF3Uoi3tF",
        "1SknOTQ7O9BS",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "Lyzd22RQX-Yg"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNgiAXusjcyBFDDiJhrVOUm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}