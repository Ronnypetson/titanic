{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P"
      },
      "outputs": [],
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  x = x.resize((img_dim, img_dim))\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "\n",
        "bsize = 32\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, d=2):\n",
        "  idx = np.zeros((rows, cols, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      # idx[row, col, 0] = (1 + row) / rows\n",
        "      # idx[row, col, 1] = (1 + col) / cols\n",
        "      idx[row, col, 0] = 2.0 * ((row) / rows) - 1.0 ### (row + 1)\n",
        "      idx[row, col, 1] = 2.0 * ((col) / cols) - 1.0 ### (col + 1)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _sgbmd(u, v, idxu, idxv, sim=None, f=None, normalize=True) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Slow General Batch Maromba Dot\"\n",
        "  Slower, more general, implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  sim: index similarity function\n",
        "  f: value function\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  sim = Pairwise(sim)\n",
        "  f = Pairwise(f)\n",
        "  ###\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  ###\n",
        "  # sims: (M * N) x 1 x (d_u * d_v)\n",
        "  # vals: (M * N) x (d_u * d_v) x d_val\n",
        "  sims = sim(idxu, idxv).reshape(m * n, 1, d_u * d_v) ###\n",
        "  norm = 1.0\n",
        "  if normalize:\n",
        "    # norm: (M * N) x 1\n",
        "    norm = sims.sum(dim=-1)\n",
        "  vals = f(u, v)\n",
        "  vals = vals.reshape(m * n, d_u * d_v, d_val)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.bmm(sims, vals).squeeze(1)\n",
        "  eps = 1e-8\n",
        "  dot = (dot / (norm + eps)).reshape(m, n, d_val)\n",
        "  return dot\n",
        "\n",
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  # Pdb().set_trace()\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  # normalizer: M x N x 1\n",
        "  idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv ** 6.0\n",
        "  # idxuv = nn.functional.relu(idxuv - bias) ###\n",
        "  mag = 2.0 # 10.0 # 200.0\n",
        "  idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # idxuv = nn.functional.gumbel_softmax(\n",
        "  #     6.0 * idxuv - 3.0, dim=2, hard=False, tau=0.2\n",
        "  # )\n",
        "  # idxuv = get_eye(m, d_u, d_v, n, idxuv.device)\n",
        "  # idxuv = idxuv / (idxuv.sum(dim=2).unsqueeze(2) + 1e-6)\n",
        "  # Pdb().set_trace()\n",
        "  ###\n",
        "  # normalizer = idxuv.reshape(m, d_u * d_v, n).sum(dim=1).reshape(m, n, 1)\n",
        "  ###\n",
        "  # normalizer = 1.0 - 1e-6\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  # dot = dot / (normalizer + 1e-6)\n",
        "  return dot\n",
        "\n",
        "def _gbmd(u, v, idxu, idxv, kernel=None, idx_part=None) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"General Batch Maromba Dot\"\n",
        "  Shorter implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u\n",
        "  v: N x d_v\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u = u.shape\n",
        "  n, d_v = v.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  assert (m, d_u, d_idx) == idxu.shape\n",
        "  assert (n, d_v, d_idx) == idxv.shape\n",
        "  if kernel:\n",
        "    idxu = kernel(idxu, idx_part)\n",
        "    idxv = kernel(idxv, idx_part)\n",
        "  # uidxu: M x d_idx\n",
        "  # vidxv: N x d_idx\n",
        "  uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "  vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "  dot = uidxu @ vidxv.T\n",
        "  ### Under experimentation\n",
        "  normalizer = idxu.sum(dim=1) @ idxv.sum(dim=1).T\n",
        "  dot = dot / (normalizer + 1e-8) ###\n",
        "  ###\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    # kernel = _cosine_kernel\n",
        "    # mdot = _gbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1]),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1]),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel=kernel,\n",
        "    #     idx_part=self._idx_part,\n",
        "    # )\n",
        "    # mdot = _sgbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     f=vecprod,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = _nsbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # _kernel_idx # _fast_kernel_idx # _fast_kernel_idx_sum\n",
        "    # midx = _fast_kernel_idx_sum(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel,\n",
        "    #     self._idx_part,\n",
        "    # )\n",
        "    # midx = _sgbmd(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     # f=vecsum,\n",
        "    #     f=vecmean,\n",
        "    # )\n",
        "    ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # midx = norm_normalize(\n",
        "    #     norm_normalize(_nsbmd(aidx, onesb, aidx, bidx))\n",
        "    #     + norm_normalize(_nsbmd(onesa, bidx, aidx, bidx))\n",
        "    # )\n",
        "    # midx = norm_normalize(_nsbmd(aidx, bidx, aidx, bidx))\n",
        "    midx = (\n",
        "        _nsbmd(aidx, onesb, aidx, bidx)\n",
        "        + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    # Pdb().set_trace()\n",
        "    ###\n",
        "    # midx = norm_normalize(\n",
        "    #     norm_normalize(_rdot(aidx, onesb, aidx, bidx))\n",
        "    #     + norm_normalize(_rdot(onesa, bidx, aidx, bidx))\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "def idx2d(\n",
        "    channels: int,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    stride: int=2,\n",
        "    dilation: int=1,\n",
        "    device=\"cpu\"\n",
        "  ):\n",
        "  idx = []\n",
        "  dilh = 1 + dilation * (h - 1)\n",
        "  dilw = 1 + dilation * (w - 1)\n",
        "  for row in range(0, rows - (dilh - 1), stride):\n",
        "    for col in range(0, cols - (dilw - 1), stride):\n",
        "      for ch in range(channels):\n",
        "        for drow in range(0, dilh, dilation):\n",
        "          for dcol in range(0, dilw, dilation):\n",
        "            idx.append(\n",
        "                cols * rows * ch\n",
        "                + cols * (row + drow)\n",
        "                + (col + dcol)\n",
        "            )\n",
        "  idx = torch.tensor(idx).long().to(device)\n",
        "  return idx\n",
        "\n",
        "def unsort(idxs):\n",
        "  ridxs = [0 for _ in idxs]\n",
        "  for i, idx in enumerate(idxs):\n",
        "    ridxs[idx] = i\n",
        "  ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "  return ridxs\n",
        "\n",
        "def get_perms(tmp_idx):\n",
        "  idxs, _idxs = [], []\n",
        "  for dim in range(tmp_idx.shape[-1]):\n",
        "    ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "    idxs.append(ordering.cpu().detach())\n",
        "    _idxs.append(unsort(ordering).cpu().detach())\n",
        "  return idxs, _idxs\n",
        "\n",
        "def resort(k, src, tgt):\n",
        "  assert src == 0 or tgt == 0\n",
        "  global idxs, _idxs\n",
        "  if tgt == 0:\n",
        "    return idxs[src][k]\n",
        "  return _idxs[tgt][k]\n",
        "\n",
        "def hoods(dims, k0, w, _min=0, _max=None):\n",
        "  assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "  if len(dims) == 0:\n",
        "    return [k0] # [k0.item()]\n",
        "  _hoods = []\n",
        "  global idxs, _idxs\n",
        "  _k0d = resort(k0, 0, dims[-1]) #, idxs, _idxs)\n",
        "  for _w in range(-(w[-1] // 2), (w[-1] // 2) + (w[-1] % 2)):\n",
        "    # k0d = min(_max, max(_min, _k0d + _w))\n",
        "    k0d = torch.clip(_k0d + _w, min=_min, max=_max)\n",
        "    _hoods += hoods(\n",
        "        dims[:-1],\n",
        "        resort(\n",
        "            k0d,\n",
        "            dims[-1], 0,\n",
        "            # idxs, _idxs\n",
        "        ),\n",
        "        w[:-1],\n",
        "        # idxs, _idxs,\n",
        "        _min, _max\n",
        "    )\n",
        "  return _hoods\n",
        "\n",
        "idxs, _idxs = None, None\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def idxhood(xidx, ws, stride):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  all_hoods = neigh.kneighbors(xidx, return_distance=False).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods\n",
        "\n",
        "def _idxhood(xidx, ws, stride):\n",
        "  \"\"\"\n",
        "  xidx: in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  dims = tuple(range(xidx.shape[-1]))\n",
        "  global idxs, _idxs\n",
        "  idxs, _idxs = get_perms(xidx)\n",
        "  pivots = torch.tensor([piv for piv in range(0, len(xidx), stride)]).long()\n",
        "  all_hoods = hoods(dims, pivots, ws, 0, len(xidx) - 1)\n",
        "  # all_hoods = torch.tensor(all_hoods).long().T.reshape(-1)\n",
        "  all_hoods = torch.cat(all_hoods, dim=0).reshape(len(all_hoods), -1).T\n",
        "  all_hoods = all_hoods.reshape(-1)\n",
        "  # Pdb().set_trace()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdZ8zHIcPQPS"
      },
      "source": [
        "#### MModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tQoFxrDIPScK"
      },
      "outputs": [],
      "source": [
        "class MModule(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _W_step(\n",
        "      self,\n",
        "      x: MTensor,\n",
        "      W: MTensor,\n",
        "      sets,\n",
        "      samples,\n",
        "      random=True,\n",
        "      conv=False,\n",
        "      filter_size=4,\n",
        "      activation=True,\n",
        "      regular_dot=False):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    # Put 1 into x\n",
        "    if not conv:\n",
        "      filter_size = in_dim\n",
        "    assert (in_dim % filter_size) == 0\n",
        "    num_windows = (in_dim // filter_size)\n",
        "    # one = MTensor(\n",
        "    #     torch.ones((n * num_windows), 1).to(self.device),\n",
        "    #     torch.ones((n * num_windows), 1, idx_dim).to(self.device),\n",
        "    # )\n",
        "    x = MTensor.reshape(x, (n * num_windows, filter_size))\n",
        "    # Sample W\n",
        "    if conv:\n",
        "      ### filter_size + 1\n",
        "      assert (sets * samples) % (filter_size) == 0\n",
        "      numw_windows = (sets * samples) // (filter_size)\n",
        "      sets, samples = numw_windows, (filter_size)\n",
        "    W_sets = MTensor.reshape(W, (sets, samples))\n",
        "    ## mdot: N x sets\n",
        "    # mdot: (N * num_windows) x numw_windows\n",
        "    mdot = x @ W_sets\n",
        "    if activation:\n",
        "      mdot.data = self.activation(mdot.data)\n",
        "    # mdot: N x num_windows x numw_windows\n",
        "    if conv:\n",
        "      ### Várias \"imagens\" coladas em um sentido\n",
        "      mdot = MTensor.reshape(mdot, (n, num_windows, numw_windows))\n",
        "    return mdot\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    channels = 1\n",
        "    img_h, img_w = img_dim, img_dim\n",
        "    filter_whs = [(3, 3), (3, 3)]\n",
        "    strides = [2, 1]\n",
        "    filter_w, filter_h = filter_whs[0]\n",
        "    stride = strides[0]\n",
        "    filter_area = filter_w * filter_h\n",
        "    filter_volume = channels * filter_area\n",
        "    self.all_pools = [x[:4]]\n",
        "    idx = idx2d(\n",
        "        channels,\n",
        "        img_h, img_w,\n",
        "        filter_w, filter_h,\n",
        "        stride=stride,\n",
        "        device=self.device\n",
        "    )\n",
        "    x = x[:, idx]\n",
        "    ###\n",
        "    pool = x\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      if conv:\n",
        "        pool = self._W_step(\n",
        "            pool,\n",
        "            self.MW[:, wl: wr],\n",
        "            self.sets[step],\n",
        "            self.samples[step],\n",
        "            random=False,\n",
        "            conv=conv,\n",
        "            filter_size=filter_volume,\n",
        "            activation=activate,\n",
        "        )\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        filter_volume = channels * filter_area\n",
        "        pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # assert img_dim % stride == 0\n",
        "        img_h = (img_h - filter_h + stride) // stride\n",
        "        img_w = (img_w - filter_w + stride) // stride\n",
        "        assert img_h * img_w == img_area\n",
        "        # cols = pool.data.shape[1] // rows\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        filter_w, filter_h = filter_whs[nxt_conv_step]\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_area = filter_w * filter_h\n",
        "        filter_volume = channels * filter_area\n",
        "        if nxt_conv:\n",
        "          idx = idx2d(\n",
        "              channels,\n",
        "              img_h, img_w,\n",
        "              filter_w, filter_h,\n",
        "              stride=stride,\n",
        "              device=self.device\n",
        "          )\n",
        "          pool = pool[:, idx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mlldpkcPFvk"
      },
      "source": [
        "#### MModule II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Oipx_P9qYUUb"
      },
      "outputs": [],
      "source": [
        "class MModule2(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "    self._prev_idx = None\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(3, 3, 1), (3, 3, 2), (3, 3, 2)]\n",
        "    strides = [1, 1, 1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0]) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    # idxw = idxhood(\n",
        "    #     mw.idx,\n",
        "    #     filter_whs[0],\n",
        "    #     strides[0]\n",
        "    # ) ### FIX\n",
        "    # mw = mw[:, idxw]\n",
        "    for step in range(n_sets):\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        # Pdb().set_trace()\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        # pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step]\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    # Pdb().set_trace()\n",
        "    # if self._prev_idx is not None:\n",
        "    #   print((self._prev_idx - self.all_pools[-1][0].idx).mean())\n",
        "    # self._prev_idx = self.all_pools[-1][0].idx\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  y_pred = 10.0 * y_pred.data\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, d=idx_dim)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OisDCAuLCmQ8"
      },
      "outputs": [],
      "source": [
        "# tmp_idx = template_x_idx[0].reshape(-1, 3)[:, :2]\n",
        "# idxs, _idxs = get_perms(tmp_idx)\n",
        "# sampled = hoods([0, 1], 14 * 28 + 14, [3, 3], idxs, _idxs, 0, 783)\n",
        "# sampled = np.array([[idx // 28, idx % 28] for idx in sampled])\n",
        "# # print(sampled)\n",
        "# plt.scatter(sampled[:, 0], sampled[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tmp_idx = template_x_idx[0].reshape(-1, 2).cpu().detach().numpy()\n",
        "# # set desired number of neighbors\n",
        "# neigh = NearestNeighbors(n_neighbors=9)\n",
        "# neigh.fit(tmp_idx)\n",
        "# # select indices of k nearest neighbors of the vectors in the input list\n",
        "# neighbors = neigh.kneighbors(tmp_idx, return_distance=False)\n",
        "# print(neighbors[0])\n",
        "# print(neighbors[1])\n",
        "# print(neighbors[28])\n",
        "# print(neighbors[29])"
      ],
      "metadata": {
        "id": "OoGmgn1K--XO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "HNheVxvNNK30",
        "outputId": "8ec2152f-3d04-4724-b540-0916d7a29565"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABQcAAAEmCAYAAADfgia2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOWElEQVR4nO3deXRU9f3/8dedycxkDyQhgUDCvq8KiIBVdkSLe9VKLWpra0Wt4tLqt1pwqdtXi1trl2/1ZytaraK2aBVBoCIoS6Mo+xoQSFgTsk0mM/f3x2SGbEACk9ybzPNxTs7MXebe94R3bshrPvdewzRNUwAAAAAAAACijsPqAgAAAAAAAABYg3AQAAAAAAAAiFKEgwAAAAAAAECUIhwEAAAAAAAAohThIAAAAAAAABClCAcBAAAAAACAKEU4CAAAAAAAAEQpwkEAAAAAAAAgSsVYXUBtgUBAe/bsUVJSkgzDsLocAAAAAAAAoEUxTVNHjx5VVlaWHI4Tjw20XTi4Z88eZWdnW10GAAAAAAAA0KLt2rVLnTp1OuE6jQ4Hly5dqieffFKrV6/W3r17NW/ePF1yySX1rnvTTTfpD3/4g37729/q9ttvb9D2k5KSJAWLT05Obmx5LYLP59NHH32kSZMmyeVyWV0OQE/CluhL2BF9CTuiL2FH9CXshp6EHTVlXxYVFSk7Ozucs51Io8PBkpISDR48WDfccIMuu+yy4643b948rVixQllZWY3afuhU4uTk5FYdDsbHxys5OZmDEmyBnoQd0ZewI/oSdkRfwo7oS9gNPQk7ao6+bMgl+xodDk6ZMkVTpkw54Trffvutbr31Vn344Ye68MILG7sLAAAAAAAAAM0g4tccDAQCuvbaa3X33Xerf//+J13f6/XK6/WGp4uKiiQF01Ofzxfp8mwh9L5a6/tDy0NPwo7oS9gRfQk7oi9hR/Ql7IaehB01ZV82ZpsRDwcff/xxxcTE6LbbbmvQ+o8++qhmz55dZ/5HH32k+Pj4SJdnKwsWLLC6BKAGehJ2RF/CjuhL2BF9CTuiL2E39CTsqCn6srS0tMHrRjQcXL16tZ555hmtWbOmQec0S9K9996rmTNnhqdDF0ycNGlSq77m4IIFCzRx4kSudQBboCdhR/Ql7Ii+hB3Rl7Aj+hJ2Q08en2ma8vv98vv9Mk3T6nKiSmVlpT777DONGjVKMTGNi+gMw1BMTIycTme9y0Nn5jZERMPB//znPyooKFBOTk54nt/v15133qk5c+Zox44ddV7j8Xjk8XjqzHe5XK3+BzYa3iNaFnoSdkRfwo7oS9gRfQk7oi9hN/RkTRUVFdq7d2+jRpkhckzTVPv27bV3794GD7KrzjAMderUSYmJiXWWNabPIxoOXnvttZowYUKNeZMnT9a1116r66+/PpK7avEChPEAAAAAAMAigUBA27dvl9PpVFZWltxu9ykFVDh1gUBAxcXFSkxMlMPhaNRrTdPU/v37tXv3bvXs2fO4IwgbotHhYHFxsbZs2RKe3r59u3Jzc5WamqqcnBylpaXVWN/lcql9+/bq3bv3KRfZmny8Ll9PL9iotIBD37W6GAAAAAAAEJUqKioUCASUnZ3d6u/5YFeBQEAVFRWKjY1tdDgoSe3atdOOHTvk8/maNxxctWqVxo4dG54OXS9w+vTpevnll0+5kGhhGNK6vUfV1m1wLj8AAAAAALDUqYRSsIdIjfRsdDg4ZsyYRoVa9V1nMJqN6p4uT4xDhysC2pRfrAHZqVaXBAAAAAAAgChFPNzM4txOjeoeDAQ/2bjf4moAAAAAAAAQzQgHLTC2dztJ0iebDlhcCQAAAAAAQPTq0qWL5syZY/k2rBTRuxWjYcb0aidpvf6764gOFnuVluixuiQAAAAAAADbGzNmjIYMGRKxMG7lypVKSEiIyLZaKkYOWqBDSqw6xpsyTWkxpxYDAAAAAABEjGmaqqysbNC67dq1i/q7NRMOWmRA2+BNXRZtKLC4EgAAAAAAEO1M01RpRaUlXw298e11112nJUuW6JlnnpFhGDIMQzt27NDixYtlGIY++OADDR06VB6PR59++qm2bt2qiy++WJmZmUpMTNTw4cP18ccf19hm7VOCDcPQn//8Z1166aWKj49Xz5499d577zXqe5mXl6eLL75YiYmJSk5O1pVXXqn8/Pzw8i+//FJjx45VSkqKcnJyNHz4cK1atUqStHPnTk2dOlVt27ZVQkKC+vfvr/fff79R+28sTiu2SP+2AX34rUNLN+1XRWVA7hhyWgAAAAAAYI0yn1/9HvjQkn2ve3Cy4t0nj6ieeeYZbdq0SQMGDNCDDz4oKTjyb8eOHZKkX/7yl/rf//1fdevWTW3bttWuXbt0wQUX6JFHHpHH49Err7yiqVOnauPGjcrJyTnufmbPnq0nnnhCTz75pJ577jlNmzZNO3fuVGpq6klrDAQC4WBwyZIlqqys1IwZM3TVVVdp8eLFkqRp06bpjDPO0AsvvKCysjJt2bJFLpdLkjRjxgxVVFRo6dKlSkhI0Lp165SYmHjS/Z4OwkGLZCdKaQluHSyp0ModhzS6R7rVJQEAAAAAANhWSkqK3G634uPj1b59+zrLH3zwQU2cODE8nZqaqsGDB4enH3roIc2bN0/vvfeebrnlluPu57rrrtP3v/99SdJvfvMbPfvss/riiy90/vnnn7TGhQsXau3atdq+fbuys7MlSa+88or69++vlStXavjw4crLy9Pdd9+tPn36qKioSGeccYYcjuCgsby8PF1++eUaOHCgJKlbt24N+M6cHsJBizgMaUzvdL21Zo8Wri8gHAQAAAAAAJaJczm17sHJlu07EoYNG1Zjuri4WLNmzdL8+fO1d+9eVVZWqqysTHl5eSfczqBBg8LPExISlJycrIKChl0Wbv369crOzg4Hg5LUr18/tWnTRuvXr9fw4cM1c+ZM/fjHP9Zf//pXjR49Wj/4wQ/Us2dPSdJtt92mn/3sZ/roo480YcIEXX755TXqaQqcy2qhcb3bSZIWbshv8Pn1AAAAAAAAkWYYhuLdMZZ8GYYRkfdQ+67Dd911l+bNm6ff/OY3+s9//qPc3FwNHDhQFRUVJ9xO6BTf6t+bQCAQkRoladasWfrmm290wQUX6D//+Y8GDBigefPmSZJ+/OMfa9u2bbr22mu1du1aDRs2TM8991zE9l0fwkELjeqeJrfToZ0HS7XtQInV5QAAAAAAANia2+2W3+9v0LrLli3Tddddp0svvVQDBw5U+/btw9cnbCp9+/bVrl27tGvXrvC8devW6ciRI+rXr194Xq9evXT77bfr7bff1qWXXqqXXnopvCw7O1s33XST3n77bd15553605/+1KQ1Ew5aKNEToxHdghezXLg+/yRrAwAAAAAARLcuXbro888/144dO3TgwIETjujr2bOn3n77beXm5urLL7/UNddcE9ERgPWZMGGCBg4cqGnTpmnNmjX64osv9MMf/lDnnXeehg0bprKyMt1yyy1avHixdu7cqRUrVmjVqlXq27evJOn222/Xhx9+qO3bt2vNmjX65JNPwsuaCuGgxcb3yZAkLVzfsHPXAQAAAAAAotVdd90lp9Opfv36qV27die8fuDTTz+ttm3batSoUZo6daomT56sM888s0nrMwxD7777rtq2batzzz1XEyZMULdu3fT3v/9dkuR0OnXw4EH98Ic/VJ8+fXTDDTfo/PPP1+zZsyVJfr9fM2bMUN++fXX++eerV69e+t3vftekNXNDEouN75upWf9cp1U7D6uw1KeUeNfJXwQAAAAAABCFevXqpeXLl9eY16VLl3rv5dClSxctWrSoxrwZM2bUmK59mnF92zly5MgJa6q9jZycHL377rv1rut2u/Xaa69JkgKBgIqKipScnBy+W3FTX1+wPowctFh2arx6ZSbKHzC1ZPN+q8sBAAAAAABAFCEctIFxfTIlcd1BAAAAAAAANC/CQRsY3zd43cHFG/er0t+0F8YEAAAAAAAAQggHbeCM7DZqE+9SYZlPa/KOWF0OAAAAAAAAogThoA3EOB0a27vqrsUbOLUYAAAAAAA0j/puwIGWIVL/doSDNjGuTzAcXLS+wOJKAAAAAABAa+dyuSRJpaWlFleCU1VRUSFJcjqdp7WdmEgUg9N3bq92cjoMbS4oVt7BUuWkxVtdEgAAAAAAaKWcTqfatGmjgoLgIKX4+HgZhmFxVdElEAiooqJC5eXlcjgaN34vEAho//79io+PV0zM6cV7jX710qVL9eSTT2r16tXau3ev5s2bp0suuUSS5PP59Ktf/Urvv/++tm3bppSUFE2YMEGPPfaYsrKyTqvQ1i4lzqXhXdpqxbZDWrghX9eP7mp1SQAAAAAAoBVr3769JIUDQjQv0zRVVlamuLi4UwpmHQ6HcnJyTjvUbXQ4WFJSosGDB+uGG27QZZddVmNZaWmp1qxZo/vvv1+DBw/W4cOH9fOf/1wXXXSRVq1adVqFRoMJfTO1YtshLdpQQDgIAAAAAACalGEY6tChgzIyMuTz+awuJ+r4fD4tXbpU5557bvg078Zwu92NHnFYn0aHg1OmTNGUKVPqXZaSkqIFCxbUmPf888/rrLPOUl5ennJyck6tyigxrk+GHp6/Xiu2HVSxt1KJHs76BgAAAAAATcvpdJ72devQeE6nU5WVlYqNjT2lcDBSmjx9KiwslGEYatOmTb3LvV6vvF5veLqoqEhSMD1tral16H3Vfn/ZbTzqkhavHQdL9cn6fTq/f6YV5SEKHa8nASvRl7Aj+hJ2RF/CjuhL2A09CTtqyr5szDYN8zTue2wYRo1rDtZWXl6u0aNHq0+fPnr11VfrXWfWrFmaPXt2nflz585VfHz03ZRj3g6HFu916Kx2AU3rEbC6HAAAAAAAALQwpaWluuaaa1RYWKjk5OQTrttk4aDP59Pll1+u3bt3a/HixcctpL6Rg9nZ2Tpw4MBJi2+pfD6fFixYoIkTJ9YZNrpi2yFd+9IqpSa4tPyeMXI4uFMQmt6JehKwCn0JO6IvYUf0JeyIvoTd0JOwo6bsy6KiIqWnpzcoHGyS04p9Pp+uvPJK7dy5U4sWLTphER6PRx6Pp858l8vV6n9g63uPZ/dopyRPjA6V+LQuv0Rn5LS1qDpEo2j4uUPLQ1/CjuhL2BF9CTuiL2E39CTsqCn6sjHbO/1bmtQSCgY3b96sjz/+WGlpaZHeRavmcjp0bu92kqSF67mVOAAAAAAAAJpOo8PB4uJi5ebmKjc3V5K0fft25ebmKi8vTz6fT1dccYVWrVqlV199VX6/X/v27dO+fftUUVER6dpbrfF9MiRJCzcQDgIAAAAAAKDpNPq04lWrVmns2LHh6ZkzZ0qSpk+frlmzZum9996TJA0ZMqTG6z755BONGTPm1CuNImN6Z8hhSOv3FmnPkTJltYmzuiQAAAAAAAC0Qo0OB8eMGaMT3cPkNO5vgiqpCW6dmdNWq3Ye1qINBfrB2Z2tLgkAAAAAAACtUMSvOYjIGNe36tTi9fkWVwIAAAAAAIDWinDQpsb3yZQkLdt6UKUVlRZXAwAAAAAAgNaIcNCmemUmqlPbOFVUBvTZloNWlwMAAAAAAIBWiHDQpgzD4K7FAAAAAAAAaFKEgzY2rm/w1OJFG/K50QsAAAAAAAAijnDQxkZ0TVW826n8Iq++2VNkdTkAAAAAAABoZQgHbSzW5dR3eqZLkhau59RiAAAAAAAARBbhoM2F7lq8aEO+xZUAAAAAAACgtSEctLkxfdpJkr7cXaiConKLqwEAAAAAAEBrQjhocxlJsRrcKUWS9MlGTi0GAAAAAABA5BAOtgDjqk4t5rqDAAAAAAAAiCTCwRZgfN8MSdKnWw6o3Oe3uBoAAAAAAAC0FoSDLUD/rGRlJntUWuHXim0HrS4HAAAAAAAArQThYAtgGEb41OJFGzi1GAAAAAAAAJFBONhCjO8TPLV44foCmaZpcTUAAAAAAABoDQgHW4jRPdLliXHo2yNl2pRfbHU5AAAAAAAAaAUIB1uIOLdTo3ukS5I+Xp9vcTUAAAAAAABoDQgHW5BxVacWc91BAAAAAAAARALhYAsSCgfX5B3WoZIKi6sBAAAAAABAS0c42IJktYlTvw7JMk1p8UZGDwIAAAAAAOD0EA62MOP7Vt21mFOLAQAAAAAAcJoaHQ4uXbpUU6dOVVZWlgzD0DvvvFNjuWmaeuCBB9ShQwfFxcVpwoQJ2rx5c6TqjXqhU4uXbtyvisqAxdUAAAAAAACgJWt0OFhSUqLBgwfrhRdeqHf5E088oWeffVYvvviiPv/8cyUkJGjy5MkqLy8/7WIhDe7URumJbh31VmrVjkNWlwMAAAAAAIAWLKaxL5gyZYqmTJlS7zLTNDVnzhz96le/0sUXXyxJeuWVV5SZmal33nlHV1999elVCzkchsb2ztCbq3dr4YYCjeqRbnVJAAAAAAAAaKEaHQ6eyPbt27Vv3z5NmDAhPC8lJUUjRozQ8uXL6w0HvV6vvF5veLqoqEiS5PP55PP5IlmebYTe16m+v/N6pgXDwfX5+uXknpEsDVHqdHsSaAr0JeyIvoQd0ZewI/oSdkNPwo6asi8bs82IhoP79u2TJGVmZtaYn5mZGV5W26OPPqrZs2fXmf/RRx8pPj4+kuXZzoIFC07pdeV+yWk4teNgqV56631lxkW4MEStU+1JoCnRl7Aj+hJ2RF/CjuhL2A09CTtqir4sLS1t8LoRDQdPxb333quZM2eGp4uKipSdna1JkyYpOTnZwsqajs/n04IFCzRx4kS5XK5T2sZ7B1dr2daDCrTvpwtGd4lsgYg6kehJINLoS9gRfQk7oi9hR/Ql7IaehB01ZV+GzsxtiIiGg+3bt5ck5efnq0OHDuH5+fn5GjJkSL2v8Xg88ng8dea7XK5W/wN7Ou9xYr9MLdt6UIs3HdBNYzi1GJERDT93aHnoS9gRfQk7oi9hR/Ql7IaehB01RV82ZnuNvlvxiXTt2lXt27fXwoULw/OKior0+eefa+TIkZHcVdQb1yd46vbKHYdVWMY1EwAAAAAAANB4jQ4Hi4uLlZubq9zcXEnBm5Dk5uYqLy9PhmHo9ttv18MPP6z33ntPa9eu1Q9/+ENlZWXpkksuiXDp0S0nLV49MxLlD5hasmm/1eUAAAAAAACgBWr0acWrVq3S2LFjw9Oh6wVOnz5dL7/8su655x6VlJToJz/5iY4cOaJzzjlH//73vxUbGxu5qiFJGtc3Q5sLirVofb4uGpxldTkAAAAAAABoYRodDo4ZM0amaR53uWEYevDBB/Xggw+eVmE4uQl9M/WHJdu0eNN+VfoDinFG9CxxAAAAAAAAtHKkSS3YGdlt1CbepSOlPv131xGrywEAAAAAAEALQzjYgsU4HRrTq50k6eP1+RZXAwAAAAAAgJaGcLCFG9c3eNfiResLLK4EAAAAAAAALQ3hYAt3Xq92cjoMbS4oVt7BUqvLAQAAAAAAQAtCONjCpcS5NLxLW0nSog2cWgwAAAAAAICGIxxsBcb3CZ5avHADpxYDAAAAAACg4QgHW4FxfTMkSSu2HVSxt9LiagAAAAAAANBSEA62At3SE9QlLV4+v6lPN++3uhwAAAAAAAC0EISDrYBhGBpfddfihdy1GAAAAAAAAA1EONhKjO8TPLX4k40FCgRMi6sBAAAAAABAS0A42EoM65KqJE+MDhRX6MvdR6wuBwAAAAAAAC0A4WAr4Y5x6Nxe7SRJi7hrMQAAAAAAABqAcLAVGV9112KuOwgAAAAAAICGIBxsRcb0zpBhSOv2FmnPkTKrywEAAAAAAIDNEQ62IqkJbp2Z01YSpxYDAAAAAADg5AgHW5lxVXctJhwEAAAAAADAyRAOtjIT+mZKkpZtOaCyCr/F1QAAAAAAAMDOCAdbmV6ZierYJk7eyoA+23rA6nIAAAAAAABgY4SDrYxhGOG7Fn/MXYsBAAAAAABwAoSDrdCx6w7myzRNi6sBAAAAAACAXUU8HPT7/br//vvVtWtXxcXFqXv37nrooYcIqZrR2d3SFO92Kr/Iq2/2FFldDgAAAAAAAGwqJtIbfPzxx/X73/9e/+///T/1799fq1at0vXXX6+UlBTddtttkd4d6hHrcuqcHun6aF2+Fm0o0ICOKVaXBAAAAAAAABuK+MjBzz77TBdffLEuvPBCdenSRVdccYUmTZqkL774ItK7wgmErju4cH2+xZUAAAAAAADAriI+cnDUqFH64x//qE2bNqlXr1768ssv9emnn+rpp5+ud32v1yuv1xueLioKngbr8/nk8/kiXZ4thN5XU76/c7qnSpK+3F2oPYeK1S7J02T7QsvXHD0JNBZ9CTuiL2FH9CXsiL6E3dCTsKOm7MvGbNMwI3wxwEAgoPvuu09PPPGEnE6n/H6/HnnkEd177731rj9r1izNnj27zvy5c+cqPj4+kqVFnae+ciqvxND3u/t1dgbXfAQAAAAAAIgGpaWluuaaa1RYWKjk5OQTrhvxkYNvvPGGXn31Vc2dO1f9+/dXbm6ubr/9dmVlZWn69Ol11r/33ns1c+bM8HRRUZGys7M1adKkkxbfUvl8Pi1YsEATJ06Uy+Vqsv1sjduqZxdt1QF3B11wwZAm2w9avubqSaAx6EvYEX0JO6IvYUf0JeyGnoQdNWVfhs7MbYiIh4N33323fvnLX+rqq6+WJA0cOFA7d+7Uo48+Wm846PF45PHUPeXV5XK1+h/Ypn6Pk/p30LOLtmrZ1oPyy6FYl7PJ9oXWIRp+7tDy0JewI/oSdkRfwo7oS9gNPQk7aoq+bMz2In5DktLSUjkcNTfrdDoVCAQivSucRP+sZGUme1Ra4dfn2w9ZXQ4AAAAAAABsJuLh4NSpU/XII49o/vz52rFjh+bNm6enn35al156aaR3hZMwDEPj+mRKkhZx12IAAAAAAADUEvFw8LnnntMVV1yhm2++WX379tVdd92ln/70p3rooYcivSs0wPg+GZKkhRsKFOF7zwAAAAAAAKCFi/g1B5OSkjRnzhzNmTMn0pvGKRjdI12eGId2Hy7Tpvxi9W6fZHVJAAAAAAAAsImIjxyEvcS5nRrVPU2StHADpxYDAAAAAADgGMLBKDC+b+i6gwUWVwIAAAAAAAA7IRyMAuOqrju4Ju+wDpVUWFwNAAAAAAAA7IJwMApktYlT3w7JCpjS4o2MHgQAAAAAAEAQ4WCUqH7XYgAAAAAAAEAiHIwa4/oGw8GlG/fL5w9YXA0AAAAAAADsgHAwSgzp1EZpCW4d9VZq5Y5DVpcDAAAAAAAAGyAcjBIOh6GxoVOLuWsxAAAAAAAARDgYVULXHVzEdQcBAAAAAAAgwsGock7PdLmchrYfKNG2/cVWlwMAAAAAAACLEQ5GkaRYl87uliaJ0YMAAAAAAAAgHIw646pOLf54fb7FlQAAAAAAAMBqhINRJhQOrtxxWIVlPourAQAAAAAAgJUIB6NM57QE9chIlD9gaumm/VaXAwAAAAAAAAsRDkah8X2DowcXcmoxAAAAAABAVCMcjEIT+mZKkt79co+eW7hZgYBpcUUAAAAAAACwAuFgFBrWua2mj+ws05SeWrBJP/3bah0t5/qDAAAAAAAA0YZwMAoZhqHZFw/Q45cPlNvp0IJ1+br4hWXaUnDU6tIAAAAAAADQjAgHo9hVw3P0xk0j1SElVtv2l+ji55fp31/vs7osAAAAAAAANBPCwSg3JLuN/nnrORrRNVUlFX7d9LfVevLDDfJzHUIAAAAAAIBWr0nCwW+//VY/+MEPlJaWpri4OA0cOFCrVq1qil0hAtITPfrbj0fohtFdJUkvfLJVN7y8UkdKKyyuDAAAAAAAAE0p4uHg4cOHNXr0aLlcLn3wwQdat26dnnrqKbVt2zbSu0IEuZwOPTC1n565eohiXQ4t2bRfFz2/TOv2FFldGgAAAAAAAJpITKQ3+Pjjjys7O1svvfRSeF7Xrl0jvRs0kYuHdFSPjETd9LfVyjtUqst+v0yPXz5IFw/paHVpAAAAAAAAiLCIh4PvvfeeJk+erO9973tasmSJOnbsqJtvvlk33nhjvet7vV55vd7wdFFRcKSaz+eTz+eLdHm2EHpfdn1/vdrF6+2fnq073vxKn245qJ+/nqsv8w7r7kk9FePkMpWtkd17EtGJvoQd0ZewI/oSdkRfwm7oSdhRU/ZlY7ZpmKYZ0TtPxMbGSpJmzpyp733ve1q5cqV+/vOf68UXX9T06dPrrD9r1izNnj27zvy5c+cqPj4+kqWhkQKmNH+XQx9/GwwEeyYHdF2vgBJdFhcGAAAAAACA4yotLdU111yjwsJCJScnn3DdiIeDbrdbw4YN02effRaed9ttt2nlypVavnx5nfXrGzmYnZ2tAwcOnLT4lsrn82nBggWaOHGiXC77J20ffpOvX7z9tUoq/OqQEqsXvj9YAzumWF0WIqil9SSiA30JO6IvYUf0JeyIvoTd0JOwo6bsy6KiIqWnpzcoHIz4acUdOnRQv379aszr27ev3nrrrXrX93g88ng8dea7XK5W/wPbUt7jd4d0Uu8OKfrpX1dr24ESXf3nlXr4kgG6cli21aUhwlpKTyK60JewI/oSdkRfwo7oS9gNPQk7aoq+bMz2In4BudGjR2vjxo015m3atEmdO3eO9K7QjHpmJumdW0ZrQt9MVVQGdM8/vtKv3lmrisqA1aUBAAAAAADgFEU8HLzjjju0YsUK/eY3v9GWLVs0d+5c/fGPf9SMGTMivSs0s+RYl/547VDNnNhLhiH9bUWevv+nFSooKre6NAAAAAAAAJyCiIeDw4cP17x58/Taa69pwIABeuihhzRnzhxNmzYt0ruCBRwOQ7eN76n/mz5MSbExWr3zsL773KdavfOQ1aUBAAAAAACgkSIeDkrSd7/7Xa1du1bl5eVav369brzxxqbYDSw0rk+m3rvlHPXKTFTBUa+u/uMK/XX5DkX4/jYAAAAAAABoQk0SDiI6dE1P0LybR+vCQR3k85u6/91vdM8/vlK5z291aQAAAAAAAGgAwkGclgRPjJ7//hm674I+chjSm6t368o/LNe3R8qsLg0AAAAAAAAnQTiI02YYhn5ybne9csMItY136avdhZr63Kf6bOsBq0sDAAAAAADACRAOImLO6Zmu9245R/2zknWopELX/t8X+vN/tnEdQgAAAAAAAJsiHEREZafG662fjdJlZ3aUP2Dq4fnrddvruSqtqLS6NAAAAAAAANRCOIiIi3U59dT3Bmv2Rf0V4zD0zy/36LLffaadB0usLg0AAAAAAADVEA6iSRiGoemjumjujWcrPdGjDfuOaupzn2rxxgKrSwMAAAAAAEAVwkE0qbO6pupft56jM3LaqKi8Ute/vFIvfLKF6xACAAAAAADYAOEgmlz7lFi9/pOzdc2IHJmm9OSHG3XT31braLnP6tIAAAAAAACiGuEgmoUnxqnfXDpQj18+UG6nQx9+k69LXlimLQXFVpcGAAAAAAAQtQgH0ayuGp6jN24aqfbJsdq6v0QXPf+p/rZiJ6cZAwAAAAAAWIBwEM1uSHYb/fPWczSyW5pKK/z61Ttf64d/+UJ7jpRZXRoAAAAAAEBUIRyEJdolefTqj0foge/2U6zLof9sPqDJv12qN1buYhQhAAAAAABAMyEchGUcDkM3nNNV79/2HZ2Z00ZHvZW6562v9KP/t0r5ReVWlwcAAAAAANDqEQ7Cct3aJerNm0bp3il95HY6tGhDgSb9dqne+e+3jCIEAAAAAABoQoSDsAWnw9BPz+uu+bedo0GdUlRY5tPtf8/VTX9brQPFXqvLAwAAAAAAaJUIB2ErPTOT9NbPRunOib3kchr68Jt8TfrtUr2/dq/VpQEAAAAAALQ6hIOwHZfToVvH99S7M85Rn/ZJOlRSoZtfXaNbX/uvDpdUWF0eAAAAAABAq0E4CNvql5Ws9245R7eO6yGnw9A/v9yjSXOW6uN1+VaXBgAAAAAA0CoQDsLW3DEO3Tmpt97+2Sj1yEjU/qNe/fiVVbrzjS9VWOazujwAAAAAAIAWjXAQLcLg7Db6163n6KfndpNhSG+t2a3Jv12qJZv2W10aAAAAAABAi9Xk4eBjjz0mwzB0++23N/Wu0MrFupy694K++sdNI9U1PUH7iso1/S9f6N63v1Kxt9Lq8gAAAAAAAFqcJg0HV65cqT/84Q8aNGhQU+4GUWZo51S9f9t3dN2oLpKk177Ypcm/XarPth6wtjAAAAAAAIAWpsnCweLiYk2bNk1/+tOf1LZt26baDaJUnNupWRf112s3nq1ObeP07ZEyXfOnzzXrvW9UWsEoQgAAAAAAgIaIaaoNz5gxQxdeeKEmTJighx9++Ljreb1eeb3e8HRRUZEkyefzyedrnTecCL2v1vr+mtOwnGT9c8ZIPf7hJr2+crde/myHPtlQoMcv66+hnQmlG4qehB3Rl7Aj+hJ2RF/CjuhL2A09CTtqyr5szDYN0zTNSBfw+uuv65FHHtHKlSsVGxurMWPGaMiQIZozZ06ddWfNmqXZs2fXmT937lzFx8dHujS0YhuOGHptq0NHKgwZMjW2g6kLcgJycdsdAAAAAAAQRUpLS3XNNdeosLBQycnJJ1w34uHgrl27NGzYMC1YsCB8rcEThYP1jRzMzs7WgQMHTlp8S+Xz+bRgwQJNnDhRLpfL6nJalaIynx75YKPe/u8eSVK39AQ9cfkADe6UYnFl9kZPwo7oS9gRfQk7oi9hR/Ql7IaehB01ZV8WFRUpPT29QeFgxE8rXr16tQoKCnTmmWeG5/n9fi1dulTPP/+8vF6vnE5neJnH45HH46mzHZfL1ep/YKPhPTa3NJdLT191hi4clKVfvr1W2w6U6Ko/faGbzuum28b3lCfGefKNRDF6EnZEX8KO6EvYEX0JO6IvYTf0JOyoKfqyMduL+AmX48eP19q1a5Wbmxv+GjZsmKZNm6bc3NwawSDQVMb3zdRHt5+ri4dkyR8w9cInW3Xx88v0zZ5Cq0sDAAAAAACwjYiPHExKStKAAQNqzEtISFBaWlqd+UBTapvg1jNXn6Hz+7fXr975Whv2HdXFzy/TreN66uax3eVycjFCAAAAAAAQ3UhH0OpNGdhBH95xrqYMaK/KgKnffrxJl/3uM23KP2p1aQAAAAAAAJZqlnBw8eLF9d6MBGgu6Yke/W7amXrm6iFKiXNp7beF+u6zn+r3i7fKH4j4DbsBAAAAAABaBEYOImoYhqGLh3TUgjvO1fg+GarwB/T4vzfo0t8t0/yv9srnD1hdIgAAAAAAQLMiHETUyUiO1Z+nD9OTVwxSkidGX+0u1Iy5azTqsUV6+qON2ltYZnWJAAAAAAAAzYJwEFHJMAx9b1i2Ft55nm4d10PpiR7tP+rVs4u2aPRji/STV1Zp6ab9CnDKMQAAAAAAaMUifrdioCXJSI7VnZN669ZxPfXRun366/Kd+nz7IX20Ll8frctXl7R4TRvRWd8b1klt4t1WlwsAAAAAABBRhIOAJHeMQ98dlKXvDsrS5vyjevXzPL21erd2HCzVI++v1/9+tFHfHZSla0d21uBOKTIMw+qSAQAAAAAAThvhIFBLz8wkzbqov+6e3Fvv5u7R31bs1Lq9RXprzW69tWa3BnRM1rVnd9ZFgzsqzu20ulwAAAAAAIBTxjUHgeNI8MTomhE5mn/bOXrrZ6N02Rkd5Y5x6Otvi/SLt9bqrN98rNn//EZbCoqtLhUAAAAAAOCUMHIQOAnDMDS0c1sN7dxWv/puP725apde/TxPeYdK9dKyHXpp2Q6N6p6mH5zdWRP7ZcrlJHMHAAAAAAAtA+Eg0AipCW799LzuuvE73bR08379bUWeFm3I12dbD+qzrQeVkeTR1Wfl6PtnZatDSpzV5QIAAAAAAJwQ4SBwChwOQ2N6Z2hM7wx9e6RMr32ep9dX5qngqFfPLtysFz7Zogl9M3Tt2V00qnuaHA5uYAIAAAAAAOyHcBA4TR3bxOmuyb112/ie+vCbffrrip36YvshffhNvj78Jl9d0xM0bUSOvjc0WynxLqvLBQAAAAAACCMcBCLEHePQ1MFZmjo4S5vyj+pvK3bq7TXfavuBEj08f72e/HCjLhqcpR+c3VmDs9tYXS4AAAAAAADhINAUemUm6cGLB+gX5/fRO7nf6q/Ld2rDvqN6c/Vuvbl6twZ1StEPRnTW1MFZinM7rS4XAAAAAABEKcJBoAkleGI0bURnXXNWjtbkHdbfVuRp/ld79dXuQt2z+ys9PH+drhiarWln56h7u0SrywUAAAAAAFGGcBBoBoZhaGjnVA3tnKpfXdhXb67erVc/36ldh8r0l2Xb9Zdl2zW8S1t9b2i2LhjUQYkefjQBAAAAAEDTI4EAmllaokc3ndddP/lONy3ZvF9/W75Tn2ws0Modh7Vyx2H9+r1vdMHADrpiaCeN6JrKnY4BAAAAAECTIRwELOJwGBrbO0Nje2doX2G53v7vbv1j1W5tO1Cit9bs1ltrdis7NU5XnJmty4d2VKe28VaXDAAAAAAAWhnCQcAG2qfE6uYxPfSz87prTd5hvblqt/711V7tOlSm3368SXMWbtKo7mm6Ymgnnd+/AzcxAQAAAAAAEUE4CNhI9WsT/npqf/37m716c9Vufbb1oJZtCX494PlG3x3cQVcMzdaZOW1kGJx2DAAAAAAATg3hIGBTcW6nLj2jky49o5N2Hy7VW6u/1T/W7NKuQ2V67Ytdeu2LXerWLkFXDO2ky8/spMzkWKtLBgAAAAAALYwj0ht89NFHNXz4cCUlJSkjI0OXXHKJNm7cGOndAFGlU9t4/XxCTy25a6xeu/FsXXZmR8W5nNq2v0RP/HujRj66UNe99IXmf7VX3kq/1eUCAAAAAIAWIuIjB5csWaIZM2Zo+PDhqqys1H333adJkyZp3bp1SkhIiPTugKjicBga2T1NI7un6cGLK/X+V3v15updWrnjsBZv3K/FG/crJc6li4dk6XtDszWgYzKnHQMAAAAAgOOKeDj473//u8b0yy+/rIyMDK1evVrnnntupHcHRK1ET4yuHJ6tK4dna/uBEr21OniH472F5Xpl+U69snyn+rRP0hVDO+mSMzoqPdFjdckAAAAAAMBmmvyag4WFhZKk1NTUepd7vV55vd7wdFFRkSTJ5/PJ5/M1dXmWCL2v1vr+0Pw6pbj183HddMuYrvps20G9tWaPFqwv0IZ9R/Xw/PV67IMNGtMrXZef2VHn9UqXy1nzigL0JOyIvoQd0ZewI/oSdkRfwm7oSdhRU/ZlY7ZpmKZpRryCKoFAQBdddJGOHDmiTz/9tN51Zs2apdmzZ9eZP3fuXMXHxzdVaUCrV1oprTlg6Iv9Du0sPnZqcWKMqWHtTI1oF1AWZ/oDAAAAANDqlJaW6pprrlFhYaGSk5NPuG6ThoM/+9nP9MEHH+jTTz9Vp06d6l2nvpGD2dnZOnDgwEmLb6l8Pp8WLFigiRMnyuVyWV0OosDm/GK99d9v9e6Xe3WguCI8f0BWsi4/M0uT+6Zr5aeL6UnYCsdK2BF9CTuiL2FH9CXshp6EHTVlXxYVFSk9Pb1B4WCTnVZ8yy236F//+peWLl163GBQkjwejzyeutdCc7lcrf4HNhreI+yhX6e26tepre69oJ+WbNqvN1ft1sIN+fp6T5G+3lOk33xgqH8bh8zsgxrbt71S4uhL2AfHStgRfQk7oi9hR/Ql7IaehB01RV82ZnsRDwdN09Stt96qefPmafHixeratWukdwHgFMU4HRrfN1Pj+2bqUEmF3s39Vm+u2q11e4uUe9Ch29/4Sk7HWg3v0lbj+2RqXN8MdUtP4I7HAAAAAAC0UhEPB2fMmKG5c+fq3XffVVJSkvbt2ydJSklJUVxcXKR3B+AUpSa4df3orrp+dFd9mXdQz77zmXb6krRlf4lWbDukFdsO6ZH316tLWrzG9cnU+L4ZGt4lVe4Yx8k3DgAAAAAAWoSIh4O///3vJUljxoypMf+ll17SddddF+ndAYiAfh2SdVHngC64YLT2Fvm0aEO+Fm4o0OfbDmnHwVL9Zdl2/WXZdiV6YnRur3SN65OpMb3bKT2x7iUBAAAAAABAy9EkpxUDaLly0uJ13eiuum50VxV7K/Xp5gNatCFfizbs14Fir95fu0/vr90nw5CGZLfR+D4ZGtcnU307JHH6MQAAAAAALUyT3ZAEQMuX6InR+QPa6/wB7RUImFr7baEWbijQog35+vrbIv0374j+m3dE//vRJnVIidW4Phka3zdDo7qnK9bltLp8AAAAAABwEoSDABrE4TA0OLuNBme30cyJvbSvsFyfbCzQwvUF+nTLfu0tLNern+fp1c/zFOtyaHT3dI3rm6FxfTLUIYXrjQIAAAAAYEeEgwBOSfuUWH3/rBx9/6wclfv8Wr7toBatL9DC9fnaU1iuhRsKtHBDgaTgNQ3HVwWFgzu1kcPB6ccAAAAAANgB4SCA0xbrcmps7wyN7Z2hBy/ur435R7VwfYEWbSjQmrzDWre3SOv2Fum5RVuUluDWmN7B04+/0zNdSbEuq8sHAAAAACBqEQ4CiCjDMNSnfbL6tE/WjLE9dLDYqyWb9mvhhgIt3bhfB0sq9Naa3XprzW65nIbO6pqqcX0yNb5PhrqkJ1hdPgAAAAAAUYVwEECTSkv06LIzO+myMzvJ5w9o5Y5DwdOPNxRo+4ESLdtyUMu2HNRD/1qnbukJykmLV6InRkmxMUqKdSnRExP8io1RUuixan5SbHBZvNvJnZIBAAAAADgFhIMAmo3L6dCo7uka1T1dv/puP23bX6xFG4I3NVm545C2HSjRtgMljd6uw1BVWOgKB4mhx+TQc4+rVsAYUy1gDC5LIGQEAAAAAEQZwkEAlunWLlHd2iXqx9/ppqJyn1ZuP6SDJRUqLq9UsTf4dbQ89OgLz68+L2BKAVMqKq9UUXnladVjVIWMnhiHHIahGIchh6Pmo9PhkNOh4KMhxTgccjiCj06HcezLMOR0Bh9rvv7461TfdlqCWz0yE9UzI5HrMgIAAAAAmgzhIABbSI51aXzfzEa9xjRNlfn8Ki6v1FFvZY3w8Gi5LxgwhuZVPQ/NP1orgPQHTJmmgq9tovd4qrJSYtUzM0k9MxLVKzNJPTMT1TMzSYkeDuEAAAAAgNPDX5YAWizDMBTvjlG8O0YZp7Ed0zRV7gvoqDc4OtHnN1UZCCgQkCoDAfkD5rEv01RlwFQgEHz01/dVtY7fH5DflPyBgPyBWo/hdYLrV399ZcDUvsJybco/qoKjXu0pLNeewnIt2bS/Rt0d28QFg8KMYFjYqypATCA0BAAAAAA0EH9BAoh6hmEozu1UnNupjCSrq6npSGmFNhcUa1P+UW3OL9bmgqPalF+s/Ue9+vZImb49UqbFG+uGhr0yg6MMe2QceyQ0BAAAAADUxl+KAGBjbeLdGt4lVcO7pNaYf6S0Qpvyg6HhlqrwcFN+sQ4UHwsNP6kVGnZqG3fstOSMJPXKTFSPjETFu/lVAAAAAADRir8IAaAFahPv1lldU3VW15qh4eGSiuAow4Jiba4KDDcXHNWB4grtPlym3YfLtGhDQXh9w6gKDTOSalzXsEdGouLczuZ+WwAAAACAZkY4CACtSNsEt0Z0S9OIbmk15h8qqQiGheHQMHia8sGSCu06VKZdh8q0sFZomJbgDt+FOcYZvKNy9Wmnw5Cr1nSMwxG883K19atPOx2GXM6q1xxnOsYZfI3MgNYfMJS0+YDSk+PUNt6ttgluJbidMgyjub+1AAAAANAqEQ4CQBRIPU5oeLDYW2OUYWjU4aGSCh0orrCo2uqcemXzmhpzXE5DbeLdSo13q028qyo0rHqsMc+ttlXPU+JccjgIFAEAAACgNsJBAIhiaYkepSV6dHat0PBAsVf7j3rDd0/2BwKq9AfvpuxryLQ/EL6bc2XArFp2bJ6v1nRwnZrTFZV+7dlXIGdcso6UVepwaYW8lQH5/Kb2Hw3W11CGIbWJc9UbHrapChVTE449D813xziOu83g+wiowh+QrzJQVXNAPn+wxjrLqp7XWOYPft+OrWtWvT44HVrm85uKczuU4IlRojsm+OgJPiZ4nOHn1ed5YjgtHACiiWmaKiqv1IFir46U+mQYOjYq3+GQ0yE5q0b0O6qP2K8z7ZDDEKP0ASCKEA4CAOpIT/QoPdFjaQ0+n0/vv/++LrhglFwulySprMKvQ6UVOlxSoSOlPh0qrdCR0godLvHpcGlF1ZcvOK9qfrG3UqYpHS716XCpr1E1JHpilBQbEw4CK/1mONQLmE3xriPH5TSCQaE7FBo6awSIiTWeO6tCxfrnJbhj5Kw18tI0g0Gu3zwW6Pr9x5sOVAuJq61TYzpw3OWVoXn+gFwxDiW4YxTndirBHaN4T9WjO1hvvNspT4yj1f1RGwiYKq/0q9wXUJnPL7/flCvGkNvpkDum6svZ+t43EO1M01RRWaX2V31od6C42tfRCu0PP/fqQHGFKvyBiO3bWS08dBo1LxFybNpxbLrqMiMOoypwNKSjRxz615FcJXhiFOtyVvtyKK7qeZzLKU/1abdTsTFOxbkd8sRUTbucio1xKMZ5/A/tAACnjnAQANBixLmd6uiOU8c2cQ1+TUVlQEfKqsLEkqowsbQqTCypHib6qqYrdKTMJ9OUir2VKvZWNmg/wesnBq+h6HY65HI65IoJTrsc1Z6Hlx+bDj+PqbksxumQ22nI6XCozOdXibdSJVU1BZ/7g88rKlVcHpzvrQz+YejzmzpS6tORRgaixxPncsowFB7d6bdxOup0GMGwsFZ4GO92Kt4TowS3U/HuYGAa766argpBa68fChzj6wlIJcnnD4Z15RXHgrsyn1/loccKv8or/SqrCITnl/v8Kqs2v7za+mVVy7yVAZVVHNtW6N/1ZFzOWoFhzLF+9NSa546p6seYqmXVXhea7671ulD/hpbJkAwZCmWShoKjjQwj9DxUWfV5RrV1a75eteYd2+7xt2makhTsR9MMPgs+msHHqlYNTava8pqvMcOvDb+i+vbM0Cuqvb76j4EhOQyjnu9BreeqWi/03qrer8NR930a1bdXNc8R+v5VLXcYUmVlpY54pb2F5XI4feH3EDCD7yEQfm/H3lONZQ1ZP2CGX6f6tqHgKDVPTDCg97gcx57HOOQh3AkzTVOFZb6qUfpVAV+N4K8iHAQePIXAL8kTozYJwQ/V/H7z2HHbNI9Nmyc/loeWn95FRhxaf6Tg5Ks1kMtp1BswxoaDRkc4cAzNczurrmfsDF4rOaZq2lXt2scxVUGnq9qy2q9xVa0TE/odXbWOq9prT+UDmtCHbdXPngg+Bup+UFZtvs9fa72AWePfu8b8BvzePulvdfM0X6/g8Sv0uzfRc+yDvYRqv5tPdNYGIscfMIO/j7jsDqoQDgIAWjV3jEMZSbHKSIpt8GsCAVNF5cEw8Wh5ZfgPgVCQdyz8qwryHA7b/Oeq0h8IhoYVtYPEShV7/cedV1JRT+jorVRl1R8TZT5/g2uoMdqk2uOxU9vqO43t2DrHW8/hMFTpD6i0IlhzaYVfJRWVKvUGH8t9wT+g/QFTR8srdbS8YcFuQ8W6HIp3O+WrcOq+NQvl9QXC35/m5I5xyGkYwdGstfYfPG3dr5KKhv97obWI0a/XLLW6iJNyOoxjgWGMsypEPBYkxrqOHy6GnofXqef1MU6HTiGfqeF0j+YVlQEdKDkW8B0L/oLzDpZ45fM37tiRFBujdlWj+tOT3EpP9ASnk6rmJVbNS/Io1tXwy0o0ZBR4oPolRqoFTTWX1V23vKJSK1f/V736DZAvoGMfmvgC4edeX6DmByq+mh+YlFfNCwke4yJ/fI+U0O+t2oGjdOzDtUp/oE4YiGPcTkf4g7rwh3jh6WCgGAwWj50VEfpAMHRplXD4WPW6+j7ca06maSpgHnsMmMEzUby+gLyVflVUBuStDIQfq8+rd7nPL2/49aH5/hrPj72+vuWBcFjsMFTj/1xOZ7WRwI6aI4Rr/5+t9o0K68yv9/96jjrrV785Yeh59TA+tL1QeB9TtW74efXg3uGQ02mEw/9QgB+6kaJd/r9uR4SDAADU4nAEb3rSJt5tdSmNFuN0KCXeoZR412lvyzRNeSsD4cBQUo3Tyux2nSp/wFRpRWWN8LB2gFjqrVRJhV+lFcH3VFpRNV1t/rF1g4+hv9uCf7QGFIwOaoZvhhEcXRlXfURL+NS4mqNaqo9oCa7jqLVOcH5c1XZqj4Kp/kdOoOp6lhX+4H/4w1/+Wo9VX6HrWXprreurtq63nnmh9byhbVQ9Vh91J1WNHDnOSLw6I/mqvabGSD+Flle9qtb2QstC09VH50mqM9JOdUY21hyhJ1UbzWgcWx6errY91XpNaHv1jT6s8bzae689P2DW/14D1dZV7fnVv1fh0X8BOZ3OGiMMQ6MUw6Maq+oPP681IrH697L2+jVHRh4bwXhsW5I/oOAfoL5jf9R6fYEaI9+CP6fBn00pMiObW6rk2JhwuNeuKtgLhXzp4eAvON2YwK8xDKPqD+sm2LbP55Oxy9QFZ2WHLw9yKkK/i46NuD42UtvrqzkKu/oI7dA6oWv3hq5tHLpMSGWgan6g9vITrOsPyFcV8NWX6YWC04aO9j6Z6qFGzd+/jjofrIUDkmrTzmrTjmrHtuM52a/vky4/yfZDo+1D/68oqfqdXeytVEXV96zCH1BFaSBiZz5IwQ/3QpckqSx36vmty2TKCI+EDo1+DpimAlX/dNVHRgeqDra1A746rzVVZ95JBlxaLmAGv+eKks8UQ2FoKKAMjQJees/YJjvOthRNFg6+8MILevLJJ7Vv3z4NHjxYzz33nM4666ym2h0AAIgwwzh2+lZaotXVnJzTYSgp1qWk2NMPRkNCf5SGAsei0nItWfofTRo3RolxnmBo57buen8Oh6FYhzPq/0Mb7Y5do3XyaYUwTSUUYodGyYSCw3JftVEw1Ua21FwvED61/th6gTohZHnVayobOSKvtkj8He90GEpLcCs96cShHzeOapjqv4vsJBAw5au6Xm6l/9jz0KjuSv+x8NGQUe8Iq+ojpuobcRVNfP7AsQ/nKoJnNoQ+uAud4VBadWZDeHnVB30lVfPC61a9LjQ6LvjhXoVUIkmG9pWVWPpeqwtduqP6SGl3rdHVbqfj2GOdecdGUFffjjum7rzQNkOXCql9Snu9p7WHR7we/3T1GjcwrLN+3ZsQhkYYV/qPXZO6smrboTA++DMVfG0omK9+Or2v+s0Qq/3MHdte/QF+KAytfYKF1aNL7aBJwsG///3vmjlzpl588UWNGDFCc+bM0eTJk7Vx40ZlZGQ0xS4BAAAirvofpakJbvmSXNqSIHVOi7dlCAPYUc0Qm58btA4OhyGPwykP5+JFhCuCZz5IdT/cK6moVFGJV4uXLdfZI86SK8YVHgXtCI0aN4wao65Do6Id1UZUO6qGkTvC61cbSV1thKbDUHjEdY1tBi/XK0+M85SvU4mGCQX4oVAxHDDWEyTGEA42TTj49NNP68Ybb9T1118vSXrxxRc1f/58/eUvf9Evf/nLptglAAAAAABAnQ/3pOAo671fmxrZLY0P+KJAKMBHw0Q8HKyoqNDq1at17733huc5HA5NmDBBy5cvr7O+1+uV1+sNTxcVFUkK/uD6fK3zOiSh99Va3x9aHnoSdkRfwo7oS9gRfQk7oi9hN/Qk7Kgp+7Ix2zRMM7KXyNyzZ486duyozz77TCNHjgzPv+eee7RkyRJ9/vnnNdafNWuWZs+eXWc7c+fOVXx8fCRLAwAAAAAAAFq90tJSXXPNNSosLFRycvIJ17X8Cgn33nuvZs6cGZ4uKipSdna2Jk2adNLiWyqfz6cFCxZo4sSJDGeGLdCTsCP6EnZEX8KO6EvYEX0Ju6EnYUdN2ZehM3MbIuLhYHp6upxOp/Lz82vMz8/PV/v27eus7/F45PF46sx3uVyt/gc2Gt4jWhZ6EnZEX8KO6EvYEX0JO6IvYTf0JOyoKfqyMdtzRHTPktxut4YOHaqFCxeG5wUCAS1cuLDGacYAAAAAAAAArNUkpxXPnDlT06dP17Bhw3TWWWdpzpw5KikpCd+9GAAAAAAAAID1miQcvOqqq7R//3498MAD2rdvn4YMGaJ///vfyszMbIrdAQAAAAAAADgFTXZDkltuuUW33HJLo18XunlyYy6c2NL4fD6VlpaqqKiIax3AFuhJ2BF9CTuiL2FH9CXsiL6E3dCTsKOm7MtQrhbK2U7E8rsV13b06FFJUnZ2tsWVAAAAAAAAAC3X0aNHlZKScsJ1DLMhEWIzCgQC2rNnj5KSkmQYhtXlNImioiJlZ2dr165dSk5OtrocgJ6ELdGXsCP6EnZEX8KO6EvYDT0JO2rKvjRNU0ePHlVWVpYcjhPfj9h2IwcdDoc6depkdRnNIjk5mYMSbIWehB3Rl7Aj+hJ2RF/CjuhL2A09CTtqqr482YjBkBNHhwAAAAAAAABaLcJBAAAAAAAAIEoRDlrA4/Ho17/+tTwej9WlAJLoSdgTfQk7oi9hR/Ql7Ii+hN3Qk7Aju/Sl7W5IAgAAAAAAAKB5MHIQAAAAAAAAiFKEgwAAAAAAAECUIhwEAAAAAAAAohThIAAAAAAAABClCAeb2QsvvKAuXbooNjZWI0aM0BdffGF1SYhis2bNkmEYNb769OljdVmIMkuXLtXUqVOVlZUlwzD0zjvv1FhumqYeeOABdejQQXFxcZowYYI2b95sTbGIGifry+uuu67O8fP888+3plhEhUcffVTDhw9XUlKSMjIydMkll2jjxo011ikvL9eMGTOUlpamxMREXX755crPz7eoYkSDhvTlmDFj6hwvb7rpJosqRjT4/e9/r0GDBik5OVnJyckaOXKkPvjgg/ByjpVobifrSTscJwkHm9Hf//53zZw5U7/+9a+1Zs0aDR48WJMnT1ZBQYHVpSGK9e/fX3v37g1/ffrpp1aXhChTUlKiwYMH64UXXqh3+RNPPKFnn31WL774oj7//HMlJCRo8uTJKi8vb+ZKEU1O1peSdP7559c4fr722mvNWCGizZIlSzRjxgytWLFCCxYskM/n06RJk1RSUhJe54477tA///lPvfnmm1qyZIn27Nmjyy67zMKq0do1pC8l6cYbb6xxvHziiScsqhjRoFOnTnrssce0evVqrVq1SuPGjdPFF1+sb775RhLHSjS/k/WkZP1x0jBN02zWPUaxESNGaPjw4Xr++eclSYFAQNnZ2br11lv1y1/+0uLqEI1mzZqld955R7m5uVaXAkiSDMPQvHnzdMkll0gKjhrMysrSnXfeqbvuukuSVFhYqMzMTL388su6+uqrLawW0aJ2X0rBkYNHjhypM6IQaC779+9XRkaGlixZonPPPVeFhYVq166d5s6dqyuuuEKStGHDBvXt21fLly/X2WefbXHFiAa1+1IKjogZMmSI5syZY21xiGqpqal68skndcUVV3CshC2EevJHP/qRLY6TjBxsJhUVFVq9erUmTJgQnudwODRhwgQtX77cwsoQ7TZv3qysrCx169ZN06ZNU15entUlAWHbt2/Xvn37ahw7U1JSNGLECI6dsNzixYuVkZGh3r1762c/+5kOHjxodUmIIoWFhZKCf1xI0urVq+Xz+WocL/v06aOcnByOl2g2tfsy5NVXX1V6eroGDBige++9V6WlpVaUhyjk9/v1+uuvq6SkRCNHjuRYCcvV7skQq4+TMc26tyh24MAB+f1+ZWZm1pifmZmpDRs2WFQVot2IESP08ssvq3fv3tq7d69mz56t73znO/r666+VlJRkdXmA9u3bJ0n1HjtDywArnH/++brsssvUtWtXbd26Vffdd5+mTJmi5cuXy+l0Wl0eWrlAIKDbb79do0eP1oABAyQFj5dut1tt2rSpsS7HSzSX+vpSkq655hp17txZWVlZ+uqrr/SLX/xCGzdu1Ntvv21htWjt1q5dq5EjR6q8vFyJiYmaN2+e+vXrp9zcXI6VsMTxelKyx3GScBCIYlOmTAk/HzRokEaMGKHOnTvrjTfe0I9+9CMLKwMAe6t+SvvAgQM1aNAgde/eXYsXL9b48eMtrAzRYMaMGfr666+5TjBs5Xh9+ZOf/CT8fODAgerQoYPGjx+vrVu3qnv37s1dJqJE7969lZubq8LCQv3jH//Q9OnTtWTJEqvLQhQ7Xk/269fPFsdJTituJunp6XI6nXXugpSfn6/27dtbVBVQU5s2bdSrVy9t2bLF6lIASQofHzl2wu66deum9PR0jp9ocrfccov+9a9/6ZNPPlGnTp3C89u3b6+KigodOXKkxvocL9EcjteX9RkxYoQkcbxEk3K73erRo4eGDh2qRx99VIMHD9YzzzzDsRKWOV5P1seK4yThYDNxu90aOnSoFi5cGJ4XCAS0cOHCGueZA1YqLi7W1q1b1aFDB6tLASRJXbt2Vfv27WscO4uKivT5559z7ISt7N69WwcPHuT4iSZjmqZuueUWzZs3T4sWLVLXrl1rLB86dKhcLleN4+XGjRuVl5fH8RJN5mR9WZ/QjfA4XqI5BQIBeb1ejpWwjVBP1seK4ySnFTejmTNnavr06Ro2bJjOOusszZkzRyUlJbr++uutLg1R6q677tLUqVPVuXNn7dmzR7/+9a/ldDr1/e9/3+rSEEWKi4trfCq2fft25ebmKjU1VTk5Obr99tv18MMPq2fPnuratavuv/9+ZWVl1bhzLBBpJ+rL1NRUzZ49W5dffrnat2+vrVu36p577lGPHj00efJkC6tGazZjxgzNnTtX7777rpKSksLXxkpJSVFcXJxSUlL0ox/9SDNnzlRqaqqSk5N16623auTIkdx9E03mZH25detWzZ07VxdccIHS0tL01Vdf6Y477tC5556rQYMGWVw9Wqt7771XU6ZMUU5Ojo4ePaq5c+dq8eLF+vDDDzlWwhIn6knbHCdNNKvnnnvOzMnJMd1ut3nWWWeZK1assLokRLGrrrrK7NChg+l2u82OHTuaV111lbllyxary0KU+eSTT0xJdb6mT59umqZpBgIB8/777zczMzNNj8djjh8/3ty4caO1RaPVO1FflpaWmpMmTTLbtWtnulwus3PnzuaNN95o7tu3z+qy0YrV14+SzJdeeim8TllZmXnzzTebbdu2NePj481LL73U3Lt3r3VFo9U7WV/m5eWZ5557rpmammp6PB6zR48e5t13320WFhZaWzhatRtuuMHs3Lmz6Xa7zXbt2pnjx483P/roo/ByjpVobifqSbscJw3TNM3miyIBAAAAAAAA2AXXHAQAAAAAAACiFOEgAAAAAAAAEKUIBwEAAAAAAIAoRTgIAAAAAAAARCnCQQAAAAAAACBKEQ4CAAAAAAAAUYpwEAAAAAAAAIhShIMAAAAAAABAlCIcBAAAQLNYvHixDMPQkSNHrC4FAAAAVQgHAQAAAAAAgChFOAgAAAAAAABEKcJBAACAKBEIBPToo4+qa9euiouL0+DBg/WPf/xD0rFTfufPn69BgwYpNjZWZ599tr7++usa23jrrbfUv39/eTwedenSRU899VSN5V6vV7/4xS+UnZ0tj8ejHj166P/+7/9qrLN69WoNGzZM8fHxGjVqlDZu3Ni0bxwAAADHRTgIAAAQJR599FG98sorevHFF/XNN9/ojjvu0A9+8AMtWbIkvM7dd9+tp556SitXrlS7du00depU+Xw+ScFQ78orr9TVV1+ttWvXatasWbr//vv18ssvh1//wx/+UK+99pqeffZZrV+/Xn/4wx+UmJhYo47/+Z//0VNPPaVVq1YpJiZGN9xwQ7O8fwAAANRlmKZpWl0EAAAAmpbX61Vqaqo+/vhjjRw5Mjz/xz/+sUpLS/WTn/xEY8eO1euvv66rrrpKknTo0CF16tRJL7/8sq688kpNmzZN+/fv10cffRR+/T333KP58+frm2++0aZNm9S7d28tWLBAEyZMqFPD4sWLNXbsWH388ccaP368JOn999/XhRdeqLKyMsXGxjbxdwEAAAC1MXIQAAAgCmzZskWlpaWaOHGiEhMTw1+vvPKKtm7dGl6venCYmpqq3r17a/369ZKk9evXa/To0TW2O3r0aG3evFl+v1+5ublyOp0677zzTljLoEGDws87dOggSSooKDjt9wgAAIDGi7G6AAAAADS94uJiSdL8+fPVsWPHGss8Hk+NgPBUxcXFNWg9l8sVfm4YhqTg9RABAADQ/Bg5CAAAEAX69esnj8ejvLw89ejRo8ZXdnZ2eL0VK1aEnx8+fFibNm1S3759JUl9+/bVsmXLamx32bJl6tWrl5xOpwYOHKhAIFDjGoYAAACwN0YOAgAARIGkpCTddddduuOOOxQIBHTOOeeosLBQy5YtU3Jysjp37ixJevDBB5WWlqbMzEz9z//8j9LT03XJJZdIku68804NHz5cDz30kK666iotX75czz//vH73u99Jkrp06aLp06frhhtu0LPPPqvBgwdr586dKigo0JVXXmnVWwcAAMAJEA4CAABEiYceekjt2rXTo48+qm3btqlNmzY688wzdd9994VP633sscf085//XJs3b9aQIUP0z3/+U263W5J05pln6o033tADDzyghx56SB06dNCDDz6o6667LryP3//+97rvvvt088036+DBg8rJydF9991nxdsFAABAA3C3YgAAAITvJHz48GG1adPG6nIAAADQTLjmIAAAAAAAABClCAcBAAAAAACAKMVpxQAAAAAAAECUYuQgAAAAAAAAEKUIBwEAAAAAAIAoRTgIAAAAAAAARCnCQQAAAAAAACBKEQ4CAAAAAAAAUYpwEAAAAAAAAIhShIMAAAAAAABAlCIcBAAAAAAAAKLU/wfNh4ry3oRnNQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0012202303623780608 0.5773221254348755\n",
            "0.00026135172811336815 0.577553927898407\n"
          ]
        }
      ],
      "source": [
        "hidden_dim = 6272\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    1 * 3 * 3,\n",
        "    2 * 3 * 3,\n",
        "    2 * 3 * 3,\n",
        "    # 4 * 8 * 3 * 3,\n",
        "    hidden_dim,\n",
        "]\n",
        "sets = [\n",
        "    # out_ch\n",
        "    2,\n",
        "    2,\n",
        "    2,\n",
        "    # 1,\n",
        "    num_classes\n",
        "]\n",
        "n_params = int(np.array(samples).dot(np.array(sets)))\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  model = MModule2(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3) # 1e-2\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  print(model.W.mean().item(), model.W.std().item())\n",
        "  print(model.W_idx.mean().item(), model.W_idx.std().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(16, 3), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 2),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            # z=idx_[::, 2],\n",
        "            z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "jdZ8zHIcPQPS",
        "QQRFtDATXUmH",
        "039kGqbPXp4d"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNkIiPIV34vhcslKJ5WnEYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}