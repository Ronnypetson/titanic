{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d4760e-4b8a-42be-bb44-4cd2875df5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 115882689.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 5553083.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 61677851.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 20983748.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 114178707.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 4241293.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 58948954.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 18890881.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  x = x.resize((img_dim, img_dim))\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "\n",
        "bsize = 32\n",
        "\n",
        "MNIST_train_data = FashionMNIST(#MNIST(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = FashionMNIST(#MNIST(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def _cat2d(rows, cols, d=32):\n",
        "  \"\"\"\n",
        "  Index in the log-softmax scale.\n",
        "  After sotmax (in the partition dimension)\n",
        "  -inf --> 0\n",
        "  1.0  --> 1\n",
        "  \"\"\"\n",
        "  assert rows + cols <= d\n",
        "  inf = 1.0\n",
        "  idx = np.zeros((rows, cols, d)) - inf\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      idx[row, col, row] = 1.0\n",
        "      idx[row, col, rows + col] = 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, d=2):\n",
        "  idx = np.zeros((rows, cols, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      # idx[row, col, 0] = (1 + row) / rows\n",
        "      # idx[row, col, 1] = (1 + col) / cols\n",
        "      idx[row, col, 0] = 2.0 * ((row + 1) / rows) - 1.0\n",
        "      idx[row, col, 1] = 2.0 * ((col + 1) / cols) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _sgbmd(u, v, idxu, idxv, sim=None, f=None, normalize=True) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Slow General Batch Maromba Dot\"\n",
        "  Slower, more general, implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  sim: index similarity function\n",
        "  f: value function\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  sim = Pairwise(sim)\n",
        "  f = Pairwise(f)\n",
        "  ###\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  ###\n",
        "  # sims: (M * N) x 1 x (d_u * d_v)\n",
        "  # vals: (M * N) x (d_u * d_v) x d_val\n",
        "  sims = sim(idxu, idxv).reshape(m * n, 1, d_u * d_v) ###\n",
        "  norm = 1.0\n",
        "  if normalize:\n",
        "    # norm: (M * N) x 1\n",
        "    norm = sims.sum(dim=-1)\n",
        "  vals = f(u, v)\n",
        "  vals = vals.reshape(m * n, d_u * d_v, d_val)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.bmm(sims, vals).squeeze(1)\n",
        "  eps = 1e-8\n",
        "  dot = (dot / (norm + eps)).reshape(m, n, d_val)\n",
        "  return dot\n",
        "\n",
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  # Pdb().set_trace()\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  # normalizer: M x N x 1\n",
        "  idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv ** 6.0\n",
        "  # idxuv = nn.functional.relu(idxuv - bias) ###\n",
        "  mag = 2.0 # 10.0 # 200.0\n",
        "  idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # idxuv = nn.functional.gumbel_softmax(\n",
        "  #     6.0 * idxuv - 3.0, dim=2, hard=False, tau=0.2\n",
        "  # )\n",
        "  # idxuv = get_eye(m, d_u, d_v, n, idxuv.device)\n",
        "  # idxuv = idxuv / (idxuv.sum(dim=2).unsqueeze(2) + 1e-6)\n",
        "  # Pdb().set_trace()\n",
        "  # normalizer = idxuv.reshape(m, d_u * d_v, n).sum(dim=1).reshape(m, n, 1)\n",
        "  # normalizer = 1.0 - 1e-6\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  # dot = dot / (normalizer + 1e-6)\n",
        "  return dot\n",
        "\n",
        "def _gbmd(u, v, idxu, idxv, kernel=None, idx_part=None) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"General Batch Maromba Dot\"\n",
        "  Shorter implementation for the \"batch maromba dot\" operation.\n",
        "  u: M x d_u\n",
        "  v: N x d_v\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u = u.shape\n",
        "  n, d_v = v.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  assert (m, d_u, d_idx) == idxu.shape\n",
        "  assert (n, d_v, d_idx) == idxv.shape\n",
        "  if kernel:\n",
        "    idxu = kernel(idxu, idx_part)\n",
        "    idxv = kernel(idxv, idx_part)\n",
        "  # uidxu: M x d_idx\n",
        "  # vidxv: N x d_idx\n",
        "  uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "  vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "  dot = uidxu @ vidxv.T\n",
        "  ### Under experimentation\n",
        "  normalizer = idxu.sum(dim=1) @ idxv.sum(dim=1).T\n",
        "  dot = dot / (normalizer + 1e-8) ###\n",
        "  ###\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, idx_part)\n",
        "  kidxv = k(idxv, idx_part)\n",
        "  d_idx_k = kidxu.shape[-1]\n",
        "  assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "  assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "  sidx = (\n",
        "      (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "      + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "  )\n",
        "  sidx = sidx / norm\n",
        "  sidx = sidx.repeat(batch_m, 1, 1)\n",
        "  return sidx\n",
        "\n",
        "def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  ### idxu MUST be the input mini-batch\n",
        "  batch_m = 1 # idxu.shape[0]\n",
        "  # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "  ###\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # kiTi: (M * d_idx) x d_idx(k)\n",
        "  # kjTj: (N * d_idx) x d_idx(k)\n",
        "  iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "  jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "  # iTki_kjTj: M x N x d_idx x d_idx\n",
        "  iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "  diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "  ###\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  diag = diag / norm\n",
        "  ###\n",
        "  diag = diag.repeat(batch_m, 1, 1)\n",
        "  return diag\n",
        "\n",
        "def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "  \"\"\"\n",
        "  k: callable: A x B x C -> A x B x C\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # kidxu: M x d_u x d_idx\n",
        "  # kidxv: N x d_v x d_idx\n",
        "  kidxu = k(idxu, _idx_part)\n",
        "  kidxv = k(idxv, _idx_part)\n",
        "  assert kidxu.shape == idxu.shape\n",
        "  assert kidxv.shape == idxv.shape\n",
        "  # ski: (M * N) x d_idx\n",
        "  # skj: (M * N) x d_idx\n",
        "  # norm: M x N x 1\n",
        "  ski = kidxu.sum(dim=1)\n",
        "  skj = kidxv.sum(dim=1)\n",
        "  norm = (ski @ skj.T).unsqueeze(-1)\n",
        "  ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "  skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "  # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "  # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "  idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "  idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "  kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "  kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "  # sikiT: M x d_idx x d_idx\n",
        "  # sjkjT: N x d_idx x d_idx\n",
        "  sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "  sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "  sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "  sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "  del kidxu\n",
        "  del kidxv\n",
        "  del idxu\n",
        "  del idxv\n",
        "  # sikiT: (M * N) x d_idx x d_idx\n",
        "  # sjkjT: (M * N) x d_idx x d_idx\n",
        "  sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "  # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "  # skjjT = sjkjT.permute(0, 2, 1)\n",
        "  # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "  # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "  xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "  # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "  # xor_idx = diag_sikiT_skjjT\n",
        "  xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "  xor_idx = xor_idx / norm\n",
        "  return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    kernel = _soft_kernel\n",
        "    # kernel = _cosine_kernel\n",
        "    # mdot = _gbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1]),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1]),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel=kernel,\n",
        "    #     idx_part=self._idx_part,\n",
        "    # )\n",
        "    # mdot = _sgbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     f=vecprod,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = _nsbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # _kernel_idx # _fast_kernel_idx # _fast_kernel_idx_sum\n",
        "    # midx = _fast_kernel_idx_sum(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     kernel,\n",
        "    #     self._idx_part,\n",
        "    # )\n",
        "    # midx = _sgbmd(\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    #     sim=relu_cosine,\n",
        "    #     # sim=squared_cosine,\n",
        "    #     # f=vecsum,\n",
        "    #     f=vecmean,\n",
        "    # )\n",
        "    ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # midx = norm_normalize(\n",
        "    #     norm_normalize(_nsbmd(aidx, onesb, aidx, bidx))\n",
        "    #     + norm_normalize(_nsbmd(onesa, bidx, aidx, bidx))\n",
        "    # )\n",
        "    # midx = norm_normalize(_nsbmd(aidx, bidx, aidx, bidx))\n",
        "    midx = (\n",
        "        _nsbmd(aidx, onesb, aidx, bidx)\n",
        "        + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    # Pdb().set_trace()\n",
        "    ###\n",
        "    # midx = norm_normalize(\n",
        "    #     norm_normalize(_rdot(aidx, onesb, aidx, bidx))\n",
        "    #     + norm_normalize(_rdot(onesa, bidx, aidx, bidx))\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sampling functions"
      ],
      "metadata": {
        "id": "1SknOTQ7O9BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def idx2d(\n",
        "    channels: int,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    stride: int=2,\n",
        "    dilation: int=1,\n",
        "    device=\"cpu\"\n",
        "  ):\n",
        "  idx = []\n",
        "  dilh = 1 + dilation * (h - 1)\n",
        "  dilw = 1 + dilation * (w - 1)\n",
        "  for row in range(0, rows - (dilh - 1), stride):\n",
        "    for col in range(0, cols - (dilw - 1), stride):\n",
        "      for ch in range(channels):\n",
        "        for drow in range(0, dilh, dilation):\n",
        "          for dcol in range(0, dilw, dilation):\n",
        "            idx.append(\n",
        "                cols * rows * ch\n",
        "                + cols * (row + drow)\n",
        "                + (col + dcol)\n",
        "            )\n",
        "  idx = torch.tensor(idx).long().to(device)\n",
        "  return idx\n",
        "\n",
        "def unsort(idxs):\n",
        "  ridxs = [0 for _ in idxs]\n",
        "  for i, idx in enumerate(idxs):\n",
        "    ridxs[idx] = i\n",
        "  ridxs = torch.tensor(ridxs).long().to(idxs.device)\n",
        "  return ridxs\n",
        "\n",
        "def get_perms(tmp_idx):\n",
        "  idxs, _idxs = [], []\n",
        "  for dim in range(tmp_idx.shape[-1]):\n",
        "    ordering = torch.argsort(tmp_idx[:, dim], stable=True)\n",
        "    idxs.append(ordering)\n",
        "    _idxs.append(unsort(ordering))\n",
        "  return idxs, _idxs\n",
        "\n",
        "def resort(k, src, tgt, idxs, _idxs):\n",
        "  assert src == 0 or tgt == 0\n",
        "  if tgt == 0:\n",
        "    return idxs[src][k]\n",
        "  return _idxs[tgt][k]\n",
        "\n",
        "def hoods(dims, k0, w, idxs, _idxs):\n",
        "  assert len(dims) == len(w), f\"{len(dims)} != {len(w)}\"\n",
        "  if len(dims) == 0:\n",
        "    return [k0.item()]\n",
        "  _hoods = []\n",
        "  for _w in range(-(w[-1] // 2), w[-1] // 2 + 1):\n",
        "    _hoods += hoods(\n",
        "        dims[:-1],\n",
        "        resort(\n",
        "            resort(k0, 0, dims[-1], idxs, _idxs) + _w,\n",
        "            dims[-1], 0,\n",
        "            idxs, _idxs\n",
        "        ),\n",
        "        w[:-1],\n",
        "        idxs, _idxs\n",
        "    )\n",
        "  return _hoods\n",
        "\n",
        "def idxhood(xidx, ws, stride):\n",
        "  \"\"\"\n",
        "  xidx: in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  dims = list(range(xidx.shape[-1]))\n",
        "  idxs, _idxs = get_perms(xidx)\n",
        "  all_hoods = []\n",
        "  for pivot in range(0, len(xidx), stride):\n",
        "    all_hoods += hoods(dims, pivot, ws, idxs, _idxs)\n",
        "  return all_hoods"
      ],
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MModule"
      ],
      "metadata": {
        "id": "jdZ8zHIcPQPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MModule(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _W_step(\n",
        "      self,\n",
        "      x: MTensor,\n",
        "      W: MTensor,\n",
        "      sets,\n",
        "      samples,\n",
        "      random=True,\n",
        "      conv=False,\n",
        "      filter_size=4,\n",
        "      activation=True,\n",
        "      regular_dot=False):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    # Put 1 into x\n",
        "    if not conv:\n",
        "      filter_size = in_dim\n",
        "    assert (in_dim % filter_size) == 0\n",
        "    num_windows = (in_dim // filter_size)\n",
        "    # one = MTensor(\n",
        "    #     torch.ones((n * num_windows), 1).to(self.device),\n",
        "    #     torch.ones((n * num_windows), 1, idx_dim).to(self.device),\n",
        "    # )\n",
        "    x = MTensor.reshape(x, (n * num_windows, filter_size))\n",
        "    # Sample W\n",
        "    if conv:\n",
        "      ### filter_size + 1\n",
        "      assert (sets * samples) % (filter_size) == 0\n",
        "      numw_windows = (sets * samples) // (filter_size)\n",
        "      sets, samples = numw_windows, (filter_size)\n",
        "    W_sets = MTensor.reshape(W, (sets, samples))\n",
        "    ## mdot: N x sets\n",
        "    # mdot: (N * num_windows) x numw_windows\n",
        "    mdot = x @ W_sets\n",
        "    if activation:\n",
        "      mdot.data = self.activation(mdot.data)\n",
        "    # mdot: N x num_windows x numw_windows\n",
        "    if conv:\n",
        "      ### Várias \"imagens\" coladas em um sentido\n",
        "      mdot = MTensor.reshape(mdot, (n, num_windows, numw_windows))\n",
        "    return mdot\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    channels = 1\n",
        "    img_h, img_w = img_dim, img_dim\n",
        "    filter_whs = [(3, 3), (3, 3)]\n",
        "    strides = [2, 1]\n",
        "    filter_w, filter_h = filter_whs[0]\n",
        "    stride = strides[0]\n",
        "    filter_area = filter_w * filter_h\n",
        "    filter_volume = channels * filter_area\n",
        "    self.all_pools = [x[:4]]\n",
        "    idx = idx2d(\n",
        "        channels,\n",
        "        img_h, img_w,\n",
        "        filter_w, filter_h,\n",
        "        stride=stride,\n",
        "        device=self.device\n",
        "    )\n",
        "    x = x[:, idx]\n",
        "    ###\n",
        "    pool = x\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      if conv:\n",
        "        pool = self._W_step(\n",
        "            pool,\n",
        "            self.MW[:, wl: wr],\n",
        "            self.sets[step],\n",
        "            self.samples[step],\n",
        "            random=False,\n",
        "            conv=conv,\n",
        "            filter_size=filter_volume,\n",
        "            activation=activate,\n",
        "        )\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        filter_volume = channels * filter_area\n",
        "        pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # assert img_dim % stride == 0\n",
        "        img_h = (img_h - filter_h + stride) // stride\n",
        "        img_w = (img_w - filter_w + stride) // stride\n",
        "        assert img_h * img_w == img_area\n",
        "        # cols = pool.data.shape[1] // rows\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        filter_w, filter_h = filter_whs[nxt_conv_step]\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_area = filter_w * filter_h\n",
        "        filter_volume = channels * filter_area\n",
        "        if nxt_conv:\n",
        "          idx = idx2d(\n",
        "              channels,\n",
        "              img_h, img_w,\n",
        "              filter_w, filter_h,\n",
        "              stride=stride,\n",
        "              device=self.device\n",
        "          )\n",
        "          pool = pool[:, idx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ],
      "metadata": {
        "id": "tQoFxrDIPScK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MModule II"
      ],
      "metadata": {
        "id": "3mlldpkcPFvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Oipx_P9qYUUb"
      },
      "outputs": [],
      "source": [
        "class MModule2(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    ### TODO: checar inicialização de W\n",
        "    # self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params), device=device) - 1.0\n",
        "    )\n",
        "    self.W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((1, n_params, idx_dim), device=device) - 1.0\n",
        "    )\n",
        "    # self.W_idx = _W_idx\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    ###\n",
        "    if probe_dim:\n",
        "      self.probe = nn.Linear(probe_dim, 10).to(device) # 288, 400, 512\n",
        "    ###\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    # channels = 1\n",
        "    # img_h, img_w = img_dim, img_dim\n",
        "    filter_whs = [(3, 3, 1), (3, 3, 2)]\n",
        "    strides = [2, 1]\n",
        "    # filter_w, filter_h = filter_whs[0]\n",
        "    stride = strides[0]\n",
        "    # filter_area = filter_w * filter_h\n",
        "    filter_volume = np.prod(filter_whs[0]) # channels * filter_area\n",
        "    self.all_pools = [x[:4]]\n",
        "    # idx = idx2d(\n",
        "    #     channels,\n",
        "    #     img_h, img_w,\n",
        "    #     filter_w, filter_h,\n",
        "    #     stride=stride,\n",
        "    #     device=self.device\n",
        "    # )\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0]) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    mw = MTensor.reshape(\n",
        "        self.MW[0, wl: wr],\n",
        "        (self.sets[0], self.samples[0])\n",
        "    )\n",
        "    # idxw = idxhood(\n",
        "    #     mw.idx,\n",
        "    #     filter_whs[0],\n",
        "    #     strides[0]\n",
        "    # ) ### FIX\n",
        "    # mw = mw[:, idxw]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        pool.data = self.probe(pool.data)\n",
        "      ###\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      ###\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        # filter_volume = channels * filter_area\n",
        "        pool = MTensor.permute(pool, (0, 2, 1))\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # assert img_dim % stride == 0\n",
        "        # img_h = (img_h - filter_h + stride) // stride\n",
        "        # img_w = (img_w - filter_w + stride) // stride\n",
        "        # assert img_h * img_w == img_area\n",
        "        # cols = pool.data.shape[1] // rows\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        # filter_w, filter_h = filter_whs[nxt_conv_step]\n",
        "        stride = strides[nxt_conv_step]\n",
        "        # filter_area = filter_w * filter_h\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step]) # channels * filter_area\n",
        "        if nxt_conv:\n",
        "          # idx = idx2d(\n",
        "          #     channels,\n",
        "          #     img_h, img_w,\n",
        "          #     filter_w, filter_h,\n",
        "          #     stride=stride,\n",
        "          #     device=self.device\n",
        "          # )\n",
        "          idxx = idxhood(pool.idx[0], filter_whs[nxt_conv_step], strides[nxt_conv_step]) ### FIX\n",
        "          pool = pool[:, idx]\n",
        "      ###\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  y_pred = 10.0 * y_pred.data\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, d=idx_dim)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_idx = template_x_idx[0].reshape(-1, 3)[:, :2]\n",
        "idxs, _idxs = get_perms(tmp_idx)\n",
        "sampled = hoods([0, 1], 14 * 28 + 14, [3, 3], idxs, _idxs)\n",
        "sampled = np.array([[idx // 28, idx % 28] for idx in sampled])\n",
        "# print(sampled)\n",
        "plt.scatter(sampled[:, 0], sampled[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "OisDCAuLCmQ8",
        "outputId": "c0f93b64-844d-449a-db0e-3ce87dcb9fcd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f1aa47bd060>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HNheVxvNNK30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f256cf2-2dfe-41ef-f794-9ae73956ba59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0035266736522316933 0.5764922499656677\n",
            "0.002129731699824333 0.577811062335968\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1aaddf8fb283>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaromba_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-ce704dc545cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m#     device=self.device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0midxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midxhood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_whs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### FIX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;31m# pool: N x (num_windows * window_volume)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-8c2a6db614f6>\u001b[0m in \u001b[0;36midxhood\u001b[0;34m(xidx, ws, stride)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0mall_hoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpivot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mall_hoods\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhoods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mall_hoods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-8c2a6db614f6>\u001b[0m in \u001b[0;36mhoods\u001b[0;34m(dims, k0, w, idxs, _idxs)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0m_hoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     _hoods += hoods(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         resort(\n",
            "\u001b[0;32m<ipython-input-27-8c2a6db614f6>\u001b[0m in \u001b[0;36mhoods\u001b[0;34m(dims, k0, w, idxs, _idxs)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0m_hoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     _hoods += hoods(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         resort(\n",
            "\u001b[0;32m<ipython-input-27-8c2a6db614f6>\u001b[0m in \u001b[0;36mhoods\u001b[0;34m(dims, k0, w, idxs, _idxs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     _hoods += hoods(\n\u001b[1;32m     55\u001b[0m         \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         resort(\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mresort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-8c2a6db614f6>\u001b[0m in \u001b[0;36mresort\u001b[0;34m(k, src, tgt, idxs, _idxs)\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 784 is out of bounds for dimension 0 with size 784"
          ]
        }
      ],
      "source": [
        "hidden_dim = 484\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "# TODO: Visualize conv layer output\n",
        "samples = [\n",
        "    # in_ch * h * w,\n",
        "    1 * 3 * 3,\n",
        "    2 * 3 * 3,\n",
        "    # 4 * 8 * 3 * 3,\n",
        "    hidden_dim,\n",
        "]\n",
        "sets = [\n",
        "    # out_ch\n",
        "    2,\n",
        "    4,\n",
        "    # 1,\n",
        "    num_classes\n",
        "]\n",
        "n_params = int(np.array(samples).dot(np.array(sets)))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if start_mode:\n",
        "  # model = MModule(\n",
        "  model = MModule2(\n",
        "      n_params=n_params,\n",
        "      idx_dim=idx_dim,\n",
        "      samples=samples,\n",
        "      sets=sets,\n",
        "      device=device,\n",
        "      probe_dim=hidden_dim,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3) # 1e-2\n",
        "\n",
        "train_log = {\n",
        "    \"train loss\": [],\n",
        "    \"eval loss\": [],\n",
        "    \"acc\": [],\n",
        "    \"set\": [],\n",
        "    \"epoch\": [],\n",
        "}\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  ###\n",
        "  print(model.W.mean().item(), model.W.std().item())\n",
        "  print(model.W_idx.mean().item(), model.W_idx.std().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    group_cols = [\"epoch\", \"train loss\", \"eval loss\", \"acc\"]\n",
        "  else:\n",
        "    group_cols = [\"epoch\", \"train loss\"]\n",
        "  df_train = pd.DataFrame(train_log)\n",
        "  display.clear_output(wait=True)\n",
        "  (\n",
        "    df_train[group_cols]\n",
        "    .groupby(\"epoch\")\n",
        "    .agg(lambda x: x.median(skipna=True))\n",
        "    # .tail(200)\n",
        "    .plot(figsize=(24, 4), grid=True)\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5tP_tfMAjw",
        "outputId": "a5c2be37-d2b3-48f1-b98d-69813f80e345"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([4, 784]), torch.Size([4, 169, 2]), torch.Size([4, 121, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 2) // 2, (img_dim - 2) // 2, 2),\n",
        "    (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  for ch in range(shapes[idx][2]):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(img_.mean(), img_.min(), img_.max())\n",
        "    plt.imshow(img_)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  idx_ = idx[:, 0].numpy()\n",
        "  plt.figure(figsize=(4, 4))\n",
        "  plt.scatter(idx_[:, 0], idx_[:, 1], marker=\"+\")\n",
        "  plt.grid()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt-a46cmSBmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b09e1aba-6831-4e59-c841-2d2bc15edbfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>),\n",
              " tensor(0.5751, device='cuda:0', grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "### Ordenar pelo índice\n",
        "# filters = model.W_idx[0, :25].reshape(1, 5, 5, idx_dim)\n",
        "# print(filters)\n",
        "model.W_idx.mean(), model.W_idx.std()\n",
        "# for filter in filters:\n",
        "#   filter = filter.cpu().detach().numpy()\n",
        "#   plt.imshow(filter)\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.W_idx.mean(), model.W_idx.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnweClNF0-Ik",
        "outputId": "6000465f-4501-4e62-a171-74aa55e3a8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>),\n",
              " tensor(0.5751, device='cuda:0', grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPdqOyP9Sdx1"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(train_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "_T9hF3Uoi3tF",
        "jdZ8zHIcPQPS",
        "QQRFtDATXUmH",
        "039kGqbPXp4d"
      ],
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNUPKP/zrvZ9wcEQzwN4INB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}