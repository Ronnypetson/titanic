{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612808f1-ef5b-4eab-b552-56e0abb6e849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to MNIST_root/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 67523029.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/cifar-10-python.tar.gz to MNIST_root/\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to MNIST_root_test/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 96698269.88it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/cifar-10-python.tar.gz to MNIST_root_test/\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 3\n",
        "img_dim = 32\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  return (\n",
        "      cifar10_norm(tr(x))\n",
        "      .reshape(channels, img_dim, img_dim)\n",
        "      .permute(1, 2, 0)\n",
        "      .reshape(-1)\n",
        "  )\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  # return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x)).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "# SOURCE_DATASET = FashionMNIST\n",
        "SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "outputs": [],
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "outputs": [],
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "outputs": [],
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 0.001 * ((ch  + offset) /  chs) - 0.005\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx\n",
        "\n",
        "def _cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = (row + offset)\n",
        "        idx[row, col, ch, 1] = (col + offset)\n",
        "        idx[row, col, ch, 2] = (ch  + offset)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "def poly1norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  idxu = (0.5 ** 0.5) * torch.cat([idxu, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "def poly2norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  _idxu = idxu.reshape((-1, d_idx, 1))\n",
        "  middle = (\n",
        "      torch.bmm(_idxu, _idxu.permute(0, 2, 1))\n",
        "      .reshape((*idxu.shape[:-1], d_idx ** 2))\n",
        "  )\n",
        "  idxu = 0.5 * torch.cat([(2.0 ** 0.5) * idxu, middle, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "from collections import defaultdict as dd\n",
        "from itertools import product\n",
        "\n",
        "@lru_cache()\n",
        "def poly_terms(idx_dim, degree):\n",
        "  combs = dd(int)\n",
        "  ranges = (range(idx_dim) for _ in range(degree))\n",
        "  for idxs in product(*ranges):\n",
        "      comb = tuple(sorted(idxs))\n",
        "      combs[comb] += 1\n",
        "  return list(combs.items())\n",
        "\n",
        "\"\"\"\n",
        "sigmoid(8*x - 4)\n",
        "1/(1 + e^4)\n",
        "+ (8 e^4 x)/(1 + e^4)^2\n",
        "+ (32 e^4 (e^4 - 1) x^2)/(1 + e^4)^3\n",
        "+ (256 (e^4 - 4 e^8 + e^12) x^3)/(3 (1 + e^4)^4)\n",
        "+ (512 e^4 (-1 + 11 e^4 - 11 e^8 + e^12) x^4)/(3 (1 + e^4)^5)\n",
        "+ (4096 (e^4 - 26 e^8 + 66 e^12 - 26 e^16 + e^20) x^5)/(15 (1 + e^4)^6)\n",
        "+ O(x^6)\n",
        "(Taylor series)\n",
        "-------------------------\n",
        "0.017986  * x^0\n",
        "0.14130   * x^1\n",
        "0.5448747 * x^2\n",
        "1.3474883 * x^3\n",
        "2.290065  * x^4\n",
        "2.4479883 * x^5\n",
        "\"\"\"\n",
        "\n",
        "def poly_norm(idxu, degree):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  pre_shape = idxu.shape[:-1]\n",
        "  idx_dim = idxu.shape[-1]\n",
        "  idxu = normalized(idxu)\n",
        "  terms = poly_terms(idx_dim, degree)\n",
        "  factors = torch.tensor([term[1] for term in terms]).float().to(idxu.device)\n",
        "  factors = factors ** 0.5\n",
        "  intidx = torch.tensor([list(term[0]) for term in terms]).long().to(idxu.device)\n",
        "  intidx = intidx.reshape(-1)\n",
        "  idxu = idxu.reshape(-1, idx_dim)[:, intidx]\n",
        "  idxu = idxu.reshape(*pre_shape, degree, -1)\n",
        "  idxu = idxu.prod(dim=-2) * factors.reshape(*((1,) * len(pre_shape)), idxu.shape[-1])\n",
        "  return idxu\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _knndot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"k-NN Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  num_neigh = 1\n",
        "  dots = []\n",
        "  q_idxu = idxu.cpu().detach().numpy().reshape(-1, d_idx)\n",
        "  for _pos in range(n):\n",
        "    neigh = NearestNeighbors(n_neighbors=num_neigh, metric=\"cosine\")\n",
        "    neigh.fit(idxv[_pos].cpu().detach().numpy().reshape(-1, d_idx))\n",
        "    n_idxu = neigh.kneighbors(\n",
        "        q_idxu, return_distance=False\n",
        "    ).reshape(-1)\n",
        "    n_idxu = torch.from_numpy(n_idxu).long()\n",
        "    _v = v[_pos].reshape(-1, d_val)[n_idxu].reshape(m, d_u, d_val)\n",
        "    # _dot: M x d_val x d_val\n",
        "    _dot = torch.bmm(_v.permute(0, 2, 1), _v)\n",
        "    # _dot: M x 1 x d_val\n",
        "    _dot = torch.diagonal(_dot, dim1=1, dim2=2).unsqueeze(1)\n",
        "    dots.append(_dot)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.cat(dots, dim=1)\n",
        "  return dot\n",
        "\n",
        "def _icbmd(u, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Conv Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x 1 x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_v == 1\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: M x d_u x N\n",
        "  idxv = (\n",
        "      (idxu.reshape(m * d_u, d_idx))\n",
        "      @ idxv.permute(2, 1, 0).reshape(d_idx, n)\n",
        "  ).reshape(m, d_u, n)\n",
        "  # idxv: M x N x d\n",
        "  idxv = torch.bmm(\n",
        "      u.permute(0, 2, 1),\n",
        "      idxv\n",
        "  ).permute(0, 2, 1)\n",
        "  return idxv\n",
        "\n",
        "def _ibmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  v: N x d_v x d_valv\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu, d_valv = u.shape[-1], v.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxu = poly_norm(idxu, 1) # / (d_u)\n",
        "  # idxv = poly_norm(idxv, 1) # / (d_v)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: N x d_idx x d_valv\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxv: M x d_u x (d_valv * N)\n",
        "  idxv = (\n",
        "      idxu.reshape(m * d_u, d_idx)\n",
        "      @ idxv.permute(1, 2, 0).reshape(d_idx, d_valv * n)\n",
        "  ).reshape(m, d_u, d_valv * n)\n",
        "  # idxv: M x d_valu x (d_valv * N)\n",
        "  idxv = torch.bmm(u.permute(0, 2, 1), idxv)\n",
        "  if d_valv == 1:\n",
        "    # idxv: M x N x d_valu\n",
        "    idxv = idxv.reshape(m, d_valu, n).permute(0, 2, 1)\n",
        "  else:\n",
        "    # idxv: M x N x d_valu or error\n",
        "    idxv = idxv.reshape(m, d_valu, d_valv, n).permute(0, 3, 1, 2)\n",
        "    idxv = torch.diagonal(idxv, dim1=2, dim2=3)\n",
        "  return idxv\n",
        "\n",
        "def _fbmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Fast Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxu: M x d_val x d_idx\n",
        "  # idxv: N x d_idx x d_val\n",
        "  idxu = torch.bmm(u.permute(0, 2, 1), idxu)\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxu: M x N x d_val\n",
        "  idxu = (\n",
        "    (\n",
        "        idxu.reshape(m * d_val, d_idx)\n",
        "        @ (\n",
        "            idxv\n",
        "            .permute(0, 2, 1)\n",
        "            .reshape(n * d_val, d_idx)\n",
        "            .T\n",
        "          )\n",
        "    ).reshape(m, d_val, n, d_val)\n",
        "    .permute(0, 2, 1, 3)\n",
        "  )\n",
        "  idxu = torch.diagonal(idxu, dim1=2, dim2=3)\n",
        "  return idxu\n",
        "\n",
        "def batch_mdot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  if d_idx * (d_u + n) < n * d_u * (d_idx + 1):\n",
        "    return _fbmd(u, v, idxu, idxv)\n",
        "  else:\n",
        "    return _ibmd(u, v, idxu, idxv)\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  ###\n",
        "  # siter = 6\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  #### Tanh seems to work for high-dimensional idx\n",
        "  #### ReLU(x - alpha) / (1.0 - alpha) works for small samples\n",
        "  # alpha = 1.0 - 1.0 / d_v # 0.95\n",
        "  # alpha = min(0.999, alpha)\n",
        "  alpha = 0.97\n",
        "  idxuv = nn.functional.relu((idxuv - alpha) / (1.0 - alpha))\n",
        "  ###\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    ###\n",
        "    # _nsbmd\n",
        "    # _rdot\n",
        "    # _knndot\n",
        "    # _fbmd\n",
        "    # _ibmd, _mbmd\n",
        "    # batch_mdot\n",
        "    ###\n",
        "    mdot = _rdot(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    # _aidx = aidx.mean(dim=-2, keepdim=True)\n",
        "    # _bidx = bidx.mean(dim=-2, keepdim=True)\n",
        "    # onesa = torch.ones(_aidx.shape).to(_aidx.device)\n",
        "    # onesb = torch.ones(_bidx.shape).to(_bidx.device)\n",
        "    # midx = (\n",
        "    #     _nsbmd(_aidx, onesb, _aidx, _bidx)\n",
        "    #     + _nsbmd(onesa, _bidx, _aidx, _bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    _aidx = aidx.mean(dim=-2, keepdim=True)\n",
        "    _bidx = bidx.mean(dim=-2, keepdim=True)\n",
        "    _bnorm = _bidx.norm(dim=-1)\n",
        "    _bidx *= 0.0\n",
        "    _bidx[:, :, 2] = _bnorm\n",
        "    _aidx[:, :, 2] = 0.0\n",
        "    # midx = (\n",
        "    #     _aidx + _bidx.permute(1, 0, 2)\n",
        "    # ) / 2.0\n",
        "    # midx = (_aidx + _bidx.permute(1, 0, 2))\n",
        "    __bidx = (\n",
        "        torch.arange(1, _bidx.shape[0] + 1)\n",
        "        .to(_bidx.device)\n",
        "        .reshape(1, _bidx.shape[0], 1)\n",
        "        / (_bidx.shape[0])\n",
        "    )\n",
        "    midx = _aidx + 1e-3 * __bidx\n",
        "    ###\n",
        "    # midx = _icbmd(aidx, aidx, bidx.sum(dim=-2, keepdim=True)) # / aidx.shape[-2]\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  nneigh = min(nneigh, len(xidx))\n",
        "  neigh = NearestNeighbors(\n",
        "      n_neighbors=nneigh,\n",
        "      algorithm=\"brute\",\n",
        "      # metric=\"minkowski\",\n",
        "      # p=1,\n",
        "  )\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    num_sets = min(num_sets, len(xidx))\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False,\n",
        "    )\n",
        "    all_hoods = set(tuple(sorted(hood)) for hood in all_hoods)\n",
        "    all_hoods = np.array(list(all_hoods))\n",
        "    ###\n",
        "    hood_means = xidx[all_hoods.reshape(-1)]\n",
        "    hood_means = hood_means.reshape(len(all_hoods), nneigh, xidx.shape[-1])\n",
        "    hood_mins = hood_means.min(axis=1)[:, None, :]\n",
        "    hood_maxes = hood_means.max(axis=1)[:, None, :]\n",
        "    hood_norm = (hood_means - hood_mins) / (hood_maxes - hood_mins + 1e-6)\n",
        "    hood_norm_ = hood_norm.mean(axis=1)\n",
        "    hood_consensus = np.median(hood_norm_, axis=0)\n",
        "    hood_filter = (np.linalg.norm(hood_norm_ - hood_consensus[None, :], axis=1) < 1e-4)\n",
        "    all_hoods = all_hoods[hood_filter]\n",
        "    ###\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ) # .reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    # self._ones_idx = torch.zeros((1, 1, idx_dim), device=device)\n",
        "    # self.activation = nn.ELU()\n",
        "    self.activation = nn.ReLU()\n",
        "    # self.activation = nn.LeakyReLU()\n",
        "    self._probe = nn.Linear(self._feat_samples[-1], 10).to(device)\n",
        "    self._num_fwd = 0\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    self._bn_w = nn.Parameter(torch.ones(n_layers - 1).to(device))\n",
        "    self._bn_b = nn.Parameter(torch.zeros(n_layers - 1).to(device))\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _mag = 0.1 # 2.0 # 1000.0 * 0.01\n",
        "    _W_idx = _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    ###\n",
        "    # _W_idx = _W_idx.reshape(-1, idxdim)\n",
        "    # _W_idx[:, 2] = 1.0\n",
        "    # _W_idx = _W_idx.reshape(*shape, idxdim)\n",
        "    ###\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #   _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    # )\n",
        "    # _std = 1.0\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #   _std * torch.randn((*shape, idxdim), device=device)\n",
        "    # )\n",
        "    # _W = torch.ones(shape).float().to(device)\n",
        "    _std = 0.01\n",
        "    # _W = _std * torch.randn(shape, device=device)\n",
        "    # _W = _mag * torch.rand(shape, device=device) - (_mag / 2.0)\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def _reinit_indices(self, pool, params):\n",
        "    \"\"\"\n",
        "    pool: N x mshape\n",
        "    params: param_shape\n",
        "    \"\"\"\n",
        "    idx_dim = pool.idx.shape[-1]\n",
        "    assert params.idx.shape[-1] == idx_dim\n",
        "    pool_idx = pool.idx.reshape(-1, idx_dim)\n",
        "    eps = 1e-6\n",
        "    idx_max = pool_idx.max(dim=0, keepdim=True)[0] + eps\n",
        "    idx_min = pool_idx.min(dim=0, keepdim=True)[0] - eps\n",
        "    idx_itv = idx_max - idx_min\n",
        "    n_samples = len(params.idx.reshape(-1, idx_dim))\n",
        "    sampled_idx = torch.rand((n_samples, idx_dim), device=pool.data.device)\n",
        "    sampled_idx = sampled_idx * idx_itv + idx_min\n",
        "    params.idx = sampled_idx\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = deepcopy(self._config[\"params\"][\"sets\"])\n",
        "    param_samples = deepcopy(self._config[\"params\"][\"samples\"])\n",
        "    feat_sets = deepcopy(self._config[\"features\"][\"sets\"])\n",
        "    feat_samples = deepcopy(self._config[\"features\"][\"samples\"])\n",
        "    ###\n",
        "    # self._curr_sets = feat_sets\n",
        "    # self._curr_samples = feat_samples\n",
        "    ###\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._num_fwd == 0:\n",
        "        self._reinit_indices(pool, self.MW[wl: wr])\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # idx_slice = pool.idx[0]\n",
        "        idx_slice = pool.idx[0, :, :3]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      ###\n",
        "      feat_sets[step] = idxx.shape[0]\n",
        "      feat_samples[step] = idxx.shape[1]\n",
        "      idxx = idxx.reshape(-1)\n",
        "      ###\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      ###\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      maromba_only = False\n",
        "      if maromba_only or (step < n_layers - 1):\n",
        "        pool = (\n",
        "            MTensor.reshape(\n",
        "                pool, (n * feat_sets[step], -1)\n",
        "            )\n",
        "            @ mw\n",
        "        )\n",
        "      else:\n",
        "        pool = self._probe(pool.data.reshape(n, -1))\n",
        "        pool = MTensor(\n",
        "            pool,\n",
        "            torch.zeros((*pool.shape, self._idx_dim)).to(pool.device)\n",
        "        )\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        # pool.data = nn.functional.batch_norm(\n",
        "        #     pool.data,\n",
        "        #     pool.data.mean(dim=0).detach(),\n",
        "        #     pool.data.var(dim=0).detach(),\n",
        "        #     training=True,\n",
        "        #     weight=self._bn_w[step],\n",
        "        #     bias=self._bn_b[step],\n",
        "        # )\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    self._num_fwd += 1\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # 500 # 3 # 10\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim, mag=2.0) # 1000.0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_m1YvjxBdj9"
      },
      "source": [
        "### Visualizações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "outputs": [],
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "80102639-d056-43af-c905-4bf49ab238de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784, 2*784, 4*784, 1,],\n",
        "#         \"samples\": [9, 18, 36, 2904,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [2, 4, 6, num_classes,],\n",
        "#         \"samples\": [9, 18, 36, 784,],\n",
        "#         \"is conv\": [False, False, False, False]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [3072, 4*3072, 1,],\n",
        "        \"samples\": [27, 36, 1416,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [4, 8, num_classes,],\n",
        "        \"samples\": [27, 36, 3072,],\n",
        "        \"is conv\": [False, False, False]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.MW.idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 10 # 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.MW.idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    ###\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    _loss = loss.item()\n",
        "    # loss += 1e-1 * torch.cat(model._penalties, dim=0).sum()\n",
        "    ###\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(_loss)\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 1\n",
        "    _batchidx = 0\n",
        "    feat_map = True\n",
        "    if feat_map:\n",
        "      pool = model.all_pools[_layer]\n",
        "      pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "      display.clear_output(wait=True)\n",
        "      plot_features(pool)\n",
        "    else:\n",
        "      pool = model.all_samples[_layer - 1]\n",
        "      _shape = (\n",
        "          model._curr_sets[_layer - 1],\n",
        "          model._curr_samples[_layer - 1],\n",
        "      )\n",
        "      _set = (model._curr_sets[_layer - 1]) // 2\n",
        "      pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "      display.clear_output(wait=True)\n",
        "      plot_features(pool)\n",
        "    from time import sleep\n",
        "    sleep(3)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "outputs": [],
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "##\n",
        "# phi = idxu[0] @ idxv[0].T\n",
        "# import seaborn as sns\n",
        "# sns.heatmap(phi.cpu().detach().numpy()); plt.show()\n",
        "##\n",
        "# iidx = xidx[(all_hoods[hood_filter]).reshape(-1)].reshape(sum(hood_filter), -1, 3)\n",
        "# iidx_ = iidx.mean(axis=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "ilOucSYLd2zy",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "e0TdCxX0Jzn0",
        "kTfYY3SQXNJF",
        "1SknOTQ7O9BS",
        "vCh8kNiFl15G",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "8_m1YvjxBdj9"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNJ+zgp5yNwlCCKD3YJBiUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}