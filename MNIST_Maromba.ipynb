{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x)).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 8 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "outputs": [],
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "outputs": [],
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "outputs": [],
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx\n",
        "\n",
        "def _cartesian_idx(rows, cols, chs=1, d=2, offset=0, mag=0.1):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-mag, high=mag, size=(rows, cols, chs, d))\n",
        "  # idx = np.ones((rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = (row + offset)\n",
        "        idx[row, col, ch, 1] = (col + offset)\n",
        "        idx[row, col, ch, 2] = (ch  + offset)\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "def poly1norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  idxu = (0.5 ** 0.5) * torch.cat([idxu, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "def poly2norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  _idxu = idxu.reshape((-1, d_idx, 1))\n",
        "  middle = (\n",
        "      torch.bmm(_idxu, _idxu.permute(0, 2, 1))\n",
        "      .reshape((*idxu.shape[:-1], d_idx ** 2))\n",
        "  )\n",
        "  idxu = 0.5 * torch.cat([(2.0 ** 0.5) * idxu, middle, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "from collections import defaultdict as dd\n",
        "from itertools import product\n",
        "\n",
        "@lru_cache()\n",
        "def poly_terms(idx_dim, degree):\n",
        "  combs = dd(int)\n",
        "  ranges = (range(idx_dim) for _ in range(degree))\n",
        "  for idxs in product(*ranges):\n",
        "      comb = tuple(sorted(idxs))\n",
        "      combs[comb] += 1\n",
        "  return list(combs.items())\n",
        "\n",
        "\"\"\"\n",
        "sigmoid(8*x - 4)\n",
        "1/(1 + e^4)\n",
        "+ (8 e^4 x)/(1 + e^4)^2\n",
        "+ (32 e^4 (e^4 - 1) x^2)/(1 + e^4)^3\n",
        "+ (256 (e^4 - 4 e^8 + e^12) x^3)/(3 (1 + e^4)^4)\n",
        "+ (512 e^4 (-1 + 11 e^4 - 11 e^8 + e^12) x^4)/(3 (1 + e^4)^5)\n",
        "+ (4096 (e^4 - 26 e^8 + 66 e^12 - 26 e^16 + e^20) x^5)/(15 (1 + e^4)^6)\n",
        "+ O(x^6)\n",
        "(Taylor series)\n",
        "-------------------------\n",
        "0.017986  * x^0\n",
        "0.14130   * x^1\n",
        "0.5448747 * x^2\n",
        "1.3474883 * x^3\n",
        "2.290065  * x^4\n",
        "2.4479883 * x^5\n",
        "\"\"\"\n",
        "\n",
        "def poly_norm(idxu, degree):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  pre_shape = idxu.shape[:-1]\n",
        "  idx_dim = idxu.shape[-1]\n",
        "  idxu = normalized(idxu)\n",
        "  terms = poly_terms(idx_dim, degree)\n",
        "  factors = torch.tensor([term[1] for term in terms]).float().to(idxu.device)\n",
        "  factors = factors ** 0.5\n",
        "  intidx = torch.tensor([list(term[0]) for term in terms]).long().to(idxu.device)\n",
        "  intidx = intidx.reshape(-1)\n",
        "  idxu = idxu.reshape(-1, idx_dim)[:, intidx]\n",
        "  idxu = idxu.reshape(*pre_shape, degree, -1)\n",
        "  idxu = idxu.prod(dim=-2) * factors.reshape(*((1,) * len(pre_shape)), idxu.shape[-1])\n",
        "  return idxu\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _knndot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"k-NN Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  num_neigh = 1\n",
        "  dots = []\n",
        "  q_idxu = idxu.cpu().detach().numpy().reshape(-1, d_idx)\n",
        "  for _pos in range(n):\n",
        "    neigh = NearestNeighbors(n_neighbors=num_neigh, metric=\"cosine\")\n",
        "    neigh.fit(idxv[_pos].cpu().detach().numpy().reshape(-1, d_idx))\n",
        "    n_idxu = neigh.kneighbors(\n",
        "        q_idxu, return_distance=False\n",
        "    ).reshape(-1)\n",
        "    n_idxu = torch.from_numpy(n_idxu).long()\n",
        "    _v = v[_pos].reshape(-1, d_val)[n_idxu].reshape(m, d_u, d_val)\n",
        "    # _dot: M x d_val x d_val\n",
        "    _dot = torch.bmm(_v.permute(0, 2, 1), _v)\n",
        "    # _dot: M x 1 x d_val\n",
        "    _dot = torch.diagonal(_dot, dim1=1, dim2=2).unsqueeze(1)\n",
        "    dots.append(_dot)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.cat(dots, dim=1)\n",
        "  return dot\n",
        "\n",
        "def _ibmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Index Batch Maromba Dot\"\n",
        "  u: M x d_u x d_valu\n",
        "  v: N x d_v x d_valv\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_valu, d_valv = u.shape[-1], v.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxu = poly_norm(idxu, 1) # / (d_u)\n",
        "  # idxv = poly_norm(idxv, 1) # / (d_v)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxv: N x d_idx x d_valv\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxv: M x d_u x (d_valv * N)\n",
        "  idxv = (\n",
        "      idxu.reshape(m * d_u, d_idx)\n",
        "      @ idxv.permute(1, 2, 0).reshape(d_idx, d_valv * n)\n",
        "  ).reshape(m, d_u, d_valv * n)\n",
        "  # idxv: M x d_valu x (d_valv * N)\n",
        "  idxv = torch.bmm(u.permute(0, 2, 1), idxv)\n",
        "  if d_valv == 1:\n",
        "    # idxv: M x N x d_valu\n",
        "    idxv = idxv.reshape(m, d_valu, n).permute(0, 2, 1)\n",
        "  else:\n",
        "    # idxv: M x N x d_valu or error\n",
        "    idxv = idxv.reshape(m, d_valu, d_valv, n).permute(0, 3, 1, 2)\n",
        "    idxv = torch.diagonal(idxv, dim1=2, dim2=3)\n",
        "  return idxv\n",
        "\n",
        "def _fbmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Fast Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # idxu: M x d_val x d_idx\n",
        "  # idxv: N x d_idx x d_val\n",
        "  idxu = torch.bmm(u.permute(0, 2, 1), idxu)\n",
        "  idxv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # idxu: M x N x d_val\n",
        "  idxu = (\n",
        "    (\n",
        "        idxu.reshape(m * d_val, d_idx)\n",
        "        @ (\n",
        "            idxv\n",
        "            .permute(0, 2, 1)\n",
        "            .reshape(n * d_val, d_idx)\n",
        "            .T\n",
        "          )\n",
        "    ).reshape(m, d_val, n, d_val)\n",
        "    .permute(0, 2, 1, 3)\n",
        "  )\n",
        "  idxu = torch.diagonal(idxu, dim1=2, dim2=3)\n",
        "  return idxu\n",
        "\n",
        "def batch_mdot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  if d_idx * (d_u + n) < n * d_u * (d_idx + 1):\n",
        "    return _fbmd(u, v, idxu, idxv)\n",
        "  else:\n",
        "    return _ibmd(u, v, idxu, idxv)\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  ###\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  ###\n",
        "  # Tanh seems to work for high-dimensional idx\n",
        "  # idxuv = torch.tanh(idxuv)\n",
        "  ###\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "# def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, idx_part)\n",
        "#   kidxv = k(idxv, idx_part)\n",
        "#   d_idx_k = kidxu.shape[-1]\n",
        "#   assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "#   assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "#   sidx = (\n",
        "#       (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "#       + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "#   )\n",
        "#   sidx = sidx / norm\n",
        "#   sidx = sidx.repeat(batch_m, 1, 1)\n",
        "#   return sidx\n",
        "\n",
        "# def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "#   # iTki_kjTj: M x N x d_idx x d_idx\n",
        "#   iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "#   diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "#   ###\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   diag = diag / norm\n",
        "#   ###\n",
        "#   diag = diag.repeat(batch_m, 1, 1)\n",
        "#   return diag\n",
        "\n",
        "# def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # ski: (M * N) x d_idx\n",
        "#   # skj: (M * N) x d_idx\n",
        "#   # norm: M x N x 1\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "#   skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "#   # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "#   # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "#   idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "#   idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "#   kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "#   kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "#   # sikiT: M x d_idx x d_idx\n",
        "#   # sjkjT: N x d_idx x d_idx\n",
        "#   sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "#   sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "#   sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "#   sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "#   del kidxu\n",
        "#   del kidxv\n",
        "#   del idxu\n",
        "#   del idxv\n",
        "#   # sikiT: (M * N) x d_idx x d_idx\n",
        "#   # sjkjT: (M * N) x d_idx x d_idx\n",
        "#   sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "#   # skjjT = sjkjT.permute(0, 2, 1)\n",
        "#   # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "#   # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "#   xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "#   # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "#   # xor_idx = diag_sikiT_skjjT\n",
        "#   xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "#   xor_idx = xor_idx / norm\n",
        "#   return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    ###\n",
        "    # _nsbmd\n",
        "    # _rdot\n",
        "    # _knndot\n",
        "    # _fbmd\n",
        "    # _ibmd, _mbmd\n",
        "    # batch_mdot\n",
        "    ###\n",
        "    mdot = batch_mdot(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones((*self.idx.shape[:-1], 1)).to(self.idx.device)\n",
        "    onesb = torch.ones((*b.idx.shape[:-1], 1)).to(b.idx.device)\n",
        "    # ###\n",
        "    midx = (\n",
        "        _ibmd(aidx, onesb, aidx, bidx)\n",
        "        + _ibmd(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # xidx = xidx / np.linalg.norm(xidx, axis=-1)[:, None]\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    # self._ones_idx = _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # self.activation = nn.ELU()\n",
        "    self.activation = nn.ReLU()\n",
        "    # self.activation = nn.LeakyReLU()\n",
        "    self._probe = nn.Linear(self._feat_samples[-1], 10).to(device)\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _mag = 1000.0\n",
        "    # _W_idx = _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    _W_idx = nn.Parameter(\n",
        "      0.01 * _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    )\n",
        "    _W = torch.ones(shape).float().to(device)\n",
        "    # _std = 0.01\n",
        "    # _W = _std * torch.randn(shape, device=device)\n",
        "    # _W = nn.Parameter(\n",
        "    #     _std * torch.randn(shape, device=device)\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        # idx_slice = pool.idx[0]\n",
        "        idx_slice = pool.idx[0, :, :3]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      ###\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      maromba_only = True\n",
        "      if maromba_only or (step < n_layers - 1):\n",
        "        pool = (\n",
        "            MTensor.reshape(\n",
        "                pool, (n * feat_sets[step], -1)\n",
        "            )\n",
        "            @ mw\n",
        "        )\n",
        "      else:\n",
        "        pool = self._probe(pool.data.reshape(n, -1))\n",
        "        pool = MTensor(\n",
        "            pool,\n",
        "            torch.zeros((*pool.shape, self._idx_dim)).to(pool.device)\n",
        "        )\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 1000 # 500 # 3 # 10\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim, mag=1000.0)\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_m1YvjxBdj9"
      },
      "source": [
        "### Visualizações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "outputs": [],
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "xGn5VTZPw-1K",
        "outputId": "16c95b73-f10e-4473-b63e-0561659ac317"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784, 1,],\n",
        "        \"samples\": [9, 784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [1, num_classes,],\n",
        "        \"samples\": [1, 8,],\n",
        "        \"is conv\": [False, False,]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.MW.idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 10 # 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.MW.idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    ###\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    _loss = loss.item()\n",
        "    # loss += 1e-1 * torch.cat(model._penalties, dim=0).sum()\n",
        "    ###\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(_loss)\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 1\n",
        "    _batchidx = 0\n",
        "    pool = model.all_pools[_layer]\n",
        "    pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "    display.clear_output(wait=True)\n",
        "    plot_features(pool)\n",
        "    from time import sleep\n",
        "    sleep(3)\n",
        "    #\n",
        "    # pool = model.all_samples[_layer - 1]\n",
        "    # _shape = (\n",
        "    #     config[\"features\"][\"sets\"][_layer - 1],\n",
        "    #     config[\"features\"][\"samples\"][_layer - 1],\n",
        "    # )\n",
        "    # _set = (config[\"features\"][\"sets\"][_layer - 1]) // 2\n",
        "    # pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "    # display.clear_output(wait=True)\n",
        "    # plot_features(pool)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "outputs": [],
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "##\n",
        "# phi = idxu[0] @ idxv[0].T\n",
        "# import seaborn as sns\n",
        "# sns.heatmap(phi.cpu().detach().numpy()); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "ilOucSYLd2zy",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "1SknOTQ7O9BS",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "8_m1YvjxBdj9",
        "Y-K_7fUh2anJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMBXTTuc76V8EPiOaTUHfhj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}