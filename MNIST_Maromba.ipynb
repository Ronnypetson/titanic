{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTdTbjAGjsnP"
      },
      "source": [
        "## Experimentos do Produto Interno Maromba no MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQSziNdjoUm"
      },
      "source": [
        "### Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip3 install ipympl\n",
        "# !pip3 install mpl_interactions\n",
        "# %matplotlib widget\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import plotly.express as px\n",
        "# import mpl_interactions.ipyplot as iplt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# %matplotlib inline\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCfrrmCXap_"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6dxGxcHAx5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d397ff-8880-4923-8ec9-fbb73083fb9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12201255.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 207938.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3854510.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 22077992.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12219020.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 207244.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3816217.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 1977676.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_root_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_root_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr = ToTensor()\n",
        "# cifar10_norm = Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "cifar10_norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "channels = 1\n",
        "img_dim = 28\n",
        "\n",
        "def _transform(x):\n",
        "  # x = x.resize((channels, img_dim, img_dim))\n",
        "  # return cifar10_norm(tr(x)).reshape(-1)\n",
        "  # return (tr(x) / 255.0).reshape(-1)\n",
        "  # return transform(x).reshape(-1)\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "  # return (tr(x).mean(dim=0)).reshape(-1)\n",
        "\n",
        "bsize = 32 ###\n",
        "\n",
        "# SOURCE_DATASET = MNIST\n",
        "SOURCE_DATASET = FashionMNIST\n",
        "# SOURCE_DATASET = CIFAR10\n",
        "\n",
        "MNIST_train_data = SOURCE_DATASET(\n",
        "    \"MNIST_root/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = SOURCE_DATASET(\n",
        "    \"MNIST_root_test/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # config = {\n",
        "# #     \"features\": {\n",
        "# #         \"pre-set\": channels,\n",
        "# #         \"sets\":    [1024,    1024,    1,],\n",
        "# #         \"samples\": [25,      1,       1024,],\n",
        "# #     },\n",
        "# #     \"params\": {\n",
        "# #         \"sets\":    [4,       1,       num_classes,],\n",
        "# #         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "# #         \"is conv\": [True,    True,    False,]\n",
        "# #     },\n",
        "# # }\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 4, 5, padding=\"same\", bias=False)\n",
        "#         # self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # self.conv2 = nn.Conv2d(6, 8, 5, padding=\"same\", bias=False)\n",
        "#         self.conv2 = nn.Conv2d(4, 1, 1, padding=\"same\", bias=False)\n",
        "#         self.fc1 = nn.Linear(1024, 10, bias=False)\n",
        "#         # self.fc2 = nn.Linear(100, 10, bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.elu(self.conv1(x))\n",
        "#         x = F.elu(self.conv2(x))\n",
        "#         # x = F.elu(self.conv3(x))\n",
        "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "# net = Net()"
      ],
      "metadata": {
        "id": "NH7FAomMIRJC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "n7DuUfPdITHx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainloader = train_data_loader\n",
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(trainloader, 0):\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 60 == 59:    # print every 60 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
        "#             running_loss = 0.0\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "3spYLqaUIa3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, lbl = next(iter(test_data_loader))\n",
        "# img = img.reshape(-1, 3, 32, 32)\n",
        "# img = img.permute(0, 2, 3, 1).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "aE6KCRaT_zjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img[0].min(), img[0].max(), img[0].mean()\n",
        "\n",
        "# cifar10_classes = [\n",
        "#     \"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "# ]\n",
        "# _idx = 3\n",
        "# print(cifar10_classes[lbl[_idx].item()])\n",
        "# plt.imshow(img[_idx])"
      ],
      "metadata": {
        "id": "xHhauWzb_4b1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "outputs": [],
      "source": [
        "# def _cat2d(rows, cols, d=32):\n",
        "#   \"\"\"\n",
        "#   Index in the log-softmax scale.\n",
        "#   After sotmax (in the partition dimension)\n",
        "#   -inf --> 0\n",
        "#   1.0  --> 1\n",
        "#   \"\"\"\n",
        "#   assert rows + cols <= d\n",
        "#   inf = 1.0\n",
        "#   idx = np.zeros((rows, cols, d)) - inf\n",
        "#   for row in range(rows):\n",
        "#     for col in range(cols):\n",
        "#       idx[row, col, row] = 1.0\n",
        "#       idx[row, col, rows + col] = 1.0\n",
        "#   idx = torch.from_numpy(idx)\n",
        "#   idx = idx.reshape(rows * cols, d)\n",
        "#   return idx\n",
        "\n",
        "def cartesian_idx(rows, cols, chs=1, d=2, offset=0):\n",
        "  # idx = np.zeros((rows, cols, chs, d))\n",
        "  idx = np.random.uniform(low=-0.01, high=0.01, size=(rows, cols, chs, d))\n",
        "  for row in range(rows):\n",
        "    for col in range(cols):\n",
        "      for ch in range(chs):\n",
        "        idx[row, col, ch, 0] = 2.0 * ((row + offset) / rows) - 1.0\n",
        "        idx[row, col, ch, 1] = 2.0 * ((col + offset) / cols) - 1.0\n",
        "        idx[row, col, ch, 2] = 2.0 * ((ch  + offset) /  chs) - 1.0\n",
        "  idx = torch.from_numpy(idx)\n",
        "  idx = idx.reshape(rows * cols * chs, d)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOucSYLd2zy"
      },
      "source": [
        "### Kernels, similaridades e funções de índice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKu4c8hisNY"
      },
      "source": [
        "#### Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XG4U__-kiw2J"
      },
      "outputs": [],
      "source": [
        "def _soft_kernel(idxu, part_dim):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  assert d_idx % part_dim == 0\n",
        "  range = 20.0\n",
        "  norm_idxu = range * idxu.reshape(m, d_u, -1, part_dim) - (range / 2.0)\n",
        "  norm_idxu = torch.softmax(norm_idxu, dim=-1)\n",
        "  dim_norm = (d_idx // part_dim) ** 0.5\n",
        "  norm_idxu = norm_idxu.reshape(m, d_u, d_idx) / dim_norm\n",
        "  return norm_idxu\n",
        "\n",
        "def _cosine_kernel(idxu, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  \"\"\"\n",
        "  # TODO: compute min_idx, max_idx and normalize\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-4\n",
        "  idxu = (idxu - min_idxu) / (max_idxu - min_idxu + eps)\n",
        "  norm_idxu = idxu / (torch.norm(idxu, dim=-1).unsqueeze(-1) + eps)\n",
        "  # Reverse kernel trick for polynomial x^2\n",
        "  idxu2 = norm_idxu.reshape(-1, d_idx, 1)\n",
        "  idxu2 = torch.bmm(idxu2, idxu2.permute(0, 2, 1)).reshape(m, d_u, -1)\n",
        "  # return norm_idxu\n",
        "  return idxu2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr5gOnn5RRu"
      },
      "source": [
        "#### Similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S9RbSzv45T8B"
      },
      "outputs": [],
      "source": [
        "def squared_cosine(idxu, idxv):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = torch.bmm(\n",
        "      idxu.reshape(-1, 1, d_idx),\n",
        "      idxv.reshape(-1, d_idx, 1),\n",
        "  )\n",
        "  # sim = (torch.exp(sim) - 1.0) / (1.718)\n",
        "  sim = sim ** 4.0\n",
        "  return sim\n",
        "\n",
        "def relu_cosine(idxu, idxv, bias=0.9):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  idxv: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  assert idxu.shape == idxv.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  sim = nn.functional.relu(\n",
        "      torch.bmm(\n",
        "          idxu.reshape(-1, 1, d_idx),\n",
        "          idxv.reshape(-1, d_idx, 1),\n",
        "      )\n",
        "      - bias\n",
        "  )\n",
        "  sim = sim.reshape(idxu.shape[:-1])\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzFCy32AGsX"
      },
      "source": [
        "#### Funções-valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvUcMTxDAJlx"
      },
      "outputs": [],
      "source": [
        "def vecsum(u, v):\n",
        "  return u + v\n",
        "\n",
        "def vecmean(u, v):\n",
        "  return (u + v) / 2.0\n",
        "\n",
        "def vecprod(u, v):\n",
        "  \"\"\"\n",
        "  Element-wise product. NOT dot product.\n",
        "  \"\"\"\n",
        "  return u * v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvUP7nZjDd7"
      },
      "source": [
        "#### Dots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytm2bU_JvrK"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nzos5YCYJozy"
      },
      "outputs": [],
      "source": [
        "class Pairwise:\n",
        "  def __init__(self, f):\n",
        "    \"\"\"\n",
        "    f: (pre_shape x d_val, pre_shape x d_val) -> pre_shape x d_val_out\n",
        "    \"\"\"\n",
        "    self._f = f\n",
        "\n",
        "  def __call__(self, u, v):\n",
        "    \"\"\"\n",
        "    u: pre_shape_u x d_u x d_val\n",
        "    v: pre_shape_v x d_v x d_val\n",
        "    ans: pre_shape_u x pre_shape_v x d_u x d_v x d_val_out\n",
        "    \"\"\"\n",
        "    ps_u, ps_v = u.shape[:-2], v.shape[:-2]\n",
        "    pps_u, pps_v = np.prod(ps_u), np.prod(ps_v)\n",
        "    d_u, d_val = u.shape[-2:]\n",
        "    d_v, d_valv = v.shape[-2:]\n",
        "    assert d_val == d_valv\n",
        "    # u, v: pps_u x pps_v x d_u x d_v x d_val\n",
        "    u = u.reshape(pps_u,     1, d_u,   1, d_val)\n",
        "    v = v.reshape(    1, pps_v,   1, d_v, d_val)\n",
        "    u = u.repeat(     1, pps_v,   1, d_v,     1)\n",
        "    v = v.repeat( pps_u,     1, d_u,   1,     1)\n",
        "    # fuv: ps_u x ps_v x d_u x d_v x d_val_out\n",
        "    fuv = self._f(u, v)\n",
        "    fuv = fuv.reshape(*ps_u, *ps_v, d_u, d_v, -1)\n",
        "    return fuv\n",
        "\n",
        "def __minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = min_idxu + ((idxu - min_idxu) / (max_idxu - min_idxu + eps))\n",
        "  return idxu\n",
        "\n",
        "def minmax_normalize(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  min_idxu = torch.min(idxu, dim=1)[0].unsqueeze(1)\n",
        "  max_idxu = torch.max(idxu, dim=1)[0].unsqueeze(1)\n",
        "  eps = 1e-6\n",
        "  idxu = 2.0 * ((idxu - min_idxu) / (max_idxu - min_idxu + eps)) - 1.0\n",
        "  return idxu\n",
        "\n",
        "def norm_normalize(u):\n",
        "  \"\"\"\n",
        "  u: pre_shape x d_val\n",
        "  \"\"\"\n",
        "  eps = 1e-6\n",
        "  u = u / (u.norm(dim=-1).unsqueeze(-1) + eps)\n",
        "  return u\n",
        "\n",
        "def normalized(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = minmax_normalize(idxu)\n",
        "  idxu = norm_normalize(idxu)\n",
        "  return idxu\n",
        "\n",
        "def poly1norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  idxu = (0.5 ** 0.5) * torch.cat([idxu, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "def poly2norm(idxu):\n",
        "  \"\"\"\n",
        "  idxu: pre_shape x d_idx\n",
        "  \"\"\"\n",
        "  idxu = normalized(idxu)\n",
        "  ones = torch.ones((*idxu.shape[:-1], 1)).to(idxu.device)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  _idxu = idxu.reshape((-1, d_idx, 1))\n",
        "  middle = (\n",
        "      torch.bmm(_idxu, _idxu.permute(0, 2, 1))\n",
        "      .reshape((*idxu.shape[:-1], d_idx ** 2))\n",
        "  )\n",
        "  idxu = 0.5 * torch.cat([(2.0 ** 0.5) * idxu, middle, ones], dim=-1)\n",
        "  return idxu\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def get_eye(m, d_u, d_v, n, device=\"cpu\"):\n",
        "  eye = (\n",
        "      torch.eye(max(d_u, d_v))\n",
        "      [:d_u, :d_v]\n",
        "      .unsqueeze(0)\n",
        "      .unsqueeze(-1)\n",
        "      .repeat(m, 1, 1, n)\n",
        "      .to(device)\n",
        "  )\n",
        "  return eye\n",
        "\n",
        "def log_sinkhorn(log_alpha, n_iter):\n",
        "    \"\"\" https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/sampling/permutations.html\n",
        "    [1] Sinkhorn, Richard and Knopp, Paul.\n",
        "    Concerning nonnegative matrices and doubly stochastic\n",
        "    matrices. Pacific Journal of Mathematics, 1967\n",
        "    Args:\n",
        "      log_alpha: 2D tensor (a matrix of shape [N, N])\n",
        "        or 3D tensor (a batch of matrices of shape = [batch_size, N, N])\n",
        "      n_iters: number of sinkhorn iterations\n",
        "    \"\"\"\n",
        "    for _ in range(n_iter):\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "        # log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
        "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
        "    return log_alpha.exp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TdCxX0Jzn0"
      },
      "source": [
        "##### Dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LBhkMTmSeAP0"
      },
      "outputs": [],
      "source": [
        "def _rdot(u, v, *args):\n",
        "  \"\"\"\n",
        "  \"Regular Dot product\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  \"\"\"\n",
        "  m, d_u, d_val = u.shape\n",
        "  n, d_v, _d_val = v.shape\n",
        "  if d_u != d_v:\n",
        "    return _nsbmd(u, v, *args)\n",
        "  assert _d_val == d_val\n",
        "  dot = (\n",
        "      u.permute(0, 2, 1).reshape(-1, d_u)\n",
        "      @ v.permute(1, 0, 2).reshape(d_v, -1)\n",
        "  ).reshape(m, d_val, n, d_val).permute(0, 2, 1, 3)\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _knndot(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"k-NN Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  num_neigh = 1\n",
        "  dots = []\n",
        "  q_idxu = idxu.cpu().detach().numpy().reshape(-1, d_idx)\n",
        "  for _pos in range(n):\n",
        "    neigh = NearestNeighbors(n_neighbors=num_neigh)\n",
        "    neigh.fit(idxv[_pos].cpu().detach().numpy().reshape(-1, d_idx))\n",
        "    n_idxu = neigh.kneighbors(\n",
        "        q_idxu, return_distance=False\n",
        "    ).reshape(-1)\n",
        "    n_idxu = torch.from_numpy(n_idxu).long()\n",
        "    _v = v[_pos].reshape(-1, d_val)[n_idxu].reshape(m, d_u, d_val)\n",
        "    # _dot: M x d_val x d_val\n",
        "    _dot = torch.bmm(_v.permute(0, 2, 1), _v)\n",
        "    # _dot: M x 1 x d_val\n",
        "    _dot = torch.diagonal(_dot, dim1=1, dim2=2).unsqueeze(1)\n",
        "    dots.append(_dot)\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.cat(dots, dim=1)\n",
        "  return dot\n",
        "\n",
        "def _fbmd(u, v, idxu, idxv) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Fast Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = poly2norm(idxu)\n",
        "  idxv = poly2norm(idxv)\n",
        "  d_idx = idxu.shape[-1]\n",
        "  # uidxu: M x d_val x d_idx\n",
        "  # idxvv: N x d_idx x d_val\n",
        "  uidxu = torch.bmm(u.permute(0, 2, 1), idxu)\n",
        "  idxvv = torch.bmm(idxv.permute(0, 2, 1), v)\n",
        "  # dot: M x N x d_val\n",
        "  dot = (\n",
        "    (\n",
        "        uidxu.reshape(m * d_val, d_idx)\n",
        "        @ (\n",
        "            idxvv\n",
        "            .permute(0, 2, 1)\n",
        "            .reshape(n * d_val, d_idx)\n",
        "            .T\n",
        "          )\n",
        "    ).reshape(m, d_val, n, d_val)\n",
        "    .permute(0, 2, 1, 3)\n",
        "  )\n",
        "  dot = torch.diagonal(dot, dim1=2, dim2=3)\n",
        "  return dot\n",
        "\n",
        "def _nsbmd(u, v, idxu, idxv, bias=0.5) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  \"Non-linear Similarity Batch Maromba Dot\"\n",
        "  u: M x d_u x d_val\n",
        "  v: N x d_v x d_val\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx  = idxu.shape\n",
        "  n, d_v, d_idxv = idxv.shape\n",
        "  d_val = u.shape[-1]\n",
        "  assert d_idx == d_idxv\n",
        "  assert d_val == v.shape[-1]\n",
        "  assert (m, d_u) == u.shape[:2]\n",
        "  assert (n, d_v) == v.shape[:2]\n",
        "  idxu = normalized(idxu)\n",
        "  idxv = normalized(idxv)\n",
        "  # idxuv: M x d_u x d_v x N\n",
        "  ###\n",
        "  # idxuv = idxu.reshape(m * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # mag = 80.0\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv - (mag / 2.0), dim=2)\n",
        "  # # idxuv = nn.functional.softmax(mag * idxuv, dim=2)\n",
        "  # idxuv = (\n",
        "  #     log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), 6)\n",
        "  #     .permute(0, 2, 3, 1)\n",
        "  # )\n",
        "  ###\n",
        "  from random import randint\n",
        "  bsidx = randint(0, m - 1)\n",
        "  m_ = 1 # m,\n",
        "  idxuv = (\n",
        "      idxu[bsidx].reshape(m_ * d_u, d_idx)\n",
        "      @ idxv.reshape(n * d_v, d_idx).T\n",
        "  )\n",
        "  idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  mag = 80.0\n",
        "  # siter = 2 * int(np.log((d_u + d_v) // 2)) + 6\n",
        "  siter = 6\n",
        "  idxuv = (\n",
        "      log_sinkhorn(mag * idxuv.permute(0, 3, 1, 2), siter)\n",
        "      .permute(0, 2, 3, 1)\n",
        "  )\n",
        "  idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # from random import randint\n",
        "  # bsidx = randint(0, m - 1)\n",
        "  # m_ = 1\n",
        "  # mag = 80.0\n",
        "  # # idxu = log_sinkhorn(mag * idxu[bsidx].unsqueeze(0), 6)\n",
        "  # # idxv = log_sinkhorn(mag * idxv, 6)\n",
        "  # idxu = nn.functional.softmax(mag * idxu[bsidx].unsqueeze(0), dim=1)\n",
        "  # idxv = nn.functional.softmax(mag * idxv, dim=1)\n",
        "  # idxuv = idxu.reshape(m_ * d_u, d_idx) @ idxv.reshape(n * d_v, d_idx).T\n",
        "  # idxuv = idxuv.reshape(m_, d_u, n, d_v).permute(0, 1, 3, 2)\n",
        "  # idxuv = idxuv.repeat(m, 1, 1, 1)\n",
        "  ###\n",
        "  # uidxuv: (M x d_val x d_v x N) -> (N x d_v x d_val x M)\n",
        "  uidxuv = (\n",
        "      torch.bmm(\n",
        "        u.permute(0, 2, 1),\n",
        "        idxuv.reshape(m, d_u, d_v * n)\n",
        "      )\n",
        "      .reshape(m, d_val, d_v, n)\n",
        "      .permute(3, 2, 1, 0)\n",
        "  )\n",
        "  # uidxuvv: N x M x d_val x d_val\n",
        "  uidxuvv = (\n",
        "      torch.bmm(\n",
        "          uidxuv.permute(0, 3, 2, 1).reshape(n * m, d_val, d_v),\n",
        "          v.unsqueeze(1).repeat(1, m, 1, 1).reshape(n * m, d_v, d_val)\n",
        "      )\n",
        "      .reshape(n, m, d_val, d_val)\n",
        "  )\n",
        "  # dot: M x N x d_val\n",
        "  dot = torch.diagonal(uidxuvv, dim1=2, dim2=3)\n",
        "  dot = dot.permute(1, 0, 2)\n",
        "  return dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9hF3Uoi3tF"
      },
      "source": [
        "#### Índices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UrPFWDtli55C"
      },
      "outputs": [],
      "source": [
        "# def _fast_kernel_idx_sum(idxu, idxv, k, idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, idx_part)\n",
        "#   kidxv = k(idxv, idx_part)\n",
        "#   d_idx_k = kidxu.shape[-1]\n",
        "#   assert kidxu.shape[:-1] == idxu.shape[:-1]\n",
        "#   assert kidxv.shape[:-1] == idxv.shape[:-1]\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx_k)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx_k)\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   # sidx: (M * d_idx) x N + (N * d_idx) x M\n",
        "#   sidx = (\n",
        "#       (iTki @ skj.T).reshape(m, d_idx, n).permute(0, 2, 1)\n",
        "#       + (jTkj @ ski.T).reshape(n, d_idx, m).permute(2, 0, 1)\n",
        "#   )\n",
        "#   sidx = sidx / norm\n",
        "#   sidx = sidx.repeat(batch_m, 1, 1)\n",
        "#   return sidx\n",
        "\n",
        "# def _fast_kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   ### idxu MUST be the input mini-batch\n",
        "#   batch_m = 1 # idxu.shape[0]\n",
        "#   # idxu = idxu.mean(dim=0).unsqueeze(0)\n",
        "#   ###\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # kiTi: (M * d_idx) x d_idx(k)\n",
        "#   # kjTj: (N * d_idx) x d_idx(k)\n",
        "#   iTki = torch.bmm(idxu.permute(0, 2, 1), kidxu).reshape(m * d_idx, d_idx)\n",
        "#   jTkj = torch.bmm(idxv.permute(0, 2, 1), kidxv).reshape(n * d_idx, d_idx)\n",
        "#   # iTki_kjTj: M x N x d_idx x d_idx\n",
        "#   iTki_kjTj = (iTki @ jTkj.T).reshape(m, d_idx, n, d_idx).permute(0, 2, 1, 3)\n",
        "#   diag = torch.diagonal(iTki_kjTj, dim1=2, dim2=3)\n",
        "#   ###\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   diag = diag / norm\n",
        "#   ###\n",
        "#   diag = diag.repeat(batch_m, 1, 1)\n",
        "#   return diag\n",
        "\n",
        "# def _kernel_idx(idxu, idxv, k, _idx_part):\n",
        "#   \"\"\"\n",
        "#   k: callable: A x B x C -> A x B x C\n",
        "#   idxu: M x d_u x d_idx\n",
        "#   idxv: N x d_v x d_idx\n",
        "#   \"\"\"\n",
        "#   m, d_u, d_idx = idxu.shape\n",
        "#   n, d_v, _ = idxv.shape\n",
        "#   assert d_idx == idxv.shape[-1]\n",
        "#   # kidxu: M x d_u x d_idx\n",
        "#   # kidxv: N x d_v x d_idx\n",
        "#   kidxu = k(idxu, _idx_part)\n",
        "#   kidxv = k(idxv, _idx_part)\n",
        "#   assert kidxu.shape == idxu.shape\n",
        "#   assert kidxv.shape == idxv.shape\n",
        "#   # ski: (M * N) x d_idx\n",
        "#   # skj: (M * N) x d_idx\n",
        "#   # norm: M x N x 1\n",
        "#   ski = kidxu.sum(dim=1)\n",
        "#   skj = kidxv.sum(dim=1)\n",
        "#   norm = (ski @ skj.T).unsqueeze(-1)\n",
        "#   ski = ski.unsqueeze(1).repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "#   skj = skj.unsqueeze(1).repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "#   # idxu, kidxu: (M * d_u) x d_idx x 1\n",
        "#   # idxv, kidxv: (N * d_v) x d_idx x 1\n",
        "#   idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "#   idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "#   kidxu = kidxu.reshape(m * d_u, d_idx, 1)\n",
        "#   kidxv = kidxv.reshape(n * d_v, d_idx, 1)\n",
        "#   # sikiT: M x d_idx x d_idx\n",
        "#   # sjkjT: N x d_idx x d_idx\n",
        "#   sikiT = torch.bmm(idxu, kidxu.permute(0, 2, 1))\n",
        "#   sikiT = sikiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "#   sjkjT = torch.bmm(idxv, kidxv.permute(0, 2, 1))\n",
        "#   sjkjT = sjkjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1)\n",
        "#   del kidxu\n",
        "#   del kidxv\n",
        "#   del idxu\n",
        "#   del idxv\n",
        "#   # sikiT: (M * N) x d_idx x d_idx\n",
        "#   # sjkjT: (M * N) x d_idx x d_idx\n",
        "#   sikiT = sikiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   sjkjT = sjkjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "#   # diag_sikiT_skjjT: (M * N) x d_idx\n",
        "#   # skjjT = sjkjT.permute(0, 2, 1)\n",
        "#   # diag_sikiT_skjjT = torch.diagonal(torch.bmm(sikiT, skjjT), dim1=1, dim2=2)\n",
        "#   # diag_sikiT_skjjT = diag_sikiT_skjjT.unsqueeze(-1)\n",
        "#   xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski)\n",
        "#   # xor_idx = torch.bmm(sikiT, skj) + torch.bmm(sjkjT, ski) - diag_sikiT_skjjT\n",
        "#   # xor_idx = diag_sikiT_skjjT\n",
        "#   xor_idx = xor_idx.reshape(m, n, d_idx)\n",
        "#   xor_idx = xor_idx / norm\n",
        "#   return xor_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfYY3SQXNJF"
      },
      "source": [
        "### Classe Tensor Maromba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "outputs": [],
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.idx_dim = indices.shape[-1]\n",
        "    self.indexer = indexer\n",
        "    self._idx_part = img_dim\n",
        "    self._eps = 1e-6\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    if dim == -1:\n",
        "      dim = len(mt.data.shape) - 1\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def unsqueeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.unsqueeze(dim)\n",
        "    mt.idx = mt.idx.unsqueeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def squeeze(mt, dim=0):\n",
        "    assert dim != -1\n",
        "    assert dim < len(mt.idx.shape) - 1\n",
        "    mt.data = mt.data.squeeze(dim)\n",
        "    mt.idx = mt.idx.squeeze(dim)\n",
        "    return mt\n",
        "\n",
        "  @staticmethod\n",
        "  def clone(mt):\n",
        "    return MTensor(mt.data, mt.idx, mt.indexer)\n",
        "\n",
        "  @staticmethod\n",
        "  def reshape(mt, shape):\n",
        "    idx_shape = shape + (mt.idx_dim,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.reshape(shape),\n",
        "        mt.idx.reshape(idx_shape),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  @staticmethod\n",
        "  def permute(mt, perm):\n",
        "    idx_perm = perm + (-1,)\n",
        "    nmt = MTensor(\n",
        "        mt.data.permute(*perm),\n",
        "        mt.idx.permute(*idx_perm),\n",
        "        mt.indexer\n",
        "    )\n",
        "    return nmt\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    \"\"\"\n",
        "    Useful for computing m-product between a batch of inputs (N x ...) and a\n",
        "    parameter matrix (m x n).\n",
        "\n",
        "    self.data: pre_shape(self) x in_dim(self)\n",
        "    self.data.idx: pre_shape(self) x in_dim(self) x d_idx\n",
        "    b.data: pre_shape(b) x in_dim(b)\n",
        "    b.idx: pre_shape(b) x in_dim(b) x d_idx\n",
        "\n",
        "    Returns \"mdot\"\n",
        "    mdot.data: pre_shape(self) x pre_shape(b)\n",
        "    mdot.idx: pre_shape(self) x pre_shape(b) x d_idx\n",
        "    \"\"\"\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    ###\n",
        "    # mdot = _nsbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    # mdot = _fbmd(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ###\n",
        "    # mdot = _rdot(\n",
        "    #     self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "    #     b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "    #     aidx,\n",
        "    #     bidx,\n",
        "    # )\n",
        "    ### _knndot\n",
        "    mdot = _knndot(\n",
        "        self.data.reshape(-1, self.data.shape[-1], 1),\n",
        "        b.data.reshape(-1, b.data.shape[-1], 1),\n",
        "        aidx,\n",
        "        bidx,\n",
        "    )\n",
        "    ###\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # New indices\n",
        "    # ###\n",
        "    onesa = torch.ones(self.idx.shape).to(self.idx.device)\n",
        "    onesb = torch.ones(b.idx.shape).to(b.idx.device)\n",
        "    # ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, onesb, aidx, bidx)\n",
        "    #     + _nsbmd(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _fbmd(aidx, onesb, aidx, bidx)\n",
        "    #     + _fbmd(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _rdot(aidx, onesb, aidx, bidx)\n",
        "    #     + _rdot(onesa, bidx, aidx, bidx)\n",
        "    # ) / 2.0\n",
        "    ###\n",
        "    # midx = (\n",
        "    #     _nsbmd(aidx, 1.0 - bidx, aidx, bidx)\n",
        "    #     + _nsbmd(1.0 - aidx, bidx, aidx, bidx)\n",
        "    # )\n",
        "    # midx = _nsbmd(aidx, bidx, aidx, bidx)\n",
        "    ###\n",
        "    midx = (\n",
        "        _knndot(aidx, onesb, aidx, bidx)\n",
        "        + _knndot(onesa, bidx, aidx, bidx)\n",
        "    ) / 2.0\n",
        "    ###\n",
        "    new_shape = apre + bpre + (d_idx,)\n",
        "    midx = midx.reshape(new_shape)\n",
        "    #\n",
        "    mdot = MTensor(mdot, midx, self.indexer)\n",
        "    return mdot\n",
        "\n",
        "  def __mul__(self, b):\n",
        "    \"\"\"\n",
        "    self: N x out_a x in_a (x d_idx)\n",
        "    b:    N x out_b x in_b (x d_idx)\n",
        "    \"\"\"\n",
        "    n, out_a, in_a = self.data.shape\n",
        "    assert b.data.shape[0] == n\n",
        "    _, out_b, in_b = b.data.shape\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert b.idx.shape[-1] == d_idx\n",
        "    ### Solução provisória. Calcular o índice com paralelismo ainda não é possível.\n",
        "    mdots = [MTensor.unsqueeze(self[idx] @ b[idx], dim=0) for idx in range(n)]\n",
        "    mdots = MTensor.cat(mdots, dim=0)\n",
        "    return mdots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGg59zEqYGe6"
      },
      "source": [
        "### Classe do Módulo Treinável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SknOTQ7O9BS"
      },
      "source": [
        "#### Sampling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WicPIpyIO3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def idxhood(xidx, ws, stride=None, num_sets=None, sample=False):\n",
        "  xidx = xidx.reshape(-1, xidx.shape[-1]).cpu().detach().numpy()\n",
        "  # xidx = xidx / np.linalg.norm(xidx, axis=-1)[:, None]\n",
        "  # set desired number of neighbors\n",
        "  nneigh = int(np.prod(ws))\n",
        "  neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "  neigh.fit(xidx)\n",
        "  # select indices of k nearest neighbors of the vectors in the input list\n",
        "  if sample:\n",
        "    if num_sets is None:\n",
        "      num_sets = (len(xidx) + (len(xidx) % stride)) // stride\n",
        "    subidx = np.random.choice(len(xidx), size=num_sets, replace=False)\n",
        "    all_hoods = neigh.kneighbors(\n",
        "        xidx[subidx], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  else:\n",
        "    _neigh = NearestNeighbors(n_neighbors=nneigh)\n",
        "    _ids = np.array([[pos // img_dim, pos % img_dim] for pos in range(len(xidx))])\n",
        "    # _ids = np.array([[pos] for pos in range(len(xidx))])\n",
        "    _neigh.fit(_ids)\n",
        "    if stride is None:\n",
        "      stride = len(xidx) // num_sets\n",
        "    all_hoods = _neigh.kneighbors(\n",
        "        _ids[::stride], return_distance=False\n",
        "    ).reshape(-1)\n",
        "  all_hoods = torch.from_numpy(all_hoods).long()\n",
        "  return all_hoods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH27yFEuqtg"
      },
      "source": [
        "#### MModule III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VvlcR_tmuyy2"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.arrays.categorical import Shape\n",
        "\n",
        "class MModule3(nn.Module):\n",
        "  def __init__(\n",
        "      self, n_params=600, idx_dim=3, samples=32, sets=64, device=\"cpu\",\n",
        "      probe_dim=None,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self._samples = samples\n",
        "    self.samples = [int(np.prod(samp)) for samp in samples]\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (1, n_params), idx_dim, device\n",
        "    )\n",
        "    if probe_dim:\n",
        "      n_classes = 10\n",
        "      self._pw, self._pw_idx, self.probe = self._make_pmt(\n",
        "          (n_classes, probe_dim), idx_dim, device\n",
        "      )\n",
        "    self.activation = nn.ELU()\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    _W = nn.Parameter(\n",
        "        2.0 * torch.rand(shape, device=device) - 1.0\n",
        "    )\n",
        "    _W_idx = nn.Parameter(\n",
        "        2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    )\n",
        "    # _W_idx = (\n",
        "    #     2.0 * torch.rand((*shape, idxdim), device=device) - 1.0\n",
        "    # )\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n_sets, n_samples = len(self.sets), len(self.samples)\n",
        "    assert n_sets == n_samples\n",
        "    assert n_sets > 0\n",
        "    ### Under experimentation\n",
        "    n = x.data.shape[0]\n",
        "    filter_whs = [(samp[1], samp[2], samp[0]) for samp in self._samples[:-1]]\n",
        "    strides = self.sets[:-1]\n",
        "    stride = strides[0]\n",
        "    filter_volume = np.prod(filter_whs[0])\n",
        "    self.all_pools = [x[:4]]\n",
        "    idxx = idxhood(x.idx[0], filter_whs[0], strides[0], sample=True) ### FIX\n",
        "    # pool: N x (num_windows * window_volume)\n",
        "    pool = x[:, idxx]\n",
        "    ###\n",
        "    wl, wr = 0, self.sets[0] * self.samples[0]\n",
        "    for step in range(n_sets):\n",
        "      activate = (step < n_sets - 1)\n",
        "      conv = activate\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[0, wl: wr],\n",
        "          (self.sets[step], self.samples[step])\n",
        "      )\n",
        "      if conv:\n",
        "        # pool: (N * num_windows) x  sets\n",
        "        pool = MTensor.reshape(pool, (-1, filter_volume)) @ mw\n",
        "        pool = MTensor.reshape(pool, (n, -1, self.sets[step]))\n",
        "      else:\n",
        "        # pool.data = self.probe(pool.data)\n",
        "        # pool: N x n_classes\n",
        "        pool = pool @ self.probe\n",
        "      nxt_conv = (step + 1 < n_sets - 1)\n",
        "      if conv:\n",
        "        # pool: N x num_windows x numw_windows\n",
        "        self.all_pools.append(pool[:4])\n",
        "        n, img_area, channels = pool.data.shape\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        nxt_conv_step = (step + 1) % len(strides)\n",
        "        stride = strides[nxt_conv_step]\n",
        "        filter_volume = np.prod(filter_whs[nxt_conv_step])\n",
        "        if nxt_conv:\n",
        "          idxx = idxhood(\n",
        "              pool.idx[0],\n",
        "              filter_whs[nxt_conv_step],\n",
        "              strides[nxt_conv_step],\n",
        "              sample=True,\n",
        "          ) ### FIX\n",
        "          pool = pool[:, idxx]\n",
        "      nxt_step = (step + 1) % n_sets\n",
        "      next_wr = wr + self.sets[nxt_step] * self.samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCh8kNiFl15G"
      },
      "source": [
        "#### MModule IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PAqc0d7Kl6Ud"
      },
      "outputs": [],
      "source": [
        "def _count_params(config):\n",
        "  tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "  n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "  return n_params\n",
        "\n",
        "class MModule4(nn.Module):\n",
        "  def __init__(self, config, idx_dim=3, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    assert len(config[\"features\"][\"sets\"]) > 0\n",
        "    assert len(config[\"params\"][\"sets\"]) > 0\n",
        "    assert len(config[\"features\"][\"sets\"]) == len(config[\"params\"][\"sets\"])\n",
        "    for key in [\"sets\", \"samples\"]:\n",
        "      assert len(config[\"features\"][key]) == len(config[\"features\"][\"sets\"])\n",
        "      assert len(config[\"params\"][key]) == len(config[\"params\"][\"sets\"])\n",
        "    self._idx_dim = idx_dim\n",
        "    self.device = device\n",
        "    self._config = config\n",
        "    self._config[\"params\"][\"samples\"] = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "    self._ch0 = config[\"features\"][\"pre-set\"]\n",
        "    self._is_conv = config[\"params\"][\"is conv\"]\n",
        "    self._feat_samples = config[\"features\"][\"samples\"]\n",
        "    self._n_params = _count_params(config)\n",
        "    self.W, self.W_idx, self.MW = self._make_pmt(\n",
        "        (self._n_params,), idx_dim, device\n",
        "    )\n",
        "    # _std = 0.1\n",
        "    # self._ones_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # )\n",
        "    # self._ones_idx = _std * torch.randn((1, 1, idx_dim), device=device)\n",
        "    # self.activation = nn.ELU()\n",
        "    # self.activation = nn.ReLU()\n",
        "    self.activation = nn.LeakyReLU()\n",
        "    self._probe = nn.Linear(self._feat_samples[-1], 10).to(device)\n",
        "\n",
        "  def _make_pmt(self, shape, idxdim, device):\n",
        "    # _mag = 1.0\n",
        "    # _W = nn.Parameter(\n",
        "    #     _mag * torch.rand(shape, device=device) - (_mag / 2.0)\n",
        "    # )\n",
        "    # _mag = 10.0\n",
        "    # _W_idx = _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    # _mag = 0.001\n",
        "    # _template = _mag * torch.rand((1, idxdim), device=device) - (_mag / 2.0)\n",
        "    # _num_idx = np.prod(shape)\n",
        "    # _pos = torch.tensor([[pos + 1.0] for pos in range(_num_idx)]).to(device)\n",
        "    # _W_idx = nn.Parameter(_pos @ _template)\n",
        "    _mag = 0.1\n",
        "    _W_idx = nn.Parameter(\n",
        "        _mag * torch.rand((*shape, idxdim), device=device) - (_mag / 2.0)\n",
        "    )\n",
        "    _std = 0.01\n",
        "    _W = nn.Parameter(\n",
        "        _std * torch.randn(shape, device=device)\n",
        "    )\n",
        "    # _W_idx = nn.Parameter(\n",
        "    #     _std * torch.randn((*shape, idxdim), device=device)\n",
        "    # )\n",
        "    # _W_idx = _std * torch.randn((*shape, idxdim), device=device)\n",
        "    _mt = MTensor(_W, _W_idx)\n",
        "    return _W, _W_idx, _mt\n",
        "\n",
        "  def _put_one(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    device = x.data.device\n",
        "    assert device == x.idx.device\n",
        "    ones_idx = self._ones_idx.repeat(n, 1, 1)\n",
        "    dummy_ones = MTensor(\n",
        "        values=torch.ones(n, 1).to(device),\n",
        "        indices=ones_idx,\n",
        "    )\n",
        "    x = MTensor.cat([x, dummy_ones], dim=1)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    ###\n",
        "    n_layers = len(self._config[\"params\"][\"sets\"])\n",
        "    n = x.data.shape[0]\n",
        "    param_sets = self._config[\"params\"][\"sets\"]\n",
        "    param_samples = self._config[\"params\"][\"samples\"]\n",
        "    feat_sets = self._config[\"features\"][\"sets\"]\n",
        "    feat_samples = self._config[\"features\"][\"samples\"]\n",
        "    self.all_pools = []\n",
        "    self.all_samples = []\n",
        "    pool = x\n",
        "    pool = MTensor.reshape(pool, (n, self._ch0, -1))\n",
        "    pool = MTensor.permute(pool, (0, 2, 1))\n",
        "    wl, wr = 0, param_sets[0] * param_samples[0]\n",
        "    for step in range(n_layers):\n",
        "      self.all_pools.append(pool[:4])\n",
        "      ###\n",
        "      if self._is_conv[step]:\n",
        "        idx_slice = pool.idx[0, :, 0]\n",
        "      else:\n",
        "        pool = MTensor.reshape(pool, (n, -1))\n",
        "        idx_slice = pool.idx[0]\n",
        "      # pool = MTensor.reshape(pool, (n, -1))\n",
        "      # idx_slice = pool.idx[0]\n",
        "      idxx = idxhood(\n",
        "          idx_slice,\n",
        "          feat_samples[step],\n",
        "          num_sets=feat_sets[step],\n",
        "          sample=True,\n",
        "      )\n",
        "      # pool: N x (num_windows * window_volume)\n",
        "      pool = pool[:, idxx]\n",
        "      self.all_samples.append(pool[:4])\n",
        "      ###\n",
        "      mw = MTensor.reshape(\n",
        "          self.MW[wl: wr],\n",
        "          (param_sets[step], param_samples[step])\n",
        "      )\n",
        "      # pool: (N * num_windows) x sets\n",
        "      # pool = MTensor.reshape(pool, (-1, feat_samples[step])) @ mw\n",
        "      ### o 1 do bias parece que atrapalha\n",
        "      # pool = (\n",
        "      #     self._put_one(MTensor.reshape(\n",
        "      #         pool, (n * feat_sets[step], -1)\n",
        "      #     ))\n",
        "      #     @ mw\n",
        "      # )\n",
        "      ###\n",
        "      if (step < n_layers - 1):\n",
        "        pool = (\n",
        "            MTensor.reshape(\n",
        "                pool, (n * feat_sets[step], -1)\n",
        "            )\n",
        "            @ mw\n",
        "        )\n",
        "      else:\n",
        "        pool = self._probe(pool.data.reshape(n, -1))\n",
        "        pool = MTensor(\n",
        "            pool,\n",
        "            torch.zeros((*pool.shape, self._idx_dim)).to(pool.device)\n",
        "        )\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, -1))\n",
        "      # pool: N x (num_windows * sets)\n",
        "      if step < n_layers - 1:\n",
        "        pool.data = self.activation(pool.data)\n",
        "        pass\n",
        "      else:\n",
        "        break\n",
        "      ###\n",
        "      pool = MTensor.reshape(pool, (n, feat_sets[step], param_sets[step]))\n",
        "      ###\n",
        "      nxt_step = step + 1\n",
        "      next_wr = wr + param_sets[nxt_step] * param_samples[nxt_step]\n",
        "      wl, wr = wr, next_wr\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRFtDATXUmH"
      },
      "source": [
        "### Função de Custo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def _check_shapes(y_true, y_pred, true_index, pred_index):\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape[0] == y_pred.shape[0]\n",
        "  assert true_index.shape[0] == pred_index.shape[0]\n",
        "  assert true_index.shape[-1] == pred_index.shape[-1]\n",
        "\n",
        "def _maromba_loss(y_true, y_pred, true_index, pred_index):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out(true)\n",
        "  y_pred: N x d_out(pred)\n",
        "  true_index: N x d_out(true) x d_index\n",
        "  pred_index: N x d_out(pred) x d_index\n",
        "  \"\"\"\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  ###\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  ###\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  ### Under experimentation\n",
        "  # index_match = nn.functional.softmax(index_match, dim=-1)\n",
        "  ###\n",
        "  # y_true_match: N x 1 x d_out(pred)\n",
        "  # y_pred_match: N x 1 x d_out(true)\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  # huber = nn.HuberLoss()\n",
        "  # match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  # match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  # loss = match_loss_lr + match_loss_rl\n",
        "  ce = nn.CrossEntropyLoss() # nn.NLLLoss() #\n",
        "  loss_lr = ce(y_pred_match.squeeze(1), torch.argmax(y_true, dim=-1))\n",
        "  # loss_rl = ce(y_true_match.squeeze(1), torch.argmax(y_pred, dim=-1))\n",
        "  loss_rl = ce(y_pred, torch.argmax(y_true_match.squeeze(1), dim=-1))\n",
        "  loss = loss_lr + loss_rl\n",
        "  return loss\n",
        "\n",
        "def _pool2category(y_true, y_pred, true_index, pred_index):\n",
        "  _check_shapes(y_true, y_pred, true_index, pred_index)\n",
        "  # index_match: N x d_out(pred) x d_out(true)\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  y_pred_match = torch.argmax(y_pred_match.squeeze(1), dim=-1).tolist()\n",
        "  return y_pred_match\n",
        "\n",
        "def _maromba_accuracy(y_true, y_pred, true_index, pred_index):\n",
        "  ###\n",
        "  # pred_index = MTensor._cosine_kernel(pred_index)\n",
        "  pred_index = MTensor._soft_kernel(pred_index, img_dim)\n",
        "  ###\n",
        "  y_pred_match = _pool2category(y_true, y_pred, true_index, pred_index)\n",
        "  y_true = torch.argmax(y_true, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred_match)\n",
        "  return acc\n",
        "\n",
        "def maromba_accuracy(y_true, y_pred):\n",
        "  return _maromba_accuracy(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def maromba_loss(y_true, y_pred):\n",
        "  return _maromba_loss(y_true.data, y_pred.data, y_true.idx, y_pred.idx)\n",
        "\n",
        "def regular_accuracy(y_true, y_pred):\n",
        "  y_true = torch.argmax(y_true.data, dim=-1).tolist()\n",
        "  y_pred = torch.argmax(y_pred.data, dim=-1).tolist()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  return acc\n",
        "\n",
        "def regular_loss(y_true, y_pred):\n",
        "  y_true = y_true.data\n",
        "  # y_pred = 10.0 * y_pred.data ### WHY 10x?\n",
        "  y_pred = y_pred.data ### WHY 10x?\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  loss = ce(y_pred, torch.argmax(y_true, dim=-1))\n",
        "  return loss\n",
        "\n",
        "maromba_loss = regular_loss\n",
        "maromba_accuracy = regular_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039kGqbPXp4d"
      },
      "source": [
        "### Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CeSzd7OmTDDn"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "rows, cols = img_dim, img_dim\n",
        "hidden_dim = 1 * img_dim\n",
        "clf_dim = (1 + (num_classes - 1) // img_dim) * img_dim\n",
        "idx_dim = 3 # rows + cols + hidden_dim + clf_dim # 3\n",
        "\n",
        "# template_x_idx = _cat2d(rows, cols, d=idx_dim)\n",
        "template_x_idx = cartesian_idx(rows, cols, chs=channels, offset=1, d=idx_dim) ### offset=0\n",
        "template_x_idx = template_x_idx.unsqueeze(0).float().to(device)\n",
        "# template_y_idx = torch.eye(idx_dim)[-num_classes:]\n",
        "template_y_idx = torch.eye(num_classes)[:, -idx_dim:]\n",
        "template_y_idx = template_y_idx.float().unsqueeze(0).to(device)\n",
        "\n",
        "def prepare_input(x, y, device=\"cpu\"):\n",
        "  n = x.shape[0]\n",
        "  x_idx = template_x_idx.repeat(n, 1, 1)\n",
        "  yoh = torch.zeros(n, num_classes)\n",
        "  yoh[range(n), y] = 1.0\n",
        "  yoh = yoh.to(device)\n",
        "  y_idx = template_y_idx.repeat(n, 1, 1)\n",
        "  x = MTensor(x, x_idx)\n",
        "  y = MTensor(yoh, y_idx)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzd22RQX-Yg"
      },
      "source": [
        "### Treino (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcZxz9MYMwd"
      },
      "outputs": [],
      "source": [
        "# tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5gdtyeWnjJ"
      },
      "outputs": [],
      "source": [
        "# tidx = aidx.reshape(32, -1, 9, 3)[0, 100].cpu().detach().numpy(); tidx = tidx.reshape(-1, 3)\n",
        "# tidx = aidx.reshape(32, -1, 9, 2)[0].cpu().detach().numpy(); tidx = tidx.reshape(-1, 2)\n",
        "\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 1] * 0.0})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "# midx.reshape(32, -1, 3)[0, 100:105].cpu().detach().numpy()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tJHxWRO_xoX"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0uL2kM1Okfd"
      },
      "outputs": [],
      "source": [
        "imgs = [img.data.cpu().detach() for img in model.all_pools]\n",
        "idxs = [img.idx.cpu().detach() for img in model.all_pools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj5tP_tfMAjw"
      },
      "outputs": [],
      "source": [
        "[img.shape for img in imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWVQRznvaer"
      },
      "outputs": [],
      "source": [
        "shapes = [\n",
        "    (img_dim, img_dim, 1),\n",
        "    ((img_dim - 0) // 1, (img_dim - 0) // 1, 1),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 4),\n",
        "    # ((img_dim - 0) // 1, (img_dim - 0) // 1, 8),\n",
        "    # (((img_dim - 2) // 2 - 2) // 1, ((img_dim - 2) // 2 - 2) // 1, 4),\n",
        "    # (((img_dim - 4) // 1 - 4) // 2, ((img_dim - 4) // 1 - 4) // 2, 8),\n",
        "    # ((img_dim - 4) // 2 - 2, (img_dim - 4) // 2 - 2, 4),\n",
        "    # ((img_dim - 4) // 2 - 4, (img_dim - 4) // 2 - 4, 8),\n",
        "]\n",
        "# display.clear_output(wait=True)\n",
        "plt.close()\n",
        "for idx, img in enumerate(imgs[:len(shapes)]):\n",
        "  img = img[0]\n",
        "  print(img.shape)\n",
        "  img = img.reshape(*shapes[idx])\n",
        "  rows, cols = 1, shapes[idx][2]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize=(min(18, 3 * cols), 3))\n",
        "  for ch in range(cols):\n",
        "    img_ = img[:, :, ch].numpy()\n",
        "    if cols > 1:\n",
        "      ax[ch].imshow(img_)\n",
        "    else:\n",
        "      ax.imshow(img_)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgY4NUoRagWO"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def scatter3d(x, y, z):\n",
        "  plot_df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None)\n",
        "  return fig\n",
        "\n",
        "# plt.clf(); plt.cla()\n",
        "# plt.close()\n",
        "for i, idx in enumerate(idxs[:len(shapes)]):\n",
        "  idx = idx[0]\n",
        "  print(idx.shape)\n",
        "  idx = idx.reshape(-1, shapes[i][2], idx_dim)\n",
        "  rows, cols = 1 + (idx.shape[1] - 1) // 2, 2\n",
        "  # fig = plt.figure(figsize=(min(18, 3 * cols), 3))\n",
        "  fig = make_subplots(\n",
        "    rows=rows, cols=cols,\n",
        "    specs=[[{\"type\": \"scene\"} for _ in range(cols)] for _ in range(rows)],\n",
        "    # row_heights=[10 for _ in range(rows)],\n",
        "    vertical_spacing=0.05\n",
        "  )\n",
        "  fig.update_layout(\n",
        "    height=600 * rows,\n",
        "    width=600 * cols\n",
        ")\n",
        "  for ch in range(idx.shape[1]):\n",
        "    idx_ = idx[:, ch].numpy()\n",
        "    # ax = fig.add_subplot(rows, cols, ch + 1, projection=\"3d\")\n",
        "    # ax.scatter(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2], marker=\"+\")\n",
        "    # fig = scatter3d(idx_[::4, 0], idx_[::4, 1], idx_[::4, 2])\n",
        "    row, col = (ch // cols) + 1, (ch % cols) + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=idx_[::, 0],\n",
        "            y=idx_[::, 1],\n",
        "            z=idx_[::, 2],\n",
        "            # z=idx_[::, 1] * 0.0,\n",
        "            # color=None,\n",
        "            # colorscale=\"Viridis\",\n",
        "            # showscale=False\n",
        "        ),\n",
        "        row=row,\n",
        "        col=col,\n",
        "    )\n",
        "  fig.show()\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWbwRwuE9lu"
      },
      "outputs": [],
      "source": [
        "# model.MW.idx[0, 0]\n",
        "threshold = rows * cols * hidden_dim\n",
        "param_id = 0\n",
        "layer_idx = model.MW.idx[:, param_id: param_id + 100] # threshold\n",
        "n_parts = idx_dim // img_dim\n",
        "scaled_idx = (\n",
        "    MTensor\n",
        "    ._soft_kernel(layer_idx, img_dim)[0]\n",
        "    .reshape(-1, n_parts, img_dim)\n",
        ") * (n_parts ** 0.5)\n",
        "idx_att = torch.argmax(\n",
        "    scaled_idx,\n",
        "    dim=-1\n",
        ")[:, :2]\n",
        "idx_att = idx_att.cpu().detach().numpy()\n",
        "grid = np.zeros((rows, cols))\n",
        "# for pos in range(len(idx_att)):\n",
        "#   idxx, idxy = idx_att[pos]\n",
        "#   idxx, idxy = int(idxx), int(idxy)\n",
        "#   # grid[int(idxx), int(idxy)] += 1\n",
        "#   grid[idxx, idxy] += scaled_idx[pos, 0, idxx] * scaled_idx[pos, 1, idxy]\n",
        "for idxx in range(rows):\n",
        "  for idxy in range(cols):\n",
        "    grid[idxx, idxy] = (scaled_idx[:, 0, idxx] * scaled_idx[:, 1, idxy]).sum()\n",
        "grid = grid / grid.max()\n",
        "\n",
        "# plt.imshow(grid)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(grid, cmap=\"seismic\")\n",
        "\n",
        "for (i, j), z in np.ndenumerate(grid):\n",
        "    ax.text(j, i, \"{:0.2f}\".format(z), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCHvt7xQq6q"
      },
      "outputs": [],
      "source": [
        "MTensor._soft_kernel(y_pred.idx, img_dim)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizações"
      ],
      "metadata": {
        "id": "8_m1YvjxBdj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(x: MTensor):\n",
        "  \"\"\"\n",
        "  x.data: in_dim\n",
        "  x.idx:  in_dim x idx_dim\n",
        "  \"\"\"\n",
        "  n, idx_dim = x.idx.shape\n",
        "  assert x.data.shape == (n,)\n",
        "  tidx = x.idx.cpu().detach().numpy()\n",
        "  tdata = x.data.cpu().detach().numpy()\n",
        "  plot_df = pd.DataFrame(\n",
        "      {\n",
        "          \"x\": tidx[:, 0],\n",
        "          \"y\": tidx[:, 1],\n",
        "          \"z\": tidx[:, 2],\n",
        "          \"val\": tdata,\n",
        "      }\n",
        "  )\n",
        "  fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=\"val\")\n",
        "  fig.show();"
      ],
      "metadata": {
        "id": "UZ4DrI6mBn39"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbo5JtHw3bq"
      },
      "source": [
        "### Treino (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xGn5VTZPw-1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "83d21ba8-1fd0-401c-ee78-31f715bf0ee7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-36cf2dc2b42b>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaromba_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-fbdb118c1d0e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         pool = (\n\u001b[0;32m--> 137\u001b[0;31m             MTensor.reshape(\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfeat_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-15-ff8914ef1b38>\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     midx = (\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0m_knndot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monesb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0m_knndot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monesa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     ) / 2.0\n",
            "\u001b[0;32m<ipython-input-27-4054e4da8357>\u001b[0m in \u001b[0;36m_knndot\u001b[0;34m(u, v, idxu, idxv)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_neigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     n_idxu = neigh.kneighbors(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mq_idxu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     ).reshape(-1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 )\n\u001b[0;32m--> 879\u001b[0;31m             chunked_results = Parallel(n_jobs, prefer=\"threads\")(\n\u001b[0m\u001b[1;32m    880\u001b[0m                 delayed(_tree_query_parallel_helper)(\n\u001b[1;32m    881\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \"\"\"\n\u001b[0;32m--> 685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.query\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# error message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mfirst_pass_isfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst_pass_isfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2298\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2299\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hidden_dim = 10\n",
        "start_mode = True\n",
        "valid_mode = False\n",
        "index_mode = False\n",
        "\n",
        "# TODO: Visualize conv layer output\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [1024,    1024,    1,],\n",
        "#         \"samples\": [25,      1,       1024,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [4,       1,       num_classes,],\n",
        "#         \"samples\": [(76, 1), (1, 5),  (1025, 1),],\n",
        "#         \"is conv\": [True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "# config = {\n",
        "#     \"features\": {\n",
        "#         \"pre-set\": channels,\n",
        "#         \"sets\":    [784,     784,     784,     1,],\n",
        "#         \"samples\": [9,       9,       1,       784,],\n",
        "#     },\n",
        "#     \"params\": {\n",
        "#         \"sets\":    [8,       16,      1,       num_classes,],\n",
        "#         \"samples\": [(3, 1),  (9, 1),  (1, 4),  (28, 1),],\n",
        "#         \"is conv\": [True,    True,    True,    False,]\n",
        "#     },\n",
        "# }\n",
        "###\n",
        "config = {\n",
        "    \"features\": {\n",
        "        \"pre-set\": channels,\n",
        "        \"sets\":    [784,   1,],\n",
        "        \"samples\": [9,     784,],\n",
        "    },\n",
        "    \"params\": {\n",
        "        \"sets\":    [1,     num_classes,],\n",
        "        \"samples\": [9,     784,],\n",
        "        \"is conv\": [False, False,]\n",
        "    },\n",
        "}\n",
        "\n",
        "tot_samples = [np.prod(smp) for smp in config[\"params\"][\"samples\"]]\n",
        "conv_params = int(np.dot(config[\"params\"][\"sets\"][:-1], tot_samples[:-1]))\n",
        "n_params = int(np.dot(config[\"params\"][\"sets\"], tot_samples))\n",
        "\n",
        "if start_mode:\n",
        "  model = MModule4(\n",
        "      config=config,\n",
        "      idx_dim=idx_dim,\n",
        "      device=device,\n",
        "  )\n",
        "  optimizer = Adam(model.parameters(), lr=1e-2)\n",
        "  # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "  widx0 = model.W_idx[:, :conv_params].clone().detach()\n",
        "  train_log = {\n",
        "      \"train loss\": [],\n",
        "      \"eval loss\": [],\n",
        "      \"acc\": [],\n",
        "      \"set\": [],\n",
        "      \"epoch\": [],\n",
        "  }\n",
        "  epoch = 0\n",
        "\n",
        "num_epochs = 720 * 4\n",
        "epoch_len = 60\n",
        "\n",
        "while epoch < num_epochs:\n",
        "  epoch += 1\n",
        "  ###\n",
        "  # widx_diff = (model.W_idx[:, :conv_params] - widx0)\n",
        "  # print(widx_diff.abs().mean().item(), widx_diff.min().item(), widx_diff.max().item())\n",
        "  ###\n",
        "  model.train()\n",
        "  train_iter = iter(train_data_loader)\n",
        "  for _ in range(epoch_len):\n",
        "    x, y = next(train_iter)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    x, y = prepare_input(x, y, device=device)\n",
        "    y_pred = model.forward(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss = maromba_loss(y, y_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_log[\"train loss\"].append(loss.item())\n",
        "    train_log[\"eval loss\"].append(np.nan)\n",
        "    train_log[\"acc\"].append(np.nan)\n",
        "    train_log[\"set\"].append(\"train\")\n",
        "    train_log[\"epoch\"].append(epoch)\n",
        "  if valid_mode:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in iter(test_data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x, y = prepare_input(x, y, device=device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = maromba_loss(y, y_pred)\n",
        "        acc = maromba_accuracy(y, y_pred)\n",
        "        train_log[\"eval loss\"].append(loss.item())\n",
        "        train_log[\"train loss\"].append(np.nan)\n",
        "        train_log[\"acc\"].append(acc.item())\n",
        "        train_log[\"set\"].append(\"eval\")\n",
        "        train_log[\"epoch\"].append(epoch)\n",
        "    metric_cols = [\"eval loss\", \"acc\"]\n",
        "    set_val = \"eval\"\n",
        "  else:\n",
        "    metric_cols = [\"train loss\",]\n",
        "    set_val = \"train\"\n",
        "  if index_mode:\n",
        "    _layer = 1\n",
        "    _batchidx = 0\n",
        "    pool = model.all_pools[_layer]\n",
        "    pool = MTensor.reshape(pool[_batchidx], (-1,))\n",
        "    display.clear_output(wait=True)\n",
        "    plot_features(pool)\n",
        "    from time import sleep\n",
        "    sleep(3)\n",
        "    #\n",
        "    # pool = model.all_samples[_layer - 1]\n",
        "    # _shape = (\n",
        "    #     config[\"features\"][\"sets\"][_layer - 1],\n",
        "    #     config[\"features\"][\"samples\"][_layer - 1],\n",
        "    # )\n",
        "    # _set = (config[\"features\"][\"sets\"][_layer - 1]) // 2\n",
        "    # pool = MTensor.reshape(pool[_batchidx], _shape)[_set]\n",
        "    # display.clear_output(wait=True)\n",
        "    # plot_features(pool)\n",
        "  else:\n",
        "    group_cols = [\"epoch\"] + metric_cols\n",
        "    df_train = pd.DataFrame(train_log)\n",
        "    df_train = df_train[df_train[\"set\"] == set_val]\n",
        "    display.clear_output(wait=True)\n",
        "    (\n",
        "      df_train[group_cols]\n",
        "      .groupby(\"epoch\")\n",
        "      .agg(lambda x: x.median(skipna=True))\n",
        "      .reset_index()\n",
        "      .sort_values(\"epoch\", ascending=True)\n",
        "      .tail(30)[metric_cols]\n",
        "      .plot(figsize=(16, 3), grid=True)\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tidx = idxu.reshape(32, -1, 3)[0].cpu().detach().numpy()\n",
        "# tidx = idxu.reshape(32, -1, 18, 3)[0, 0].cpu().detach().numpy()\n",
        "# tidx = idxv.reshape(-1, 3).cpu().detach().numpy()\n",
        "## tidx = model.W_idx[0, :18].cpu().detach().numpy()\n",
        "# plot_df = pd.DataFrame({\"x\": tidx[:, 0], \"y\": tidx[:, 1], \"z\": tidx[:, 2]})\n",
        "# fig = px.scatter_3d(plot_df, x=\"x\", y=\"y\", z=\"z\", color=None); fig.show();\n",
        "##\n",
        "# phi = idxu[0] @ idxv[0].T"
      ],
      "metadata": {
        "id": "n5Hm-pCJqjTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-K_7fUh2anJ"
      },
      "source": [
        "### Visualização dos índices dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNJnesCt2f1p"
      },
      "outputs": [],
      "source": [
        "soft_W_idx = scaled_idx # MTensor._soft_kernel(model.MW.idx, img_dim)\n",
        "threshold = 100 # rows * cols * hidden_dim\n",
        "# First layer\n",
        "soft_W_idx = soft_W_idx[:, :threshold].reshape(1, -1, idx_dim)\n",
        "# Last layer\n",
        "# soft_W_idx = soft_W_idx[:, threshold:].reshape(1, -1, idx_dim)\n",
        "soft_W_idx = soft_W_idx.cpu().detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaTHY1L2it1"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_idx = np.random.choice(\n",
        "    len(soft_W_idx),\n",
        "    min(len(soft_W_idx), 10000),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "W_idx_tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=10,\n",
        ").fit_transform(soft_W_idx[sample_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6icrE2unf"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"W_idx x tsne\": W_idx_tsne[:, 0],\n",
        "        \"W_idx y tsne\": W_idx_tsne[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_df.plot.scatter(\n",
        "    x=\"W_idx x tsne\",\n",
        "    y=\"W_idx y tsne\",\n",
        "    figsize=(24, 4),\n",
        "    grid=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUDvxRS3yZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ndQSziNdjoUm",
        "RGCfrrmCXap_",
        "tzKu4c8hisNY",
        "YLr5gOnn5RRu",
        "XzzFCy32AGsX",
        "9Ytm2bU_JvrK",
        "_T9hF3Uoi3tF",
        "kTfYY3SQXNJF",
        "4NH27yFEuqtg",
        "QQRFtDATXUmH",
        "039kGqbPXp4d",
        "Lyzd22RQX-Yg",
        "8_m1YvjxBdj9",
        "Y-K_7fUh2anJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOGNW6unZhaH5hVEmT1erVb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}