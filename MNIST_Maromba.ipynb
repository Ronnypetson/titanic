{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kTfYY3SQXNJF",
        "QQRFtDATXUmH"
      ],
      "authorship_tag": "ABX9TyPBwiziH92IDJ28cwgWBDx3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/MNIST_Maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "elxoSeIKAV1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "RGCfrrmCXap_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "def _transform(x):\n",
        "  return (tr(x) * 2.0 - 1.0).reshape(-1)\n",
        "\n",
        "bsize = 32\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    'MNIST_root/',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    'MNIST_root_test/',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "j6dxGxcHAx5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _posenc(shape, d=32):\n",
        "  \"\"\"\n",
        "  3D Positional encodings (sin(row) + cos(col))\n",
        "  \"\"\"\n",
        "  assert len(shape) == 2\n",
        "  rows, cols = shape\n",
        "  idx_sin = np.zeros((rows, d))\n",
        "  idx_cos = np.zeros((cols, d))\n",
        "  for idx in range(rows):\n",
        "    _x = (np.arange(0, d) / d) * (4 * np.pi * (1 + idx / rows))\n",
        "    idx_sin[idx] = np.sin(_x)\n",
        "  for idx in range(cols):\n",
        "    _x = (np.arange(0, d) / d) * (4 * np.pi * (1 + idx / cols))\n",
        "    idx_cos[idx] = np.cos(_x)\n",
        "  idx_sin = torch.from_numpy(idx_sin)\n",
        "  idx_cos = torch.from_numpy(idx_cos)\n",
        "  idx = (\n",
        "      idx_sin.reshape((rows, 1, d)).repeat(1, cols, 1)\n",
        "      + idx_cos.reshape((1, cols, d)).repeat(rows, 1, 1)\n",
        "  )\n",
        "  idx = idx.reshape(rows * cols, d) / 2.0\n",
        "  return idx"
      ],
      "metadata": {
        "id": "_1cLnafymDzd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows, cols, d = 5, 5, 10\n",
        "pos = _posenc((rows, cols), d).reshape(rows, cols, d)\n",
        "fig, axs = plt.subplots(nrows=rows, ncols=cols, layout=None)\n",
        "for row in range(rows):\n",
        "  for col in range(cols):\n",
        "    axs[row][col].plot(range(d), pos[row, col].numpy())\n",
        "plt.show()\n",
        "print(pos[0] @ pos[1].T)"
      ],
      "metadata": {
        "id": "fyWPtI28l-pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = MNIST_train_data[0]\n",
        "plt.imshow(np.array(x.reshape(28, 28))), y"
      ],
      "metadata": {
        "id": "KS12YlllA3xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classe Tensor Maromba"
      ],
      "metadata": {
        "id": "kTfYY3SQXNJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module=nn.Identity(),\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.indexer = indexer\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return MTensor(self.data[idx], self.idx[idx], self.indexer)\n",
        "\n",
        "  def __setitem__(self, idx, value):\n",
        "    self.data[idx] = value.data\n",
        "    self.idx[idx] = value.idx\n",
        "\n",
        "  def __delitem__(self, idx):\n",
        "    del self.data[idx]\n",
        "    del self.idx[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  @staticmethod\n",
        "  def cat(mts, dim=0):\n",
        "    values = [mt.data for mt in mts]\n",
        "    indices = [mt.idx for mt in mts]\n",
        "    values = torch.cat(values, dim=dim)\n",
        "    indices = torch.cat(indices, dim=dim)\n",
        "    mt = MTensor(values, indices)\n",
        "    return mt\n",
        "\n",
        "  def _gbmd(self, u, v, idxu, idxv) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    'General Batch Maromba Dot'\n",
        "    Shorter implementation for the 'batch maromba dot' operation.\n",
        "    u: M x d_u\n",
        "    v: N x d_v\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u = u.shape\n",
        "    n, d_v = v.shape\n",
        "    d_idx = idxu.shape[-1]\n",
        "    assert (m, d_u, d_idx) == idxu.shape\n",
        "    assert (n, d_v, d_idx) == idxv.shape\n",
        "    # uidxu: M x d_idx\n",
        "    # vidxv: N x d_idx\n",
        "    uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "    vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "    dot = uidxu @ vidxv.T\n",
        "    return dot\n",
        "\n",
        "  def _xor_idx(self, idxu, idxv):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    # idxu: (M * d_u) x d_idx x 1\n",
        "    # idxv: (N * d_v) x d_idx x 1\n",
        "    idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "    idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "    # siiT: M x d_idx x d_idx\n",
        "    # sjjT: N x d_idx x d_idx\n",
        "    siiT = torch.bmm(idxu, idxu.permute(0, 2, 1))\n",
        "    siiT = siiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "    sjjT = torch.bmm(idxv, idxv.permute(0, 2, 1))\n",
        "    sjjT = sjjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1) ###\n",
        "    # siiT: (M * N) x d_idx x d_idx\n",
        "    # sjjT: (M * N) x d_idx x d_idx\n",
        "    siiT = siiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    sjjT = sjjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    # si: (M * N) x d_idx x 1\n",
        "    # sj: (M * N) x d_idx x 1\n",
        "    si = idxu.reshape(m, d_u, d_idx).sum(dim=1).unsqueeze(1)\n",
        "    si = si.repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "    sj = idxv.reshape(n, d_v, d_idx).sum(dim=1).unsqueeze(0)\n",
        "    sj = sj.repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "    diag_siiT_sjjT = torch.diagonal(torch.bmm(siiT, sjjT), dim1=1, dim2=2)\n",
        "    diag_siiT_sjjT = diag_siiT_sjjT.unsqueeze(-1)\n",
        "    xor_idx = torch.bmm(siiT, sj) + torch.bmm(sjjT, si) - 2 * diag_siiT_sjjT\n",
        "    xor_idx = xor_idx.reshape(m, n, d_idx) / d_u\n",
        "    return xor_idx\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    mdot = self._gbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1]),\n",
        "        b.data.reshape(-1, b.data.shape[-1]),\n",
        "        aidx,\n",
        "        bidx\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    midx = self._xor_idx(aidx, bidx)\n",
        "    midx = midx.reshape(apre + bpre + (d_idx,))\n",
        "    mans = MTensor(mdot, midx, self.indexer)\n",
        "    return mans"
      ],
      "metadata": {
        "id": "OJVRPHg7UvVV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = MTensor(torch.randn(1, 2), torch.randn(1, 2, 3))\n",
        "# b = MTensor(torch.randn(1, 2), torch.randn(1, 2, 3))\n",
        "# c = MTensor.cat([a, b])\n",
        "# print(a.data)\n",
        "# print(b.data)\n",
        "# print(c.data)\n",
        "# print(a.idx)\n",
        "# print(b.idx)\n",
        "# print(c.idx)\n",
        "# print(a.data)\n",
        "# print(a.idx)\n",
        "# idx = torch.tensor([1, 2]).long()\n",
        "# b = a[:, idx]\n",
        "# print(b.data)\n",
        "# print(b.idx)"
      ],
      "metadata": {
        "id": "ykbQ7l4ut_Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classe do Módulo Treinável"
      ],
      "metadata": {
        "id": "yGg59zEqYGe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MModule(nn.Module):\n",
        "  def __init__(self, n_params=600, idx_dim=32, samples=32, sets=64, device=\"cpu\"):\n",
        "    super().__init__()\n",
        "    self.idx_dim = idx_dim\n",
        "    self.samples = samples\n",
        "    self.sets = sets\n",
        "    self.device = device\n",
        "    self.n_params = n_params\n",
        "    self.W = nn.Parameter(torch.randn((1, n_params), device=device))\n",
        "    self.W_idx = nn.Parameter(torch.randn((1, n_params, idx_dim), device=device))\n",
        "    self.MW = MTensor(self.W, self.W_idx)\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def _msample(self, x: MTensor, n_samples):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    idx = np.random.choice(in_dim, n_samples, replace=True)\n",
        "    idx = torch.tensor(idx).long()\n",
        "    x_sampled = x[:, idx]\n",
        "    return x_sampled\n",
        "\n",
        "  def _W_step(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    # Put 1 into x\n",
        "    one = MTensor(\n",
        "        torch.ones(n, 1).to(self.device),\n",
        "        torch.zeros(n, 1, idx_dim).to(self.device),\n",
        "    )\n",
        "    x = MTensor.cat([x, one], dim=1)\n",
        "    # Sample W\n",
        "    W_sets = []\n",
        "    for _ in range(self.sets):\n",
        "      idx = np.random.choice(self.n_params, self.samples, replace=True)\n",
        "      idx = torch.tensor(idx).long()\n",
        "      W_sets.append(self.MW[:, idx])\n",
        "    W_sets = MTensor.cat(W_sets, dim=0)\n",
        "    # mdot: N x sets\n",
        "    mdot = x @ W_sets\n",
        "    mdot.data = self.activation(mdot.data)\n",
        "    return mdot\n",
        "\n",
        "  def _pool_step(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    n, in_dim, idx_dim = x.idx.shape\n",
        "    assert x.data.shape == (n, in_dim)\n",
        "    x0 = self._msample(x, self.samples)\n",
        "    x1 = self._msample(x, self.samples)\n",
        "    # TODO: Overload '*' operator for batch-wise '@'\n",
        "    # ex.:\n",
        "    # mdot = x0 * x1\n",
        "    # mdot.data = self.activation(mdot.data)\n",
        "    # return mdot\n",
        "\n",
        "  def forward(self, x: MTensor):\n",
        "    \"\"\"\n",
        "    x.data: N x in_dim\n",
        "    x.idx: N x in_dim x idx_dim\n",
        "    \"\"\"\n",
        "    pool = self._W_step(x)\n",
        "    pool_new = self._pool_step(pool)\n",
        "    pool = MTensor.cat([pool, pool_new], dim=1)\n",
        "    # ..."
      ],
      "metadata": {
        "id": "Oipx_P9qYUUb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(10, requires_grad=True)\n",
        "idx1 = torch.tensor([0, 1, 2]).long()\n",
        "idx2 = torch.tensor([5, 6, 7]).long()\n",
        "print(a)\n",
        "print(a[idx1])\n",
        "print(a[idx2])\n",
        "print(a.unsqueeze(1).repeat(1, 10)[idx1, idx2])\n",
        "# Uma indexação por vez, depois concatena\n",
        "# Amostra, indexa, opera, concatena"
      ],
      "metadata": {
        "id": "oOobWyLxBKRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Custo"
      ],
      "metadata": {
        "id": "QQRFtDATXUmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  # index_match: N x d_out x d_out\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  # y_true_match: N x 1 x d_out\n",
        "  # y_pred_match: N x 1 x d_out\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  huber = nn.HuberLoss()\n",
        "  match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  loss = match_loss_lr + match_loss_rl\n",
        "  return loss"
      ],
      "metadata": {
        "id": "vX8kHpfLXVzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### -------"
      ],
      "metadata": {
        "id": "039kGqbPXp4d"
      }
    }
  ]
}