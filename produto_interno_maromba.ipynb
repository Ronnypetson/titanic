{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP6yLlmQgancMKCil4XA62",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/produto_interno_maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3woABE_SOgS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement example of \"Produto Interno Maromba\": fitting linear transform using maromba product"
      ],
      "metadata": {
        "id": "wcumRBtgXbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementação do Tensor Maromba"
      ],
      "metadata": {
        "id": "WpnnNOnmkGTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module,\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.indexer = indexer\n",
        "\n",
        "  def _gbmd(self, u, v, idxu, idxv) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    'General Batch Maromba Dot'\n",
        "    Shorter implementation for the 'batch maromba dot' operation.\n",
        "    u: M x d_u\n",
        "    v: N x d_v\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u = u.shape\n",
        "    n, d_v = v.shape\n",
        "    d_idx = idxu.shape[-1]\n",
        "    assert (m, d_u, d_idx) == idxu.shape\n",
        "    assert (n, d_v, d_idx) == idxv.shape\n",
        "    # uidxu: M x d_idx\n",
        "    # vidxv: N x d_idx\n",
        "    uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "    vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "    dot = uidxu @ vidxv.T\n",
        "    return dot\n",
        "\n",
        "  def _genidx(self, idxu, idxv):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    # idxu_new: M x d_idx\n",
        "    # idxv_new: N x d_idx\n",
        "    idxu_new = (\n",
        "        self.indexer(idxu.reshape(-1, d_idx))\n",
        "        .reshape(m, d_u, d_idx).mean(dim=1)\n",
        "    )\n",
        "    idxv_new = (\n",
        "        self.indexer(idxv.reshape(-1, d_idx))\n",
        "        .reshape(n, d_v, d_idx).mean(dim=1)\n",
        "    )\n",
        "    idxu_new = idxu_new.unsqueeze(1).repeat(1, n, 1)\n",
        "    idxv_new = idxv_new.unsqueeze(0).repeat(m, 1, 1)\n",
        "    idx_new = idxu_new + idxv_new\n",
        "    # idx_new = nn.functional.gumbel_softmax(idx_new, hard=False, dim=-1)\n",
        "    idx_new = nn.functional.softmax(idx_new, dim=-1)\n",
        "    return idx_new\n",
        "\n",
        "  def _xor_idx(self, idxu, idxv):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    # idxu: (M * d_u) x d_idx x 1\n",
        "    # idxv: (N * d_v) x d_idx x 1\n",
        "    idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "    idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "    # siiT: M x d_idx x d_idx\n",
        "    # sjjT: N x d_idx x d_idx\n",
        "    siiT = torch.bmm(idxu, idxu.permute(0, 2, 1))\n",
        "    siiT = siiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "    sjjT = torch.bmm(idxv, idxv.permute(0, 2, 1))\n",
        "    sjjT = sjjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1) ###\n",
        "    # siiT: (M * N) x d_idx x d_idx\n",
        "    # sjjT: (M * N) x d_idx x d_idx\n",
        "    siiT = siiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    sjjT = sjjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    # si: (M * N) x d_idx x 1\n",
        "    # sj: (M * N) x d_idx x 1\n",
        "    si = idxu.reshape(m, d_u, d_idx).sum(dim=1).unsqueeze(1)\n",
        "    si = si.repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "    sj = idxv.reshape(n, d_v, d_idx).sum(dim=1).unsqueeze(0)\n",
        "    sj = sj.repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "    diag_siiT_sjjT = torch.diagonal(torch.bmm(siiT, sjjT), dim1=1, dim2=2)\n",
        "    diag_siiT_sjjT = diag_siiT_sjjT.unsqueeze(-1)\n",
        "    xor_idx = torch.bmm(siiT, sj) + torch.bmm(sjjT, si) - 2 * diag_siiT_sjjT\n",
        "    # xor_idx = torch.bmm(siiT, sj) + torch.bmm(sjjT, si) - diag_siiT_sjjT\n",
        "    xor_idx = xor_idx.reshape(m, n, d_idx) / d_u\n",
        "    # xor_idx = nn.functional.softmax(xor_idx, dim=-1)\n",
        "    return xor_idx\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    mdot = self._gbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1]),\n",
        "        b.data.reshape(-1, b.data.shape[-1]),\n",
        "        aidx,\n",
        "        bidx\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # midx = self._genidx(aidx, bidx)\n",
        "    midx = self._xor_idx(aidx, bidx)\n",
        "    midx = midx.reshape(apre + bpre + (d_idx,))\n",
        "    mans = MTensor(mdot, midx, self.indexer)\n",
        "    return mans"
      ],
      "metadata": {
        "id": "O0XHlVtxgxMM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funções auxiliares"
      ],
      "metadata": {
        "id": "tZBrWrSFD72R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x, W):\n",
        "  \"\"\"\n",
        "  x: N x d_in\n",
        "  W: d_out x d_in\n",
        "  \"\"\"\n",
        "  return x @ W.T\n",
        "\n",
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  ###\n",
        "  # index_match = (pred_index.mean(dim=0) @ true_index.mean(dim=0).T)\n",
        "  # match_loss_lr = huber(y_pred, y_true @ index_match.T)\n",
        "  # match_loss_rl = huber(y_true, y_pred @ index_match)\n",
        "  ###\n",
        "  # index_match: N x d_out x d_out\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  # index_match_pred_true = nn.functional.softmax(index_match, dim=2)\n",
        "  # index_match_true_pred = nn.functional.softmax(index_match, dim=1)\n",
        "  # y_true_match: N x 1 x d_out\n",
        "  # y_pred_match: N x 1 x d_out\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  # y_true_match = torch.bmm(y_true.unsqueeze(1), index_match_pred_true.permute(0, 2, 1))\n",
        "  # y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match_true_pred)\n",
        "  huber = nn.HuberLoss()\n",
        "  match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  match_loss_reg = huber(\n",
        "      torch.bmm(index_match.permute(0, 2, 1), index_match),\n",
        "      torch.bmm(index_match, index_match.permute(0, 2, 1))\n",
        "      # torch.eye(d_out).unsqueeze(0).repeat(n, 1, 1)\n",
        "  )\n",
        "  loss = match_loss_lr + match_loss_rl + 100 * match_loss_reg\n",
        "  return loss"
      ],
      "metadata": {
        "id": "eCR6VV4NXpjw"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inicialização de parâmetros"
      ],
      "metadata": {
        "id": "zm9Ndc2CTb3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 5\n",
        "out_dim = 10\n",
        "index_dim = in_dim + out_dim # making things easier\n",
        "__hidden_dim = 5 * index_dim\n",
        "num_examples = 1000\n",
        "\n",
        "# Ground-truth parameters\n",
        "W_true = torch.randn((out_dim, in_dim), requires_grad=False)\n",
        "W_true = W_true.float().to(device)\n",
        "\n",
        "# Parameters to be trained\n",
        "bag_values_W = nn.Parameter(torch.randn((out_dim, in_dim)))\n",
        "bag_values_W = bag_values_W.float().to(device)\n",
        "bag_indices_W = nn.Parameter(torch.randn((out_dim, in_dim, index_dim)))\n",
        "# bag_indices_W = nn.Parameter(\n",
        "#     torch.eye(index_dim)[:in_dim].unsqueeze(0).repeat(out_dim, 1, 1)\n",
        "#     + torch.eye(index_dim)[in_dim:].unsqueeze(1).repeat(1, in_dim, 1)\n",
        "# )\n",
        "bag_indices_W = bag_indices_W.float().to(device)\n",
        "###\n",
        "# Indexer model to be trained\n",
        "# indexer = nn.Sequential(\n",
        "#     nn.Linear(index_dim, __hidden_dim),\n",
        "#     # nn.Dropout(0.5),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(__hidden_dim, index_dim),\n",
        "# ).to(device)\n",
        "indexer = nn.Identity().to(device)\n",
        "__W = MTensor(bag_values_W, bag_indices_W, indexer)\n",
        "###\n",
        "\n",
        "# Input data\n",
        "values_x = 1e0 * torch.randn((num_examples, in_dim))\n",
        "index_x = torch.eye(index_dim)[:in_dim]\n",
        "index_x = index_x.unsqueeze(0).repeat(num_examples, 1, 1)\n",
        "\n",
        "# Ground-truth target\n",
        "y_true = y(values_x, W_true)\n",
        "y_true_index = torch.eye(index_dim)[in_dim:]\n",
        "y_true_index = y_true_index.unsqueeze(0).repeat(num_examples, 1, 1)"
      ],
      "metadata": {
        "id": "UHC_bTf1GumV"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Treino para aproximar função f(x) = Wx"
      ],
      "metadata": {
        "id": "RrTiawhcEAO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Optimize optimization of index and parameters. Is it possible in the\n",
        "###       general case?\n",
        "###       Analyse positional encoding of input and ouput versus multi one-hot.\n",
        "###       Analyse parameterized positional encoding for the learnable indices.\n",
        "\n",
        "# opt_vectors = Adam([bag_values_W, bag_indices_W], lr=1e-2)\n",
        "opt_vectors = Adam([__W.data, __W.idx], lr=1e-3) # \n",
        "# opt_vectors = Adam([__W.data], lr=1e-1)\n",
        "# opt_indexer = Adam(indexer.parameters(), lr=3e-4)\n",
        "\n",
        "num_epochs = 80\n",
        "batch_size = 32\n",
        "epoch_len = num_examples // batch_size\n",
        "\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_losses = []\n",
        "  for _ in range(epoch_len):\n",
        "    batch_idx = np.random.choice(num_examples, batch_size)\n",
        "    batch_x = values_x[batch_idx].float().to(device)\n",
        "    batch_x_index = index_x[batch_idx].float().to(device)\n",
        "    ###\n",
        "    __batch_x = MTensor(batch_x, batch_x_index, indexer)\n",
        "    ###\n",
        "    batch_y_true = y_true[batch_idx].float().to(device)\n",
        "    batch_y_true_index = y_true_index[batch_idx].float().to(device)\n",
        "    # y_pred_val, y_pred_index = gbmd(\n",
        "    #     batch_x, bag_values_W, batch_x_index, bag_indices_W, indexer\n",
        "    # )\n",
        "    ###\n",
        "    # __W_idx = __W.idx.clone()\n",
        "    # __W_idx[:, :, :in_dim] = nn.functional.softmax(__W_idx.clone()[:, :, :in_dim], dim=-1)\n",
        "    # __W_idx[:, :, in_dim:] = nn.functional.softmax(__W_idx.clone()[:, :, in_dim:], dim=-1)\n",
        "    # __W2 = MTensor(__W.data, __W_idx, indexer)\n",
        "    # __y_pred = __batch_x @ __W2\n",
        "    __y_pred = __batch_x @ __W\n",
        "    y_pred_val, y_pred_index = __y_pred.data, __y_pred.idx\n",
        "    ###\n",
        "    loss = maromba_loss(\n",
        "        batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "    )\n",
        "    opt_vectors.zero_grad()\n",
        "    # opt_indexer.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_vectors.step()\n",
        "    # opt_indexer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  all_losses.append(np.mean(epoch_losses))\n",
        "  df_train = pd.DataFrame({\n",
        "      \"train loss\": all_losses,\n",
        "  })\n",
        "  display.clear_output(wait=True)\n",
        "  df_train.plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TmZOcAvg-Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "5e8edfd3-8363-4a11-b540-77a24809646e"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x144 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABWMAAACMCAYAAAAZfruAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj1UlEQVR4nO3deXhc9X3v8c93RpsXeUGWHWPZyKzekfESJ2YJSyiQFAw3gHlIQ3rT0MVpEprS6/Y+bUPa3JKEbDRbHUpK0xYIEBKaUBpKSCAkgGVjwGAHg7GxjBdZYBsvkjUz3/vHnJHOjEayrRnNkUbv1/PomXN+Z/ue0Q9JfM7PvzF3FwAAAAAAAABgYMWiLgAAAAAAAAAAhgPCWAAAAAAAAAAoAcJYAAAAAAAAACgBwlgAAAAAAAAAKAHCWAAAAAAAAAAoAcJYAAAAAAAAACiBiqgLkKQJEyZ4Y2Nj1GUAAAAAAAAAQEHWrFmzx93r820bFGFsY2Ojmpuboy4DAAAAAAAAAApiZlt728Y0BQAAAAAAAABQAoSxAAAAAAAAAFAChLEl5u76vw++qK88+krUpQAAAAAAAAAooaPOGWtmd0r6oKTd7j4naDtB0r2SGiVtkXSNu79tZibp65Iuk3RI0kfdfe3AlD40mZneOnhE/7V+p1acf4qqK+JRlwQAAAAAAIBhprOzUy0tLWpvb4+6lCGrpqZGDQ0NqqysPOZjjuUDvP5F0jck/WuobaWkx9z9VjNbGaz/H0mXSjot+Hq3pG8HrwhZvnia/mv9Tj368i59cN6JUZcDAAAAAACAYaalpUW1tbVqbGxUenwljoe7q62tTS0tLZo+ffoxH3fUaQrc/QlJb+U0XyHprmD5LknLQu3/6mlPSxpnZpOPuZph4pxTJ2jKuBG6d/W2qEsBAAAAAADAMNTe3q66ujqC2H4yM9XV1R33yOL+zhk7yd13BMs7JU0KlqdICieMLUEbQmIx0zULp+rJTXu07a1DUZcDAAAAAACAYYggtjD9ef8K/gAvd3dJfrzHmdmNZtZsZs2tra2FljHkXLOoQTETo2MBAAAAAAAw7Ozdu1ff+ta3+nXsZZddpr179x7z/p/97Gd122239etaxdbfMHZXZvqB4HV30L5d0tTQfg1BWw/uvsrdF7r7wvr6+n6WMXRNHjtC7ztjou5bs02JZCrqcgAAAAAAAICS6SuMTSQSfR778MMPa9y4cQNQ1cDrbxj7kKQbguUbJP041P4RS1siaV9oOgPkWL5oqnbt79Djvx1+I4MBAAAAAAAwfK1cuVKvvfaampqadPPNN+sXv/iFzjnnHF1++eWaNWuWJGnZsmVasGCBZs+erVWrVnUd29jYqD179mjLli2aOXOmPv7xj2v27Nm6+OKLdfjw4T6vu27dOi1ZskTz5s3TlVdeqbfffluSdPvtt2vWrFmaN2+eli9fLkn65S9/qaamJjU1NWn+/Pl65513Cr7vo4axZna3pN9IOsPMWszsY5JulfR+M9sk6aJgXZIelrRZ0quSvivpTwqusIydP2Oi6murde/qN6IuBQAAAAAAACiZW2+9VaeccorWrVunL33pS5KktWvX6utf/7peeeUVSdKdd96pNWvWqLm5Wbfffrva2tp6nGfTpk1asWKFXnrpJY0bN04PPPBAn9f9yEc+oi984Qt64YUXNHfuXN1yyy1d9Tz33HN64YUX9J3vfEeSdNttt+mb3/ym1q1bpyeffFIjRowo+L4rjraDu1/Xy6YL8+zrklYUWtRwURmP6eoFDfrOL1/Tzn3tetfYmqhLAgAAAAAAwDBzy3++pJff3F/Uc846cYz+9ndnH9cxixcv1vTp07vWb7/9dj344IOSpG3btmnTpk2qq6vLOmb69OlqamqSJC1YsEBbtmzp9fz79u3T3r17dd5550mSbrjhBl199dWSpHnz5un666/XsmXLtGzZMknS0qVL9Wd/9me6/vrrddVVV6mhoeG47iefgj/AC4W5dtFUpVy6r5kP8gIAAAAAAMDwNWrUqK7lX/ziF/qf//kf/eY3v9Hzzz+v+fPnq729vccx1dXVXcvxePyo88325qc//alWrFihtWvXatGiRUokElq5cqXuuOMOHT58WEuXLtXGjRv7de6wo46MxcA6qW6Ulp5ap3ubt2nF+acqFrOoSwIAAAAAAMAwcrwjWIuhtra2zzlY9+3bp/Hjx2vkyJHauHGjnn766YKvOXbsWI0fP15PPvmkzjnnHH3/+9/Xeeedp1QqpW3btun888/X2WefrXvuuUcHDhxQW1ub5s6dq7lz52r16tXauHGjZsyYUVANjIwdBK5dNE0tbx/WU6/tiboUAAAAAAAAYMDV1dVp6dKlmjNnjm6++eYe2y+55BIlEgnNnDlTK1eu1JIlS4py3bvuuks333yz5s2bp3Xr1ulv/uZvlEwm9eEPf1hz587V/Pnz9clPflLjxo3T1772Nc2ZM0fz5s1TZWWlLr300oKvb+lpXqO1cOFCb25ujrqMyHQkklry/x7Te0+ZoG9ef1bU5QAAAAAAAKDMbdiwQTNnzoy6jCEv3/toZmvcfWG+/RkZOwhUV8R11VkN+tnLO9V2oCPqcgAAAAAAAAAMAMLYQWL5oqnqTLoeWNsSdSkAAAAAAAAABgBh7CBx2qRaLThpvO5ZvU2DYeoIAAAAAAAAAMVFGDuILF80VZtbD2r1lrejLgUAAAAAAABljgGBhenP+0cYO4h8YN5k1VZX6J5n34i6FAAAAAAAAJSxmpoatbW1Ecj2k7urra1NNTU1x3VcxQDVg34YWVWhK+afqPuaW/S3vztbY0dWRl0SAAAAAAAAylBDQ4NaWlrU2toadSlDVk1NjRoaGo7rGMLYQWb5omn6t6ff0I/WbdcN722MuhwAAAAAAACUocrKSk2fPj3qMoYdpikYZOZMGas5U8bo7mffYJg4AAAAAAAAUEYIYweh5YumaePOd/RCy76oSwEAAAAAAABQJISxg9AVTSdqRGVc96zmg7wAAAAAAACActHvMNbMzjCzdaGv/Wb2aTP7rJltD7VfVsyCh4Pamkp9YN5kPbTuTR3sSERdDgAAAAAAAIAi6HcY6+6/dfcmd2+StEDSIUkPBpu/mtnm7g8Xoc5h57rFU3XwSFL/+fybUZcCAAAAAAAAoAiKNU3BhZJec/etRTrfsHfWtPE6beJo3bN6W9SlAAAAAAAAACiCYoWxyyXdHVr/hJm9YGZ3mtn4Il1jWDEzLV88Teu27dXGnfujLgcAAAAAAABAgQoOY82sStLlku4Lmr4t6RRJTZJ2SPpyL8fdaGbNZtbc2tpaaBll6ar5U1QVj+meZxkdCwAAAAAAAAx1xRgZe6mkte6+S5LcfZe7J909Jem7khbnO8jdV7n7QndfWF9fX4Qyys/4UVX6nTnv0g/Xtqi9Mxl1OQAAAAAAAAAKUIww9jqFpigws8mhbVdKWl+Eawxb1y2aqv3tCT2yfmfUpQAAAAAAAAAoQEFhrJmNkvR+ST8MNX/RzF40sxcknS/ppkKuMdwtOblOJ9WN1N3PvhF1KQAAAAAAAAAKUFHIwe5+UFJdTtvvFVQRssRipmsXTdUXH/mtNrce0Mn1o6MuCQAAAAAAAEA/FGOaAgywD53VoHjMdO9qPsgLAAAAAAAAGKoIY4eAiWNqdOGMibp/TYuOJFJRlwMAAAAAAACgHwhjh4jrFk9T28EjemzDrqhLAQAAAAAAANAPhLFDxLmn12vy2BrdzVQFAAAAAAAAwJBEGDtExGOmqxdO1ZObWrXtrUNRlwMAAAAAAADgOBHGDiHXLGyQJN3XzOhYAAAAAAAAYKghjB1CGsaP1Lmn1esHzS3qTPJBXgAAAAAAAMBQQhg7xHx0aaN27m/XN37+atSlAAAAAAAAADgOhLFDzPlnTNRV86foG4+/qufeeDvqcgAAAAAAAAAcI8LYIeizV8zWu8bU6KZ71+nQkUTU5QAAAAAAAAA4BoSxQ9CYmkp9+ZoztfWtQ/r8TzdEXQ4AAAAAAACAY0AYO0QtOblOHz/nZP37M2/o5xt3RV0OAAAAAAAAgKMgjB3CPnPx6Zrxrlr9xf0vqu1AR9TlAAAAAAAAAOgDYewQVl0R11evbdL+w536yx++KHePuiQAAAAAAAAAvSCMHeJmTh6jP/+d0/Wzl3fpvjUtUZcDAAAAAAAAoBcFhbFmtsXMXjSzdWbWHLSdYGaPmtmm4HV8cUpFb/7g7JO15OQTdMtDL2nbW4eiLgcAAAAAAABAHsUYGXu+uze5+8JgfaWkx9z9NEmPBesYQLGY6barz1TMTDfdu07JFNMVAAAAAAAAAIPNQExTcIWku4LluyQtG4BrIEfD+JH63LLZat76tv7pideiLgcAAAAAAABAjkLDWJf0MzNbY2Y3Bm2T3H1HsLxT0qQCr4FjtKxpij4wd7K++ugrWr99X9TlAAAAAAAAAAgpNIw9293PknSppBVmdm54o7u70oFtD2Z2o5k1m1lza2trgWVAksxMf79sjsaPrNJN965Te2cy6pIAAAAAAAAABAoKY919e/C6W9KDkhZL2mVmkyUpeN3dy7Gr3H2huy+sr68vpAyEjB9VpS9dfaY27T6gLz7y26jLAQAAAAAAABDodxhrZqPMrDazLOliSeslPSTphmC3GyT9uNAicXzOO71eN7znJN351Ot66tU9UZcDAAAAAAAAQIWNjJ0k6Vdm9rykZyX91N0fkXSrpPeb2SZJFwXrKLGVl87UKfWj9JkfPK99hzqjLgcAAAAAAAAY9vodxrr7Znc/M/ia7e6fD9rb3P1Cdz/N3S9y97eKVy6O1YiquL56bZP2HOjQX/94fdTlAAAAAAAAAMNeoR/ghUFsXsM4ferC0/TQ82/qx+u2R10OAAAAAAAAMKwRxpa5P37fKTpr2jj99Y/W6829h6MuBwAAAAAAABi2CGPLXEU8pq9c06REynXz/c8rlfKoSwIAAAAAAACGJcLYYaBxwij99Qdn6alX2/S9X2+JuhwAAAAAAABgWCKMHSaWL5qqi2ZO1Bce2aiX39wfdTkAAAAAAADAsEMYO0yYmf7hqnkaO6JSy1f9Rk+80hp1SQAAAAAAAMCwQhg7jNTXVuvBP3mvThw3Qh/93rO681evy505ZAEAAAAAAIBSIIwdZhrGj9QDf/xeXTRzkj73k5e18oEXdSSRirosAAAAAAAAoOwRxg5Do6or9J0PL9CfXnCq7m3epuvveFp7DnREXRYAAAAAAABQ1ghjh6lYzPSZi8/QP143Xy+07NMV33iKD/YCAAAAAAAABhBh7DD3u2eeqPv/6L1Kplwf+s6v9cj6nVGXBAAAAAAAAJQlwlhobsNYPfSJpTptUq3+6N/W6B8f28QHewEAAAAAAABFRhgLSdLEMTW698YlunL+FH350Vf0p3c/p8NHklGXBQAAAAAAAJSNiqgLwOBRUxnXV645U6dPqtUX/3ujtrYd0qqPLNDksSOiLg0AAAAAAAAY8hgZiyxmpj9+3yn67u8t1ObWA7r8G0/puTfejrosAAAAAAAAYMjrdxhrZlPN7HEze9nMXjKzTwXtnzWz7Wa2Lvi6rHjlolQumjVJD65YqhGVcV276mk9+FxL1CUBAAAAAAAAQ1ohI2MTkj7j7rMkLZG0wsxmBdu+6u5NwdfDBVeJSJw+qVY/WrFUZ00bp5vufV7/8F8blEzxwV4AAAAAAABAf/Q7jHX3He6+Nlh+R9IGSVOKVRgGhxNGVen7H3u3rn/3NP3TLzfrI3c+ozVbmbYAAAAAAAAAOF5FmTPWzBolzZf0TND0CTN7wczuNLPxxbgGolMZj+nzV87V3y+bo/Xb9+t/ffvX+tC3f62fvbRTKUbKAgAAAAAAAMfE3AsL08xstKRfSvq8u//QzCZJ2iPJJf2dpMnu/r/zHHejpBsladq0aQu2bt1aUB0ojYMdCf2geZvuePJ1bd97WCfXj9LHzzlZV86foprKeNTlAQAAAAAAAJEyszXuvjDvtkLCWDOrlPQTSf/t7l/Js71R0k/cfU5f51m4cKE3Nzf3uw6UXiKZ0k9f3KFVT2zWS2/u14TR1fr9pY368LtP0tiRlVGXBwAAAAAAAERiQMJYMzNJd0l6y90/HWqf7O47guWbJL3b3Zf3dS7C2KHL3fXr19r0T09s1hOvtGpkVVzXLpqqj509XQ3jR0ZdHgAAAAAAAFBSAxXGni3pSUkvSkoFzX8l6TpJTUpPU7BF0h9mwtneEMaWhw079uu7T2zWQ8+/KZf0gbmTdeO5J2vOlLFRlwYAAAAAAACUxIBNU1AshLHl5c29h/W9p17X3c9u04GOhM4+dYJuPPdknXPaBKUHVAMAAAAAAADliTAWkdjf3qn/eOYNfe+p17Vrf4dmvKtWy+ZP0YUzJurUiaMJZgEAAAAAAFB2CGMRqSOJlH68brv+9Tdb9eL2fZKkaSeM1AUzJurCmRO1ePoJqq6IR1wlAAAAAAAAUDjCWAwaO/Yd1s837tbPN+zWr17do45ESqOq4jr39HpdMGOizp8xURNGV0ddJgAAAAAAANAvhLEYlA4fSerXr+3RY0E4u3N/u8ykpqnjdOGMibpw5iTNeFct0xkAAAAAAABgyCCMxaDn7nrpzf16bMNu/XzjLj3fkp7O4MSxNbpgZjqYXdx4gkZVV0RcKQAAAAAAANA7wlgMObvfadfjG3frsQ279eSmPTrcmZQkTaytVmPdKDVOGKmT6kZp+oRROqlupBrrRhHUAgAAAAAAIHKEsRjS2juTenpzm156c7+27DmoLW0HtaXtkFrf6cjar762WtPrgnB2wig1hpZHE9QCAAAAAACgBAhjUZYOdCS0te2gtrYd0ut7Dmpr20Ft2XNIW9oOandOUDthdJXqa2tUX1ut+tHVmlBbpfrR1V3r9bXpr7EjKpmjFgAAAAAAAP3WVxjLcEEMWaOrKzT7xLGafeLYHtsOdiS0te2QtrYd1OttB7XtrfRI2tYDR/Ta7gNqfadDR5KpHsdVxk0TckLaCaOrNW5kpcaMqNSYmkqNGVGhMTWVGhusj66pUDxGgAsAAAAAAIC+EcaiLI2qrtCsE8do1olj8m53d+0/nFDrgY4gpA1e3+nQnmB5x752vbB9n9oOdCh1lAHktdUVGjOiUrU1FT1C29qaCo2oimtEZfBVFVdNaHlEZbAeLI+siqu6IsYIXQAAAAAAgDJDGIthycw0dmSlxo6s1KkTR/e5bzLlOtCR0P7Dndrf3qn9hxPBa6f2t+dv3773sDbsSLe/057oV43pkDammsp0OJt5ra6Iq7oylrMcbAstd++f5xzBuasrer4yyhcAAAAAAGBgEMYCRxGPmcaOSE9L0B/uro5ESoePJHW4M/g6klR7aPlwZ7B+JKnDnamu9UNHEuroTKkjkVJHIqmORErtnUkd6Eio7UB3W6a9I5HSkUTP6ReOR2XcugLdiripIpZ+jcdMlbFMm6kiHku3xU3xWEyVsWCfoD0T/o6oiqumIqaaqrhqKjKjgGPp5a62WLBfev/qipgq4+lrVcZiihEQAwAAAACAMkAYCwwwM1NNMBXB+BJcL5VyHUkGAW5nMiuo7Ugk1d6Z57Vrv+xtiaQrkXIlUqn0azKlZMrVmfTgNaWOzpQ6U8nQtvS+R4LrpoPlwgLieCwdAFcFAW1FPNa9HATA6a/ubZXxoL0iHRRnlsPb0vuGjq+IqSJmipvJLH3deMxklm6LmRQLtsdiUsxMMUvvk3mtjJuqghHJVfH0yOWqeExVFemviuB8AAAAAABg+CGMBcpMLGaqiaXDX/VzNG+xZUYHtwfBbNdI4OC1I6etozOlRCqlzmQ63O1MppRIetd6IpXSkUQQEifT4XMiFAIf7kxqf3t6lHD6eM957W4vNTN1hbOZqSaqKrrD5ZiZYrF08BsPLweBb3f4mx0GZ0YlV1VYEDinr5F5rcpZT4+A7l6PByFzPGZdgXPmvJlrV8R6314ZjKKujBM2AwAAAADQG8JYAAMuPDp4MHFPB7yJVEqdiSDUTaWU8vQI42TKlfLMV3r+4GTK5S4lM+1d+6l7tHAipSPJdBjckUjqSDB9xJGs9lTXtBLptmTX+ZOerq3r+imlRx4H18tcK1Nb5rjOIJjuTGYH0aWWnsYiNK1FnpHMmSkwquKxrlHG3aOQlR1K5xmdHMusx0zxWM9gOr3cHWh37xtazoTcofNZOPgOheIWDsFD4XTmXitisaxpOirjlr0eiyke7z4mc08AAAAAgOFlQMJYM7tE0tclxSXd4e63DsR1AKAQZpYeSaqYVBV1NQMjlXJ1pjLhrHeFtB2J7tD2SDDFRHcYnA59E6kgbA4FvpkQOJmSkqn0cYnMVxD+hkc1J/KsZ6ayyIxQTnk6bE55bhCtIHxO1+DhELqrLnUF0pm2TICdqXuwsszo55xpL8LTYZjljIzOBNc5I5MrglC5IhMUx8OjmWOKx6SKYP7luKX7vil4NcmUPq9Zui4pfd30tsyyddUcz71erDvszrSF6+sOwdPXUeh6sZxaMuuxWPraFlw7PFo8PDVI5rzhoL07rO/ZHgvuybre8+yaMuuZ6wIAAABAMRU9jDWzuKRvSnq/pBZJq83sIXd/udjXAgD0LRYzVcfiqq4YXKOSSykcKHcHt91hrXsmxA2Fv5kwODT62HNGJCcycyenXMkgcM6Mjk6mPHvO5WR47uV0u3t3sB1e7h6NnVuTumrN1JGpIRyYJ1IeTPXhPUL2rtHdSt+PB+G3K72cCi1L6etntqeC9yDlQVDvmfuI9Ns7oDJBdSa8zrRJ6UA3WAi/5N0nlhWAd4fLmVcpE0TnCb9DIXc8FusaWd31Gu+lPTTqOzts7xnA5wbk6TC8+55l3cF45l7D95g5JnPzXfcZDvVzw/ZwPaH3KBYc3BW+h47LfmiRPVI9HKJn7ie3xq7vUy/t4fcmXG8sdP/dbaHvWe49hc+b873v8Z5Z9rqFrqeuByI5/SdUS+6xvfZFHiwAAAAMGgMxMnaxpFfdfbMkmdk9kq6QRBgLACi5WMwUk2mQzZJRNjIjmROp7GkzcgPgTMDtQcjcHfYGIXDwKmWvu7qPCY+Azh6lHQ7RQ6GzZ4fu3QF7EDKH1ruuHQriM8ekq1BX8Oxd955ZDyXSPfbJXEehEDwIuEPbJM95L7pD+kywnv2aDvnTwXsyuz2zX7L399NdOTWkG1Kh2jL36Fn35VnvQ+Zewu8HBr+scFo9w151Bbw9A9/uEDl/uJ/7cCE34A6fMxPOK3TOTD2Z+vKF6j1qtt5H2WeH/qFtOfl0n2F2nv2y6wvfZ8/APHx/PcP5nGv3+rAgu72v64YfSFjuPlnfw57HZx6I5P/+Fx7s93hQ03U/3dcMPxjKPJzJ/f6Hvwf5rtFzv3DnyT4293uf3c+6j8/X/8L31L0cPkfOw6A+rhe+Vm6dvR6T5/zKW4/l1Nbzv+vch0n57i1fnT3vL1RIjmP/Hva839zrZdXYx/vTo8aj1p+n7rw15mkMnTf3QMvf3ONnSu7+4fPlff/y7Je3rqP8p3s8NeXuA+D4DUQYO0XSttB6i6R3D8B1AABAxMyCeXMJuxGSSmUH6eHR2KmcMNpzwuJwQBweHZ4bkmfC9/C+6alJcgPjYDknOPZQcp5p76pJ2QF1vgcJWSG3Zx/bdS3PF2CH3o+gmK72rvcgvaw8+2eth66Z2Tejt4cImYZwdp5de3Bs+F7yXDv8nmbaMw9Ych8u5N5f+D5zvzd5g/+chyK5Dzuy+1pOnwrV1tVn1P3AIe971Mv7lPv+Zvp05pr5vl9Z95e7b9a1s+9XucfmOXf4vQ6/r+EHLLnt2X0v93yeVRMA9EePwLzHdut1e89j+z5Zvx7I9LFf7+c8tpD+WHc46ntynO/h8dR19By9j3Mf13vWs+0Hf/genVQ36mgFDAuRfYCXmd0o6UZJmjZtWlRlAAAAoMhisa4xRpHWAaB/coPuYoS0qZzAOjwVTu7DhXCQngm9e9Sono3598u+r3z7hUPxnm35AvR8Dwf6fojQ1/VyHwjkC+yVZ9/wg5EebVkPVfIH71mBfB8PC/Jd+1juI/uej60D5TtnX++PjlJD3gceORfL3fdodfd2J9kPbPo+R8/98/e9nm099zuao733vdfdd325++crKnd7j/8W+rif4zm294KOrz8e7WdIX/tlH9P7Dkc99jjfw2O97jFdu1/HHtvPYkkaUcXojYyBCGO3S5oaWm8I2rK4+ypJqyRp4cKFBf5qBwAAAAAUQ+aftQdrUZYCAEDZiQ3AOVdLOs3MpptZlaTlkh4agOsAAAAAAAAAwJBR9JGx7p4ws09I+m9JcUl3uvtLxb4OAAAAAAAAAAwlAzJnrLs/LOnhgTg3AAAAAAAAAAxFdqwTaQ9oEWatkrZGXUeJTZC0J+oiUPboZygF+hlKgX6GUqCfoRToZygV+hpKgX6GUhiK/ewkd6/Pt2FQhLHDkZk1u/vCqOtAeaOfoRToZygF+hlKgX6GUqCfoVToaygF+hlKodz62UB8gBcAAAAAAAAAIAdhLAAAAAAAAACUAGFsdFZFXQCGBfoZSoF+hlKgn6EU6GcoBfoZSoW+hlKgn6EUyqqfMWcsAAAAAAAAAJQAI2MBAAAAAAAAoAQIY0vMzC4xs9+a2atmtjLqelA+zOxOM9ttZutDbSeY2aNmtil4HR9ljRj6zGyqmT1uZi+b2Utm9qmgnb6GojGzGjN71syeD/rZLUH7dDN7Jvgdeq+ZVUVdK4Y+M4ub2XNm9pNgnX6GojKzLWb2opmtM7PmoI3fmygqMxtnZveb2UYz22Bm76GfoZjM7Izg51jma7+ZfZp+hmIzs5uC/wdYb2Z3B/9vUFZ/nxHGlpCZxSV9U9KlkmZJus7MZkVbFcrIv0i6JKdtpaTH3P00SY8F60AhEpI+4+6zJC2RtCL4OUZfQzF1SLrA3c+U1CTpEjNbIukLkr7q7qdKelvSx6IrEWXkU5I2hNbpZxgI57t7k7svDNb5vYli+7qkR9x9hqQzlf65Rj9D0bj7b4OfY02SFkg6JOlB0c9QRGY2RdInJS109zmS4pKWq8z+PiOMLa3Fkl51983ufkTSPZKuiLgmlAl3f0LSWznNV0i6K1i+S9KyUtaE8uPuO9x9bbD8jtJ/6E8RfQ1F5GkHgtXK4MslXSDp/qCdfoaCmVmDpA9IuiNYN9HPUBr83kTRmNlYSedK+mdJcvcj7r5X9DMMnAslvebuW0U/Q/FVSBphZhWSRkraoTL7+4wwtrSmSNoWWm8J2oCBMsnddwTLOyVNirIYlBcza5Q0X9Izoq+hyIJ/Or5O0m5Jj0p6TdJed08Eu/A7FMXwNUl/ISkVrNeJfobic0k/M7M1ZnZj0MbvTRTTdEmtkr4XTLtyh5mNEv0MA2e5pLuDZfoZisbdt0u6TdIbSoew+yStUZn9fUYYCwwT7u5K/88AUDAzGy3pAUmfdvf94W30NRSDuyeDfwbXoPS/LJkRbUUoN2b2QUm73X1N1LWg7J3t7mcpPVXZCjM7N7yR35soggpJZ0n6trvPl3RQOf9UnH6GYgnm6rxc0n252+hnKFQw5/AVSj9kOlHSKPWcjnHII4wtre2SpobWG4I2YKDsMrPJkhS87o64HpQBM6tUOoj9d3f/YdBMX8OACP6Z5eOS3iNpXPDPlSR+h6JwSyVdbmZblJ466gKl51ykn6GoglE+cvfdSs+vuFj83kRxtUhqcfdngvX7lQ5n6WcYCJdKWuvuu4J1+hmK6SJJr7t7q7t3Svqh0n+zldXfZ4SxpbVa0mnBp8BVKT20/6GIa0J5e0jSDcHyDZJ+HGEtKAPBfIr/LGmDu38ltIm+hqIxs3ozGxcsj5D0fqXnJ35c0oeC3ehnKIi7/6W7N7h7o9J/k/3c3a8X/QxFZGajzKw2syzpYknrxe9NFJG775S0zczOCJoulPSy6GcYGNepe4oCiX6G4npD0hIzGxn8v2fm51lZ/X1m6VHkKBUzu0zp+cniku50989HWxHKhZndLel9kiZI2iXpbyX9SNIPJE2TtFXSNe6e+yFfwDEzs7MlPSnpRXXPsfhXSs8bS19DUZjZPKUn5o8r/eD4B+7+OTM7WekRjCdIek7Sh929I7pKUS7M7H2S/tzdP0g/QzEF/enBYLVC0n+4++fNrE783kQRmVmT0h9GWCVps6TfV/A7VPQzFEnwUOkNSSe7+76gjZ9nKCozu0XStZISSv8t9gdKzxFbNn+fEcYCAAAAAAAAQAkwTQEAAAAAAAAAlABhLAAAAAAAAACUAGEsAAAAAAAAAJQAYSwAAAAAAAAAlABhLAAAAAAAAACUAGEsAAAAAAAAAJQAYSwAAAAAAAAAlABhLAAAAAAAAACUwP8HdsAXv1l3Rm8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(all_losses[-5:]))\n",
        "# y_pred_index.shape, batch_y_true_index.shape\n",
        "index_match = (y_pred_index[0] @ batch_y_true_index[0].T)\n",
        "print(index_match.sum(dim=-1))\n",
        "print(index_match.sum(dim=0))"
      ],
      "metadata": {
        "id": "82uoeJaS9BbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbab8fa5-6e23-48f2-8434-8e0594e72c2d"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06446360692141519\n",
            "tensor([ 0.1650, -1.0759,  0.6731, -0.5285,  0.2113, -0.7789, -2.2170,  1.4002,\n",
            "        -0.7035,  0.2146], grad_fn=<SumBackward1>)\n",
            "tensor([-0.2169,  0.5113, -1.0688, -0.1605, -0.0818,  1.4831, -1.2566, -0.1413,\n",
            "         0.4437, -2.1517], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index_match com valores \"quebrados\" mas que minimizam a função de custo\n",
        "# possível causa: solução numericamente viável com index_match.T @ index_match != Id\n",
        "print(batch_y_true[0] @ index_match.T)\n",
        "print(y_pred_val[0])\n",
        "print()\n",
        "print(y_pred_val[0] @ index_match)\n",
        "print(batch_y_true[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0AucohQ_IKj",
        "outputId": "7bef8f5c-e265-4e9f-8a6d-b4b87c249b9b"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.6503, -1.8802, -2.1769,  0.6799, -3.7190,  4.6465, -2.2721,  1.5841,\n",
            "        -5.6405, -1.0663], grad_fn=<SqueezeBackward3>)\n",
            "tensor([ 1.7067, -1.8874, -2.2500,  0.6766, -3.7413,  4.3548, -2.2010,  1.4712,\n",
            "        -5.3203, -0.8919], grad_fn=<SelectBackward0>)\n",
            "\n",
            "tensor([ 4.3081,  4.4393,  2.1343, -3.8027, -1.7177, -0.0557,  2.2716,  1.7568,\n",
            "        -3.9791,  1.3936], grad_fn=<SqueezeBackward3>)\n",
            "tensor([ 4.2331,  4.2870,  2.0348, -3.8181, -1.6711, -0.1173,  2.0980,  1.5961,\n",
            "        -3.8857,  1.5254])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (batch_y_true_index[0].T @ batch_y_true_index[0])\n",
        "print(batch_y_true[0] @ (index_match.T @ index_match))\n",
        "print(batch_y_true[0])\n",
        "print()\n",
        "print(y_pred_val[0] @ (index_match @ index_match.T))\n",
        "print(y_pred_val[0])\n",
        "# index_match.T @ index_match"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lgXoW42BvcF",
        "outputId": "3232756c-e495-4bef-a7d3-024476890251"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4.3495,  4.7051,  2.1510, -3.8893, -1.7158, -0.0853,  2.5971,  1.8681,\n",
            "        -4.2215,  1.3010], grad_fn=<SqueezeBackward3>)\n",
            "tensor([ 4.2331,  4.2870,  2.0348, -3.8181, -1.6711, -0.1173,  2.0980,  1.5961,\n",
            "        -3.8857,  1.5254])\n",
            "\n",
            "tensor([ 1.6025, -1.9310, -2.1621,  0.6548, -3.6775,  4.9135, -2.3923,  1.7175,\n",
            "        -5.7571, -1.1133], grad_fn=<SqueezeBackward3>)\n",
            "tensor([ 1.7067, -1.8874, -2.2500,  0.6766, -3.7413,  4.3548, -2.2010,  1.4712,\n",
            "        -5.3203, -0.8919], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_match.T @ index_match - index_match @ index_match.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxlCieOANvcR",
        "outputId": "8b3adf02-d817-496d-a684-fc3977449bf8"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0141,  0.0092,  0.0025,  0.0032,  0.0024, -0.0018, -0.0146,  0.0209,\n",
              "          0.0005, -0.0128],\n",
              "        [ 0.0092, -0.0175,  0.0052, -0.0007, -0.0116, -0.0086, -0.0078, -0.0146,\n",
              "          0.0143, -0.0035],\n",
              "        [ 0.0025,  0.0052, -0.0007,  0.0056,  0.0103, -0.0033,  0.0004,  0.0024,\n",
              "         -0.0056, -0.0235],\n",
              "        [ 0.0032, -0.0007,  0.0056, -0.0049, -0.0038,  0.0021,  0.0095,  0.0074,\n",
              "         -0.0085, -0.0076],\n",
              "        [ 0.0024, -0.0116,  0.0103, -0.0038, -0.0206,  0.0005, -0.0004, -0.0082,\n",
              "         -0.0111,  0.0147],\n",
              "        [-0.0018, -0.0086, -0.0033,  0.0021,  0.0005,  0.0083, -0.0033,  0.0098,\n",
              "         -0.0111, -0.0046],\n",
              "        [-0.0146, -0.0078,  0.0004,  0.0095, -0.0004, -0.0033,  0.0175, -0.0037,\n",
              "          0.0017,  0.0079],\n",
              "        [ 0.0209, -0.0146,  0.0024,  0.0074, -0.0082,  0.0098, -0.0037,  0.0051,\n",
              "         -0.0064, -0.0160],\n",
              "        [ 0.0005,  0.0143, -0.0056, -0.0085, -0.0111, -0.0111,  0.0017, -0.0064,\n",
              "          0.0124,  0.0010],\n",
              "        [-0.0128, -0.0035, -0.0235, -0.0076,  0.0147, -0.0046,  0.0079, -0.0160,\n",
              "          0.0010,  0.0145]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(W_true - __W.data).abs().mean()"
      ],
      "metadata": {
        "id": "f8CuZ6KMihSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffb417e-4e58-429e-a8f5-9abbfa98959c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4143, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = torch.argmax(y_pred_index[0], dim=-1) - in_dim\n",
        "print(idxs)\n",
        "print((batch_y_true[0][idxs] - y_pred_val[0]).abs().mean())\n",
        "print(batch_y_true[0][idxs])\n",
        "print(y_pred_val[0])"
      ],
      "metadata": {
        "id": "KC809FMxPquK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9682dc0-18ce-4868-e4c5-bcb8e6cc6183"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8,  4,  0,  8,  8,  1, -2,  9,  7,  4])\n",
            "tensor(1.5179, grad_fn=<MeanBackward0>)\n",
            "tensor([ 2.0276,  1.8994,  1.9724,  2.0276,  2.0276, -1.2420,  2.0276,  0.7494,\n",
            "        -1.0927,  1.8994])\n",
            "tensor([ 1.8267, -0.5796,  1.5078, -0.3355,  0.1351, -0.8224, -1.6041, -0.3918,\n",
            "        -0.2896,  3.6826], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# idxs = torch.argmax(batch_y_true_index[0], dim=-1) - in_dim\n",
        "# print(idxs)\n",
        "# print((batch_y_true[0] - y_pred_val[0][idxs]).abs().mean())\n",
        "# print(batch_y_true[0])\n",
        "# print(y_pred_val[0][idxs])"
      ],
      "metadata": {
        "id": "ZnoDBUKr7oPQ"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_index[0]"
      ],
      "metadata": {
        "id": "9EcXdnaSscYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maromba_loss(\n",
        "      batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "  )"
      ],
      "metadata": {
        "id": "g61wYaoiOwa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTfxTDtI1gJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}