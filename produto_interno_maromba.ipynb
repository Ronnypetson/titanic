{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1IEGpuSfZ/OC1bh3P89nC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/produto_interno_maromba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3woABE_SOgS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement example of \"Produto Interno Maromba\": fitting linear transform using maromba product"
      ],
      "metadata": {
        "id": "wcumRBtgXbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementação do Tensor Maromba"
      ],
      "metadata": {
        "id": "WpnnNOnmkGTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MTensor:\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module,\n",
        "    ):\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.indexer = indexer\n",
        "\n",
        "  def _gbmd(self, u, v, idxu, idxv) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    'General Batch Maromba Dot'\n",
        "    Shorter implementation for the 'batch maromba dot' operation.\n",
        "    u: M x d_u\n",
        "    v: N x d_v\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u = u.shape\n",
        "    n, d_v = v.shape\n",
        "    d_idx = idxu.shape[-1]\n",
        "    assert (m, d_u, d_idx) == idxu.shape\n",
        "    assert (n, d_v, d_idx) == idxv.shape\n",
        "    # uidxu: M x d_idx\n",
        "    # vidxv: N x d_idx\n",
        "    uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "    vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "    dot = uidxu @ vidxv.T\n",
        "    return dot\n",
        "\n",
        "  def _genidx(self, idxu, idxv):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    # idxu_new: M x d_idx\n",
        "    # idxv_new: N x d_idx\n",
        "    idxu_new = (\n",
        "        self.indexer(idxu.reshape(-1, d_idx))\n",
        "        .reshape(m, d_u, d_idx).mean(dim=1)\n",
        "    )\n",
        "    idxv_new = (\n",
        "        self.indexer(idxv.reshape(-1, d_idx))\n",
        "        .reshape(n, d_v, d_idx).mean(dim=1)\n",
        "    )\n",
        "    idxu_new = idxu_new.unsqueeze(1).repeat(1, n, 1)\n",
        "    idxv_new = idxv_new.unsqueeze(0).repeat(m, 1, 1)\n",
        "    idx_new = idxu_new + idxv_new\n",
        "    # idx_new = nn.functional.gumbel_softmax(idx_new, hard=False, dim=-1)\n",
        "    idx_new = nn.functional.softmax(idx_new, dim=-1)\n",
        "    return idx_new\n",
        "\n",
        "  def _xor_idx(self, idxu, idxv):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    # idxu: (M * d_u) x d_idx x 1\n",
        "    # idxv: (N * d_v) x d_idx x 1\n",
        "    idxu = idxu.reshape(m * d_u, d_idx, 1)\n",
        "    idxv = idxv.reshape(n * d_v, d_idx, 1)\n",
        "    # siiT: M x d_idx x d_idx\n",
        "    # sjjT: N x d_idx x d_idx\n",
        "    siiT = torch.bmm(idxu, idxu.permute(0, 2, 1))\n",
        "    siiT = siiT.reshape(m, d_u, d_idx, d_idx).sum(dim=1)\n",
        "    sjjT = torch.bmm(idxv, idxv.permute(0, 2, 1))\n",
        "    sjjT = sjjT.reshape(n, d_v, d_idx, d_idx).sum(dim=1) ###\n",
        "    # siiT: (M * N) x d_idx x d_idx\n",
        "    # sjjT: (M * N) x d_idx x d_idx\n",
        "    siiT = siiT.unsqueeze(1).repeat(1, n, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    sjjT = sjjT.unsqueeze(0).repeat(m, 1, 1, 1).reshape(m * n, d_idx, d_idx)\n",
        "    # si: (M * N) x d_idx x 1\n",
        "    # sj: (M * N) x d_idx x 1\n",
        "    si = idxu.reshape(m, d_u, d_idx).sum(dim=1).unsqueeze(1)\n",
        "    si = si.repeat(1, n, 1).reshape(m * n, d_idx, 1)\n",
        "    sj = idxv.reshape(n, d_v, d_idx).sum(dim=1).unsqueeze(0)\n",
        "    sj = sj.repeat(m, 1, 1).reshape(m * n, d_idx, 1)\n",
        "    diag_siiT_sjjT = torch.diagonal(torch.bmm(siiT, sjjT), dim1=1, dim2=2)\n",
        "    diag_siiT_sjjT = diag_siiT_sjjT.unsqueeze(-1)\n",
        "    xor_idx = torch.bmm(siiT, sj) + torch.bmm(sjjT, si) - 2 * diag_siiT_sjjT\n",
        "    # xor_idx = torch.bmm(siiT, sj) + torch.bmm(sjjT, si) - diag_siiT_sjjT\n",
        "    xor_idx = xor_idx.reshape(m, n, d_idx) / d_u\n",
        "    # xor_idx = nn.functional.softmax(xor_idx, dim=-1)\n",
        "    return xor_idx\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    mdot = self._gbmd(\n",
        "        self.data.reshape(-1, self.data.shape[-1]),\n",
        "        b.data.reshape(-1, b.data.shape[-1]),\n",
        "        aidx,\n",
        "        bidx\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    # midx = self._genidx(aidx, bidx)\n",
        "    # midx = self._xor_idx(self.indexer(aidx), self.indexer(bidx))\n",
        "    midx = self._xor_idx(aidx, bidx)\n",
        "    midx = midx.reshape(apre + bpre + (d_idx,))\n",
        "    mans = MTensor(mdot, midx, self.indexer)\n",
        "    return mans"
      ],
      "metadata": {
        "id": "O0XHlVtxgxMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funções auxiliares"
      ],
      "metadata": {
        "id": "tZBrWrSFD72R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x, W):\n",
        "  \"\"\"\n",
        "  x: N x d_in\n",
        "  W: d_out x d_in\n",
        "  \"\"\"\n",
        "  return x @ W.T\n",
        "\n",
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  n, d_out = y_true.shape\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  ###\n",
        "  # index_match = (pred_index.mean(dim=0) @ true_index.mean(dim=0).T)\n",
        "  # match_loss_lr = huber(y_pred, y_true @ index_match.T)\n",
        "  # match_loss_rl = huber(y_true, y_pred @ index_match)\n",
        "  ###\n",
        "  # pred_index = nn.functional.softmax(pred_index, dim=-1)\n",
        "  ###\n",
        "  # index_match: N x d_out x d_out\n",
        "  index_match = torch.bmm(pred_index, true_index.permute(0, 2, 1))\n",
        "  # y_true_match: N x 1 x d_out\n",
        "  # y_pred_match: N x 1 x d_out\n",
        "  y_true_match = torch.bmm(y_true.unsqueeze(1), index_match.permute(0, 2, 1))\n",
        "  y_pred_match = torch.bmm(y_pred.unsqueeze(1), index_match)\n",
        "  huber = nn.HuberLoss()\n",
        "  match_loss_lr = huber(y_pred, y_true_match.squeeze(1))\n",
        "  match_loss_rl = huber(y_true, y_pred_match.squeeze(1))\n",
        "  loss = match_loss_lr + match_loss_rl\n",
        "  return loss"
      ],
      "metadata": {
        "id": "eCR6VV4NXpjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inicialização de parâmetros"
      ],
      "metadata": {
        "id": "zm9Ndc2CTb3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 5\n",
        "out_dim = 10\n",
        "index_dim = in_dim + out_dim # making things easier\n",
        "__hidden_dim = 5 * index_dim\n",
        "num_examples = 1000\n",
        "\n",
        "# Ground-truth parameters\n",
        "W_true = torch.randn((out_dim, in_dim), requires_grad=False)\n",
        "W_true = W_true.to(device)\n",
        "\n",
        "# Parameters to be trained\n",
        "bag_values_W = nn.Parameter(torch.randn((out_dim, in_dim), device=device))\n",
        "bag_indices_W = nn.Parameter(\n",
        "    torch.randn((out_dim, in_dim, index_dim), device=device)\n",
        ")\n",
        "# bag_indices_W = nn.Parameter(\n",
        "#     torch.eye(index_dim, device=device)[:in_dim].unsqueeze(0).repeat(out_dim, 1, 1)\n",
        "#     + torch.eye(index_dim, device=device)[in_dim:].unsqueeze(1).repeat(1, in_dim, 1)\n",
        "# )\n",
        "###\n",
        "# Indexer model to be trained\n",
        "# indexer = nn.Sequential(\n",
        "#     nn.Linear(index_dim, __hidden_dim),\n",
        "#     # nn.Dropout(0.5),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(__hidden_dim, index_dim),\n",
        "# ).to(device)\n",
        "indexer = nn.Identity().to(device)\n",
        "__W = MTensor(bag_values_W, bag_indices_W, indexer)\n",
        "###\n",
        "\n",
        "# Input data\n",
        "values_x = 1e0 * torch.randn((num_examples, in_dim)).to(device)\n",
        "index_x = torch.eye(index_dim)[:in_dim]\n",
        "index_x = index_x.unsqueeze(0).repeat(num_examples, 1, 1).to(device)\n",
        "\n",
        "# Ground-truth target\n",
        "y_true = y(values_x, W_true)\n",
        "y_true_index = torch.eye(index_dim)[in_dim:]\n",
        "y_true_index = y_true_index.unsqueeze(0).repeat(num_examples, 1, 1)"
      ],
      "metadata": {
        "id": "UHC_bTf1GumV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Treino para aproximar função f(x) = Wx"
      ],
      "metadata": {
        "id": "RrTiawhcEAO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Optimize optimization of index and parameters. Is it possible in the\n",
        "###       general case?\n",
        "###       Analyse positional encoding of input and ouput versus multi one-hot.\n",
        "###       Analyse parameterized positional encoding for the learnable indices.\n",
        "\n",
        "opt_vectors = Adam([__W.data, __W.idx], lr=1e-3)\n",
        "# opt_indices = Adam([__W.idx], lr=3e-4)\n",
        "# opt_indexer = Adam(indexer.parameters(), lr=3e-4)\n",
        "\n",
        "num_epochs = 80\n",
        "batch_size = 32\n",
        "epoch_len = num_examples // batch_size\n",
        "\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_losses = []\n",
        "  for _ in range(epoch_len):\n",
        "    batch_idx = np.random.choice(num_examples, batch_size)\n",
        "    batch_x = values_x[batch_idx].float().to(device)\n",
        "    batch_x_index = index_x[batch_idx].float().to(device)\n",
        "    ###\n",
        "    __batch_x = MTensor(batch_x, batch_x_index, indexer)\n",
        "    ###\n",
        "    batch_y_true = y_true[batch_idx].float().to(device)\n",
        "    batch_y_true_index = y_true_index[batch_idx].float().to(device)\n",
        "    # y_pred_val, y_pred_index = gbmd(\n",
        "    #     batch_x, bag_values_W, batch_x_index, bag_indices_W, indexer\n",
        "    # )\n",
        "    ###\n",
        "    __y_pred = __batch_x @ __W\n",
        "    y_pred_val, y_pred_index = __y_pred.data, __y_pred.idx\n",
        "    y_pred_index = nn.functional.softmax(y_pred_index, dim=-1)\n",
        "    ###\n",
        "    loss = maromba_loss(\n",
        "        batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "    )\n",
        "    opt_vectors.zero_grad()\n",
        "    # opt_indices.zero_grad()\n",
        "    # opt_indexer.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_vectors.step()\n",
        "    # opt_indices.step()\n",
        "    # opt_indexer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  all_losses.append(np.mean(epoch_losses))\n",
        "  df_train = pd.DataFrame({\n",
        "      \"train loss\": all_losses,\n",
        "  })\n",
        "  display.clear_output(wait=True)\n",
        "  df_train.plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TmZOcAvg-Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# y_pred_index = nn.functional.softmax(y_pred_index, dim=-1)\n",
        "###\n",
        "print(np.mean(all_losses[-5:]))\n",
        "# y_pred_index.shape, batch_y_true_index.shape\n",
        "index_match = (y_pred_index[0] @ batch_y_true_index[0].T)\n",
        "print(index_match.sum(dim=-1))\n",
        "print(index_match.sum(dim=0))"
      ],
      "metadata": {
        "id": "82uoeJaS9BbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_match com valores \"quebrados\" mas que minimizam a função de custo\n",
        "# possível causa: solução numericamente viável com index_match.T @ index_match != Id\n",
        "print(batch_y_true[0] @ index_match.T)\n",
        "print(y_pred_val[0])\n",
        "print()\n",
        "print(y_pred_val[0] @ index_match)\n",
        "print(batch_y_true[0])"
      ],
      "metadata": {
        "id": "D0AucohQ_IKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (batch_y_true_index[0].T @ batch_y_true_index[0])\n",
        "print(batch_y_true[0] @ (index_match.T @ index_match))\n",
        "print(batch_y_true[0])\n",
        "print()\n",
        "print(y_pred_val[0] @ (index_match @ index_match.T))\n",
        "print(y_pred_val[0])\n",
        "# index_match.T @ index_match"
      ],
      "metadata": {
        "id": "6lgXoW42BvcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(index_match.T @ index_match - index_match @ index_match.T).abs().mean()"
      ],
      "metadata": {
        "id": "gxlCieOANvcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(W_true - __W.data).abs().mean()"
      ],
      "metadata": {
        "id": "f8CuZ6KMihSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = torch.argmax(y_pred_index[0], dim=-1) - in_dim\n",
        "print(idxs)\n",
        "print((batch_y_true[0][idxs] - y_pred_val[0]).abs().mean())\n",
        "print(batch_y_true[0][idxs])\n",
        "print(y_pred_val[0])"
      ],
      "metadata": {
        "id": "KC809FMxPquK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idxs = torch.argmax(batch_y_true_index[0], dim=-1) - in_dim\n",
        "# print(idxs)\n",
        "# print((batch_y_true[0] - y_pred_val[0][idxs]).abs().mean())\n",
        "# print(batch_y_true[0])\n",
        "# print(y_pred_val[0][idxs])"
      ],
      "metadata": {
        "id": "ZnoDBUKr7oPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_index[0]"
      ],
      "metadata": {
        "id": "9EcXdnaSscYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maromba_loss(\n",
        "      batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "  )"
      ],
      "metadata": {
        "id": "g61wYaoiOwa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTfxTDtI1gJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}