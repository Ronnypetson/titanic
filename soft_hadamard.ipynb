{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HFAO_DVB2UqU",
        "XUal__xwo1aF",
        "a7mWbfGvkBT1"
      ],
      "authorship_tag": "ABX9TyNJu5YLnuIWuKW31gXxw1Yn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/soft_hadamard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3woABE_SOgS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demonstração PyTorch"
      ],
      "metadata": {
        "id": "HFAO_DVB2UqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = w0 * x² + w1 * x\n",
        "# (y real: y = 2 * x² + 5 * x)\n",
        "#\n",
        "# y = f0(f1(f2(x)))"
      ],
      "metadata": {
        "id": "dMLIykGDXHXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2.0 * torch.ones((2, 2)).float()\n",
        "a.requires_grad = True\n",
        "b = 3.0 * torch.ones((2, 2)).float()\n",
        "b.requires_grad = True"
      ],
      "metadata": {
        "id": "gI0HDYjbSls9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = (a * b).sum()\n",
        "c"
      ],
      "metadata": {
        "id": "g0vhOpWdTbVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()"
      ],
      "metadata": {
        "id": "6t0yCwoSZlwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "9lb7x_evTvEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "16cq_wCLT3aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad = None"
      ],
      "metadata": {
        "id": "4gZn7eNuUZun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad = None"
      ],
      "metadata": {
        "id": "H82KJ-_RaQOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = (a * a + b).mean()"
      ],
      "metadata": {
        "id": "P8gujdeOaRUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "Z_iMO8nRabZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.backward()"
      ],
      "metadata": {
        "id": "NjDyLr7vab8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "Y3Y4C3aWafHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "8Utr61jdamo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x, a, b):\n",
        "  return (a * x * x + b * x).sum(dim=1)\n",
        "\n",
        "def y_real(x):\n",
        "  x = torch.tensor(x).float()\n",
        "  return (2 * x * x + 5 * x).sum(dim=1)\n",
        "\n",
        "# (y real: y = 2 * x * x + 5 * x)"
      ],
      "metadata": {
        "id": "DGYDMd7Manmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import shuffle\n",
        "\n",
        "X = list(range(1000))\n",
        "shuffle(X)\n",
        "X = torch.tensor(X).reshape(-1, 1).float()\n",
        "Y = y_real(X)"
      ],
      "metadata": {
        "id": "XlFabAe6a7DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "2c75VJJKkQZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(0.5).float()\n",
        "b = torch.tensor(0.5).float()\n",
        "\n",
        "a = torch.nn.Parameter(a)\n",
        "b = torch.nn.Parameter(b)\n",
        "\n",
        "optim = torch.optim.Adam([a, b], lr=1e-3)\n",
        "\n",
        "for iter in range(10000):\n",
        "  Y_pred = y(X, a, b)\n",
        "  custo = ((Y - Y_pred).abs()).mean()\n",
        "  optim.zero_grad()\n",
        "  custo.backward()\n",
        "  optim.step()\n",
        "  if iter % 10 == 0:\n",
        "    print(custo.item())"
      ],
      "metadata": {
        "id": "_wwKDj3mbVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b"
      ],
      "metadata": {
        "id": "TMc6iqdQbYcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soft Hadamard"
      ],
      "metadata": {
        "id": "XUal__xwo1aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "def _transform(x):\n",
        "  return tr(x) * 2.0 - 1.0\n",
        "\n",
        "bsize = 64\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    'MNIST_root/',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    'MNIST_root_test/',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "Q3GExd3Kqu_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPositionEncoding(seq_len, d, n=10000):\n",
        "    P = np.zeros((seq_len, d))\n",
        "    for k in range(seq_len):\n",
        "        for i in np.arange(int(d/2)):\n",
        "            denominator = np.power(n, 2*i/d)\n",
        "            P[k, 2*i] = np.sin(k/denominator)\n",
        "            P[k, 2*i+1] = np.cos(k/denominator)\n",
        "    return P\n",
        "\n",
        "class HadamardSelfAttention(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32):\n",
        "    super().__init__()\n",
        "    self.Wk = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    self.Wq = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    # self.Wv = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (N, T, D_in)\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    K = self.Wk(x).reshape(n, t, -1)\n",
        "    Q = self.Wq(x).reshape(n, t, -1)\n",
        "    # V = self.Wv(x).reshape(n, t, -1)\n",
        "    V = x.clone().reshape(n, t, -1)\n",
        "    _, _, d_out = K.shape\n",
        "    KQ = (\n",
        "        K.repeat(1, t, 1).reshape(n, t, t, d_out)\n",
        "        * Q.repeat(1, 1, t).reshape(n, t, t, d_out)\n",
        "      )\n",
        "    A = nn.functional.gumbel_softmax(KQ, hard=True, dim=2)\n",
        "    V = A * V.unsqueeze(1).repeat(1, t, 1, 1)\n",
        "    V = V.sum(dim=2)\n",
        "    return V\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.W = nn.Sequential(\n",
        "        nn.Linear(in_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, num_classes, bias=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    x = self.W(x)\n",
        "    x = x.reshape(n, t, -1)\n",
        "    x = x.mean(dim=1)\n",
        "    return x\n",
        "\n",
        "class Composer(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.hsa = nn.Sequential(\n",
        "        # nn.Identity(),\n",
        "        HadamardSelfAttention(in_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "    )\n",
        "    self.clf = nn.Linear(out_features, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    x = self.hsa(x)\n",
        "    self._hsa_out = x\n",
        "    # x: N, T, d_out\n",
        "    x = x.mean(dim=1)\n",
        "    y = self.clf(x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "OhMmhe9nAzSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Composer(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "# model = MLP(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "optimizer = Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=1e-3,\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0gt2oJ3DuKhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "valid_epoch = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for x, y in iter(train_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "  for x, y in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    y = y.reshape(-1).tolist()\n",
        "    y_pred = torch.argmax(y_pred, dim=-1).reshape(-1).tolist()\n",
        "    valid_epoch.append(epoch)\n",
        "    valid_losses.append(loss.item())\n",
        "    valid_accs.append(accuracy_score(y, y_pred))\n",
        "  loss_df = pd.DataFrame(\n",
        "      {\n",
        "          \"Epoch\": valid_epoch,\n",
        "          \"Loss\": valid_losses,\n",
        "          \"Acc\": valid_accs,\n",
        "      }\n",
        "  )\n",
        "  display.clear_output(wait=True)\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Loss\"]].plot(figsize=(24, 2))\n",
        "  plt.show()\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Acc\"]].plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nMrSJ9HqvgjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(0, 63)\n",
        "model.eval()\n",
        "for x, _ in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    break\n",
        "model.forward(x[idx: idx + 1])\n",
        "x_ = model._hsa_out.cpu().detach().numpy()\n",
        "x = x[idx, 0].cpu().detach().numpy()\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "plt.imshow(x_[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GEVrOrdk4zGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement example of \"Produto Interno Maromba\": fitting linear transform using maromba product"
      ],
      "metadata": {
        "id": "wcumRBtgXbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ---"
      ],
      "metadata": {
        "id": "a7mWbfGvkBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TODO: encapsulate in a class and override @ and +\n",
        "# # TODO: implement vectorized version and indices\n",
        "# def maromba_dot(u, v, index_u, index_v):\n",
        "#   \"\"\"\n",
        "#   u: dim_u x 1\n",
        "#   v: dim_v x 1\n",
        "#   index_u: dim_u x index_dim\n",
        "#   index_v: dim_v x index_dim\n",
        "#   \"\"\"\n",
        "#   comb = (u @ v.T).reshape(-1, 1)\n",
        "#   sim = (index_u @ index_v.T).reshape(1, -1)\n",
        "#   dot = (sim @ comb)[0, 0]\n",
        "#   return dot"
      ],
      "metadata": {
        "id": "yCPp3QJSjz5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ----"
      ],
      "metadata": {
        "id": "WpnnNOnmkGTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dotlike(\n",
        "    a: torch.Tensor,\n",
        "    b: torch.Tensor,\n",
        "    op=lambda x, y: x * y,\n",
        "  ) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  a: ... x d\n",
        "  b: d x ...\n",
        "  \"\"\"\n",
        "  d = a.shape[-1]\n",
        "  N = a.shape[:-1]\n",
        "  M = b.shape[1:]\n",
        "  assert d == b.shape[0]\n",
        "  a = a.reshape(-1, d)\n",
        "  # b: ... x d\n",
        "  b = b.reshape(d, -1).T\n",
        "  N_ = a.shape[0]\n",
        "  M_ = b.shape[0]\n",
        "  a = a.unsqueeze(1).repeat(1, M_, 1)\n",
        "  b = b.unsqueeze(0).repeat(N_, 1, 1)\n",
        "  dot = op(a, b).sum(dim=-1)\n",
        "  dot = dot.reshape(N + M)\n",
        "  return dot\n",
        "\n",
        "def y(x, W):\n",
        "  \"\"\"\n",
        "  x: N x d_in\n",
        "  W: d_out x d_in\n",
        "  \"\"\"\n",
        "  return x @ W.T\n",
        "\n",
        "def combine_indices(index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  index_new[i, j] = f(index_w.sum(dim=1)[i] + index_x.sum(dim=1)[j]; theta)\n",
        "  \"\"\"\n",
        "  d_out, d_in, d_index = index_w.shape\n",
        "  n, d_in_, d_index_ = index_x.shape\n",
        "  assert d_in == d_in_\n",
        "  assert d_index == d_index_\n",
        "  idxw_sum = index_w.sum(dim=1)\n",
        "  # idxw_sum: d_out x N x d_index\n",
        "  idxw_sum = idxw_sum.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxx_sum = index_x.sum(dim=1)\n",
        "  # idxx_sum: d_out x N x d_index\n",
        "  idxx_sum = idxx_sum.unsqueeze(0).repeat(d_out, 1, 1)\n",
        "  index_new = indexer(idxw_sum + idxx_sum)\n",
        "  # index_new: N x d_out x d_index\n",
        "  index_new = index_new.permute(1, 0, 2)\n",
        "  index_new = nn.functional.gumbel_softmax(index_new, hard=False, dim=-1)\n",
        "  # index_new = nn.functional.softmax(index_new, dim=-1)\n",
        "  return index_new\n",
        "\n",
        "def genidx(idxu, idxv, indexer, debug=False):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # idxu_new: M x d_idx\n",
        "  # idxv_new: N x d_idx\n",
        "  if debug:\n",
        "    Pdb().set_trace()\n",
        "  idxu_new = indexer(idxu.reshape(-1, d_idx)).reshape(m, d_u, d_idx).mean(dim=1)\n",
        "  idxv_new = indexer(idxv.reshape(-1, d_idx)).reshape(n, d_v, d_idx).mean(dim=1)\n",
        "  idxu_new = idxu_new.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxv_new = idxv_new.unsqueeze(0).repeat(m, 1, 1)\n",
        "  idx_new = idxu_new + idxv_new\n",
        "  idx_new = nn.functional.gumbel_softmax(idx_new, hard=True, dim=-1)\n",
        "  return idx_new\n",
        "\n",
        "def gbmd(u, v, idxu, idxv, indexer):\n",
        "  \"\"\"\n",
        "  'General Batch Maromba Dot'\n",
        "  Shorter implementation for the 'batch maromba dot' operation.\n",
        "  u: M x d_u\n",
        "  v: N x d_v\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u = u.shape\n",
        "  n, d_v = v.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  assert (m, d_u, d_idx) == idxu.shape\n",
        "  assert (n, d_v, d_idx) == idxv.shape\n",
        "  # uidxu: M x d_idx\n",
        "  # vidxv: N x d_idx\n",
        "  uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "  vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "  dot = uidxu @ vidxv.T\n",
        "  ### Strong reason for encapsulation:\n",
        "  idx_new = genidx(idxu, idxv, indexer, debug=False)\n",
        "  # idx_new = combine_indices(idxu, idxv, indexer).permute(1, 0, 2)\n",
        "  return dot, idx_new\n",
        "\n",
        "def batch_maromba_dot(W, x, index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  W: d_out x d_in\n",
        "  x: N x d_in\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  \"\"\"\n",
        "  d_out, d_in = W.shape\n",
        "  n, d_in_ = x.shape\n",
        "  d_index = index_w.shape[-1]\n",
        "  assert d_in == d_in_, \"W.shape[1] and x.shape[1] must be equal.\"\n",
        "  assert index_w.shape[1:] == index_x.shape[1:]\n",
        "  # comb: N x d_out x d_in x d_in\n",
        "  W = W.reshape(-1, 1)\n",
        "  x = x.T.reshape(1, -1)\n",
        "  comb = (W @ x).reshape(d_out, d_in, d_in, n)\n",
        "  comb = comb.permute(3, 0, 1, 2)\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  comb = comb.reshape(n * d_out, d_in * d_in, 1)\n",
        "  index_x = index_x.permute(2, 1, 0)\n",
        "  # index_x: d_index x (d_in * N)\n",
        "  index_x = index_x.reshape(d_index, d_in * n)\n",
        "  # index_w: (d_out * d_in) x d_index\n",
        "  index_w = index_w.reshape(d_out * d_in, d_index)\n",
        "  sim = (index_w @ index_x).reshape(d_out, d_in, d_in, n)\n",
        "  sim = sim.permute(3, 0, 1, 2)\n",
        "  sim = sim.reshape(n * d_out, 1, d_in * d_in)\n",
        "  # Overview of shapes:\n",
        "  # sim:  (N * d_out) x 1 x (d_in(W) * d_in(x))\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  # Matrix product of the last two dimensions seems correct.\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  dot = dot.reshape(n, d_out)\n",
        "  index_w = index_w.reshape(d_out, d_in, d_index)\n",
        "  index_x = index_x.reshape(d_index, d_in, n).permute(2, 1, 0)\n",
        "  index_new = combine_indices(index_w, index_x, indexer)\n",
        "  return dot, index_new\n",
        "\n",
        "def batch_maromba_dot_(u, v, index_u, index_v):\n",
        "  \"\"\"\n",
        "  u: N x dim_u\n",
        "  v: N x dim_v\n",
        "  index_u: N x dim_u x index_dim\n",
        "  index_v: N x dim_v x index_dim\n",
        "  \"\"\"\n",
        "  n, dim_u = u.shape\n",
        "  m, dim_v = v.shape\n",
        "  assert n == m, \"u.shape[0] and v.shape[0] must be equal.\"\n",
        "  u = u.reshape(n, dim_u, 1)\n",
        "  v = v.reshape(n, 1, dim_v)\n",
        "  # comb: N x dim_u x dim_v\n",
        "  comb = torch.bmm(u, v)\n",
        "  comb = comb.reshape(n, -1, 1)\n",
        "  index_v = index_v.permute(0, 2, 1)\n",
        "  # sim: N x dim_u x dim_v\n",
        "  sim = torch.bmm(index_u, index_v)\n",
        "  sim = sim.reshape(n, 1, -1)\n",
        "  # dot: N\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  return dot\n",
        "\n",
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  # dot_true = torch.bmm(y_true.unsqueeze(1), y_true.unsqueeze(-1))[:, 0, 0]\n",
        "  # dot_pred = torch.bmm(y_pred.unsqueeze(1), y_pred.unsqueeze(-1))[:, 0, 0]\n",
        "  # mdot_true_pred = batch_maromba_dot_(y_true, y_pred, true_index, pred_index)\n",
        "  index_match = (pred_index.mean(dim=0) @ true_index.mean(dim=0).T)\n",
        "  # match_loss_lr = (y_pred - (index_match @ y_true.T).T).abs().mean()\n",
        "  # match_loss_rl = (y_true - (index_match.T @ y_pred.T).T).abs().mean()\n",
        "  \n",
        "  # match_loss_lr = ((y_pred - (y_true @ index_match.T)).abs()).mean()\n",
        "  # match_loss_rl = ((y_true - (y_pred @ index_match)).abs()).mean()\n",
        "\n",
        "  huber = nn.HuberLoss()\n",
        "  match_loss_lr = huber(y_pred, y_true @ index_match.T)\n",
        "  match_loss_rl = huber(y_true, y_pred @ index_match)\n",
        "\n",
        "  # dot_loss = ((dot_true - mdot_true_pred).abs()).mean()\n",
        "  # mu_loss = (y_true.mean(dim=-1) - y_pred.mean(dim=-1)).abs().mean()\n",
        "  # index_loss_0 = (1.0 - index_match.sum(dim=0)).abs().mean()\n",
        "  # index_loss_1 = (1.0 - index_match.sum(dim=-1)).abs().mean()\n",
        "  if debug:\n",
        "    Pdb().set_trace() ###\n",
        "  # loss = (dot_loss + mu_loss + index_loss_0 + index_loss_1)\n",
        "  loss = match_loss_lr + match_loss_rl\n",
        "  return loss"
      ],
      "metadata": {
        "id": "eCR6VV4NXpjw"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 10\n",
        "out_dim = 15\n",
        "index_dim = in_dim + out_dim # making things easier\n",
        "__hidden_dim = 5 * index_dim\n",
        "num_examples = 1000\n",
        "\n",
        "# Ground-truth parameters\n",
        "W_true = torch.randn((out_dim, in_dim), requires_grad=False)\n",
        "W_true = W_true.float().to(device)\n",
        "\n",
        "# Parameters to be trained\n",
        "bag_values_W = nn.Parameter(torch.randn((out_dim, in_dim)))\n",
        "bag_values_W = bag_values_W.float().to(device)\n",
        "bag_indices_W = nn.Parameter(torch.randn((out_dim, in_dim, index_dim)))\n",
        "# bag_indices_W = nn.Parameter(\n",
        "#     torch.eye(index_dim)[:in_dim].unsqueeze(0).repeat(out_dim, 1, 1)\n",
        "#     + torch.eye(index_dim)[in_dim:].unsqueeze(1).repeat(1, in_dim, 1)\n",
        "# )\n",
        "bag_indices_W = bag_indices_W.float().to(device)\n",
        "\n",
        "# Indexer model to be trained\n",
        "indexer = nn.Sequential(\n",
        "    nn.Linear(index_dim, __hidden_dim),\n",
        "    # nn.Dropout(0.5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(__hidden_dim, index_dim),\n",
        ").to(device)\n",
        "# indexer = nn.Identity().to(device)\n",
        "\n",
        "# Input data\n",
        "values_x = 1e0 * torch.randn((num_examples, in_dim))\n",
        "# index_x = torch.randn((1, in_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "index_x = torch.eye(index_dim)[:in_dim]\n",
        "index_x = index_x.unsqueeze(0).repeat(num_examples, 1, 1)\n",
        "\n",
        "# Ground-truth target\n",
        "y_true = y(values_x, W_true)\n",
        "# y_true_index = torch.randn((1, out_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "y_true_index = torch.eye(index_dim)[in_dim:]\n",
        "# y_true_index = nn.functional.gumbel_softmax(\n",
        "#     y_true_index[torch.randperm(out_dim)]\n",
        "#     + y_true_index[torch.randperm(out_dim)],\n",
        "#     dim=1,\n",
        "#     hard=False,\n",
        "# )\n",
        "y_true_index = y_true_index.unsqueeze(0).repeat(num_examples, 1, 1)"
      ],
      "metadata": {
        "id": "UHC_bTf1GumV"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dot1, idx1 = gbmd(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# dot2, idx2 = batch_maromba_dot(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# print(dot1.shape, dot2.shape)\n",
        "# print(idx1.shape, idx2.shape)\n",
        "# print(torch.allclose(dot1.T, dot2), torch.allclose(idx1, idx2))"
      ],
      "metadata": {
        "id": "xEdq4WHJ_ZFO"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_vectors = Adam([bag_values_W, bag_indices_W], lr=1e-2)\n",
        "# opt_vectors = Adam([bag_values_W], lr=1e-1)\n",
        "opt_indexer = Adam(indexer.parameters(), lr=1e-2)\n",
        "\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "epoch_len = num_examples // batch_size\n",
        "\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_losses = []\n",
        "  for _ in range(epoch_len):\n",
        "    batch_idx = np.random.choice(num_examples, batch_size)\n",
        "    batch_x = values_x[batch_idx].float().to(device)\n",
        "    batch_x_index = index_x[batch_idx].float().to(device)\n",
        "    batch_y_true = y_true[batch_idx].float().to(device)\n",
        "    batch_y_true_index = y_true_index[batch_idx].float().to(device)\n",
        "    # gumbel_bag_indices_W = nn.functional.gumbel_softmax(\n",
        "    #     bag_indices_W, hard=False, dim=-1\n",
        "    # ) ###\n",
        "    # y_pred_val, y_pred_index = batch_maromba_dot(\n",
        "    #     bag_values_W, batch_x, bag_indices_W, batch_x_index, indexer\n",
        "    # ) ###\n",
        "    y_pred_val, y_pred_index = gbmd(\n",
        "        batch_x, bag_values_W, batch_x_index, bag_indices_W, indexer\n",
        "    )\n",
        "    ###\n",
        "    loss = maromba_loss(\n",
        "        batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "    )\n",
        "    opt_vectors.zero_grad()\n",
        "    opt_indexer.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_vectors.step()\n",
        "    opt_indexer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  all_losses.append(np.mean(epoch_losses))\n",
        "  df_train = pd.DataFrame({\n",
        "      \"train loss\": all_losses,\n",
        "  })\n",
        "  display.clear_output(wait=True)\n",
        "  df_train.plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TmZOcAvg-Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "4e3086e4-6af6-4e30-e90f-3fcc15a3cfed"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(all_losses[-5:]))\n",
        "# y_pred_index.shape, batch_y_true_index.shape\n",
        "index_match = (y_pred_index[0] @ batch_y_true_index[0].T)\n",
        "print(index_match.sum(dim=-1))\n",
        "print(index_match.sum(dim=0))"
      ],
      "metadata": {
        "id": "82uoeJaS9BbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d9c49b-04de-4dee-b69b-9cc098471fd5"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3657983318451912\n",
            "tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
            "       grad_fn=<SumBackward1>)\n",
            "tensor([1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.],\n",
            "       grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(W_true - bag_values_W).abs().mean()"
      ],
      "metadata": {
        "id": "f8CuZ6KMihSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd5810f-7701-4ef0-f097-964053d5eb24"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0914, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = torch.argmax(y_pred_index[0], dim=-1) - in_dim\n",
        "(batch_y_true[0][idxs] - y_pred_val[0]).abs().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC809FMxPquK",
        "outputId": "8ca6a7d8-1e4e-4875-df91-c0f30b827986"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1056, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_y_true[0][idxs], y_pred_val[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr6Usa3fmi6D",
        "outputId": "c39977e6-0fc2-445e-d8e6-a2f76c2a98e9"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-3.2561,  2.1504,  2.0897, -0.4562, -0.4562, -0.4562, -2.6015,  2.1489,\n",
              "         -0.7846, -0.4562, -4.6484,  5.0269, -0.2639,  3.2027, -0.9963]),\n",
              " tensor([-3.2454e+00,  2.1685e+00,  2.0827e+00, -7.6227e-03,  2.8591e-02,\n",
              "         -4.4263e-01, -2.5486e+00,  2.1340e+00, -7.6950e-01,  3.4045e-07,\n",
              "         -4.6358e+00,  5.0337e+00, -2.7861e-01,  3.2027e+00, -1.0246e+00],\n",
              "        grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_14rgM_9mt8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}