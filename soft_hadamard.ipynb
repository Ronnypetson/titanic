{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HFAO_DVB2UqU",
        "XUal__xwo1aF",
        "a7mWbfGvkBT1"
      ],
      "authorship_tag": "ABX9TyMay4dkv/kFOLGFeYR4PkUW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/soft_hadamard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3woABE_SOgS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demonstração PyTorch"
      ],
      "metadata": {
        "id": "HFAO_DVB2UqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = w0 * x² + w1 * x\n",
        "# (y real: y = 2 * x² + 5 * x)\n",
        "#\n",
        "# y = f0(f1(f2(x)))"
      ],
      "metadata": {
        "id": "dMLIykGDXHXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2.0 * torch.ones((2, 2)).float()\n",
        "a.requires_grad = True\n",
        "b = 3.0 * torch.ones((2, 2)).float()\n",
        "b.requires_grad = True"
      ],
      "metadata": {
        "id": "gI0HDYjbSls9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = (a * b).sum()\n",
        "c"
      ],
      "metadata": {
        "id": "g0vhOpWdTbVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()"
      ],
      "metadata": {
        "id": "6t0yCwoSZlwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "9lb7x_evTvEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "16cq_wCLT3aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad = None"
      ],
      "metadata": {
        "id": "4gZn7eNuUZun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad = None"
      ],
      "metadata": {
        "id": "H82KJ-_RaQOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = (a * a + b).mean()"
      ],
      "metadata": {
        "id": "P8gujdeOaRUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "Z_iMO8nRabZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.backward()"
      ],
      "metadata": {
        "id": "NjDyLr7vab8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "Y3Y4C3aWafHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "8Utr61jdamo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x, a, b):\n",
        "  return (a * x * x + b * x).sum(dim=1)\n",
        "\n",
        "def y_real(x):\n",
        "  x = torch.tensor(x).float()\n",
        "  return (2 * x * x + 5 * x).sum(dim=1)\n",
        "\n",
        "# (y real: y = 2 * x * x + 5 * x)"
      ],
      "metadata": {
        "id": "DGYDMd7Manmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import shuffle\n",
        "\n",
        "X = list(range(1000))\n",
        "shuffle(X)\n",
        "X = torch.tensor(X).reshape(-1, 1).float()\n",
        "Y = y_real(X)"
      ],
      "metadata": {
        "id": "XlFabAe6a7DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "2c75VJJKkQZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(0.5).float()\n",
        "b = torch.tensor(0.5).float()\n",
        "\n",
        "a = torch.nn.Parameter(a)\n",
        "b = torch.nn.Parameter(b)\n",
        "\n",
        "optim = torch.optim.Adam([a, b], lr=1e-3)\n",
        "\n",
        "for iter in range(10000):\n",
        "  Y_pred = y(X, a, b)\n",
        "  custo = ((Y - Y_pred).abs()).mean()\n",
        "  optim.zero_grad()\n",
        "  custo.backward()\n",
        "  optim.step()\n",
        "  if iter % 10 == 0:\n",
        "    print(custo.item())"
      ],
      "metadata": {
        "id": "_wwKDj3mbVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b"
      ],
      "metadata": {
        "id": "TMc6iqdQbYcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soft Hadamard"
      ],
      "metadata": {
        "id": "XUal__xwo1aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "def _transform(x):\n",
        "  return tr(x) * 2.0 - 1.0\n",
        "\n",
        "bsize = 64\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    'MNIST_root/',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    'MNIST_root_test/',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "Q3GExd3Kqu_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPositionEncoding(seq_len, d, n=10000):\n",
        "    P = np.zeros((seq_len, d))\n",
        "    for k in range(seq_len):\n",
        "        for i in np.arange(int(d/2)):\n",
        "            denominator = np.power(n, 2*i/d)\n",
        "            P[k, 2*i] = np.sin(k/denominator)\n",
        "            P[k, 2*i+1] = np.cos(k/denominator)\n",
        "    return P\n",
        "\n",
        "class HadamardSelfAttention(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32):\n",
        "    super().__init__()\n",
        "    self.Wk = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    self.Wq = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    # self.Wv = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (N, T, D_in)\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    K = self.Wk(x).reshape(n, t, -1)\n",
        "    Q = self.Wq(x).reshape(n, t, -1)\n",
        "    # V = self.Wv(x).reshape(n, t, -1)\n",
        "    V = x.clone().reshape(n, t, -1)\n",
        "    _, _, d_out = K.shape\n",
        "    KQ = (\n",
        "        K.repeat(1, t, 1).reshape(n, t, t, d_out)\n",
        "        * Q.repeat(1, 1, t).reshape(n, t, t, d_out)\n",
        "      )\n",
        "    A = nn.functional.gumbel_softmax(KQ, hard=True, dim=2)\n",
        "    V = A * V.unsqueeze(1).repeat(1, t, 1, 1)\n",
        "    V = V.sum(dim=2)\n",
        "    return V\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.W = nn.Sequential(\n",
        "        nn.Linear(in_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, num_classes, bias=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    x = self.W(x)\n",
        "    x = x.reshape(n, t, -1)\n",
        "    x = x.mean(dim=1)\n",
        "    return x\n",
        "\n",
        "class Composer(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.hsa = nn.Sequential(\n",
        "        # nn.Identity(),\n",
        "        HadamardSelfAttention(in_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "    )\n",
        "    self.clf = nn.Linear(out_features, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    x = self.hsa(x)\n",
        "    self._hsa_out = x\n",
        "    # x: N, T, d_out\n",
        "    x = x.mean(dim=1)\n",
        "    y = self.clf(x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "OhMmhe9nAzSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Composer(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "# model = MLP(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "optimizer = Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=1e-3,\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0gt2oJ3DuKhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "valid_epoch = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for x, y in iter(train_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "  for x, y in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    y = y.reshape(-1).tolist()\n",
        "    y_pred = torch.argmax(y_pred, dim=-1).reshape(-1).tolist()\n",
        "    valid_epoch.append(epoch)\n",
        "    valid_losses.append(loss.item())\n",
        "    valid_accs.append(accuracy_score(y, y_pred))\n",
        "  loss_df = pd.DataFrame(\n",
        "      {\n",
        "          \"Epoch\": valid_epoch,\n",
        "          \"Loss\": valid_losses,\n",
        "          \"Acc\": valid_accs,\n",
        "      }\n",
        "  )\n",
        "  display.clear_output(wait=True)\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Loss\"]].plot(figsize=(24, 2))\n",
        "  plt.show()\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Acc\"]].plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nMrSJ9HqvgjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(0, 63)\n",
        "model.eval()\n",
        "for x, _ in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    break\n",
        "model.forward(x[idx: idx + 1])\n",
        "x_ = model._hsa_out.cpu().detach().numpy()\n",
        "x = x[idx, 0].cpu().detach().numpy()\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "plt.imshow(x_[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GEVrOrdk4zGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement example of \"Produto Interno Maromba\": fitting linear transform using maromba product"
      ],
      "metadata": {
        "id": "wcumRBtgXbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ---"
      ],
      "metadata": {
        "id": "a7mWbfGvkBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TODO: encapsulate in a class and override @ and +\n",
        "# # TODO: implement vectorized version and indices\n",
        "# def maromba_dot(u, v, index_u, index_v):\n",
        "#   \"\"\"\n",
        "#   u: dim_u x 1\n",
        "#   v: dim_v x 1\n",
        "#   index_u: dim_u x index_dim\n",
        "#   index_v: dim_v x index_dim\n",
        "#   \"\"\"\n",
        "#   comb = (u @ v.T).reshape(-1, 1)\n",
        "#   sim = (index_u @ index_v.T).reshape(1, -1)\n",
        "#   dot = (sim @ comb)[0, 0]\n",
        "#   return dot"
      ],
      "metadata": {
        "id": "yCPp3QJSjz5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ----"
      ],
      "metadata": {
        "id": "WpnnNOnmkGTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a = torch.randn(2, 3)\n",
        "a = (1, 2)\n",
        "def f(a, b):\n",
        "  return a, b\n",
        "f(*((3,) + a[1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwHmrpeEl7MN",
        "outputId": "284858c9-8bf2-495d-df16-148e76172112"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MTensor(torch.Tensor):\n",
        "  @staticmethod \n",
        "  def __new__(cls, values, indices, indexer, *args, **kwargs): \n",
        "      return super().__new__(cls, values, *args, **kwargs)\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      values: torch.Tensor,\n",
        "      indices: torch.Tensor,\n",
        "      indexer: nn.Module,\n",
        "    ):\n",
        "    # super().__init__()\n",
        "    assert values.shape == indices.shape[:-1]\n",
        "    self.data = values\n",
        "    self.idx = indices\n",
        "    self.indexer = indexer\n",
        "\n",
        "  def clone(self, *args, **kwargs): \n",
        "    return MTensor(super().clone(*args, **kwargs), self.indices, self.indexer)\n",
        "\n",
        "  def to(self, *args, **kwargs):\n",
        "    new_obj = MTensor([], self.extra_data)\n",
        "    tempTensor = super().to(*args, **kwargs)\n",
        "    new_obj.data = tempTensor.data\n",
        "    new_obj.requires_grad = tempTensor.requires_grad\n",
        "    return new_obj\n",
        "\n",
        "  def _gbmd(self, u, v, idxu, idxv) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    'General Batch Maromba Dot'\n",
        "    Shorter implementation for the 'batch maromba dot' operation.\n",
        "    u: M x d_u\n",
        "    v: N x d_v\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    \"\"\"\n",
        "    m, d_u = u.shape\n",
        "    n, d_v = v.shape\n",
        "    d_idx = idxu.shape[-1]\n",
        "    assert (m, d_u, d_idx) == idxu.shape\n",
        "    assert (n, d_v, d_idx) == idxv.shape\n",
        "    # uidxu: M x d_idx\n",
        "    # vidxv: N x d_idx\n",
        "    uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "    vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "    dot = uidxu @ vidxv.T\n",
        "    return dot\n",
        "\n",
        "  def _genidx(self, idxu, idxv, indexer, debug=False):\n",
        "    \"\"\"\n",
        "    idxu: M x d_u x d_idx\n",
        "    idxv: N x d_v x d_idx\n",
        "    indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "    \"\"\"\n",
        "    m, d_u, d_idx = idxu.shape\n",
        "    n, d_v, _ = idxv.shape\n",
        "    Pdb().set_trace()\n",
        "    assert d_idx == idxv.shape[-1]\n",
        "    # idxu_new: M x d_idx\n",
        "    # idxv_new: N x d_idx\n",
        "    idxu_new = indexer(idxu.reshape(-1, d_idx)).reshape(m, d_u, d_idx).mean(dim=1)\n",
        "    idxv_new = indexer(idxv.reshape(-1, d_idx)).reshape(n, d_v, d_idx).mean(dim=1)\n",
        "    idxu_new = idxu_new.unsqueeze(1).repeat(1, n, 1)\n",
        "    idxv_new = idxv_new.unsqueeze(0).repeat(m, 1, 1)\n",
        "    idx_new = idxu_new + idxv_new\n",
        "    idx_new = nn.functional.gumbel_softmax(idx_new, hard=True, dim=-1)\n",
        "    return idx_new\n",
        "\n",
        "  def __matmul__(self, b):\n",
        "    apre = self.data.shape[:-1]\n",
        "    bpre = b.data.shape[:-1]\n",
        "    d_idx = self.idx.shape[-1]\n",
        "    assert d_idx == b.idx.shape[-1]\n",
        "    aidx = self.idx.reshape(*((-1,) + self.idx.shape[-2:]))\n",
        "    bidx = b.idx.reshape(*((-1,) + b.idx.shape[-2:]))\n",
        "    mdot = self._gbmd(\n",
        "        self.data.reshape(-1, d_idx),\n",
        "        b.data.reshape(-1, d_idx),\n",
        "        aidx,\n",
        "        bidx\n",
        "    )\n",
        "    mdot = mdot.reshape(apre + bpre)\n",
        "    midx = self._genidx(aidx, bidx, self.indexer)\n",
        "    midx = midx.reshape(apre + bpre + (d_idx,))\n",
        "    mans = MTensor(mdot, midx, self.indexer)\n",
        "    return mans"
      ],
      "metadata": {
        "id": "O0XHlVtxgxMM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dotlike(\n",
        "    a: torch.Tensor,\n",
        "    b: torch.Tensor,\n",
        "    op=lambda x, y: x * y,\n",
        "  ) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  a: ... x d\n",
        "  b: d x ...\n",
        "  \"\"\"\n",
        "  d = a.shape[-1]\n",
        "  N = a.shape[:-1]\n",
        "  M = b.shape[1:]\n",
        "  assert d == b.shape[0]\n",
        "  a = a.reshape(-1, d)\n",
        "  # b: ... x d\n",
        "  b = b.reshape(d, -1).T\n",
        "  N_ = a.shape[0]\n",
        "  M_ = b.shape[0]\n",
        "  a = a.unsqueeze(1).repeat(1, M_, 1)\n",
        "  b = b.unsqueeze(0).repeat(N_, 1, 1)\n",
        "  dot = op(a, b).sum(dim=-1)\n",
        "  dot = dot.reshape(N + M)\n",
        "  return dot\n",
        "\n",
        "def y(x, W):\n",
        "  \"\"\"\n",
        "  x: N x d_in\n",
        "  W: d_out x d_in\n",
        "  \"\"\"\n",
        "  return x @ W.T\n",
        "\n",
        "def combine_indices(index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  index_new[i, j] = f(index_w.sum(dim=1)[i] + index_x.sum(dim=1)[j]; theta)\n",
        "  \"\"\"\n",
        "  d_out, d_in, d_index = index_w.shape\n",
        "  n, d_in_, d_index_ = index_x.shape\n",
        "  assert d_in == d_in_\n",
        "  assert d_index == d_index_\n",
        "  idxw_sum = index_w.sum(dim=1)\n",
        "  # idxw_sum: d_out x N x d_index\n",
        "  idxw_sum = idxw_sum.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxx_sum = index_x.sum(dim=1)\n",
        "  # idxx_sum: d_out x N x d_index\n",
        "  idxx_sum = idxx_sum.unsqueeze(0).repeat(d_out, 1, 1)\n",
        "  index_new = indexer(idxw_sum + idxx_sum)\n",
        "  # index_new: N x d_out x d_index\n",
        "  index_new = index_new.permute(1, 0, 2)\n",
        "  index_new = nn.functional.gumbel_softmax(index_new, hard=False, dim=-1)\n",
        "  # index_new = nn.functional.softmax(index_new, dim=-1)\n",
        "  return index_new\n",
        "\n",
        "def genidx(idxu, idxv, indexer, debug=False):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # idxu_new: M x d_idx\n",
        "  # idxv_new: N x d_idx\n",
        "  if debug:\n",
        "    Pdb().set_trace()\n",
        "  idxu_new = indexer(idxu.reshape(-1, d_idx)).reshape(m, d_u, d_idx).mean(dim=1)\n",
        "  idxv_new = indexer(idxv.reshape(-1, d_idx)).reshape(n, d_v, d_idx).mean(dim=1)\n",
        "  idxu_new = idxu_new.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxv_new = idxv_new.unsqueeze(0).repeat(m, 1, 1)\n",
        "  idx_new = idxu_new + idxv_new\n",
        "  idx_new = nn.functional.gumbel_softmax(idx_new, hard=True, dim=-1)\n",
        "  return idx_new\n",
        "\n",
        "def gbmd(u, v, idxu, idxv, indexer):\n",
        "  \"\"\"\n",
        "  'General Batch Maromba Dot'\n",
        "  Shorter implementation for the 'batch maromba dot' operation.\n",
        "  u: M x d_u\n",
        "  v: N x d_v\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u = u.shape\n",
        "  n, d_v = v.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  assert (m, d_u, d_idx) == idxu.shape\n",
        "  assert (n, d_v, d_idx) == idxv.shape\n",
        "  # uidxu: M x d_idx\n",
        "  # vidxv: N x d_idx\n",
        "  uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "  vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "  dot = uidxu @ vidxv.T\n",
        "  ### Strong reason for encapsulation:\n",
        "  idx_new = genidx(idxu, idxv, indexer, debug=False)\n",
        "  # idx_new = combine_indices(idxu, idxv, indexer).permute(1, 0, 2)\n",
        "  return dot, idx_new\n",
        "\n",
        "def batch_maromba_dot(W, x, index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  W: d_out x d_in\n",
        "  x: N x d_in\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  \"\"\"\n",
        "  d_out, d_in = W.shape\n",
        "  n, d_in_ = x.shape\n",
        "  d_index = index_w.shape[-1]\n",
        "  assert d_in == d_in_, \"W.shape[1] and x.shape[1] must be equal.\"\n",
        "  assert index_w.shape[1:] == index_x.shape[1:]\n",
        "  # comb: N x d_out x d_in x d_in\n",
        "  W = W.reshape(-1, 1)\n",
        "  x = x.T.reshape(1, -1)\n",
        "  comb = (W @ x).reshape(d_out, d_in, d_in, n)\n",
        "  comb = comb.permute(3, 0, 1, 2)\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  comb = comb.reshape(n * d_out, d_in * d_in, 1)\n",
        "  index_x = index_x.permute(2, 1, 0)\n",
        "  # index_x: d_index x (d_in * N)\n",
        "  index_x = index_x.reshape(d_index, d_in * n)\n",
        "  # index_w: (d_out * d_in) x d_index\n",
        "  index_w = index_w.reshape(d_out * d_in, d_index)\n",
        "  sim = (index_w @ index_x).reshape(d_out, d_in, d_in, n)\n",
        "  sim = sim.permute(3, 0, 1, 2)\n",
        "  sim = sim.reshape(n * d_out, 1, d_in * d_in)\n",
        "  # Overview of shapes:\n",
        "  # sim:  (N * d_out) x 1 x (d_in(W) * d_in(x))\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  # Matrix product of the last two dimensions seems correct.\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  dot = dot.reshape(n, d_out)\n",
        "  index_w = index_w.reshape(d_out, d_in, d_index)\n",
        "  index_x = index_x.reshape(d_index, d_in, n).permute(2, 1, 0)\n",
        "  index_new = combine_indices(index_w, index_x, indexer)\n",
        "  return dot, index_new\n",
        "\n",
        "def batch_maromba_dot_(u, v, index_u, index_v):\n",
        "  \"\"\"\n",
        "  u: N x dim_u\n",
        "  v: N x dim_v\n",
        "  index_u: N x dim_u x index_dim\n",
        "  index_v: N x dim_v x index_dim\n",
        "  \"\"\"\n",
        "  n, dim_u = u.shape\n",
        "  m, dim_v = v.shape\n",
        "  assert n == m, \"u.shape[0] and v.shape[0] must be equal.\"\n",
        "  u = u.reshape(n, dim_u, 1)\n",
        "  v = v.reshape(n, 1, dim_v)\n",
        "  # comb: N x dim_u x dim_v\n",
        "  comb = torch.bmm(u, v)\n",
        "  comb = comb.reshape(n, -1, 1)\n",
        "  index_v = index_v.permute(0, 2, 1)\n",
        "  # sim: N x dim_u x dim_v\n",
        "  sim = torch.bmm(index_u, index_v)\n",
        "  sim = sim.reshape(n, 1, -1)\n",
        "  # dot: N\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  return dot\n",
        "\n",
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  # dot_true = torch.bmm(y_true.unsqueeze(1), y_true.unsqueeze(-1))[:, 0, 0]\n",
        "  # dot_pred = torch.bmm(y_pred.unsqueeze(1), y_pred.unsqueeze(-1))[:, 0, 0]\n",
        "  # mdot_true_pred = batch_maromba_dot_(y_true, y_pred, true_index, pred_index)\n",
        "  index_match = (pred_index.mean(dim=0) @ true_index.mean(dim=0).T)\n",
        "  # match_loss_lr = (y_pred - (index_match @ y_true.T).T).abs().mean()\n",
        "  # match_loss_rl = (y_true - (index_match.T @ y_pred.T).T).abs().mean()\n",
        "  \n",
        "  # match_loss_lr = ((y_pred - (y_true @ index_match.T)).abs()).mean()\n",
        "  # match_loss_rl = ((y_true - (y_pred @ index_match)).abs()).mean()\n",
        "\n",
        "  huber = nn.HuberLoss()\n",
        "  match_loss_lr = huber(y_pred, y_true @ index_match.T)\n",
        "  match_loss_rl = huber(y_true, y_pred @ index_match)\n",
        "\n",
        "  # dot_loss = ((dot_true - mdot_true_pred).abs()).mean()\n",
        "  # mu_loss = (y_true.mean(dim=-1) - y_pred.mean(dim=-1)).abs().mean()\n",
        "  # index_loss_0 = (1.0 - index_match.sum(dim=0)).abs().mean()\n",
        "  # index_loss_1 = (1.0 - index_match.sum(dim=-1)).abs().mean()\n",
        "  if debug:\n",
        "    Pdb().set_trace() ###\n",
        "  # loss = (dot_loss + mu_loss + index_loss_0 + index_loss_1)\n",
        "  loss = match_loss_lr + match_loss_rl\n",
        "  return loss"
      ],
      "metadata": {
        "id": "eCR6VV4NXpjw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 10\n",
        "out_dim = 15\n",
        "index_dim = in_dim + out_dim # making things easier\n",
        "__hidden_dim = 5 * index_dim\n",
        "num_examples = 1000\n",
        "\n",
        "# Ground-truth parameters\n",
        "W_true = torch.randn((out_dim, in_dim), requires_grad=False)\n",
        "W_true = W_true.float().to(device)\n",
        "\n",
        "# Parameters to be trained\n",
        "bag_values_W = nn.Parameter(torch.randn((out_dim, in_dim)))\n",
        "bag_values_W = bag_values_W.float().to(device)\n",
        "bag_indices_W = nn.Parameter(torch.randn((out_dim, in_dim, index_dim)))\n",
        "# bag_indices_W = nn.Parameter(\n",
        "#     torch.eye(index_dim)[:in_dim].unsqueeze(0).repeat(out_dim, 1, 1)\n",
        "#     + torch.eye(index_dim)[in_dim:].unsqueeze(1).repeat(1, in_dim, 1)\n",
        "# )\n",
        "bag_indices_W = bag_indices_W.float().to(device)\n",
        "\n",
        "# Indexer model to be trained\n",
        "indexer = nn.Sequential(\n",
        "    nn.Linear(index_dim, __hidden_dim),\n",
        "    # nn.Dropout(0.5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(__hidden_dim, index_dim),\n",
        ").to(device)\n",
        "# indexer = nn.Identity().to(device)\n",
        "\n",
        "# Input data\n",
        "values_x = 1e0 * torch.randn((num_examples, in_dim))\n",
        "# index_x = torch.randn((1, in_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "index_x = torch.eye(index_dim)[:in_dim]\n",
        "index_x = index_x.unsqueeze(0).repeat(num_examples, 1, 1)\n",
        "\n",
        "# Ground-truth target\n",
        "y_true = y(values_x, W_true)\n",
        "# y_true_index = torch.randn((1, out_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "y_true_index = torch.eye(index_dim)[in_dim:]\n",
        "# y_true_index = nn.functional.gumbel_softmax(\n",
        "#     y_true_index[torch.randperm(out_dim)]\n",
        "#     + y_true_index[torch.randperm(out_dim)],\n",
        "#     dim=1,\n",
        "#     hard=False,\n",
        "# )\n",
        "y_true_index = y_true_index.unsqueeze(0).repeat(num_examples, 1, 1)"
      ],
      "metadata": {
        "id": "UHC_bTf1GumV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__W = MTensor(bag_values_W, bag_indices_W, indexer)\n",
        "__x = MTensor(values_x, index_x, indexer)\n",
        "__W @ __x"
      ],
      "metadata": {
        "id": "b1z6J1HVxB6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dot1, idx1 = gbmd(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# dot2, idx2 = batch_maromba_dot(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# print(dot1.shape, dot2.shape)\n",
        "# print(idx1.shape, idx2.shape)\n",
        "# print(torch.allclose(dot1.T, dot2), torch.allclose(idx1, idx2))"
      ],
      "metadata": {
        "id": "xEdq4WHJ_ZFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_vectors = Adam([bag_values_W, bag_indices_W], lr=1e-2)\n",
        "# opt_vectors = Adam([bag_values_W], lr=1e-1)\n",
        "opt_indexer = Adam(indexer.parameters(), lr=1e-2)\n",
        "\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "epoch_len = num_examples // batch_size\n",
        "\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_losses = []\n",
        "  for _ in range(epoch_len):\n",
        "    batch_idx = np.random.choice(num_examples, batch_size)\n",
        "    batch_x = values_x[batch_idx].float().to(device)\n",
        "    batch_x_index = index_x[batch_idx].float().to(device)\n",
        "    batch_y_true = y_true[batch_idx].float().to(device)\n",
        "    batch_y_true_index = y_true_index[batch_idx].float().to(device)\n",
        "    # gumbel_bag_indices_W = nn.functional.gumbel_softmax(\n",
        "    #     bag_indices_W, hard=False, dim=-1\n",
        "    # ) ###\n",
        "    # y_pred_val, y_pred_index = batch_maromba_dot(\n",
        "    #     bag_values_W, batch_x, bag_indices_W, batch_x_index, indexer\n",
        "    # ) ###\n",
        "    y_pred_val, y_pred_index = gbmd(\n",
        "        batch_x, bag_values_W, batch_x_index, bag_indices_W, indexer\n",
        "    )\n",
        "    ###\n",
        "    loss = maromba_loss(\n",
        "        batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "    )\n",
        "    opt_vectors.zero_grad()\n",
        "    opt_indexer.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_vectors.step()\n",
        "    opt_indexer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  all_losses.append(np.mean(epoch_losses))\n",
        "  df_train = pd.DataFrame({\n",
        "      \"train loss\": all_losses,\n",
        "  })\n",
        "  display.clear_output(wait=True)\n",
        "  df_train.plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TmZOcAvg-Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "1bdb4cb1-20be-455d-c2c0-a73bbc79a6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(all_losses[-5:]))\n",
        "# y_pred_index.shape, batch_y_true_index.shape\n",
        "index_match = (y_pred_index[0] @ batch_y_true_index[0].T)\n",
        "print(index_match.sum(dim=-1))\n",
        "print(index_match.sum(dim=0))"
      ],
      "metadata": {
        "id": "82uoeJaS9BbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8542450b-733b-47c3-df40-e15e6903de7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2073829016377848\n",
            "tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
            "       grad_fn=<SumBackward1>)\n",
            "tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "       grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(W_true - bag_values_W).abs().mean()"
      ],
      "metadata": {
        "id": "f8CuZ6KMihSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd5810f-7701-4ef0-f097-964053d5eb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0914, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = torch.argmax(y_pred_index[0], dim=-1) - in_dim\n",
        "(batch_y_true[0][idxs] - y_pred_val[0]).abs().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC809FMxPquK",
        "outputId": "8ca6a7d8-1e4e-4875-df91-c0f30b827986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1056, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_y_true[0][idxs], y_pred_val[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr6Usa3fmi6D",
        "outputId": "c39977e6-0fc2-445e-d8e6-a2f76c2a98e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-3.2561,  2.1504,  2.0897, -0.4562, -0.4562, -0.4562, -2.6015,  2.1489,\n",
              "         -0.7846, -0.4562, -4.6484,  5.0269, -0.2639,  3.2027, -0.9963]),\n",
              " tensor([-3.2454e+00,  2.1685e+00,  2.0827e+00, -7.6227e-03,  2.8591e-02,\n",
              "         -4.4263e-01, -2.5486e+00,  2.1340e+00, -7.6950e-01,  3.4045e-07,\n",
              "         -4.6358e+00,  5.0337e+00, -2.7861e-01,  3.2027e+00, -1.0246e+00],\n",
              "        grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_14rgM_9mt8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}