{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HFAO_DVB2UqU",
        "XUal__xwo1aF",
        "a7mWbfGvkBT1"
      ],
      "authorship_tag": "ABX9TyMAlyVmUTYD/BBWVbq4CPoN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/soft_hadamard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3woABE_SOgS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demonstração PyTorch"
      ],
      "metadata": {
        "id": "HFAO_DVB2UqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = w0 * x² + w1 * x\n",
        "# (y real: y = 2 * x² + 5 * x)\n",
        "#\n",
        "# y = f0(f1(f2(x)))"
      ],
      "metadata": {
        "id": "dMLIykGDXHXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2.0 * torch.ones((2, 2)).float()\n",
        "a.requires_grad = True\n",
        "b = 3.0 * torch.ones((2, 2)).float()\n",
        "b.requires_grad = True"
      ],
      "metadata": {
        "id": "gI0HDYjbSls9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = (a * b).sum()\n",
        "c"
      ],
      "metadata": {
        "id": "g0vhOpWdTbVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()"
      ],
      "metadata": {
        "id": "6t0yCwoSZlwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "9lb7x_evTvEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "16cq_wCLT3aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad = None"
      ],
      "metadata": {
        "id": "4gZn7eNuUZun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad = None"
      ],
      "metadata": {
        "id": "H82KJ-_RaQOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = (a * a + b).mean()"
      ],
      "metadata": {
        "id": "P8gujdeOaRUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "Z_iMO8nRabZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.backward()"
      ],
      "metadata": {
        "id": "NjDyLr7vab8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "Y3Y4C3aWafHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "8Utr61jdamo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x, a, b):\n",
        "  return (a * x * x + b * x).sum(dim=1)\n",
        "\n",
        "def y_real(x):\n",
        "  x = torch.tensor(x).float()\n",
        "  return (2 * x * x + 5 * x).sum(dim=1)\n",
        "\n",
        "# (y real: y = 2 * x * x + 5 * x)"
      ],
      "metadata": {
        "id": "DGYDMd7Manmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import shuffle\n",
        "\n",
        "X = list(range(1000))\n",
        "shuffle(X)\n",
        "X = torch.tensor(X).reshape(-1, 1).float()\n",
        "Y = y_real(X)"
      ],
      "metadata": {
        "id": "XlFabAe6a7DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "2c75VJJKkQZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(0.5).float()\n",
        "b = torch.tensor(0.5).float()\n",
        "\n",
        "a = torch.nn.Parameter(a)\n",
        "b = torch.nn.Parameter(b)\n",
        "\n",
        "optim = torch.optim.Adam([a, b], lr=1e-3)\n",
        "\n",
        "for iter in range(10000):\n",
        "  Y_pred = y(X, a, b)\n",
        "  custo = ((Y - Y_pred).abs()).mean()\n",
        "  optim.zero_grad()\n",
        "  custo.backward()\n",
        "  optim.step()\n",
        "  if iter % 10 == 0:\n",
        "    print(custo.item())"
      ],
      "metadata": {
        "id": "_wwKDj3mbVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b"
      ],
      "metadata": {
        "id": "TMc6iqdQbYcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soft Hadamard"
      ],
      "metadata": {
        "id": "XUal__xwo1aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "def _transform(x):\n",
        "  return tr(x) * 2.0 - 1.0\n",
        "\n",
        "bsize = 64\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    'MNIST_root/',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    'MNIST_root_test/',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "Q3GExd3Kqu_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPositionEncoding(seq_len, d, n=10000):\n",
        "    P = np.zeros((seq_len, d))\n",
        "    for k in range(seq_len):\n",
        "        for i in np.arange(int(d/2)):\n",
        "            denominator = np.power(n, 2*i/d)\n",
        "            P[k, 2*i] = np.sin(k/denominator)\n",
        "            P[k, 2*i+1] = np.cos(k/denominator)\n",
        "    return P\n",
        "\n",
        "class HadamardSelfAttention(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32):\n",
        "    super().__init__()\n",
        "    self.Wk = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    self.Wq = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    # self.Wv = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (N, T, D_in)\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    K = self.Wk(x).reshape(n, t, -1)\n",
        "    Q = self.Wq(x).reshape(n, t, -1)\n",
        "    # V = self.Wv(x).reshape(n, t, -1)\n",
        "    V = x.clone().reshape(n, t, -1)\n",
        "    _, _, d_out = K.shape\n",
        "    KQ = (\n",
        "        K.repeat(1, t, 1).reshape(n, t, t, d_out)\n",
        "        * Q.repeat(1, 1, t).reshape(n, t, t, d_out)\n",
        "      )\n",
        "    A = nn.functional.gumbel_softmax(KQ, hard=True, dim=2)\n",
        "    V = A * V.unsqueeze(1).repeat(1, t, 1, 1)\n",
        "    V = V.sum(dim=2)\n",
        "    return V\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.W = nn.Sequential(\n",
        "        nn.Linear(in_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, num_classes, bias=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    x = self.W(x)\n",
        "    x = x.reshape(n, t, -1)\n",
        "    x = x.mean(dim=1)\n",
        "    return x\n",
        "\n",
        "class Composer(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.hsa = nn.Sequential(\n",
        "        # nn.Identity(),\n",
        "        HadamardSelfAttention(in_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "    )\n",
        "    self.clf = nn.Linear(out_features, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    x = self.hsa(x)\n",
        "    self._hsa_out = x\n",
        "    # x: N, T, d_out\n",
        "    x = x.mean(dim=1)\n",
        "    y = self.clf(x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "OhMmhe9nAzSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Composer(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "# model = MLP(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "optimizer = Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=1e-3,\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0gt2oJ3DuKhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "valid_epoch = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for x, y in iter(train_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "  for x, y in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    y = y.reshape(-1).tolist()\n",
        "    y_pred = torch.argmax(y_pred, dim=-1).reshape(-1).tolist()\n",
        "    valid_epoch.append(epoch)\n",
        "    valid_losses.append(loss.item())\n",
        "    valid_accs.append(accuracy_score(y, y_pred))\n",
        "  loss_df = pd.DataFrame(\n",
        "      {\n",
        "          \"Epoch\": valid_epoch,\n",
        "          \"Loss\": valid_losses,\n",
        "          \"Acc\": valid_accs,\n",
        "      }\n",
        "  )\n",
        "  display.clear_output(wait=True)\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Loss\"]].plot(figsize=(24, 2))\n",
        "  plt.show()\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Acc\"]].plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nMrSJ9HqvgjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(0, 63)\n",
        "model.eval()\n",
        "for x, _ in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    break\n",
        "model.forward(x[idx: idx + 1])\n",
        "x_ = model._hsa_out.cpu().detach().numpy()\n",
        "x = x[idx, 0].cpu().detach().numpy()\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "plt.imshow(x_[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GEVrOrdk4zGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement example of \"Produto Interno Maromba\": fitting linear transform using maromba product"
      ],
      "metadata": {
        "id": "wcumRBtgXbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ---"
      ],
      "metadata": {
        "id": "a7mWbfGvkBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TODO: encapsulate in a class and override @ and +\n",
        "# # TODO: implement vectorized version and indices\n",
        "# def maromba_dot(u, v, index_u, index_v):\n",
        "#   \"\"\"\n",
        "#   u: dim_u x 1\n",
        "#   v: dim_v x 1\n",
        "#   index_u: dim_u x index_dim\n",
        "#   index_v: dim_v x index_dim\n",
        "#   \"\"\"\n",
        "#   comb = (u @ v.T).reshape(-1, 1)\n",
        "#   sim = (index_u @ index_v.T).reshape(1, -1)\n",
        "#   dot = (sim @ comb)[0, 0]\n",
        "#   return dot"
      ],
      "metadata": {
        "id": "yCPp3QJSjz5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ----"
      ],
      "metadata": {
        "id": "WpnnNOnmkGTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dotlike(\n",
        "    a: torch.Tensor,\n",
        "    b: torch.Tensor,\n",
        "    op=lambda x, y: x * y,\n",
        "  ) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  a: ... x d\n",
        "  b: d x ...\n",
        "  \"\"\"\n",
        "  d = a.shape[-1]\n",
        "  N = a.shape[:-1]\n",
        "  M = b.shape[1:]\n",
        "  assert d == b.shape[0]\n",
        "  a = a.reshape(-1, d)\n",
        "  # b: ... x d\n",
        "  b = b.reshape(d, -1).T\n",
        "  N_ = a.shape[0]\n",
        "  M_ = b.shape[0]\n",
        "  a = a.unsqueeze(1).repeat(1, M_, 1)\n",
        "  b = b.unsqueeze(0).repeat(N_, 1, 1)\n",
        "  dot = op(a, b).sum(dim=-1)\n",
        "  dot = dot.reshape(N + M)\n",
        "  return dot\n",
        "\n",
        "def y(x, W):\n",
        "  \"\"\"\n",
        "  x: N x d_in\n",
        "  W: d_out x d_in\n",
        "  \"\"\"\n",
        "  return x @ W.T\n",
        "\n",
        "def combine_indices(index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  index_new[i, j] = f(index_w.sum(dim=1)[i] + index_x.sum(dim=1)[j]; theta)\n",
        "  \"\"\"\n",
        "  d_out, d_in, d_index = index_w.shape\n",
        "  n, d_in_, d_index_ = index_x.shape\n",
        "  assert d_in == d_in_\n",
        "  assert d_index == d_index_\n",
        "  idxw_sum = index_w.sum(dim=1)\n",
        "  # idxw_sum: d_out x N x d_index\n",
        "  idxw_sum = idxw_sum.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxx_sum = index_x.sum(dim=1)\n",
        "  # idxx_sum: d_out x N x d_index\n",
        "  idxx_sum = idxx_sum.unsqueeze(0).repeat(d_out, 1, 1)\n",
        "  index_new = indexer(idxw_sum + idxx_sum)\n",
        "  # index_new: N x d_out x d_index\n",
        "  index_new = index_new.permute(1, 0, 2)\n",
        "  index_new = nn.functional.gumbel_softmax(index_new, hard=False, dim=-1)\n",
        "  # index_new = nn.functional.softmax(index_new, dim=-1)\n",
        "  return index_new\n",
        "\n",
        "def batch_maromba_dot(W, x, index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  W: d_out x d_in\n",
        "  x: N x d_in\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  \"\"\"\n",
        "  d_out, d_in = W.shape\n",
        "  n, d_in_ = x.shape\n",
        "  d_index = index_w.shape[-1]\n",
        "  assert d_in == d_in_, \"W.shape[1] and x.shape[1] must be equal.\"\n",
        "  assert index_w.shape[1:] == index_x.shape[1:]\n",
        "  # comb: N x d_out x d_in x d_in\n",
        "  W = W.reshape(-1, 1)\n",
        "  x = x.T.reshape(1, -1)\n",
        "  comb = (W @ x).reshape(d_out, d_in, d_in, n)\n",
        "  comb = comb.permute(3, 0, 1, 2)\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  comb = comb.reshape(n * d_out, d_in * d_in, 1)\n",
        "  index_x = index_x.permute(2, 1, 0)\n",
        "  # index_x: d_index x (d_in * N)\n",
        "  index_x = index_x.reshape(d_index, d_in * n)\n",
        "  # index_w: (d_out * d_in) x d_index\n",
        "  index_w = index_w.reshape(d_out * d_in, d_index)\n",
        "  sim = (index_w @ index_x).reshape(d_out, d_in, d_in, n)\n",
        "  sim = sim.permute(3, 0, 1, 2)\n",
        "  sim = sim.reshape(n * d_out, 1, d_in * d_in)\n",
        "  # Overview of shapes:\n",
        "  # sim:  (N * d_out) x 1 x (d_in(W) * d_in(x))\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  # Matrix product of the last two dimensions seems correct.\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  dot = dot.reshape(n, d_out)\n",
        "  index_w = index_w.reshape(d_out, d_in, d_index)\n",
        "  index_x = index_x.reshape(d_index, d_in, n).permute(2, 1, 0)\n",
        "  index_new = combine_indices(index_w, index_x, indexer)\n",
        "  return dot, index_new\n",
        "\n",
        "def batch_maromba_dot_(u, v, index_u, index_v):\n",
        "  \"\"\"\n",
        "  u: N x dim_u\n",
        "  v: N x dim_v\n",
        "  index_u: N x dim_u x index_dim\n",
        "  index_v: N x dim_v x index_dim\n",
        "  \"\"\"\n",
        "  n, dim_u = u.shape\n",
        "  m, dim_v = v.shape\n",
        "  assert n == m, \"u.shape[0] and v.shape[0] must be equal.\"\n",
        "  u = u.reshape(n, dim_u, 1)\n",
        "  v = v.reshape(n, 1, dim_v)\n",
        "  # comb: N x dim_u x dim_v\n",
        "  comb = torch.bmm(u, v)\n",
        "  comb = comb.reshape(n, -1, 1)\n",
        "  index_v = index_v.permute(0, 2, 1)\n",
        "  # sim: N x dim_u x dim_v\n",
        "  sim = torch.bmm(index_u, index_v)\n",
        "  sim = sim.reshape(n, 1, -1)\n",
        "  # dot: N\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  return dot\n",
        "\n",
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  dot_true = torch.bmm(y_true.unsqueeze(1), y_true.unsqueeze(-1))[:, 0, 0]\n",
        "  dot_pred = torch.bmm(y_pred.unsqueeze(1), y_pred.unsqueeze(-1))[:, 0, 0]\n",
        "  mdot_true_pred = batch_maromba_dot_(y_true, y_pred, true_index, pred_index)\n",
        "  index_match = (pred_index.mean(dim=0) @ true_index.mean(dim=0).T)\n",
        "  dot_loss = ((dot_true - mdot_true_pred).abs()).mean()\n",
        "  mu_loss = (y_true.mean(dim=-1) - y_pred.mean(dim=-1)).abs().mean()\n",
        "  index_loss_0 = (1.0 - index_match.sum(dim=0)).abs().mean()\n",
        "  index_loss_1 = (1.0 - index_match.sum(dim=-1)).abs().mean()\n",
        "  if debug:\n",
        "    Pdb().set_trace() ###\n",
        "  loss = (dot_loss + mu_loss + index_loss_0 + index_loss_1)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "eCR6VV4NXpjw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 5\n",
        "out_dim = 10\n",
        "index_dim = in_dim + out_dim # making things easier\n",
        "__hidden_dim = 5 * index_dim\n",
        "num_examples = 20000\n",
        "\n",
        "# Ground-truth parameters\n",
        "W_true = torch.randn((out_dim, in_dim), requires_grad=False)\n",
        "W_true = W_true.float().to(device)\n",
        "\n",
        "# Parameters to be trained\n",
        "bag_values_W = nn.Parameter(torch.randn((out_dim, in_dim)))\n",
        "bag_values_W = bag_values_W.float().to(device)\n",
        "bag_indices_W = nn.Parameter(torch.randn((out_dim, in_dim, index_dim)))\n",
        "bag_indices_W = bag_indices_W.float().to(device)\n",
        "\n",
        "# Indexer model to be trained\n",
        "indexer = nn.Sequential(\n",
        "    nn.Linear(index_dim, __hidden_dim),\n",
        "    # nn.Dropout(0.5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(__hidden_dim, index_dim),\n",
        ").to(device)\n",
        "\n",
        "# Input data\n",
        "values_x = 1e0 * torch.randn((num_examples, in_dim))\n",
        "# index_x = torch.randn((1, in_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "index_x = torch.eye(index_dim)[:in_dim]\n",
        "index_x = index_x.unsqueeze(0).repeat(num_examples, 1, 1)\n",
        "\n",
        "# Ground-truth target\n",
        "y_true = y(values_x, W_true)\n",
        "# y_true_index = torch.randn((1, out_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "y_true_index = torch.eye(index_dim)[in_dim:]\n",
        "# y_true_index = nn.functional.gumbel_softmax(\n",
        "#     y_true_index[torch.randperm(out_dim)]\n",
        "#     + y_true_index[torch.randperm(out_dim)],\n",
        "#     dim=1,\n",
        "#     hard=False,\n",
        "# )\n",
        "y_true_index = y_true_index.unsqueeze(0).repeat(num_examples, 1, 1)"
      ],
      "metadata": {
        "id": "UHC_bTf1GumV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_vectors = Adam([bag_values_W, bag_indices_W], lr=1e-3)\n",
        "opt_indexer = Adam(indexer.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "epoch_len = num_examples // batch_size\n",
        "\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_losses = []\n",
        "  for _ in range(epoch_len):\n",
        "    batch_idx = np.random.choice(num_examples, batch_size)\n",
        "    batch_x = values_x[batch_idx].float().to(device)\n",
        "    batch_x_index = index_x[batch_idx].float().to(device)\n",
        "    batch_y_true = y_true[batch_idx].float().to(device)\n",
        "    batch_y_true_index = y_true_index[batch_idx].float().to(device)\n",
        "    y_pred_val, y_pred_index = batch_maromba_dot(\n",
        "        bag_values_W, batch_x, bag_indices_W, batch_x_index, indexer\n",
        "    )\n",
        "    loss = maromba_loss(batch_y_true, y_pred_val, batch_y_true_index, y_pred_index)\n",
        "    opt_vectors.zero_grad()\n",
        "    opt_indexer.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_vectors.step()\n",
        "    opt_indexer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  all_losses.append(np.mean(epoch_losses))\n",
        "  df_train = pd.DataFrame({\n",
        "      \"train loss\": all_losses,\n",
        "  })\n",
        "  display.clear_output(wait=True)\n",
        "  df_train.plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TmZOcAvg-Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "48c33cd6-daee-4078-86c8-c7aa983619dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(all_losses[-5:]))\n",
        "# y_pred_index.shape, batch_y_true_index.shape\n",
        "index_match = (y_pred_index[0] @ batch_y_true_index[0].T)\n",
        "print(index_match.sum(dim=-1))\n",
        "print(index_match.sum(dim=0))"
      ],
      "metadata": {
        "id": "82uoeJaS9BbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f74b77-d6a4-40c6-a2f7-88ff937fb5d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.633822693901062\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000], grad_fn=<SumBackward1>)\n",
            "tensor([1.0000e+00, 1.0000e+00, 5.0872e-09, 6.8137e-08, 1.0000e+00, 3.0000e+00,\n",
            "        1.0000e+00, 4.4796e-08, 2.0000e+00, 1.0000e+00],\n",
            "       grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maromba_loss(\n",
        "    batch_y_true, y_pred_val, batch_y_true_index, y_pred_index, debug=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ur9IbDTUib1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_true"
      ],
      "metadata": {
        "id": "f8CuZ6KMihSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_values_W"
      ],
      "metadata": {
        "id": "-MZNaRpFyh2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_indices_W"
      ],
      "metadata": {
        "id": "JIvCa1hdykQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "595gvyUK0BOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}