{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HFAO_DVB2UqU",
        "XUal__xwo1aF",
        "a7mWbfGvkBT1"
      ],
      "authorship_tag": "ABX9TyNGJVFn/ED3JXw/Zc0o0c0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/soft_hadamard__demo_convergencia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3woABE_SOgS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demonstração PyTorch"
      ],
      "metadata": {
        "id": "HFAO_DVB2UqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = w0 * x² + w1 * x\n",
        "# (y real: y = 2 * x² + 5 * x)\n",
        "#\n",
        "# y = f0(f1(f2(x)))"
      ],
      "metadata": {
        "id": "dMLIykGDXHXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2.0 * torch.ones((2, 2)).float()\n",
        "a.requires_grad = True\n",
        "b = 3.0 * torch.ones((2, 2)).float()\n",
        "b.requires_grad = True"
      ],
      "metadata": {
        "id": "gI0HDYjbSls9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = (a * b).sum()\n",
        "c"
      ],
      "metadata": {
        "id": "g0vhOpWdTbVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()"
      ],
      "metadata": {
        "id": "6t0yCwoSZlwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "9lb7x_evTvEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "16cq_wCLT3aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad = None"
      ],
      "metadata": {
        "id": "4gZn7eNuUZun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad = None"
      ],
      "metadata": {
        "id": "H82KJ-_RaQOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = (a * a + b).mean()"
      ],
      "metadata": {
        "id": "P8gujdeOaRUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "Z_iMO8nRabZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.backward()"
      ],
      "metadata": {
        "id": "NjDyLr7vab8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "Y3Y4C3aWafHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "8Utr61jdamo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x, a, b):\n",
        "  return (a * x * x + b * x).sum(dim=1)\n",
        "\n",
        "def y_real(x):\n",
        "  x = torch.tensor(x).float()\n",
        "  return (2 * x * x + 5 * x).sum(dim=1)\n",
        "\n",
        "# (y real: y = 2 * x * x + 5 * x)"
      ],
      "metadata": {
        "id": "DGYDMd7Manmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import shuffle\n",
        "\n",
        "X = list(range(1000))\n",
        "shuffle(X)\n",
        "X = torch.tensor(X).reshape(-1, 1).float()\n",
        "Y = y_real(X)"
      ],
      "metadata": {
        "id": "XlFabAe6a7DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "2c75VJJKkQZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(0.5).float()\n",
        "b = torch.tensor(0.5).float()\n",
        "\n",
        "a = torch.nn.Parameter(a)\n",
        "b = torch.nn.Parameter(b)\n",
        "\n",
        "optim = torch.optim.Adam([a, b], lr=1e-3)\n",
        "\n",
        "for iter in range(10000):\n",
        "  Y_pred = y(X, a, b)\n",
        "  custo = ((Y - Y_pred).abs()).mean()\n",
        "  optim.zero_grad()\n",
        "  custo.backward()\n",
        "  optim.step()\n",
        "  if iter % 10 == 0:\n",
        "    print(custo.item())"
      ],
      "metadata": {
        "id": "_wwKDj3mbVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b"
      ],
      "metadata": {
        "id": "TMc6iqdQbYcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soft Hadamard"
      ],
      "metadata": {
        "id": "XUal__xwo1aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "def _transform(x):\n",
        "  return tr(x) * 2.0 - 1.0\n",
        "\n",
        "bsize = 64\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    'MNIST_root/',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    'MNIST_root_test/',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "Q3GExd3Kqu_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPositionEncoding(seq_len, d, n=10000):\n",
        "    P = np.zeros((seq_len, d))\n",
        "    for k in range(seq_len):\n",
        "        for i in np.arange(int(d/2)):\n",
        "            denominator = np.power(n, 2*i/d)\n",
        "            P[k, 2*i] = np.sin(k/denominator)\n",
        "            P[k, 2*i+1] = np.cos(k/denominator)\n",
        "    return P\n",
        "\n",
        "class HadamardSelfAttention(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32):\n",
        "    super().__init__()\n",
        "    self.Wk = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    self.Wq = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    # self.Wv = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (N, T, D_in)\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    K = self.Wk(x).reshape(n, t, -1)\n",
        "    Q = self.Wq(x).reshape(n, t, -1)\n",
        "    # V = self.Wv(x).reshape(n, t, -1)\n",
        "    V = x.clone().reshape(n, t, -1)\n",
        "    _, _, d_out = K.shape\n",
        "    KQ = (\n",
        "        K.repeat(1, t, 1).reshape(n, t, t, d_out)\n",
        "        * Q.repeat(1, 1, t).reshape(n, t, t, d_out)\n",
        "      )\n",
        "    A = nn.functional.gumbel_softmax(KQ, hard=True, dim=2)\n",
        "    V = A * V.unsqueeze(1).repeat(1, t, 1, 1)\n",
        "    V = V.sum(dim=2)\n",
        "    return V\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.W = nn.Sequential(\n",
        "        nn.Linear(in_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, num_classes, bias=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    x = self.W(x)\n",
        "    x = x.reshape(n, t, -1)\n",
        "    x = x.mean(dim=1)\n",
        "    return x\n",
        "\n",
        "class Composer(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.hsa = nn.Sequential(\n",
        "        # nn.Identity(),\n",
        "        HadamardSelfAttention(in_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "    )\n",
        "    self.clf = nn.Linear(out_features, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    x = self.hsa(x)\n",
        "    self._hsa_out = x\n",
        "    # x: N, T, d_out\n",
        "    x = x.mean(dim=1)\n",
        "    y = self.clf(x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "OhMmhe9nAzSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Composer(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "# model = MLP(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "optimizer = Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=1e-3,\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0gt2oJ3DuKhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "valid_epoch = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for x, y in iter(train_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "  for x, y in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    y = y.reshape(-1).tolist()\n",
        "    y_pred = torch.argmax(y_pred, dim=-1).reshape(-1).tolist()\n",
        "    valid_epoch.append(epoch)\n",
        "    valid_losses.append(loss.item())\n",
        "    valid_accs.append(accuracy_score(y, y_pred))\n",
        "  loss_df = pd.DataFrame(\n",
        "      {\n",
        "          \"Epoch\": valid_epoch,\n",
        "          \"Loss\": valid_losses,\n",
        "          \"Acc\": valid_accs,\n",
        "      }\n",
        "  )\n",
        "  display.clear_output(wait=True)\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Loss\"]].plot(figsize=(24, 2))\n",
        "  plt.show()\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Acc\"]].plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nMrSJ9HqvgjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(0, 63)\n",
        "model.eval()\n",
        "for x, _ in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    break\n",
        "model.forward(x[idx: idx + 1])\n",
        "x_ = model._hsa_out.cpu().detach().numpy()\n",
        "x = x[idx, 0].cpu().detach().numpy()\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "plt.imshow(x_[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GEVrOrdk4zGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement example of \"Produto Interno Maromba\": fitting linear transform using maromba product"
      ],
      "metadata": {
        "id": "wcumRBtgXbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ---"
      ],
      "metadata": {
        "id": "a7mWbfGvkBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TODO: encapsulate in a class and override @ and +\n",
        "# # TODO: implement vectorized version and indices\n",
        "# def maromba_dot(u, v, index_u, index_v):\n",
        "#   \"\"\"\n",
        "#   u: dim_u x 1\n",
        "#   v: dim_v x 1\n",
        "#   index_u: dim_u x index_dim\n",
        "#   index_v: dim_v x index_dim\n",
        "#   \"\"\"\n",
        "#   comb = (u @ v.T).reshape(-1, 1)\n",
        "#   sim = (index_u @ index_v.T).reshape(1, -1)\n",
        "#   dot = (sim @ comb)[0, 0]\n",
        "#   return dot"
      ],
      "metadata": {
        "id": "yCPp3QJSjz5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ----"
      ],
      "metadata": {
        "id": "WpnnNOnmkGTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dotlike(\n",
        "    a: torch.Tensor,\n",
        "    b: torch.Tensor,\n",
        "    op=lambda x, y: x * y,\n",
        "  ) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  a: ... x d\n",
        "  b: d x ...\n",
        "  \"\"\"\n",
        "  d = a.shape[-1]\n",
        "  N = a.shape[:-1]\n",
        "  M = b.shape[1:]\n",
        "  assert d == b.shape[0]\n",
        "  a = a.reshape(-1, d)\n",
        "  # b: ... x d\n",
        "  b = b.reshape(d, -1).T\n",
        "  N_ = a.shape[0]\n",
        "  M_ = b.shape[0]\n",
        "  a = a.unsqueeze(1).repeat(1, M_, 1)\n",
        "  b = b.unsqueeze(0).repeat(N_, 1, 1)\n",
        "  dot = op(a, b).sum(dim=-1)\n",
        "  dot = dot.reshape(N + M)\n",
        "  return dot\n",
        "\n",
        "def y(x, W):\n",
        "  \"\"\"\n",
        "  x: N x d_in\n",
        "  W: d_out x d_in\n",
        "  \"\"\"\n",
        "  return x @ W.T\n",
        "\n",
        "def combine_indices(index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  index_new[i, j] = f(index_w.sum(dim=1)[i] + index_x.sum(dim=1)[j]; theta)\n",
        "  \"\"\"\n",
        "  d_out, d_in, d_index = index_w.shape\n",
        "  n, d_in_, d_index_ = index_x.shape\n",
        "  assert d_in == d_in_\n",
        "  assert d_index == d_index_\n",
        "  idxw_sum = index_w.sum(dim=1)\n",
        "  # idxw_sum: d_out x N x d_index\n",
        "  idxw_sum = idxw_sum.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxx_sum = index_x.sum(dim=1)\n",
        "  # idxx_sum: d_out x N x d_index\n",
        "  idxx_sum = idxx_sum.unsqueeze(0).repeat(d_out, 1, 1)\n",
        "  index_new = indexer(idxw_sum + idxx_sum)\n",
        "  # index_new: N x d_out x d_index\n",
        "  index_new = index_new.permute(1, 0, 2)\n",
        "  index_new = nn.functional.gumbel_softmax(index_new, hard=False, dim=-1)\n",
        "  # index_new = nn.functional.softmax(index_new, dim=-1)\n",
        "  return index_new\n",
        "\n",
        "def genidx(idxu, idxv, indexer, debug=False):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # idxu_new: M x d_idx\n",
        "  # idxv_new: N x d_idx\n",
        "  if debug:\n",
        "    Pdb().set_trace()\n",
        "  idxu_new = indexer(idxu.reshape(-1, d_idx)).reshape(m, d_u, d_idx).mean(dim=1)\n",
        "  idxv_new = indexer(idxv.reshape(-1, d_idx)).reshape(n, d_v, d_idx).mean(dim=1)\n",
        "  # idxu_new = nn.functional.gumbel_softmax(idxu_new, hard=True, dim=-1)\n",
        "  # idxv_new = nn.functional.gumbel_softmax(idxv_new, hard=True, dim=-1)\n",
        "  idxu_new = idxu_new.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxv_new = idxv_new.unsqueeze(0).repeat(m, 1, 1)\n",
        "  # idx_new = (idxu_new + idxv_new - idxu_new * idxv_new)\n",
        "  # idx_new = nn.functional.gumbel_softmax(idx_new, hard=True, dim=-1)\n",
        "  idx_new = idxu_new + idxv_new\n",
        "  return idx_new\n",
        "\n",
        "def gbmd(u, v, idxu, idxv, indexer):\n",
        "  \"\"\"\n",
        "  'General Batch Maromba Dot'\n",
        "  Shorter implementation for the 'batch maromba dot' operation.\n",
        "  u: M x d_u\n",
        "  v: N x d_v\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u = u.shape\n",
        "  n, d_v = v.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  assert (m, d_u, d_idx) == idxu.shape\n",
        "  assert (n, d_v, d_idx) == idxv.shape\n",
        "  # uidxu: M x d_idx\n",
        "  # vidxv: N x d_idx\n",
        "  uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "  vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "  dot = uidxu @ vidxv.T\n",
        "  ### Strong reason for encapsulation:\n",
        "  idx_new = genidx(idxu, idxv, indexer, debug=False)\n",
        "  # idx_new = combine_indices(idxu, idxv, indexer).permute(1, 0, 2)\n",
        "  return dot, idx_new\n",
        "\n",
        "def batch_maromba_dot(W, x, index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  W: d_out x d_in\n",
        "  x: N x d_in\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  \"\"\"\n",
        "  d_out, d_in = W.shape\n",
        "  n, d_in_ = x.shape\n",
        "  d_index = index_w.shape[-1]\n",
        "  assert d_in == d_in_, \"W.shape[1] and x.shape[1] must be equal.\"\n",
        "  assert index_w.shape[1:] == index_x.shape[1:]\n",
        "  # comb: N x d_out x d_in x d_in\n",
        "  W = W.reshape(-1, 1)\n",
        "  x = x.T.reshape(1, -1)\n",
        "  comb = (W @ x).reshape(d_out, d_in, d_in, n)\n",
        "  comb = comb.permute(3, 0, 1, 2)\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  comb = comb.reshape(n * d_out, d_in * d_in, 1)\n",
        "  index_x = index_x.permute(2, 1, 0)\n",
        "  # index_x: d_index x (d_in * N)\n",
        "  index_x = index_x.reshape(d_index, d_in * n)\n",
        "  # index_w: (d_out * d_in) x d_index\n",
        "  index_w = index_w.reshape(d_out * d_in, d_index)\n",
        "  sim = (index_w @ index_x).reshape(d_out, d_in, d_in, n)\n",
        "  sim = sim.permute(3, 0, 1, 2)\n",
        "  sim = sim.reshape(n * d_out, 1, d_in * d_in)\n",
        "  # Overview of shapes:\n",
        "  # sim:  (N * d_out) x 1 x (d_in(W) * d_in(x))\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  # Matrix product of the last two dimensions seems correct.\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  dot = dot.reshape(n, d_out)\n",
        "  index_w = index_w.reshape(d_out, d_in, d_index)\n",
        "  index_x = index_x.reshape(d_index, d_in, n).permute(2, 1, 0)\n",
        "  index_new = combine_indices(index_w, index_x, indexer)\n",
        "  return dot, index_new\n",
        "\n",
        "def batch_maromba_dot_(u, v, index_u, index_v):\n",
        "  \"\"\"\n",
        "  u: N x dim_u\n",
        "  v: N x dim_v\n",
        "  index_u: N x dim_u x index_dim\n",
        "  index_v: N x dim_v x index_dim\n",
        "  \"\"\"\n",
        "  n, dim_u = u.shape\n",
        "  m, dim_v = v.shape\n",
        "  assert n == m, \"u.shape[0] and v.shape[0] must be equal.\"\n",
        "  u = u.reshape(n, dim_u, 1)\n",
        "  v = v.reshape(n, 1, dim_v)\n",
        "  # comb: N x dim_u x dim_v\n",
        "  comb = torch.bmm(u, v)\n",
        "  comb = comb.reshape(n, -1, 1)\n",
        "  index_v = index_v.permute(0, 2, 1)\n",
        "  # sim: N x dim_u x dim_v\n",
        "  sim = torch.bmm(index_u, index_v)\n",
        "  sim = sim.reshape(n, 1, -1)\n",
        "  # dot: N\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  return dot\n",
        "\n",
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  # dot_true = torch.bmm(y_true.unsqueeze(1), y_true.unsqueeze(-1))[:, 0, 0]\n",
        "  # dot_pred = torch.bmm(y_pred.unsqueeze(1), y_pred.unsqueeze(-1))[:, 0, 0]\n",
        "  # mdot_true_pred = batch_maromba_dot_(y_true, y_pred, true_index, pred_index)\n",
        "  index_match = (pred_index.mean(dim=0) @ true_index.mean(dim=0).T)\n",
        "  # match_loss_lr = (y_pred - (index_match @ y_true.T).T).abs().mean()\n",
        "  # match_loss_rl = (y_true - (index_match.T @ y_pred.T).T).abs().mean()\n",
        "  match_loss_lr = ((y_pred - (y_true @ index_match.T)).abs()).mean()\n",
        "  match_loss_rl = ((y_true - (y_pred @ index_match)).abs()).mean()\n",
        "  # dot_loss = ((dot_true - mdot_true_pred).abs()).mean()\n",
        "  # mu_loss = (y_true.mean(dim=-1) - y_pred.mean(dim=-1)).abs().mean()\n",
        "  # index_loss_0 = (1.0 - index_match.sum(dim=0)).abs().mean()\n",
        "  # index_loss_1 = (1.0 - index_match.sum(dim=-1)).abs().mean()\n",
        "  if debug:\n",
        "    Pdb().set_trace() ###\n",
        "  # loss = (dot_loss + mu_loss + index_loss_0 + index_loss_1)\n",
        "  loss = match_loss_lr + match_loss_rl\n",
        "  return loss"
      ],
      "metadata": {
        "id": "eCR6VV4NXpjw"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 2\n",
        "out_dim = 3\n",
        "index_dim = in_dim + out_dim # making things easier\n",
        "__hidden_dim = 5 * index_dim\n",
        "num_examples = 1000\n",
        "\n",
        "# Ground-truth parameters\n",
        "W_true = torch.randn((out_dim, in_dim), requires_grad=False)\n",
        "W_true = W_true.float().to(device)\n",
        "\n",
        "# Parameters to be trained\n",
        "bag_values_W = nn.Parameter(torch.randn((out_dim, in_dim)))\n",
        "bag_values_W = bag_values_W.float().to(device)\n",
        "# bag_indices_W = nn.Parameter(torch.randn((out_dim, in_dim, index_dim)))\n",
        "bag_indices_W = nn.Parameter(\n",
        "    torch.eye(index_dim)[:in_dim].unsqueeze(0).repeat(out_dim, 1, 1)\n",
        "    + torch.eye(index_dim)[in_dim:].unsqueeze(1).repeat(1, in_dim, 1)\n",
        ")\n",
        "bag_indices_W = bag_indices_W.float().to(device)\n",
        "\n",
        "# Indexer model to be trained\n",
        "# indexer = nn.Sequential(\n",
        "#     nn.Linear(index_dim, __hidden_dim),\n",
        "#     # nn.Dropout(0.5),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(__hidden_dim, index_dim),\n",
        "# ).to(device)\n",
        "indexer = nn.Identity().to(device)\n",
        "\n",
        "# Input data\n",
        "values_x = 1e0 * torch.randn((num_examples, in_dim))\n",
        "# index_x = torch.randn((1, in_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "index_x = torch.eye(index_dim)[:in_dim]\n",
        "index_x = index_x.unsqueeze(0).repeat(num_examples, 1, 1)\n",
        "\n",
        "# Ground-truth target\n",
        "y_true = y(values_x, W_true)\n",
        "# y_true_index = torch.randn((1, out_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "y_true_index = torch.eye(index_dim)[in_dim:]\n",
        "# y_true_index = nn.functional.gumbel_softmax(\n",
        "#     y_true_index[torch.randperm(out_dim)]\n",
        "#     + y_true_index[torch.randperm(out_dim)],\n",
        "#     dim=1,\n",
        "#     hard=False,\n",
        "# )\n",
        "y_true_index = y_true_index.unsqueeze(0).repeat(num_examples, 1, 1)"
      ],
      "metadata": {
        "id": "UHC_bTf1GumV"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dot1, idx1 = gbmd(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# dot2, idx2 = batch_maromba_dot(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# print(dot1.shape, dot2.shape)\n",
        "# print(idx1.shape, idx2.shape)\n",
        "# print(torch.allclose(dot1.T, dot2), torch.allclose(idx1, idx2))"
      ],
      "metadata": {
        "id": "xEdq4WHJ_ZFO"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# opt_vectors = Adam([bag_values_W, bag_indices_W], lr=1e-3)\n",
        "opt_vectors = Adam([bag_values_W], lr=1e-3)\n",
        "# opt_indexer = Adam(indexer.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "epoch_len = num_examples // batch_size\n",
        "\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_losses = []\n",
        "  for _ in range(epoch_len):\n",
        "    batch_idx = np.random.choice(num_examples, batch_size)\n",
        "    batch_x = values_x[batch_idx].float().to(device)\n",
        "    batch_x_index = index_x[batch_idx].float().to(device)\n",
        "    batch_y_true = y_true[batch_idx].float().to(device)\n",
        "    batch_y_true_index = y_true_index[batch_idx].float().to(device)\n",
        "    # gumbel_bag_indices_W = nn.functional.gumbel_softmax(\n",
        "    #     bag_indices_W, hard=False, dim=-1\n",
        "    # ) ###\n",
        "    # y_pred_val, y_pred_index = batch_maromba_dot(\n",
        "    #     bag_values_W, batch_x, bag_indices_W, batch_x_index, indexer\n",
        "    # ) ###\n",
        "    y_pred_val, y_pred_index = gbmd(\n",
        "        batch_x, bag_values_W, batch_x_index, bag_indices_W, indexer\n",
        "    )\n",
        "    ###\n",
        "    loss = maromba_loss(\n",
        "        batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "    )\n",
        "    opt_vectors.zero_grad()\n",
        "    # opt_indexer.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_vectors.step()\n",
        "    # opt_indexer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  all_losses.append(np.mean(epoch_losses))\n",
        "  df_train = pd.DataFrame({\n",
        "      \"train loss\": all_losses,\n",
        "  })\n",
        "  display.clear_output(wait=True)\n",
        "  df_train.plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TmZOcAvg-Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "6ddca3b5-835c-4904-a070-f7ff646c9220"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(all_losses[-5:]))\n",
        "# y_pred_index.shape, batch_y_true_index.shape\n",
        "index_match = (y_pred_index[0] @ batch_y_true_index[0].T)\n",
        "print(index_match.sum(dim=-1))\n",
        "print(index_match.sum(dim=0))"
      ],
      "metadata": {
        "id": "82uoeJaS9BbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9b98f7-7e56-43c1-ba71-d8fee6261fb4"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0002255788285354708\n",
            "tensor([1., 1., 1.], grad_fn=<SumBackward1>)\n",
            "tensor([1., 1., 1.], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maromba_loss(\n",
        "    batch_y_true, y_pred_val, batch_y_true_index, y_pred_index, debug=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ur9IbDTUib1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_true, bag_values_W, bag_indices_W"
      ],
      "metadata": {
        "id": "f8CuZ6KMihSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e353acf6-810e-4bfc-87bb-36e61a3fe45b"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.7533, -1.3973],\n",
              "         [ 1.3978, -0.6443],\n",
              "         [ 0.1670, -0.0539]]), Parameter containing:\n",
              " tensor([[-0.7532, -1.3973],\n",
              "         [ 1.3978, -0.6441],\n",
              "         [ 0.1668, -0.0541]], requires_grad=True), Parameter containing:\n",
              " tensor([[[1., 0., 1., 0., 0.],\n",
              "          [0., 1., 1., 0., 0.]],\n",
              " \n",
              "         [[1., 0., 0., 1., 0.],\n",
              "          [0., 1., 0., 1., 0.]],\n",
              " \n",
              "         [[1., 0., 0., 0., 1.],\n",
              "          [0., 1., 0., 0., 1.]]], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch_y_true_index[0])\n",
        "print(y_pred_index[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fyYyFZhGeyl",
        "outputId": "0ea8b3cc-78b1-46f0-903c-24f1d41435f5"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor([[1., 1., 1., 0., 0.],\n",
            "        [1., 1., 0., 1., 0.],\n",
            "        [1., 1., 0., 0., 1.]], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_true"
      ],
      "metadata": {
        "id": "_XMMfkvyPn_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_values_W"
      ],
      "metadata": {
        "id": "xhRmg2sDPpRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KC809FMxPquK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}