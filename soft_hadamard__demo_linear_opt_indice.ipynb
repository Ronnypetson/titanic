{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HFAO_DVB2UqU",
        "XUal__xwo1aF",
        "a7mWbfGvkBT1"
      ],
      "authorship_tag": "ABX9TyOzZxMuvZHad+2FhVDWuy2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronnypetson/titanic/blob/master/soft_hadamard__demo_linear_opt_indice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3woABE_SOgS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pylab as plt\n",
        "import time\n",
        "from IPython import display\n",
        "from IPython.core.debugger import Pdb\n",
        "\n",
        "def breakpoint():\n",
        "    Pdb().set_trace()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demonstração PyTorch"
      ],
      "metadata": {
        "id": "HFAO_DVB2UqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = w0 * x² + w1 * x\n",
        "# (y real: y = 2 * x² + 5 * x)\n",
        "#\n",
        "# y = f0(f1(f2(x)))"
      ],
      "metadata": {
        "id": "dMLIykGDXHXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2.0 * torch.ones((2, 2)).float()\n",
        "a.requires_grad = True\n",
        "b = 3.0 * torch.ones((2, 2)).float()\n",
        "b.requires_grad = True"
      ],
      "metadata": {
        "id": "gI0HDYjbSls9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = (a * b).sum()\n",
        "c"
      ],
      "metadata": {
        "id": "g0vhOpWdTbVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()"
      ],
      "metadata": {
        "id": "6t0yCwoSZlwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "9lb7x_evTvEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "16cq_wCLT3aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad = None"
      ],
      "metadata": {
        "id": "4gZn7eNuUZun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad = None"
      ],
      "metadata": {
        "id": "H82KJ-_RaQOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = (a * a + b).mean()"
      ],
      "metadata": {
        "id": "P8gujdeOaRUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "Z_iMO8nRabZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.backward()"
      ],
      "metadata": {
        "id": "NjDyLr7vab8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "Y3Y4C3aWafHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "id": "8Utr61jdamo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x, a, b):\n",
        "  return (a * x * x + b * x).sum(dim=1)\n",
        "\n",
        "def y_real(x):\n",
        "  x = torch.tensor(x).float()\n",
        "  return (2 * x * x + 5 * x).sum(dim=1)\n",
        "\n",
        "# (y real: y = 2 * x * x + 5 * x)"
      ],
      "metadata": {
        "id": "DGYDMd7Manmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import shuffle\n",
        "\n",
        "X = list(range(1000))\n",
        "shuffle(X)\n",
        "X = torch.tensor(X).reshape(-1, 1).float()\n",
        "Y = y_real(X)"
      ],
      "metadata": {
        "id": "XlFabAe6a7DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "2c75VJJKkQZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(0.5).float()\n",
        "b = torch.tensor(0.5).float()\n",
        "\n",
        "a = torch.nn.Parameter(a)\n",
        "b = torch.nn.Parameter(b)\n",
        "\n",
        "optim = torch.optim.Adam([a, b], lr=1e-3)\n",
        "\n",
        "for iter in range(10000):\n",
        "  Y_pred = y(X, a, b)\n",
        "  custo = ((Y - Y_pred).abs()).mean()\n",
        "  optim.zero_grad()\n",
        "  custo.backward()\n",
        "  optim.step()\n",
        "  if iter % 10 == 0:\n",
        "    print(custo.item())"
      ],
      "metadata": {
        "id": "_wwKDj3mbVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b"
      ],
      "metadata": {
        "id": "TMc6iqdQbYcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soft Hadamard"
      ],
      "metadata": {
        "id": "XUal__xwo1aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr = ToTensor()\n",
        "\n",
        "def _transform(x):\n",
        "  return tr(x) * 2.0 - 1.0\n",
        "\n",
        "bsize = 64\n",
        "\n",
        "MNIST_train_data = MNIST(\n",
        "    'MNIST_root/',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=_transform,\n",
        ")\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_train_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "MNIST_test_data = MNIST(\n",
        "    'MNIST_root_test/',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=_transform,\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_test_data,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "Q3GExd3Kqu_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPositionEncoding(seq_len, d, n=10000):\n",
        "    P = np.zeros((seq_len, d))\n",
        "    for k in range(seq_len):\n",
        "        for i in np.arange(int(d/2)):\n",
        "            denominator = np.power(n, 2*i/d)\n",
        "            P[k, 2*i] = np.sin(k/denominator)\n",
        "            P[k, 2*i+1] = np.cos(k/denominator)\n",
        "    return P\n",
        "\n",
        "class HadamardSelfAttention(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32):\n",
        "    super().__init__()\n",
        "    self.Wk = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    self.Wq = nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(out_features, out_features, bias=True),\n",
        "    )\n",
        "    # self.Wv = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (N, T, D_in)\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    K = self.Wk(x).reshape(n, t, -1)\n",
        "    Q = self.Wq(x).reshape(n, t, -1)\n",
        "    # V = self.Wv(x).reshape(n, t, -1)\n",
        "    V = x.clone().reshape(n, t, -1)\n",
        "    _, _, d_out = K.shape\n",
        "    KQ = (\n",
        "        K.repeat(1, t, 1).reshape(n, t, t, d_out)\n",
        "        * Q.repeat(1, 1, t).reshape(n, t, t, d_out)\n",
        "      )\n",
        "    A = nn.functional.gumbel_softmax(KQ, hard=True, dim=2)\n",
        "    V = A * V.unsqueeze(1).repeat(1, t, 1, 1)\n",
        "    V = V.sum(dim=2)\n",
        "    return V\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.W = nn.Sequential(\n",
        "        nn.Linear(in_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, 2 * out_features, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(2 * out_features, num_classes, bias=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    n, t, d_in = x.shape\n",
        "    x = x.reshape(-1, d_in)\n",
        "    x = self.W(x)\n",
        "    x = x.reshape(n, t, -1)\n",
        "    x = x.mean(dim=1)\n",
        "    return x\n",
        "\n",
        "class Composer(nn.Module):\n",
        "  def __init__(self, in_features=28, out_features=32, num_classes=10):\n",
        "    super().__init__()\n",
        "    pe = getPositionEncoding(in_features, in_features)\n",
        "    self.pe = torch.tensor(pe).float().to(device)\n",
        "    self.hsa = nn.Sequential(\n",
        "        # nn.Identity(),\n",
        "        HadamardSelfAttention(in_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "        # HadamardSelfAttention(out_features, out_features),\n",
        "    )\n",
        "    self.clf = nn.Linear(out_features, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: N, 1, T, d_in\n",
        "    x = x.squeeze(1)\n",
        "    x = x + self.pe\n",
        "    x = self.hsa(x)\n",
        "    self._hsa_out = x\n",
        "    # x: N, T, d_out\n",
        "    x = x.mean(dim=1)\n",
        "    y = self.clf(x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "OhMmhe9nAzSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Composer(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "# model = MLP(in_features=28, out_features=28, num_classes=10).to(device)\n",
        "optimizer = Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=1e-3,\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0gt2oJ3DuKhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "valid_epoch = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for x, y in iter(train_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "  for x, y in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model.forward(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    y = y.reshape(-1).tolist()\n",
        "    y_pred = torch.argmax(y_pred, dim=-1).reshape(-1).tolist()\n",
        "    valid_epoch.append(epoch)\n",
        "    valid_losses.append(loss.item())\n",
        "    valid_accs.append(accuracy_score(y, y_pred))\n",
        "  loss_df = pd.DataFrame(\n",
        "      {\n",
        "          \"Epoch\": valid_epoch,\n",
        "          \"Loss\": valid_losses,\n",
        "          \"Acc\": valid_accs,\n",
        "      }\n",
        "  )\n",
        "  display.clear_output(wait=True)\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Loss\"]].plot(figsize=(24, 2))\n",
        "  plt.show()\n",
        "  loss_df.groupby(\"Epoch\").mean().reset_index()[[\"Acc\"]].plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nMrSJ9HqvgjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(0, 63)\n",
        "model.eval()\n",
        "for x, _ in iter(test_data_loader):\n",
        "    x = x.to(device)\n",
        "    break\n",
        "model.forward(x[idx: idx + 1])\n",
        "x_ = model._hsa_out.cpu().detach().numpy()\n",
        "x = x[idx, 0].cpu().detach().numpy()\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "plt.imshow(x_[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GEVrOrdk4zGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement example of \"Produto Interno Maromba\": fitting linear transform using maromba product"
      ],
      "metadata": {
        "id": "wcumRBtgXbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ---"
      ],
      "metadata": {
        "id": "a7mWbfGvkBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TODO: encapsulate in a class and override @ and +\n",
        "# # TODO: implement vectorized version and indices\n",
        "# def maromba_dot(u, v, index_u, index_v):\n",
        "#   \"\"\"\n",
        "#   u: dim_u x 1\n",
        "#   v: dim_v x 1\n",
        "#   index_u: dim_u x index_dim\n",
        "#   index_v: dim_v x index_dim\n",
        "#   \"\"\"\n",
        "#   comb = (u @ v.T).reshape(-1, 1)\n",
        "#   sim = (index_u @ index_v.T).reshape(1, -1)\n",
        "#   dot = (sim @ comb)[0, 0]\n",
        "#   return dot"
      ],
      "metadata": {
        "id": "yCPp3QJSjz5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ----"
      ],
      "metadata": {
        "id": "WpnnNOnmkGTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dotlike(\n",
        "    a: torch.Tensor,\n",
        "    b: torch.Tensor,\n",
        "    op=lambda x, y: x * y,\n",
        "  ) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  a: ... x d\n",
        "  b: d x ...\n",
        "  \"\"\"\n",
        "  d = a.shape[-1]\n",
        "  N = a.shape[:-1]\n",
        "  M = b.shape[1:]\n",
        "  assert d == b.shape[0]\n",
        "  a = a.reshape(-1, d)\n",
        "  # b: ... x d\n",
        "  b = b.reshape(d, -1).T\n",
        "  N_ = a.shape[0]\n",
        "  M_ = b.shape[0]\n",
        "  a = a.unsqueeze(1).repeat(1, M_, 1)\n",
        "  b = b.unsqueeze(0).repeat(N_, 1, 1)\n",
        "  dot = op(a, b).sum(dim=-1)\n",
        "  dot = dot.reshape(N + M)\n",
        "  return dot\n",
        "\n",
        "def y(x, W):\n",
        "  \"\"\"\n",
        "  x: N x d_in\n",
        "  W: d_out x d_in\n",
        "  \"\"\"\n",
        "  return x @ W.T\n",
        "\n",
        "def combine_indices(index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  index_new[i, j] = f(index_w.sum(dim=1)[i] + index_x.sum(dim=1)[j]; theta)\n",
        "  \"\"\"\n",
        "  d_out, d_in, d_index = index_w.shape\n",
        "  n, d_in_, d_index_ = index_x.shape\n",
        "  assert d_in == d_in_\n",
        "  assert d_index == d_index_\n",
        "  idxw_sum = index_w.sum(dim=1)\n",
        "  # idxw_sum: d_out x N x d_index\n",
        "  idxw_sum = idxw_sum.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxx_sum = index_x.sum(dim=1)\n",
        "  # idxx_sum: d_out x N x d_index\n",
        "  idxx_sum = idxx_sum.unsqueeze(0).repeat(d_out, 1, 1)\n",
        "  index_new = indexer(idxw_sum + idxx_sum)\n",
        "  # index_new: N x d_out x d_index\n",
        "  index_new = index_new.permute(1, 0, 2)\n",
        "  index_new = nn.functional.gumbel_softmax(index_new, hard=False, dim=-1)\n",
        "  # index_new = nn.functional.softmax(index_new, dim=-1)\n",
        "  return index_new\n",
        "\n",
        "def genidx(idxu, idxv, indexer, debug=False):\n",
        "  \"\"\"\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u, d_idx = idxu.shape\n",
        "  n, d_v, _ = idxv.shape\n",
        "  assert d_idx == idxv.shape[-1]\n",
        "  # idxu_new: M x d_idx\n",
        "  # idxv_new: N x d_idx\n",
        "  if debug:\n",
        "    Pdb().set_trace()\n",
        "  idxu_new = indexer(idxu.reshape(-1, d_idx)).reshape(m, d_u, d_idx).mean(dim=1)\n",
        "  idxv_new = indexer(idxv.reshape(-1, d_idx)).reshape(n, d_v, d_idx).mean(dim=1)\n",
        "  idxu_new = idxu_new.unsqueeze(1).repeat(1, n, 1)\n",
        "  idxv_new = idxv_new.unsqueeze(0).repeat(m, 1, 1)\n",
        "  idx_new = idxu_new + idxv_new\n",
        "  idx_new = nn.functional.gumbel_softmax(idx_new, hard=True, dim=-1)\n",
        "  return idx_new\n",
        "\n",
        "def gbmd(u, v, idxu, idxv, indexer):\n",
        "  \"\"\"\n",
        "  'General Batch Maromba Dot'\n",
        "  Shorter implementation for the 'batch maromba dot' operation.\n",
        "  u: M x d_u\n",
        "  v: N x d_v\n",
        "  idxu: M x d_u x d_idx\n",
        "  idxv: N x d_v x d_idx\n",
        "  indexer: (shape x d_idx) -> (shape x d_idx)\n",
        "  \"\"\"\n",
        "  m, d_u = u.shape\n",
        "  n, d_v = v.shape\n",
        "  d_idx = idxu.shape[-1]\n",
        "  assert (m, d_u, d_idx) == idxu.shape\n",
        "  assert (n, d_v, d_idx) == idxv.shape\n",
        "  # uidxu: M x d_idx\n",
        "  # vidxv: N x d_idx\n",
        "  uidxu = torch.bmm(u.reshape(m, 1, d_u), idxu).squeeze(1)\n",
        "  vidxv = torch.bmm(v.reshape(n, 1, d_v), idxv).squeeze(1)\n",
        "  dot = uidxu @ vidxv.T\n",
        "  ### Strong reason for encapsulation:\n",
        "  idx_new = genidx(idxu, idxv, indexer, debug=False)\n",
        "  # idx_new = combine_indices(idxu, idxv, indexer).permute(1, 0, 2)\n",
        "  return dot, idx_new\n",
        "\n",
        "def batch_maromba_dot(W, x, index_w, index_x, indexer):\n",
        "  \"\"\"\n",
        "  W: d_out x d_in\n",
        "  x: N x d_in\n",
        "  index_w: d_out x d_in x d_index\n",
        "  index_x: N x d_in x d_index\n",
        "  \"\"\"\n",
        "  d_out, d_in = W.shape\n",
        "  n, d_in_ = x.shape\n",
        "  d_index = index_w.shape[-1]\n",
        "  assert d_in == d_in_, \"W.shape[1] and x.shape[1] must be equal.\"\n",
        "  assert index_w.shape[1:] == index_x.shape[1:]\n",
        "  # comb: N x d_out x d_in x d_in\n",
        "  W = W.reshape(-1, 1)\n",
        "  x = x.T.reshape(1, -1)\n",
        "  comb = (W @ x).reshape(d_out, d_in, d_in, n)\n",
        "  comb = comb.permute(3, 0, 1, 2)\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  comb = comb.reshape(n * d_out, d_in * d_in, 1)\n",
        "  index_x = index_x.permute(2, 1, 0)\n",
        "  # index_x: d_index x (d_in * N)\n",
        "  index_x = index_x.reshape(d_index, d_in * n)\n",
        "  # index_w: (d_out * d_in) x d_index\n",
        "  index_w = index_w.reshape(d_out * d_in, d_index)\n",
        "  sim = (index_w @ index_x).reshape(d_out, d_in, d_in, n)\n",
        "  sim = sim.permute(3, 0, 1, 2)\n",
        "  sim = sim.reshape(n * d_out, 1, d_in * d_in)\n",
        "  # Overview of shapes:\n",
        "  # sim:  (N * d_out) x 1 x (d_in(W) * d_in(x))\n",
        "  # comb: (N * d_out) x (d_in(W) * d_in(x)) x 1\n",
        "  # Matrix product of the last two dimensions seems correct.\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  dot = dot.reshape(n, d_out)\n",
        "  index_w = index_w.reshape(d_out, d_in, d_index)\n",
        "  index_x = index_x.reshape(d_index, d_in, n).permute(2, 1, 0)\n",
        "  index_new = combine_indices(index_w, index_x, indexer)\n",
        "  return dot, index_new\n",
        "\n",
        "def batch_maromba_dot_(u, v, index_u, index_v):\n",
        "  \"\"\"\n",
        "  u: N x dim_u\n",
        "  v: N x dim_v\n",
        "  index_u: N x dim_u x index_dim\n",
        "  index_v: N x dim_v x index_dim\n",
        "  \"\"\"\n",
        "  n, dim_u = u.shape\n",
        "  m, dim_v = v.shape\n",
        "  assert n == m, \"u.shape[0] and v.shape[0] must be equal.\"\n",
        "  u = u.reshape(n, dim_u, 1)\n",
        "  v = v.reshape(n, 1, dim_v)\n",
        "  # comb: N x dim_u x dim_v\n",
        "  comb = torch.bmm(u, v)\n",
        "  comb = comb.reshape(n, -1, 1)\n",
        "  index_v = index_v.permute(0, 2, 1)\n",
        "  # sim: N x dim_u x dim_v\n",
        "  sim = torch.bmm(index_u, index_v)\n",
        "  sim = sim.reshape(n, 1, -1)\n",
        "  # dot: N\n",
        "  dot = torch.bmm(sim, comb)[:, 0, 0]\n",
        "  return dot\n",
        "\n",
        "def maromba_loss(y_true, y_pred, true_index, pred_index, debug=False):\n",
        "  \"\"\"\n",
        "  y_true: N x d_out\n",
        "  y_pred: N x d_out\n",
        "  true_index: N x d_out x d_index\n",
        "  pred_index: N x d_out x d_index\n",
        "  \"\"\"\n",
        "  assert y_true.shape == y_pred.shape\n",
        "  assert true_index.shape == pred_index.shape\n",
        "  # dot_true = torch.bmm(y_true.unsqueeze(1), y_true.unsqueeze(-1))[:, 0, 0]\n",
        "  # dot_pred = torch.bmm(y_pred.unsqueeze(1), y_pred.unsqueeze(-1))[:, 0, 0]\n",
        "  # mdot_true_pred = batch_maromba_dot_(y_true, y_pred, true_index, pred_index)\n",
        "  index_match = (pred_index.mean(dim=0) @ true_index.mean(dim=0).T)\n",
        "  # match_loss_lr = (y_pred - (index_match @ y_true.T).T).abs().mean()\n",
        "  # match_loss_rl = (y_true - (index_match.T @ y_pred.T).T).abs().mean()\n",
        "  \n",
        "  # match_loss_lr = ((y_pred - (y_true @ index_match.T)).abs()).mean()\n",
        "  # match_loss_rl = ((y_true - (y_pred @ index_match)).abs()).mean()\n",
        "\n",
        "  huber = nn.HuberLoss()\n",
        "  match_loss_lr = huber(y_pred, y_true @ index_match.T)\n",
        "  match_loss_rl = huber(y_true, y_pred @ index_match)\n",
        "\n",
        "  # dot_loss = ((dot_true - mdot_true_pred).abs()).mean()\n",
        "  # mu_loss = (y_true.mean(dim=-1) - y_pred.mean(dim=-1)).abs().mean()\n",
        "  # index_loss_0 = (1.0 - index_match.sum(dim=0)).abs().mean()\n",
        "  # index_loss_1 = (1.0 - index_match.sum(dim=-1)).abs().mean()\n",
        "  if debug:\n",
        "    Pdb().set_trace() ###\n",
        "  # loss = (dot_loss + mu_loss + index_loss_0 + index_loss_1)\n",
        "  loss = match_loss_lr + match_loss_rl\n",
        "  return loss"
      ],
      "metadata": {
        "id": "eCR6VV4NXpjw"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 10\n",
        "out_dim = 15\n",
        "index_dim = in_dim + out_dim # making things easier\n",
        "__hidden_dim = 5 * index_dim\n",
        "num_examples = 1000\n",
        "\n",
        "# Ground-truth parameters\n",
        "W_true = torch.randn((out_dim, in_dim), requires_grad=False)\n",
        "W_true = W_true.float().to(device)\n",
        "\n",
        "# Parameters to be trained\n",
        "bag_values_W = nn.Parameter(torch.randn((out_dim, in_dim)))\n",
        "bag_values_W = bag_values_W.float().to(device)\n",
        "# bag_indices_W = nn.Parameter(torch.randn((out_dim, in_dim, index_dim)))\n",
        "bag_indices_W = nn.Parameter(\n",
        "    torch.eye(index_dim)[:in_dim].unsqueeze(0).repeat(out_dim, 1, 1)\n",
        "    + torch.eye(index_dim)[in_dim:].unsqueeze(1).repeat(1, in_dim, 1)\n",
        ")\n",
        "bag_indices_W = bag_indices_W.float().to(device)\n",
        "\n",
        "# Indexer model to be trained\n",
        "# indexer = nn.Sequential(\n",
        "#     nn.Linear(index_dim, __hidden_dim),\n",
        "#     # nn.Dropout(0.5),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(__hidden_dim, index_dim),\n",
        "# ).to(device)\n",
        "indexer = nn.Identity().to(device)\n",
        "\n",
        "# Input data\n",
        "values_x = 1e0 * torch.randn((num_examples, in_dim))\n",
        "# index_x = torch.randn((1, in_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "index_x = torch.eye(index_dim)[:in_dim]\n",
        "index_x = index_x.unsqueeze(0).repeat(num_examples, 1, 1)\n",
        "\n",
        "# Ground-truth target\n",
        "y_true = y(values_x, W_true)\n",
        "# y_true_index = torch.randn((1, out_dim, index_dim)).repeat(num_examples, 1, 1)\n",
        "y_true_index = torch.eye(index_dim)[in_dim:]\n",
        "# y_true_index = nn.functional.gumbel_softmax(\n",
        "#     y_true_index[torch.randperm(out_dim)]\n",
        "#     + y_true_index[torch.randperm(out_dim)],\n",
        "#     dim=1,\n",
        "#     hard=False,\n",
        "# )\n",
        "y_true_index = y_true_index.unsqueeze(0).repeat(num_examples, 1, 1)"
      ],
      "metadata": {
        "id": "UHC_bTf1GumV"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dot1, idx1 = gbmd(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# dot2, idx2 = batch_maromba_dot(bag_values_W, values_x, bag_indices_W, index_x, indexer)\n",
        "# print(dot1.shape, dot2.shape)\n",
        "# print(idx1.shape, idx2.shape)\n",
        "# print(torch.allclose(dot1.T, dot2), torch.allclose(idx1, idx2))"
      ],
      "metadata": {
        "id": "xEdq4WHJ_ZFO"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_vectors = Adam([bag_values_W, bag_indices_W], lr=1e-1)\n",
        "# opt_vectors = Adam([bag_values_W], lr=1e-1)\n",
        "# opt_indexer = Adam(indexer.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 40\n",
        "batch_size = 32\n",
        "epoch_len = num_examples // batch_size\n",
        "\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_losses = []\n",
        "  for _ in range(epoch_len):\n",
        "    batch_idx = np.random.choice(num_examples, batch_size)\n",
        "    batch_x = values_x[batch_idx].float().to(device)\n",
        "    batch_x_index = index_x[batch_idx].float().to(device)\n",
        "    batch_y_true = y_true[batch_idx].float().to(device)\n",
        "    batch_y_true_index = y_true_index[batch_idx].float().to(device)\n",
        "    # gumbel_bag_indices_W = nn.functional.gumbel_softmax(\n",
        "    #     bag_indices_W, hard=False, dim=-1\n",
        "    # ) ###\n",
        "    # y_pred_val, y_pred_index = batch_maromba_dot(\n",
        "    #     bag_values_W, batch_x, bag_indices_W, batch_x_index, indexer\n",
        "    # ) ###\n",
        "    y_pred_val, y_pred_index = gbmd(\n",
        "        batch_x, bag_values_W, batch_x_index, bag_indices_W, indexer\n",
        "    )\n",
        "    ###\n",
        "    loss = maromba_loss(\n",
        "        batch_y_true, y_pred_val, batch_y_true_index, y_pred_index\n",
        "    )\n",
        "    opt_vectors.zero_grad()\n",
        "    # opt_indexer.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_vectors.step()\n",
        "    # opt_indexer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  all_losses.append(np.mean(epoch_losses))\n",
        "  df_train = pd.DataFrame({\n",
        "      \"train loss\": all_losses,\n",
        "  })\n",
        "  display.clear_output(wait=True)\n",
        "  df_train.plot(figsize=(24, 2))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TmZOcAvg-Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "3a87d09b-d41f-4b86-a41b-6a6f067b1f99"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x144 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABVYAAACMCAYAAACXpPL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAh7UlEQVR4nO3deXyU5b338e9vFpIQEsISEQmYiBtbCBgVi9bWHvugXURPtVpcjvZBbe2xyzn00HPOq6097dNatVXOo62o1KWutdpjHz3tsVXrUrSyBFRAWZUoQkBDCCYhk7meP+aeycxkJgskc2f5vF+vvLi3655fMlduZr655rrNOScAAAAAAAAAQPcF/C4AAAAAAAAAAAYaglUAAAAAAAAA6CGCVQAAAAAAAADoIYJVAAAAAAAAAOghglUAAAAAAAAA6CGCVQAAAAAAAADooVBfnHTs2LGuvLy8L04NAAAAAAAAADmzcuXK3c650vTtfRKslpeXa8WKFX1xagAAAAAAAADIGTN7O9N2pgIAAAAAAAAAgB4iWO0Fzjm/SwAAAAAAAACQQwSrh2htbb3m3/qSdjU0+10KAAAAAAAAgBzpkzlWh5JQIKC3djbqql+v1IML5yg/HPS7JAAAAAAAAAwxra2tqq2tVXMzg/8OVn5+vsrKyhQOh7t1PMHqIZp6RLF+dsFMfeX+Vfr3372uG75QKTPzuywAAAAAAAAMIbW1tSoqKlJ5eTnZ1EFwzmnPnj2qra1VRUVFt9owFUAvOGvGeF37qWP06Mpa/eqlbX6XAwAAAAAAgCGmublZY8aMIVQ9SGamMWPG9GjEL8FqL/nGp47Rp6eO04+eWq8XN+72uxwAAAAAAAAMMYSqh6anPz+C1V4SCJh+9sUqTS4t1DUPrNLbe/b7XRIAAAAAAACQE/X19brtttsOqu3ZZ5+t+vr6bh///e9/XzfeeONBPVZvIljtRSPyQrrj0mqZSQvvXaHGlojfJQEAAAAAAAB9rrNgNRLpPCN76qmnVFJS0gdV9S2C1V525JhC3fql2dpct1/ffLhG0ajzuyQAAAAAAACgTy1evFibN29WVVWVFi1apOeee06nnXaaPv/5z2vq1KmSpPnz5+uEE07QtGnTtHTp0kTb8vJy7d69W9u2bdOUKVO0cOFCTZs2TZ/+9KfV1NTU6ePW1NRozpw5qqys1LnnnqsPP/xQkrRkyRJNnTpVlZWVuvDCCyVJf/nLX1RVVaWqqirNmjVL+/btO6TvmWC1D8w9eqz+7ewpenrdTt38p7f8LgcAAAAAAADoUz/5yU80efJk1dTU6IYbbpAkrVq1SrfccoveeiuWjy1btkwrV67UihUrtGTJEu3Zs6fDeTZu3KhrrrlGb7zxhkpKSvTb3/6208e99NJLdf3112vt2rWaMWOGrrvuukQ9q1ev1tq1a/XLX/5SknTjjTfq1ltvVU1NjV544QUVFBQc0vccOqTWyOryueVav6NBS57ZpOMOL9ZnKsf7XRIAAAAAAACGgOt+/4bWvdfQq+ecekSxvve5aT1qc9JJJ6mioiKxvmTJEj3++OOSpO3bt2vjxo0aM2ZMSpuKigpVVVVJkk444QRt27Yt6/n37t2r+vp6nX766ZKkyy67TOeff74kqbKyUgsWLND8+fM1f/58SdLcuXP1rW99SwsWLNB5552nsrKyHn0/6Rix2kfMTD88d7pmTSrRP/9mTa93ZgAAAAAAAKA/KywsTCw/99xz+tOf/qTly5drzZo1mjVrlpqbmzu0ycvLSywHg8Eu52fN5sknn9Q111yjVatW6cQTT1QkEtHixYt15513qqmpSXPnztWGDRsO6txxjFjtQ3mhoG6/+AR9/v++pIX3rtATX5urMSPyum4IAAAAAAAAHKSejiztDUVFRZ3OWbp3716NGjVKw4cP14YNG/Tyyy8f8mOOHDlSo0aN0gsvvKDTTjtN9913n04//XRFo1Ft375dn/zkJ3XqqafqoYceUmNjo/bs2aMZM2ZoxowZevXVV7VhwwYdf/zxB/34jFjtY4cV5+v2S05QXWOLvnr/KrW2Rf0uCQAAAAAAAOhVY8aM0dy5czV9+nQtWrSow/558+YpEoloypQpWrx4sebMmdMrj3vPPfdo0aJFqqysVE1Njb773e+qra1NF198sWbMmKFZs2bp2muvVUlJiW6++WZNnz5dlZWVCofDOuussw7psc253r9rfXV1tVuxYkWvn3cge3x1rb758BpdMudI/cf86X6XAwAAAAAAgEFk/fr1mjJlit9lDHiZfo5mttI5V51+LFMB5Mi5s8q0fsc+LX1+i6aML9aXTp7kd0kAAAAAAAAADlKXUwGY2UQze9bM1pnZG2b29VwUNhj9y7zj9fFjS/W9J17Xq9s+8LscAAAAAAAAAAepO3OsRiT9k3NuqqQ5kq4xs6l9W9bgFAyY/vPCWSobNVxX37dS79Y3+V0SAAAAAAAAgIPQZbDqnNvhnFvlLe+TtF7ShL4ubLAaOTysOy6t1oFIVFfeu0JNB9r8LgkAAAAAAACDQF/cS2ko6enPrzsjVhPMrFzSLEmv9OhRkOLow0bolouqtG5HgxY9uoZODwAAAAAAgEOSn5+vPXv2kDMdJOec9uzZo/z8/G636fbNq8xshKTfSvqGc64hw/4rJV0pSZMmcWOmrpxx/Dgt+l/H6ad/eFNTjyjWVz9xtN8lAQAAAAAAYIAqKytTbW2t6urq/C5lwMrPz1dZWVm3j+9WsGpmYcVC1fudc49lOsY5t1TSUkmqrq4mGu+Gr5w+Wet37NMNf3xTx40r0qemjPO7JAAAAAAAAAxA4XBYFRUVfpcxpHQ5FYCZmaS7JK13zv2s70saOsxMP/37Sk0dX6yvP1SjTbv2+V0SAAAAAAAAgG7ozhyrcyVdIukMM6vxvs7u47qGjIJhQS29tFr54YAW3rtSez9q9bskAAAAAAAAAF3oMlh1zr3onDPnXKVzrsr7eioXxQ0VE0oK9IuLT1Dthx/pHx9arbYoMykAAAAAAAAA/Vl3RqwiB04sH60fnDNdz79Vp+v/sMHvcgAAAAAAAAB0ols3r0JuXHTSJK17r0FLn9+i4w8v0nmzu38XMgAAAAAAAAC5w4jVfua7n5uqkytGa/Fjr2nN9nq/ywEAAAAAAACQAcFqPxMOBnTbgtkqHZGnK+9boV0NzX6XBAAAAAAAACANwWo/NGZEnu64tFoNTRFd9euVaom0+V0SAAAAAAAAgCQEq/3U1COKddMFM7X6nXr9++Ovyznnd0kAAAAAAAAAPASr/djZM8br2jOO1m9W1upXL23zuxwAAAAAAAAAHoLVfu4bf3eszpw6Tj96ar1e3Ljb73IAAAAAAAAAiGC13wsETD//YpUmlxbqmgdW6e09+/0uCQAAAAAAABjyCFYHgBF5Id1xabUkaeG9K9TYEvG5IgAAAAAAAGBoI1gdII4cU6hbvzRbm+v265sP1yga5WZWAAAAAAAAgF8IVgeQU48Zq387e4qeXrdTN/95o9/lAAAAAAAAAENWyO8C0DOXzy3Xuh0NWvLnjZpyeJHOmjHe75IAAAAAAACAIYcRqwOMmelH507XrEkl+tYja7TuvQa/SwIAAAAAAACGHILVASgvFNTtF5+g4oKQFt67QrsbW/wuCQAAAAAAABhSCFYHqMOK87X0kmrtbmzRRUtf1vt7m/0uCQAAAAAAABgyCFYHsJkTS3T35SfpvfomnX/7X/XOno/8LgkAAAAAAAAYEghWB7hTJo/RAwvnaF9zRF/45V/11s59fpcEAAAAAAAADHoEq4PAzIkleuSqUyRJF9y+XGu21/tbEAAAAAAAADDIEawOEseOK9KjV39MRfkhLbjzFb28ZY/fJQEAAAAAAACDFsHqIDJpzHD95qqPafzIfF227G96ZsNOv0sCAAAAAAAABiWC1UHm8JH5eviqU3TsuCJdee9K/X7Ne36XBAAAAAAAAAw6BKuD0OjCYXpg4cmafeQoXfvQaj34t3f8LgkAAAAAAAAYVAhWB6mi/LDuufwknX5sqb7z2Gta+vxmv0sCAAAAAAAABg2C1UGsYFhQSy+p1mcqx+v/PLVBN/3Pm3LO+V0WAAAAAAAAMOCF/C4AfWtYKKAlF85SUV5I//nMJu1rjui7n52qQMD8Lg0AAAAAAAAYsAhWh4BgwPTj82aoKD+kO17YqobmVv307ysVCjJgGQAAAAAAADgYBKtDhJnpX8+eouL8sG56+i3tb4loyUWzlBcK+l0aAAAAAAAAMOAwZHEIMTP946eO0fc+N1V/fGOn/vc9K/TRgYjfZQEAAAAAAAADDsHqEHT53Ard8IVKvbRpty6562/a29Tqd0kAAAAAAADAgEKwOkSdXz1Rty2YrbW19bpw6cva3djid0kAAAAAAADAgEGwOoTNmz5ed112orbubtQFv1yud+ub/C4JAAAAAAAAGBC6DFbNbJmZ7TKz13NREHLr48eW6tdfPll1jS06/xd/1Za6Rr9LAgAAAAAAAPq97oxYvVvSvD6uAz6qLh+tBxfOUUskqgtuX6517zX4XRIAAAAAAADQr3UZrDrnnpf0QQ5qgY+mTxipR64+ReFgQBcuXa6Vb3/od0kAAAAAAABAv8Ucq0iYXDpCv7n6FI0uHKZL7npFL27c7XdJAAAAAAAAQL/Ua8GqmV1pZivMbEVdXV1vnRY5VjZquB65+hRNGj1cV9z9qv74xvt+lwQAAAAAAAD0O70WrDrnljrnqp1z1aWlpb11WvjgsKJ8PXzlKZo2oVhfvX+VHltV63dJAAAAAAAAQL/CVADIaOTwsH795ZN1csVofeuRNbp3+Ta/SwIAAAAAAAD6jS6DVTN7UNJySceZWa2Zfbnvy0J/UJgX0rJ/OFFnTh2n7/7XG7r12U1yzvldFgAAAAAAAOC7UFcHOOcuykUh6J/yw0HdtmC2vv3oWt3wxzfV0NyqxfOOl5n5XRoAAAAAAADgmy6DVSAcDOim82dqRF5It/9li/Y1R/Qf50xXMEC4CgAAAAAAgKGJYBXdEgiYfnDONBXlh3Tbc5vV2BzRTRfMVDjINL0AAAAAAAAYeghW0W1mpm/PO15F+WFd/4cN2t8S0a0LZis/HPS7NAAAAAAAACCnGG6IHvvKJybrh/On65k3d+nvfvYX3fnCFu1rbvW7LAAAAAAAACBnCFZxUC6ec6TuvvwkHTGyQD98cr1O+fEzuu73b+jtPfv9Lg0AAAAAAADoc+ac6/WTVldXuxUrVvT6edE/vVa7V8te2qrfr3lPbc7pzCnjdMWpFTq5YrTMuMEVAAAAAAAABi4zW+mcq+6wnWAVvWVnQ7PuW/627n/lbX34UaumHVGsK+ZW6LMzxysvxDysAAAAAAAAGHgIVpEzza1t+t3qd7Xspa16a2ejxo7I0yVzjtSCOZM0dkSe3+UBAAAAAAAA3UawipxzzunFTbu17MWtevbNOg0LBTS/6ghdPrdCU8YX+10eAAAAAAAA0KVswWrIj2IwNJiZTjumVKcdU6pNuxp191+36tGVtXpkRa0+NnmMvnxqhT553GEKBJiHFQAAAAAAAAMLI1aRU/UfHdCDf9uue5dv0469zaoYW6h/+Fi5vnBCmQrzyPkBAAAAAADQvzAVAPqV1rao/vv193XXi1u1Znu9ivJDuuikSbr0lCNVNmq43+UBAAAAAAAAkghW0Y+teudDLXtxq/779fclSfOmHa4rTi3X7EmjZMY0AQAAAAAAAPAPc6yi35o9aZRmf2mU3q1v0r3Lt+nBV97Rk6/t0MyJJbpibrnOnjFe4WDA7zIBAAAAAACABEasot/Z3xLRY6tq9auXtmnL7v06vDhfl5xypL500iSNKhzmd3kAAAAAAAAYQpgKAANONOr03Fu7tOzFbXpx027lhwM6b3aZrphbrqMPK/K7PAAAAAAAAAwBBKsY0N58f5+WvbhVj9e8qwORqE4/tlTnzZ6gYw4rUsXYQhUMC/pdIgAAAAAAAAYhglUMCnsaW/TAK+/o3pffVt2+lsT2CSUFqhhbqKNKC3XU2EJVlI7QUWMLNaGkQIEAN8ACAAAAAADAwSFYxaByIBLVxl37tHX3fm2p268tdY3a4i03tkQSxw0LBVQxxgtcSwtVMXaEjiot1OSxIzRyeNjH7wAAAAAAAAADQbZgNeRHMcChGhYKaNoRIzXtiJEp251zqmts0Za6/V7o2qgtdfv15vv79PS6nYpE2/+QMLpwmI4amxa4lhZq4ujhygsxtQAAAAAAAACyI1jFoGJmOqwoX4cV5WvOUWNS9rW2RbX9g49iI1x3N2rr7v3aXLdfz2yo0+7G2sRxAZMmjh4em1LAC1xjUwyM0LjiPJkxtQAAAAAAAMBQR7CKISMcDOio0hE6qnSEpHEp+xqaW7U1HrjW7ddmb1qB5Vv2qLk1mjiucFhQFaWFOrp0hCrLSjRzYommHVGs/DAjXAEAAAAAAIYSglVAUnF+WDMnxoLSZNGo0/sNzd7UAo3aXLdfW3bv18tbPtDvat6TJIWDpinji1U1sURV3jkqxhRy0ywAAAAAAIBBjJtXAQdpZ0OzVr9Tr5rt9VqzvV5ra+u1/0CbJKk4P6SZE0s0ywtaqyaWaMyIPJ8rBgAAAAAAQE9lu3kVwSrQS9qiTpt2Napm+4eq2b5XNdvr9eb7DYrfL2vi6AJVTRylmWUjNWtSiaYdMZIpBAAAAAAAAPq5bMEqUwEAvSQYMB13eJGOO7xIXzwxtu2jAxG9VhsLWdfU1mvltg/0+zWxKQRCgdgUAjMnjlTVxFGqmliio8YyhQAAAAAAAMBAwIhVIMd2NTRrtTd9QM32eq2t3avGlogkqSg/pJllJYn5WqsmlWgsUwgAAAAAAAD4hqkAgH6qLeq0ua5RNV7QWvNOvd7cuU9t3hwCE0oKVDUpNl9r1cTYFAIFw5hCAAAAAAAAIBeYCgDop4IB07HjinTsuCJdUD1RktR0oE2vv7dXNe+0h61Prt2RaFMQDqpgWFAF4aDyw4Gk5dhXQfxrWNL6sIAKwkHlZd3fvj0vHFBeKCAzpiUAAAAAAADIhGAV6IcKhgV1YvlonVg+OrFt175mrdm+V+vea9D+AxE1HWhTU2vsq9lbbmyJqG5fi5pb29TcGk3sPxCJ9rgGMyWC1vxECBtQKBBQwKSAmcwkM0usx7cl/xvIcIyS9nU4VqZAIPN5TZaozeL/mrfVy4BNlro/aT3eONu++PmUtj9++mw5synzjoPJpbOF2cmfLogvOrmk5czbk9s6FzuufbnjdjmXckz8+4g/D0HvuQkGUp+fxHrAUp7b+D4zece070+se22DZonnPdbGNHxYUMUFYRXnh1Q4LMQcxAAAAACAfoNgFRggDivK15lT83Xm1HE9btsWdWr2QtamA22py5Foh21Nrd56Yjmq5tY2fXQgojYXC+qizikajYVzUSe1RaOKOsW2e8e4tPX4ctRL8pLX24+NL6e18aZGiAWILhEkpoeLStqWfKyklLAR2aWGzZZ4TvxmJhXlhVSUH06ErbHlkIrzY+vFBWEV5XvrGZbDwYDf3wYAAAAAYJDoVrBqZvMk3SIpKOlO59xP+rQqAL0qGDAV5oVUmMffUqT20DcevErKHNRmGQGacq5OHqMnxyc/XsZGprTRs5a0HN9uKaNkM23P2raL4bUuKQRvi8Z+Hm2JgD0erjs557zt8rZn2BdtD9Hbou3njUZj+513fJtzajrQpn3NrWpoisT+bY6oocn7t7lV79Y3af2OVjU0t6qxJdJlAFwQDsbC1pRgNjmA9bYljglrZEFs+8iCsPJCzG8MAAAAAIjpMmUxs6CkWyWdKalW0qtm9oRzbl1fFwcAfcEsOYDko+XdYWYKmhSUKdxPs8Vo1KnxQET74uFrU2tsuTl1uX1bRPUfHdA7H3ykfc2t2tvUqta2zpPZvFDAC1q9wDU/FrimbvNG1HphbHF+WCOHhzWCqQwAAAAAYFDpzvC1kyRtcs5tkSQze0jSOZIIVgEA/UYgYN6UAGFNKCnocXvnnFoi0UToGg9k93ohbUNzJLG8tyk2SrausUWb6/Yn1jsbMRswJaYuGJk8GtYLXuMhbXFB2JtP1pu/19pHGsfnIbakbenLAW/S4fj25DmK439QaJ8juX17t9oFUucoDpi8+jK3i4+0DmSa2zhbO26aBwC9Jv0TNIP5Gpv8iaTEupTySZvEJ2jSPyWT6Zj4J2u8T9q0pX1KJ/XTN7Hj2pI+gRONz1Wvjv/nWdr/uZb8/2Ty/6Hp+5LvD9Dpa4JOzp90zwKln7cndSZ/IsoyP4bUPqd/+/OUtJzhOcx0XMfnOvkcHc8fiTpFolFF2mLPT+py6npr1KnNW494+9vaou3LUefti2Zeb3NqjUYT5w54gxECAVPQu9dA/Ctg6ctSMBDwjkttEzBTKJjUxrsvQTCgxLZQ0jmT73OQ/Bot9T4Ysecz+R4Yyc99+r0vuntsvD/KdfwUYGJqtqRPBGaats15c7q5TOfI8KnC5HPEZe2bPezf6e0S6138Lra3i7expMdp/73uznGdfQoxvV1yffBHd4LVCZK2J63XSjq5b8oBAMAfZqZ872ZthxX1vH18xGx7GBtJBK4NKYFse0C7aVejGrzRss2tPb/J3FCU/pox/SVk+ovKjvvT23fvRWj6G7cO+7uYhqIn0xQnV5TywlqW8aBMxycfa1mPtYzb+5Oufm7Zpl3pXtuuHjs3z3nym6LYelrokdif9Kxm2JfeJnnal+R9nT/bWaax6eF0OLE23e/1Pf29VZb+3b22MSnzsyv9e3QdtiWHdcnrKedKDoXSFrK1T552KFNd6mJ/tvN1R1f9xZI6Wqbt6W/wE+0znDelzgzhZ/r0S8nff8ebdaZO4wTkgpkUDgQSgWYwaAoFArHlgCkcjIWbyWF9cvAeD2UTwXu0PcgHelt3At7OruudXdPj5zlr+uH68XmVff69DAS9NuGimV0p6UpJmjRpUm+dFgCAASF5xGzZqJ63b4m0JcLYjw5EEjd0S/4rfjT+V/vkG7hluJlbvF38DWnsRnPda6ekbentlFZT/OZ1Sjtv1KW9+c3QLlFD0siE+OPHdXir0cX+9DfYnY2SSW/vXPYAJq6r8LHr9l3Hl8k1ZxvVk3WkTnogo+yjf7KdL9ecXJc/l0N5Xrps28UBXT5jh/icu7QnrUNYlhImpbbp0J8zhE3Zw7jsP5tsFWc/Pvv32J3BM4f6e5t9b6afUdofGtLC5kx/hMj0x4300Du2reM323VYntq2Y3DeRbts9WQJ1VP6QRf9JbmvJPfTlEA0Q7/K1D+dc6l/yLHUEVnxN/zpb+Q7vtFv/75TvufORplJiZF88ZF+qSP8lBgJmPEYb6Re8ojA2PHKfExK2/afT/rou/jP+6BG8aX9fyqX4TGSzqG0x055DrM9Rtp5OtTY2WMow++aUmX9o2HawZ39jqXuSz1FKBgLPEOB2KjPYCCgsBeAxtfj+2LHBRL7EmFp0r6Q9/z3hfjrpuQgNjHyOdq+Hh89nVh2sZGzyW3abx6c/Hos6bVhyuuxjscq6bVmfES2lNw2+bVb6rFOSb/LKaNAU4O8TKOzk6+F2c6hlPWO58jWN3vavxPL3ejjHf8QlHrT5PSbKKf/H6+083gPk/EaEW/X2XFZ68hw/s6u651d05Nfa0yfMFKI6U6w+q6kiUnrZd62FM65pZKWSlJ1dbVL3w8AALLLCwVVWhRUaVGe36UAAAAgBxL3MWAefmDACnTjmFclHWNmFWY2TNKFkp7o27IAAAAAAAAAoP/qcsSqcy5iZl+T9EdJQUnLnHNv9HllAAAAAAAAANBPdWuOVefcU5Ke6uNaAAAAAAAAAGBAsJ7csbPbJzWrk/R2r5+4/xorabffRWBIoc8hl+hvyCX6G3KJ/oZcor8hl+hvyCX6G3LJr/52pHOuNH1jnwSrQ42ZrXDOVftdB4YO+hxyif6GXKK/IZfob8gl+htyif6GXKK/IZf6W3/rzs2rAAAAAAAAAABJCFYBAAAAAAAAoIcIVnvHUr8LwJBDn0Mu0d+QS/Q35BL9DblEf0Mu0d+QS/Q35FK/6m/MsQoAAAAAAAAAPcSIVQAAAAAAAADoIYLVQ2Rm88zsTTPbZGaL/a4Hg5uZbTOz18ysxsxW+F0PBhczW2Zmu8zs9aRto83saTPb6P07ys8aMXhk6W/fN7N3vWtcjZmd7WeNGDzMbKKZPWtm68zsDTP7uredaxx6XSf9jWscep2Z5ZvZ38xsjdffrvO2V5jZK9771IfNbJjftWLg66S/3W1mW5Oub1U+l4pBxMyCZrbazP6ft96vrm8Eq4fAzIKSbpV0lqSpki4ys6n+VoUh4JPOuSrnXLXfhWDQuVvSvLRtiyX92Tl3jKQ/e+tAb7hbHfubJP3cu8ZVOeeeynFNGLwikv7JOTdV0hxJ13iv2bjGoS9k628S1zj0vhZJZzjnZkqqkjTPzOZIul6x/na0pA8lfdm/EjGIZOtvkrQo6fpW41eBGJS+Lml90nq/ur4RrB6akyRtcs5tcc4dkPSQpHN8rgkADopz7nlJH6RtPkfSPd7yPZLm57ImDF5Z+hvQJ5xzO5xzq7zlfYq9OJ8grnHoA530N6DXuZhGbzXsfTlJZ0h61NvO9Q29opP+BvQJMyuT9BlJd3rrpn52fSNYPTQTJG1PWq8VL5rQt5yk/zGzlWZ2pd/FYEgY55zb4S2/L2mcn8VgSPiama31pgrgY9nodWZWLmmWpFfENQ59LK2/SVzj0Ae8j8nWSNol6WlJmyXVO+ci3iG8T0WvSe9vzrn49e1H3vXt52aW51+FGGRulvRtSVFvfYz62fWNYBUYWE51zs1WbPqJa8zs434XhKHDOefEX6TRt34habJiHy3bIekmX6vBoGNmIyT9VtI3nHMNyfu4xqG3ZehvXOPQJ5xzbc65Kkllin2q8nh/K8Jglt7fzGy6pO8o1u9OlDRa0r/4VyEGCzP7rKRdzrmVftfSGYLVQ/OupIlJ62XeNqBPOOfe9f7dJelxxV44AX1pp5mNlyTv310+14NBzDm303uxHpV0h7jGoReZWVixkOt+59xj3maucegTmfob1zj0NedcvaRnJZ0iqcTMQt4u3qei1yX1t3neFCjOOdci6Vfi+obeMVfS581sm2JTb54h6Rb1s+sbweqheVXSMd4dyYZJulDSEz7XhEHKzArNrCi+LOnTkl7vvBVwyJ6QdJm3fJmk//KxFgxy8YDLc664xqGXePNx3SVpvXPuZ0m7uMah12Xrb1zj0BfMrNTMSrzlAklnKjav77OSvuAdxvUNvSJLf9uQ9EdKU2y+S65vOGTOue8458qcc+WK5W3POOcWqJ9d3yz2qSccLDM7W7E5H4KSljnnfuRvRRiszOwoxUapSlJI0gP0N/QmM3tQ0ickjZW0U9L3JP1O0iOSJkl6W9IFzjluOIRDlqW/fUKxj8g6SdskXZU0/yVw0MzsVEkvSHpN7XN0/ati815yjUOv6qS/XSSucehlZlap2M1bgooNnHrEOfcD773DQ4p9LHu1pIu90YTAQeukvz0jqVSSSaqRdHXSTa6AQ2Zmn5D0z865z/a36xvBKgAAAAAAAAD0EFMBAAAAAAAAAEAPEawCAAAAAAAAQA8RrAIAAAAAAABADxGsAgAAAAAAAEAPEawCAAAAAAAAQA8RrAIAAAAAAABADxGsAgAAAAAAAEAPEawCAAAAAAAAQA/9f6UPU5m7q90/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(all_losses[-5:]))\n",
        "# y_pred_index.shape, batch_y_true_index.shape\n",
        "index_match = (y_pred_index[0] @ batch_y_true_index[0].T)\n",
        "print(index_match.sum(dim=-1))\n",
        "print(index_match.sum(dim=0))"
      ],
      "metadata": {
        "id": "82uoeJaS9BbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0d187e-bbb6-4be8-bc08-85bec50ef3ed"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.007991955795836064\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       grad_fn=<SumBackward1>)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maromba_loss(\n",
        "    batch_y_true, y_pred_val, batch_y_true_index, y_pred_index, debug=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ur9IbDTUib1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(W_true - bag_values_W).abs().mean()"
      ],
      "metadata": {
        "id": "f8CuZ6KMihSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6612b07-9ec1-4d45-c148-fc9389e4ff0c"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8172, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch_y_true_index[0])\n",
        "print(y_pred_index[0])"
      ],
      "metadata": {
        "id": "0fyYyFZhGeyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = torch.argmax(y_pred_index[0], dim=-1) - in_dim\n",
        "(batch_y_true[0][idxs] - y_pred_val[0]).abs().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC809FMxPquK",
        "outputId": "20f78358-356e-45a0-d3c6-49e06beb68fe"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0284, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_y_true[0][idxs], y_pred_val[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr6Usa3fmi6D",
        "outputId": "2bafa7f1-c965-4436-fdc1-f292a9dd2e2d"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.4765,  2.6790, -3.4456, -0.3745, -0.2552, -3.5033,  2.0407,  1.2470,\n",
              "          4.0887,  1.6677, -0.1149,  2.3481,  4.4079,  9.1317,  3.5390]),\n",
              " tensor([-0.5810,  2.6808, -3.4545, -0.3754, -0.2686, -3.5834,  2.0443,  1.2360,\n",
              "          4.1689,  1.6946, -0.1230,  2.3088,  4.4108,  9.1518,  3.5148],\n",
              "        grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "847IqTHZmxFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_14rgM_9mt8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}